data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		127
learning rate		0.000826566339368
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_0-lr0.00083-h_size127-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6782		0.5993		0.1564		0.3266		0.5466	0.6479		tp=0.32, tn=0.33, fp=0.1, fn=0.24		True
	2	0.5821		0.595		0.3926		0.4204		0.706	0.64		tp=0.28, tn=0.41, fp=0.056, fn=0.26		True
	3	0.5425		0.5865		0.4931		0.4185		0.7267	0.7692		tp=0.49, tn=0.22, fp=0.24, fn=0.056		False
	4	0.4765		0.5534		0.5538		0.485		0.7676	0.7111		tp=0.34, tn=0.39, fp=0.063, fn=0.21		True
	5	0.4531		0.565		0.6008		0.4948		0.7946	0.7448		tp=0.38, tn=0.36, fp=0.084, fn=0.17		True
	6	0.394		0.5685		0.657		0.5583		0.8256	0.7895		tp=0.42, tn=0.36, fp=0.077, fn=0.15		True
	7	0.3336		0.647		0.7507		0.4976		0.8729	0.7397		tp=0.38, tn=0.36, fp=0.063, fn=0.2		False
	8	0.3104		0.6112		0.7682		0.527		0.8801	0.8024		tp=0.47, tn=0.3, fp=0.13, fn=0.098		False
	9	0.2686		0.7291		0.8212		0.4817		0.9069	0.7101		tp=0.34, tn=0.38, fp=0.056, fn=0.22		False
	10	0.2187		0.7295		0.8593		0.5258		0.9268	0.7391		tp=0.36, tn=0.39, fp=0.056, fn=0.2		False
	11	0.1909		0.696		0.9032		0.5654		0.9501	0.7591		tp=0.36, tn=0.41, fp=0.049, fn=0.18		True
	12	0.1777		0.7513		0.9004		0.5281		0.9482	0.7733		tp=0.41, tn=0.36, fp=0.091, fn=0.15		False
	13	0.1548		0.7787		0.9296		0.5037		0.964	0.7376		tp=0.36, tn=0.38, fp=0.07, fn=0.19		False
	14	0.1243		0.7336		0.9531		0.5191		0.9758	0.7482		tp=0.36, tn=0.39, fp=0.084, fn=0.16		False
	15	0.139		0.8284		0.9266		0.5197		0.9623	0.8023		tp=0.48, tn=0.28, fp=0.17, fn=0.07		False
	16	0.139		0.9901		0.9005		0.4799		0.948	0.672		tp=0.29, tn=0.42, fp=0.042, fn=0.24		False
	17	0.09413		0.9083		0.9765		0.5436		0.988	0.7671		tp=0.39, tn=0.37, fp=0.063, fn=0.17		False
	18	0.08497		0.8656		0.9707		0.5088		0.9849	0.7712		tp=0.41, tn=0.34, fp=0.13, fn=0.11		False
	19	0.08078		1		0.9736		0.4785		0.9864	0.7886		tp=0.48, tn=0.26, fp=0.18, fn=0.076		False
	20	0.07411		0.9775		0.9765		0.4948		0.988	0.7632		tp=0.41, tn=0.34, fp=0.12, fn=0.13		False
	21	0.05205		0.8364		0.9883		0.5233		0.994	0.7733		tp=0.41, tn=0.36, fp=0.12, fn=0.12		False
	22	0.04606		1.02		0.9941		0.4657		0.997	0.7383		tp=0.38, tn=0.34, fp=0.091, fn=0.18		False
	23	0.04549		1.132		0.9941		0.5088		0.997	0.7338		tp=0.36, tn=0.38, fp=0.063, fn=0.2		False
	24	0.03985		1.108		0.9941		0.4705		0.997	0.7432		tp=0.38, tn=0.35, fp=0.11, fn=0.15		False
	25	0.03501		1.187		0.9971		0.4849		0.9985	0.7613		tp=0.41, tn=0.33, fp=0.11, fn=0.15		False
	26	0.03001		1.104		0.9971		0.5524		0.9985	0.7949		tp=0.43, tn=0.35, fp=0.11, fn=0.11		False
	27	0.02936		1.106		0.9971		0.5792		0.9985	0.8052		tp=0.43, tn=0.36, fp=0.12, fn=0.091		True
	28	0.02731		0.999		0.9971		0.4631		0.9985	0.731		tp=0.37, tn=0.36, fp=0.098, fn=0.17		False
	29	0.02537		1.186		0.9971		0.4834		0.9985	0.7517		tp=0.39, tn=0.35, fp=0.11, fn=0.15		False
	30	0.02386		1.232		0.9971		0.4793		0.9985	0.7643		tp=0.42, tn=0.32, fp=0.11, fn=0.15		False
	31	0.02306		1.263		0.9971		0.5117		0.9985	0.7742		tp=0.42, tn=0.34, fp=0.11, fn=0.13		False
	32	0.02137		1.266		0.9971		0.5311		0.9985	0.8		tp=0.46, tn=0.31, fp=0.14, fn=0.091		False
	33	0.02204		1.307		0.9971		0.488		0.9985	0.7483		tp=0.38, tn=0.36, fp=0.098, fn=0.16		False
	34	0.01844		1.325		0.9971		0.4834		0.9985	0.7517		tp=0.39, tn=0.35, fp=0.11, fn=0.15		False
	35	0.01909		1.251		0.9971		0.5502		0.9985	0.7975		tp=0.44, tn=0.34, fp=0.13, fn=0.091		False
	36	0.02196		1.244		0.9971		0.5341		0.9985	0.7898		tp=0.43, tn=0.34, fp=0.12, fn=0.11		False
	37	0.02062		1.193		0.9971		0.5519		0.9985	0.7895		tp=0.42, tn=0.36, fp=0.098, fn=0.13		False
	38	0.01518		1.34		0.9971		0.4827		0.9985	0.755		tp=0.4, tn=0.34, fp=0.11, fn=0.15		False
	39	0.01425		1.365		0.9971		0.4859		0.9985	0.7582		tp=0.41, tn=0.34, fp=0.098, fn=0.16		False
	40	0.01649		1.364		0.9971		0.5447		0.9985	0.8025		tp=0.45, tn=0.32, fp=0.12, fn=0.1		False
	41	0.01678		1.44		0.9971		0.5131		0.9985	0.7952		tp=0.46, tn=0.3, fp=0.13, fn=0.1		False
	42	0.01571		1.399		1		0.4599		1	0.7347		tp=0.38, tn=0.35, fp=0.1, fn=0.17		False
	43	0.01461		1.445		0.9971		0.5629		0.9985	0.8025		tp=0.44, tn=0.34, fp=0.098, fn=0.12		False
	44	0.01489		1.304		0.9971		0.5644		0.9985	0.7974		tp=0.43, tn=0.36, fp=0.1, fn=0.11		False
	45	0.01194		1.325		0.9971		0.4948		0.9985	0.7632		tp=0.41, tn=0.34, fp=0.12, fn=0.13		False
	46	0.01343		1.531		0.9971		0.4786		0.9985	0.7758		tp=0.44, tn=0.3, fp=0.15, fn=0.1		False
	47	0.01788		1.593		1		0.426		1	0.7		tp=0.34, tn=0.36, fp=0.098, fn=0.2		False
	48	0.01255		1.345		0.9971		0.505		0.9985	0.7799		tp=0.43, tn=0.32, fp=0.13, fn=0.11		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		54
learning rate		0.00425069435664
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_100-lr0.0043-h_size54-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6712		0.6214		0.1724		0.2889		0.597	0.6699		tp=0.36, tn=0.29, fp=0.18, fn=0.17		True
	2	0.6303		0.5998		0.2944		0.3416		0.6598	0.7037		tp=0.39, tn=0.28, fp=0.19, fn=0.14		True
	3	0.601		0.624		0.3664		0.3601		0.6932	0.6203		tp=0.27, tn=0.39, fp=0.082, fn=0.25		True
	4	0.5851		0.6009		0.3712		0.3813		0.6967	0.7143		tp=0.38, tn=0.31, fp=0.16, fn=0.15		True
	5	0.5717		0.6214		0.4203		0.344		0.7172	0.5785		tp=0.24, tn=0.41, fp=0.067, fn=0.28		False
	6	0.5581		0.5977		0.4199		0.3641		0.7221	0.7293		tp=0.43, tn=0.25, fp=0.22, fn=0.1		False
	7	0.5473		0.5876		0.4401		0.3949		0.7207	0.7366		tp=0.42, tn=0.27, fp=0.2, fn=0.1		True
	8	0.5076		0.6076		0.4976		0.3529		0.7546	0.6105		tp=0.27, tn=0.39, fp=0.077, fn=0.27		False
	9	0.5057		0.6121		0.5122		0.3553		0.7468	0.6243		tp=0.28, tn=0.39, fp=0.092, fn=0.24		False
	10	0.4716		0.6319		0.5544		0.27		0.767	0.7269		tp=0.51, tn=0.1, fp=0.37, fn=0.02		False
	11	0.4509		0.6286		0.5624		0.3978		0.7767	0.75		tp=0.45, tn=0.24, fp=0.22, fn=0.079		True
	12	0.4186		0.6627		0.629		0.3632		0.8067	0.6307		tp=0.28, tn=0.38, fp=0.087, fn=0.25		False
	13	0.4027		0.6266		0.6366		0.3894		0.8039	0.7119		tp=0.38, tn=0.32, fp=0.15, fn=0.15		False
	14	0.3922		0.6477		0.6137		0.3739		0.7961	0.7053		tp=0.37, tn=0.31, fp=0.16, fn=0.15		False
	15	0.3655		0.6519		0.6504		0.3528		0.8159	0.6578		tp=0.32, tn=0.36, fp=0.12, fn=0.21		False
	16	0.3471		0.6651		0.6597		0.3962		0.8252	0.705		tp=0.36, tn=0.34, fp=0.15, fn=0.16		False
	17	0.3333		0.7232		0.6935		0.3542		0.8436	0.6701		tp=0.33, tn=0.34, fp=0.13, fn=0.19		False
	18	0.3006		0.7107		0.7177		0.3161		0.8594	0.6616		tp=0.34, tn=0.32, fp=0.15, fn=0.2		False
	19	0.2939		0.7437		0.741		0.3248		0.8703	0.6633		tp=0.33, tn=0.33, fp=0.15, fn=0.19		False
	20	0.2879		0.7779		0.7655		0.2801		0.8854	0.6729		tp=0.37, tn=0.27, fp=0.21, fn=0.15		False
	21	0.2637		0.7698		0.7969		0.3443		0.9009	0.6768		tp=0.34, tn=0.33, fp=0.15, fn=0.18		False
	22	0.2714		0.7686		0.7697		0.3285		0.8877	0.7082		tp=0.41, tn=0.26, fp=0.22, fn=0.12		False
	23	0.2481		0.7528		0.8074		0.3411		0.9069	0.6938		tp=0.37, tn=0.3, fp=0.18, fn=0.15		False
	24	0.2341		0.8505		0.837		0.3543		0.921	0.6752		tp=0.34, tn=0.34, fp=0.13, fn=0.19		False
	25	0.2417		0.8347		0.8129		0.3609		0.9089	0.6819		tp=0.34, tn=0.34, fp=0.14, fn=0.18		False
	26	0.2108		0.9149		0.8567		0.3543		0.93	0.6752		tp=0.34, tn=0.34, fp=0.13, fn=0.19		False
	27	0.1996		0.838		0.8645		0.3924		0.934	0.6957		tp=0.35, tn=0.35, fp=0.13, fn=0.17		False
	28	0.2068		0.9623		0.8625		0.3348		0.933	0.6667		tp=0.33, tn=0.33, fp=0.14, fn=0.19		False
	29	0.1981		0.878		0.8714		0.3517		0.9371	0.6957		tp=0.37, tn=0.31, fp=0.17, fn=0.15		False
	30	0.1849		0.9211		0.8786		0.3805		0.9409	0.7345		tp=0.42, tn=0.27, fp=0.19, fn=0.11		False
	31	0.1827		1.034		0.881		0.3902		0.9421	0.6611		tp=0.31, tn=0.38, fp=0.097, fn=0.22		False
	32	0.1737		0.9692		0.8938		0.3498		0.9482	0.6864		tp=0.36, tn=0.32, fp=0.16, fn=0.17		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		19
learning rate		0.000159584194051
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_101-lr0.00016-h_size19-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6924		0.6934		0.0167		-0.07111		0.2882	0.4091		tp=0.19, tn=0.27, fp=0.19, fn=0.36		False
	2	0.6881		0.6937		0.1384		0.01159		0.5282	0.4783		tp=0.23, tn=0.27, fp=0.18, fn=0.32		True
	3	0.6841		0.6924		0.1623		0.02017		0.5483	0.5455		tp=0.29, tn=0.22, fp=0.21, fn=0.28		True
	4	0.6811		0.6902		0.1955		0.01789		0.6032	0.5395		tp=0.29, tn=0.22, fp=0.23, fn=0.26		False
	5	0.6776		0.6946		0.2127		0.07211		0.5851	0.5		tp=0.24, tn=0.29, fp=0.16, fn=0.31		True
	6	0.6748		0.6902		0.2311		0.05597		0.5677	0.5143		tp=0.25, tn=0.27, fp=0.2, fn=0.28		False
	7	0.6721		0.689		0.2363		0.149		0.582	0.5441		tp=0.26, tn=0.31, fp=0.15, fn=0.28		True
	8	0.6695		0.6908		0.228		0.1375		0.5667	0.5493		tp=0.27, tn=0.28, fp=0.15, fn=0.3		False
	9	0.6671		0.6907		0.2337		0.1061		0.5742	0.5113		tp=0.24, tn=0.31, fp=0.16, fn=0.29		False
	10	0.6649		0.6911		0.2364		0.1313		0.5806	0.5429		tp=0.27, tn=0.29, fp=0.15, fn=0.3		False
	11	0.6631		0.6888		0.2284		0.1061		0.5624	0.5113		tp=0.24, tn=0.31, fp=0.16, fn=0.29		False
	12	0.6606		0.6943		0.2371		0.07911		0.571	0.5037		tp=0.24, tn=0.29, fp=0.17, fn=0.3		False
	13	0.6591		0.6946		0.2362		0.02123		0.5847	0.5103		tp=0.26, tn=0.24, fp=0.19, fn=0.31		False
	14	0.6574		0.6879		0.2511		0.04573		0.5907	0.5036		tp=0.24, tn=0.27, fp=0.19, fn=0.29		False
	15	0.6557		0.6967		0.2456		0.07062		0.5808	0.4925		tp=0.23, tn=0.29, fp=0.16, fn=0.31		False
	16	0.6542		0.6857		0.2458		0.1443		0.578	0.5263		tp=0.24, tn=0.31, fp=0.14, fn=0.3		False
	17	0.6527		0.6876		0.2457		0.06207		0.5794	0.4925		tp=0.23, tn=0.29, fp=0.17, fn=0.3		False
	18	0.6518		0.691		0.2658		0.018		0.6019	0.4965		tp=0.24, tn=0.26, fp=0.2, fn=0.3		False
	19	0.6503		0.6875		0.2573		0.1292		0.59	0.5255		tp=0.25, tn=0.3, fp=0.14, fn=0.31		False
	20	0.6489		0.7001		0.2636		0.0866		0.5892	0.4962		tp=0.23, tn=0.3, fp=0.15, fn=0.31		False
	21	0.6481		0.6934		0.2748		0.1171		0.6048	0.5185		tp=0.24, tn=0.3, fp=0.15, fn=0.31		False
	22	0.6467		0.6974		0.2693		0.09729		0.5951	0.4962		tp=0.23, tn=0.31, fp=0.15, fn=0.32		False
	23	0.6454		0.6976		0.2718		0.0481		0.6026	0.4964		tp=0.24, tn=0.28, fp=0.18, fn=0.3		False
	24	0.6443		0.6852		0.2687		0.102		0.6041	0.4885		tp=0.22, tn=0.31, fp=0.13, fn=0.34		False
	25	0.6431		0.6965		0.2778		0.1166		0.6058	0.4961		tp=0.22, tn=0.32, fp=0.14, fn=0.31		False
	26	0.6421		0.6954		0.2718		0.05944		0.6038	0.4889		tp=0.23, tn=0.29, fp=0.16, fn=0.32		False
	27	0.6413		0.6919		0.2657		0.08204		0.6057	0.5315		tp=0.27, tn=0.27, fp=0.17, fn=0.3		False
	28	0.64		0.6928		0.2658		0.1155		0.6019	0.5113		tp=0.24, tn=0.31, fp=0.15, fn=0.31		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		24
learning rate		0.000286194289741
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_102-lr0.00029-h_size24-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6885		0.6835		0.07525		0.2846		0.522	0.2826		tp=0.091, tn=0.45, fp=0, fn=0.46		True
	2	0.655		0.6515		0.2769		0.2908		0.6394	0.5333		tp=0.22, tn=0.38, fp=0.063, fn=0.33		True
	3	0.6307		0.6206		0.327		0.3479		0.6051	0.7356		tp=0.45, tn=0.23, fp=0.22, fn=0.098		True
	4	0.6218		0.6034		0.3129		0.3942		0.6422	0.6715		tp=0.32, tn=0.36, fp=0.091, fn=0.22		True
	5	0.5949		0.6152		0.4594		0.3753		0.7365	0.6466		tp=0.3, tn=0.37, fp=0.084, fn=0.24		False
	6	0.5786		0.5897		0.4675		0.4822		0.7339	0.697		tp=0.32, tn=0.4, fp=0.056, fn=0.22		True
	7	0.5706		0.5819		0.478		0.3858		0.7343	0.6809		tp=0.34, tn=0.35, fp=0.1, fn=0.21		False
	8	0.5501		0.5887		0.5305		0.3816		0.7531	0.6763		tp=0.33, tn=0.36, fp=0.11, fn=0.2		False
	9	0.5345		0.5793		0.5462		0.3942		0.7717	0.6809		tp=0.33, tn=0.35, fp=0.097, fn=0.22		False
	10	0.523		0.5732		0.5601		0.4224		0.7761	0.7		tp=0.34, tn=0.36, fp=0.1, fn=0.19		False
	11	0.5101		0.5467		0.5779		0.4903		0.7757	0.7886		tp=0.48, tn=0.26, fp=0.2, fn=0.056		True
	12	0.5141		0.5514		0.5304		0.4586		0.7583	0.7841		tp=0.48, tn=0.25, fp=0.19, fn=0.077		False
	13	0.4888		0.5619		0.5951		0.4582		0.7928	0.7101		tp=0.34, tn=0.38, fp=0.084, fn=0.2		False
	14	0.4765		0.5915		0.6314		0.4388		0.8147	0.6718		tp=0.31, tn=0.39, fp=0.063, fn=0.24		False
	15	0.4616		0.6137		0.6255		0.4144		0.8118	0.6462		tp=0.29, tn=0.38, fp=0.056, fn=0.27		False
	16	0.4526		0.5459		0.6363		0.5133		0.8144	0.7651		tp=0.4, tn=0.36, fp=0.098, fn=0.15		True
	17	0.437		0.5538		0.683		0.4986		0.8364	0.7338		tp=0.36, tn=0.38, fp=0.077, fn=0.18		False
	18	0.4228		0.5801		0.7169		0.4666		0.858	0.6822		tp=0.31, tn=0.41, fp=0.056, fn=0.23		False
	19	0.4157		0.5452		0.6984		0.5103		0.8403	0.7651		tp=0.4, tn=0.36, fp=0.11, fn=0.13		False
	20	0.4002		0.5787		0.7309		0.499		0.8643	0.7413		tp=0.37, tn=0.37, fp=0.077, fn=0.18		False
	21	0.397		0.6046		0.7213		0.4486		0.8576	0.6815		tp=0.32, tn=0.38, fp=0.056, fn=0.24		False
	22	0.3816		0.5722		0.7359		0.515		0.864	0.7682		tp=0.41, tn=0.35, fp=0.091, fn=0.15		True
	23	0.3682		0.5304		0.7389		0.5475		0.8666	0.7724		tp=0.39, tn=0.38, fp=0.077, fn=0.15		True
	24	0.3586		0.5153		0.7682		0.5159		0.8812	0.7901		tp=0.45, tn=0.31, fp=0.12, fn=0.12		False
	25	0.3451		0.5452		0.7887		0.5513		0.8912	0.7692		tp=0.38, tn=0.38, fp=0.07, fn=0.16		True
	26	0.3398		0.5741		0.7829		0.5227		0.8889	0.7482		tp=0.36, tn=0.39, fp=0.077, fn=0.17		False
	27	0.3265		0.5544		0.8122		0.4921		0.9039	0.7722		tp=0.43, tn=0.32, fp=0.14, fn=0.11		False
	28	0.3249		0.537		0.7801		0.5318		0.8879	0.7671		tp=0.39, tn=0.37, fp=0.084, fn=0.15		False
	29	0.3143		0.5589		0.8153		0.5387		0.9038	0.7703		tp=0.4, tn=0.36, fp=0.07, fn=0.17		False
	30	0.3033		0.54		0.7888		0.5377		0.8919	0.7815		tp=0.41, tn=0.36, fp=0.1, fn=0.13		False
	31	0.3059		0.6104		0.8182		0.4989		0.9055	0.7376		tp=0.36, tn=0.38, fp=0.077, fn=0.18		False
	32	0.2935		0.6269		0.8239		0.4687		0.9091	0.7101		tp=0.34, tn=0.38, fp=0.07, fn=0.21		False
	33	0.2868		0.6106		0.8269		0.5204		0.9102	0.7429		tp=0.36, tn=0.38, fp=0.063, fn=0.19		False
	34	0.2665		0.5654		0.8885		0.5473		0.9426	0.7626		tp=0.37, tn=0.4, fp=0.077, fn=0.15		False
	35	0.2591		0.5749		0.8798		0.5314		0.9376	0.7703		tp=0.4, tn=0.36, fp=0.084, fn=0.15		False
	36	0.252		0.5272		0.8774		0.603		0.9354	0.8054		tp=0.42, tn=0.38, fp=0.069, fn=0.13		True
	37	0.2441		0.5093		0.8863		0.5487		0.9399	0.7949		tp=0.43, tn=0.34, fp=0.11, fn=0.11		False
	38	0.2401		0.6015		0.8947		0.4782		0.945	0.7643		tp=0.42, tn=0.32, fp=0.14, fn=0.12		False
	39	0.2335		0.5722		0.912		0.5498		0.9545	0.7922		tp=0.43, tn=0.35, fp=0.11, fn=0.11		False
	40	0.2273		0.5804		0.9149		0.4936		0.9561	0.7722		tp=0.43, tn=0.32, fp=0.15, fn=0.1		False
	41	0.2175		0.613		0.9003		0.5103		0.9483	0.7651		tp=0.4, tn=0.36, fp=0.11, fn=0.13		False
	42	0.2159		0.6516		0.9002		0.4783		0.9486	0.7194		tp=0.35, tn=0.38, fp=0.076, fn=0.19		False
	43	0.2073		0.6082		0.9066		0.5161		0.9509	0.7619		tp=0.39, tn=0.36, fp=0.091, fn=0.15		False
	44	0.1997		0.621		0.9208		0.5301		0.959	0.7763		tp=0.41, tn=0.35, fp=0.084, fn=0.15		False
	45	0.1945		0.6107		0.9356		0.5192		0.9666	0.7848		tp=0.43, tn=0.33, fp=0.12, fn=0.12		False
	46	0.1908		0.5872		0.9296		0.5442		0.9639	0.7755		tp=0.4, tn=0.37, fp=0.084, fn=0.15		False
	47	0.1846		0.6254		0.9384		0.539		0.9683	0.7571		tp=0.37, tn=0.39, fp=0.07, fn=0.17		False
	48	0.1869		0.6603		0.9325		0.523		0.9652	0.7518		tp=0.37, tn=0.38, fp=0.077, fn=0.17		False
	49	0.1746		0.5691		0.9356		0.5568		0.9666	0.7838		tp=0.41, tn=0.37, fp=0.084, fn=0.14		False
	50	0.1687		0.6295		0.953		0.5177		0.9759	0.7875		tp=0.44, tn=0.32, fp=0.12, fn=0.12		False
	51	0.1644		0.6494		0.9589		0.5156		0.979	0.7651		tp=0.4, tn=0.36, fp=0.091, fn=0.15		False
	52	0.1601		0.6546		0.956		0.5347		0.9774	0.7703		tp=0.4, tn=0.36, fp=0.077, fn=0.16		False
	53	0.1543		0.607		0.9589		0.5407		0.9789	0.7815		tp=0.41, tn=0.36, fp=0.091, fn=0.14		False
	54	0.1513		0.5922		0.9589		0.5849		0.9789	0.7973		tp=0.41, tn=0.38, fp=0.077, fn=0.13		False
	55	0.147		0.6738		0.956		0.5195		0.9774	0.7552		tp=0.38, tn=0.38, fp=0.084, fn=0.16		False
	56	0.1429		0.6401		0.9619		0.5108		0.9805	0.7682		tp=0.41, tn=0.35, fp=0.1, fn=0.14		False
	57	0.1431		0.6318		0.9677		0.4866		0.9834	0.7805		tp=0.45, tn=0.3, fp=0.14, fn=0.11		False


data			/scratch/asw462/data/levin
input size		300
hidden size		50
learning rate		0.000516103970588
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_103-lr0.00052-h_size50-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.593		0.6024		0		0		0.8412	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.5785		0.6072		0		0		0.8388	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.5719		0.5835		0		0		0.8402	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	4	0.563		0.5821		0.08634		0.05394		0.843	0.8264		tp=0.7, tn=0.007, fp=0.29, fn=0.007		True
	5	0.5566		0.5636		0.13		0.06316		0.8452	0.8455		tp=0.73, tn=0.007, fp=0.26, fn=0.007		True
	6	0.5489		0.5584		0.1381		0.1329		0.847	0.849		tp=0.73, tn=0.014, fp=0.25, fn=0.007		True
	7	0.5471		0.5677		0.1732		0.1266		0.8482	0.8408		tp=0.72, tn=0.014, fp=0.26, fn=0.0069		False
	8	0.5402		0.5888		0.1668		0.1999		0.8463	0.8255		tp=0.68, tn=0.035, fp=0.27, fn=0.014		True
	9	0.5385		0.5699		0.2369		0.1738		0.8525	0.8382		tp=0.71, tn=0.021, fp=0.27, fn=0.007		False
	10	0.5335		0.587		0.2353		0.1628		0.8513	0.822		tp=0.68, tn=0.028, fp=0.28, fn=0.014		False
	11	0.5293		0.5645		0.2633		0.2232		0.8533	0.8376		tp=0.69, tn=0.049, fp=0.24, fn=0.028		True
	12	0.5275		0.5689		0.2926		0.2685		0.8559	0.8362		tp=0.68, tn=0.056, fp=0.24, fn=0.021		True
	13	0.5173		0.5913		0.2507		0.1832		0.8522	0.8142		tp=0.64, tn=0.063, fp=0.24, fn=0.056		False
	14	0.5195		0.5973		0.2408		0.05942		0.8502	0.8085		tp=0.66, tn=0.021, fp=0.29, fn=0.028		False
	15	0.5112		0.6075		0.2739		0.03944		0.8541	0.8085		tp=0.66, tn=0.021, fp=0.28, fn=0.035		False
	16	0.5051		0.5947		0.3001		0.2168		0.8577	0.8194		tp=0.65, tn=0.063, fp=0.24, fn=0.042		False
	17	0.5009		0.5626		0.3307		0.1887		0.8615	0.8376		tp=0.69, tn=0.049, fp=0.22, fn=0.042		False
	18	0.4985		0.5829		0.3155		0.1242		0.8586	0.8205		tp=0.67, tn=0.035, fp=0.26, fn=0.035		False
	19	0.4982		0.5412		0.325		0.2362		0.8587	0.8523		tp=0.7, tn=0.056, fp=0.2, fn=0.042		False
	20	0.4996		0.5772		0.3164		0.164		0.8537	0.8174		tp=0.66, tn=0.049, fp=0.25, fn=0.042		False
	21	0.4929		0.5738		0.3195		0.2298		0.8575	0.8362		tp=0.68, tn=0.056, fp=0.23, fn=0.035		False
	22	0.4876		0.6402		0.3313		0.07679		0.8559	0.8069		tp=0.66, tn=0.028, fp=0.28, fn=0.035		False
	23	0.4802		0.5762		0.3165		0.1956		0.8565	0.8225		tp=0.66, tn=0.056, fp=0.24, fn=0.042		False
	24	0.4831		0.5502		0.3398		0.2165		0.8564	0.8297		tp=0.66, tn=0.063, fp=0.22, fn=0.049		False
	25	0.4769		0.5863		0.3375		0.2372		0.8587	0.8348		tp=0.67, tn=0.063, fp=0.22, fn=0.042		False
	26	0.4737		0.6484		0.3472		0.1		0.8594	0.7982		tp=0.64, tn=0.042, fp=0.27, fn=0.049		False
	27	0.4761		0.5725		0.3183		0.2542		0.8518	0.8333		tp=0.66, tn=0.076, fp=0.21, fn=0.056		False
	28	0.4654		0.576		0.3459		0.2793		0.8578	0.8356		tp=0.66, tn=0.084, fp=0.2, fn=0.056		True
	29	0.4658		0.588		0.3607		0.2165		0.8594	0.8297		tp=0.66, tn=0.063, fp=0.22, fn=0.049		False
	30	0.4603		0.6137		0.362		0.2109		0.861	0.8178		tp=0.64, tn=0.07, fp=0.23, fn=0.056		False
	31	0.4591		0.6001		0.3784		0.1742		0.8619	0.8261		tp=0.66, tn=0.056, fp=0.22, fn=0.056		False
	32	0.4545		0.6038		0.3852		0.2236		0.8651	0.8348		tp=0.67, tn=0.063, fp=0.22, fn=0.049		False
	33	0.4603		0.6487		0.3744		0.09319		0.8598	0.8052		tp=0.65, tn=0.042, fp=0.26, fn=0.056		False
	34	0.4608		0.6007		0.3716		0.261		0.8583	0.8235		tp=0.64, tn=0.091, fp=0.2, fn=0.07		False
	35	0.4513		0.633		0.3899		0.2422		0.8645	0.8161		tp=0.64, tn=0.077, fp=0.24, fn=0.049		False
	36	0.4434		0.6225		0.3906		0.1869		0.8666	0.7647		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	37	0.4487		0.611		0.4004		0.2354		0.8605	0.8261		tp=0.66, tn=0.056, fp=0.25, fn=0.028		False
	38	0.4418		0.633		0.4169		0.2301		0.8685	0.8161		tp=0.64, tn=0.077, fp=0.23, fn=0.056		False
	39	0.4454		0.6176		0.4175		0.2387		0.8657	0.8297		tp=0.66, tn=0.069, fp=0.22, fn=0.049		False
	40	0.4364		0.6528		0.4158		0.1674		0.8691	0.8106		tp=0.64, tn=0.056, fp=0.25, fn=0.049		False
	41	0.4368		0.602		0.4205		0.2122		0.8671	0.8194		tp=0.65, tn=0.069, fp=0.23, fn=0.056		False
	42	0.431		0.6057		0.4274		0.1904		0.8707	0.7788		tp=0.57, tn=0.11, fp=0.17, fn=0.15		False
	43	0.4391		0.6523		0.4502		0.1765		0.8746	0.8089		tp=0.64, tn=0.063, fp=0.24, fn=0.056		False
	44	0.429		0.5977		0.4384		0.1433		0.8696	0.8018		tp=0.62, tn=0.07, fp=0.22, fn=0.091		False
	45	0.4281		0.6306		0.4507		0.1173		0.8727	0.7946		tp=0.62, tn=0.062, fp=0.24, fn=0.083		False
	46	0.4184		0.6765		0.4783		0.1416		0.8794	0.8		tp=0.63, tn=0.056, fp=0.26, fn=0.056		False
	47	0.4218		0.6508		0.4594		0.1743		0.877	0.7751		tp=0.57, tn=0.1, fp=0.2, fn=0.13		False
	48	0.4181		0.6285		0.4913		0.1801		0.8816	0.821		tp=0.66, tn=0.056, fp=0.24, fn=0.049		False
	49	0.4151		0.6464		0.4636		0.1157		0.8762	0.7928		tp=0.62, tn=0.063, fp=0.24, fn=0.084		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		88
learning rate		0.00170008069555
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_104-lr0.0017-h_size88-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6906		0.6749		0.08724		0.1761		0.5727	0.6945		tp=0.47, tn=0.12, fp=0.35, fn=0.062		True
	2	0.6823		0.6796		0.1184		0.205		0.6198	0.5683		tp=0.27, tn=0.33, fp=0.14, fn=0.26		True
	3	0.6794		0.6768		0.1447		0.1289		0.6028	0.6731		tp=0.45, tn=0.12, fp=0.35, fn=0.082		False
	4	0.6813		0.6747		0.1267		0.205		0.6252	0.6351		tp=0.34, tn=0.26, fp=0.2, fn=0.19		True
	5	0.6813		0.6743		0.1331		0.1951		0.6197	0.6406		tp=0.36, tn=0.24, fp=0.23, fn=0.17		False
	6	0.681		0.679		0.135		0.175		0.6188	0.6244		tp=0.34, tn=0.25, fp=0.23, fn=0.18		False
	7	0.682		0.681		0.1076		0.1811		0.6082	0.6441		tp=0.37, tn=0.23, fp=0.24, fn=0.16		False
	8	0.6821		0.6793		0.1223		0.1704		0.6089	0.6413		tp=0.37, tn=0.23, fp=0.24, fn=0.17		False
	9	0.6813		0.6753		0.1302		0.1871		0.6256	0.6274		tp=0.34, tn=0.26, fp=0.22, fn=0.19		False
	10	0.683		0.6787		0.1163		0.1864		0.6133	0.6456		tp=0.37, tn=0.23, fp=0.24, fn=0.16		False
	11	0.6835		0.6761		0.1228		0.1683		0.6	0.6508		tp=0.38, tn=0.2, fp=0.27, fn=0.14		False
	12	0.6807		0.6732		0.1311		0.1631		0.6222	0.6582		tp=0.4, tn=0.19, fp=0.27, fn=0.14		False
	13	0.6802		0.6699		0.1328		0.1588		0.6221	0.6568		tp=0.4, tn=0.18, fp=0.29, fn=0.12		False
	14	0.681		0.6793		0.1169		0.1751		0.6254	0.646		tp=0.37, tn=0.22, fp=0.26, fn=0.15		False
	15	0.6807		0.6769		0.1326		0.1214		0.6121	0.6529		tp=0.4, tn=0.17, fp=0.3, fn=0.13		False
	16	0.6803		0.6778		0.1359		0.1496		0.6266	0.6719		tp=0.44, tn=0.13, fp=0.36, fn=0.074		False
	17	0.6819		0.6749		0.1275		0.2148		0.6271	0.6545		tp=0.37, tn=0.24, fp=0.23, fn=0.16		True
	18	0.6817		0.6757		0.1203		0.2002		0.6101	0.6338		tp=0.35, tn=0.26, fp=0.23, fn=0.17		False
	19	0.6802		0.6754		0.1317		0.1951		0.6212	0.6549		tp=0.38, tn=0.22, fp=0.25, fn=0.15		False
	20	0.6793		0.6883		0.1182		0.07654		0.6123	0.3704		tp=0.14, tn=0.38, fp=0.097, fn=0.38		False
	21	0.6823		0.6742		0.1124		0.1319		0.5962	0.6732		tp=0.44, tn=0.13, fp=0.34, fn=0.09		False
	22	0.6803		0.6823		0.128		0.1664		0.6205	0.6265		tp=0.35, tn=0.24, fp=0.22, fn=0.19		False
	23	0.6802		0.6751		0.1361		0.1507		0.6197	0.6496		tp=0.39, tn=0.19, fp=0.28, fn=0.14		False
	24	0.6797		0.6773		0.1337		0.1212		0.6225	0.6559		tp=0.42, tn=0.15, fp=0.33, fn=0.11		False
	25	0.6793		0.6743		0.1414		0.1401		0.617	0.6543		tp=0.41, tn=0.16, fp=0.32, fn=0.11		False
	26	0.6802		0.6801		0.1438		0.1919		0.6278	0.6217		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	27	0.6809		0.6796		0.1267		0.1248		0.6121	0.6744		tp=0.45, tn=0.12, fp=0.35, fn=0.079		False
	28	0.6787		0.6912		0.13		0.1143		0.6159	0.6716		tp=0.46, tn=0.087, fp=0.4, fn=0.051		False
	29	0.6813		0.6714		0.1268		0.2002		0.6147	0.6548		tp=0.38, tn=0.23, fp=0.25, fn=0.15		False
	30	0.6781		0.6791		0.1439		0.1312		0.6197	0.6706		tp=0.44, tn=0.13, fp=0.35, fn=0.082		False
	31	0.6817		0.6769		0.127		0.13		0.6153	0.6756		tp=0.45, tn=0.12, fp=0.36, fn=0.077		False
	32	0.6785		0.678		0.1316		0.1863		0.6259	0.6376		tp=0.36, tn=0.24, fp=0.24, fn=0.17		False
	33	0.6787		0.6784		0.1294		0.1949		0.6119	0.6438		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	34	0.6781		0.6772		0.1271		0.1519		0.609	0.6224		tp=0.35, tn=0.23, fp=0.26, fn=0.16		False
	35	0.6773		0.6754		0.1437		0.1817		0.6277	0.6489		tp=0.37, tn=0.22, fp=0.25, fn=0.15		False
	36	0.6769		0.6835		0.1399		0.1437		0.6246	0.5815		tp=0.3, tn=0.27, fp=0.2, fn=0.23		False
	37	0.6778		0.6849		0.1472		0.1608		0.6196	0.611		tp=0.33, tn=0.25, fp=0.23, fn=0.19		False
	38	0.678		0.6814		0.1398		0.1636		0.6024	0.6479		tp=0.38, tn=0.2, fp=0.29, fn=0.13		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		146
learning rate		0.000139651167152
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_105-lr0.00014-h_size146-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5864		0.5718		0.1608		0.3067		0.8186	0.8236		tp=0.63, tn=0.1, fp=0.21, fn=0.055		True
	2	0.565		0.5723		0.246		0.2836		0.8243	0.82		tp=0.63, tn=0.092, fp=0.23, fn=0.052		False
	3	0.5584		0.5623		0.2681		0.2416		0.827	0.8224		tp=0.65, tn=0.068, fp=0.24, fn=0.04		False
	4	0.5538		0.567		0.2825		0.3397		0.8289	0.8289		tp=0.63, tn=0.11, fp=0.2, fn=0.059		True
	5	0.548		0.5724		0.2989		0.2585		0.8317	0.8221		tp=0.65, tn=0.068, fp=0.25, fn=0.033		False
	6	0.5441		0.5701		0.3004		0.2886		0.8327	0.819		tp=0.63, tn=0.096, fp=0.22, fn=0.055		False
	7	0.5393		0.5762		0.3295		0.305		0.8366	0.815		tp=0.61, tn=0.11, fp=0.21, fn=0.067		False
	8	0.5329		0.5744		0.3488		0.2779		0.8401	0.8129		tp=0.62, tn=0.099, fp=0.22, fn=0.061		False
	9	0.5282		0.5783		0.3431		0.2876		0.8382	0.8227		tp=0.64, tn=0.081, fp=0.24, fn=0.037		False
	10	0.5237		0.5822		0.3474		0.2774		0.8388	0.8165		tp=0.63, tn=0.087, fp=0.24, fn=0.046		False
	11	0.5181		0.5983		0.3664		0.2415		0.8414	0.8199		tp=0.66, tn=0.055, fp=0.27, fn=0.022		False
	12	0.5169		0.5836		0.3731		0.2639		0.843	0.8192		tp=0.64, tn=0.071, fp=0.25, fn=0.033		False
	13	0.5127		0.5841		0.382		0.2689		0.8449	0.8016		tp=0.59, tn=0.12, fp=0.2, fn=0.095		False
	14	0.506		0.5965		0.3929		0.241		0.8456	0.8166		tp=0.64, tn=0.068, fp=0.25, fn=0.037		False
	15	0.5046		0.5886		0.3971		0.2655		0.8473	0.8028		tp=0.6, tn=0.11, fp=0.23, fn=0.07		False
	16	0.5043		0.5931		0.4057		0.268		0.8484	0.7914		tp=0.57, tn=0.13, fp=0.2, fn=0.1		False
	17	0.4983		0.5938		0.4244		0.2764		0.8518	0.8016		tp=0.59, tn=0.12, fp=0.21, fn=0.086		False
	18	0.496		0.5921		0.4063		0.2647		0.8478	0.8206		tp=0.64, tn=0.084, fp=0.23, fn=0.052		False
	19	0.4931		0.5846		0.4083		0.2725		0.8477	0.8145		tp=0.62, tn=0.1, fp=0.21, fn=0.07		False
	20	0.4893		0.6001		0.4406		0.2453		0.8546	0.8145		tp=0.63, tn=0.081, fp=0.23, fn=0.053		False
	21	0.4886		0.6042		0.4196		0.2592		0.8502	0.7931		tp=0.58, tn=0.12, fp=0.2, fn=0.1		False
	22	0.4885		0.5992		0.4237		0.2694		0.8507	0.8056		tp=0.6, tn=0.11, fp=0.2, fn=0.086		False
	23	0.4848		0.6068		0.4265		0.2692		0.8505	0.8012		tp=0.59, tn=0.12, fp=0.21, fn=0.086		False
	24	0.4865		0.6131		0.4265		0.2702		0.8501	0.8036		tp=0.6, tn=0.11, fp=0.21, fn=0.079		False
	25	0.4828		0.6008		0.4311		0.2545		0.8511	0.8101		tp=0.62, tn=0.096, fp=0.22, fn=0.07		False


data			/scratch/asw462/data/levin
input size		300
hidden size		77
learning rate		0.000625619313209
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_106-lr0.00063-h_size77-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5891		0.5949		0		0		0.8416	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.5683		0.5667		0		0		0.8412	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5509		0.5781		0.0429		0		0.8406	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	4	0.5281		0.5225		0.1386		0.137		0.8435	0.8455		tp=0.73, tn=0.007, fp=0.27, fn=0		True
	5	0.5017		0.5365		0.2634		0.3727		0.8548	0.8509		tp=0.68, tn=0.084, fp=0.22, fn=0.021		True
	6	0.4803		0.5082		0.3493		0.3689		0.8626	0.8472		tp=0.68, tn=0.077, fp=0.23, fn=0.014		False
	7	0.4606		0.5147		0.3933		0.3258		0.8667	0.8448		tp=0.69, tn=0.063, fp=0.24, fn=0.014		False
	8	0.4354		0.4906		0.43		0.4601		0.8741	0.8636		tp=0.66, tn=0.13, fp=0.17, fn=0.035		True
	9	0.4187		0.518		0.4721		0.4173		0.8777	0.8559		tp=0.66, tn=0.11, fp=0.19, fn=0.035		False
	10	0.4066		0.4965		0.5044		0.4601		0.8837	0.8636		tp=0.66, tn=0.13, fp=0.17, fn=0.035		False
	11	0.3893		0.4995		0.5232		0.4393		0.8862	0.87		tp=0.68, tn=0.12, fp=0.15, fn=0.049		False
	12	0.3783		0.4928		0.5727		0.3658		0.8972	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.07		False
	13	0.3724		0.5017		0.585		0.4551		0.8985	0.8545		tp=0.64, tn=0.15, fp=0.16, fn=0.056		False
	14	0.362		0.4934		0.6008		0.4917		0.9002	0.8676		tp=0.66, tn=0.13, fp=0.17, fn=0.028		True
	15	0.3519		0.4993		0.6		0.4254		0.9009	0.8406		tp=0.61, tn=0.16, fp=0.13, fn=0.098		False
	16	0.345		0.5014		0.6211		0.4752		0.9056	0.8585		tp=0.64, tn=0.15, fp=0.15, fn=0.056		False
	17	0.3332		0.5147		0.6363		0.3441		0.9089	0.8496		tp=0.67, tn=0.091, fp=0.2, fn=0.042		False
	18	0.3224		0.5566		0.6361		0.3357		0.909	0.8341		tp=0.65, tn=0.097, fp=0.22, fn=0.042		False
	19	0.3187		0.5144		0.6846		0.4209		0.9202	0.8532		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False
	20	0.318		0.5492		0.6609		0.3221		0.913	0.8444		tp=0.66, tn=0.097, fp=0.18, fn=0.062		False
	21	0.3167		0.5409		0.656		0.3608		0.9123	0.8468		tp=0.65, tn=0.11, fp=0.17, fn=0.062		False
	22	0.303		0.5877		0.6763		0.4218		0.9183	0.8421		tp=0.62, tn=0.15, fp=0.15, fn=0.084		False
	23	0.3052		0.5626		0.6731		0.4228		0.9166	0.8451		tp=0.62, tn=0.15, fp=0.16, fn=0.069		False
	24	0.2972		0.5655		0.6976		0.3925		0.9216	0.8372		tp=0.63, tn=0.13, fp=0.2, fn=0.049		False
	25	0.3105		0.5735		0.6613		0.3814		0.9152	0.8159		tp=0.57, tn=0.17, fp=0.12, fn=0.14		False
	26	0.294		0.5882		0.6919		0.3486		0.9207	0.8173		tp=0.59, tn=0.14, fp=0.18, fn=0.084		False
	27	0.2941		0.5384		0.695		0.3875		0.9211	0.852		tp=0.66, tn=0.11, fp=0.18, fn=0.049		False
	28	0.2814		0.5927		0.7094		0.3537		0.9252	0.8213		tp=0.59, tn=0.15, fp=0.14, fn=0.12		False
	29	0.2877		0.5751		0.7153		0.3525		0.9264	0.8455		tp=0.65, tn=0.11, fp=0.17, fn=0.07		False
	30	0.2719		0.6346		0.7237		0.3584		0.9286	0.8286		tp=0.61, tn=0.14, fp=0.15, fn=0.1		False
	31	0.2722		0.5904		0.7271		0.3382		0.9289	0.8468		tp=0.66, tn=0.1, fp=0.17, fn=0.07		False
	32	0.2715		0.6436		0.7374		0.3713		0.9318	0.81		tp=0.57, tn=0.17, fp=0.15, fn=0.11		False
	33	0.2671		0.6434		0.7495		0.3302		0.9345	0.8208		tp=0.6, tn=0.13, fp=0.17, fn=0.097		False
	34	0.2669		0.6559		0.7215		0.3842		0.9275	0.8411		tp=0.63, tn=0.13, fp=0.16, fn=0.077		False
	35	0.2621		0.6599		0.7162		0.3621		0.9275	0.8372		tp=0.63, tn=0.13, fp=0.17, fn=0.077		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		151
learning rate		0.000377413667982
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_107-lr0.00038-h_size151-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6113		0.6142		0.04958		0.09502		0.8181	0.8004		tp=0.65, tn=0.03, fp=0.29, fn=0.03		True
	2	0.5992		0.6097		0.08597		0.1457		0.8188	0.8008		tp=0.63, tn=0.056, fp=0.26, fn=0.055		True
	3	0.5934		0.6058		0.1213		0.1362		0.8183	0.807		tp=0.65, tn=0.034, fp=0.29, fn=0.025		False
	4	0.5925		0.6138		0.1157		0.133		0.8159	0.8125		tp=0.67, tn=0.016, fp=0.3, fn=0.0059		False
	5	0.5864		0.6049		0.1542		0.1311		0.8201	0.8119		tp=0.67, tn=0.027, fp=0.29, fn=0.018		False
	6	0.5836		0.6022		0.1573		0.1225		0.8185	0.8137		tp=0.67, tn=0.024, fp=0.29, fn=0.016		False
	7	0.5803		0.5962		0.1588		0.1704		0.818	0.8093		tp=0.64, tn=0.052, fp=0.26, fn=0.04		True
	8	0.5771		0.5947		0.1508		0.1804		0.8156	0.8127		tp=0.65, tn=0.056, fp=0.25, fn=0.044		True
	9	0.5756		0.5986		0.1806		0.1678		0.8175	0.8081		tp=0.65, tn=0.044, fp=0.28, fn=0.03		False
	10	0.5748		0.6067		0.1746		0.116		0.8163	0.8076		tp=0.66, tn=0.027, fp=0.29, fn=0.021		False
	11	0.5719		0.5945		0.1831		0.1794		0.8178	0.8042		tp=0.63, tn=0.068, fp=0.24, fn=0.061		False
	12	0.5714		0.6014		0.1899		0.1468		0.8177	0.8077		tp=0.65, tn=0.041, fp=0.28, fn=0.033		False
	13	0.5711		0.5952		0.2037		0.1583		0.8199	0.8107		tp=0.65, tn=0.041, fp=0.28, fn=0.03		False
	14	0.5673		0.5992		0.209		0.1249		0.8193	0.8077		tp=0.66, tn=0.033, fp=0.29, fn=0.027		False
	15	0.5671		0.5971		0.2157		0.156		0.8197	0.8139		tp=0.66, tn=0.037, fp=0.28, fn=0.025		False
	16	0.5664		0.6047		0.228		0.1876		0.8219	0.7878		tp=0.59, tn=0.09, fp=0.23, fn=0.086		True
	17	0.5632		0.6033		0.2227		0.1703		0.822	0.8074		tp=0.64, tn=0.047, fp=0.28, fn=0.033		False
	18	0.5651		0.6134		0.2202		0.1071		0.8191	0.8037		tp=0.65, tn=0.03, fp=0.29, fn=0.027		False
	19	0.5634		0.603		0.2277		0.1853		0.8205	0.8082		tp=0.64, tn=0.053, fp=0.27, fn=0.036		False
	20	0.5603		0.6119		0.229		0.1662		0.8226	0.773		tp=0.57, tn=0.099, fp=0.22, fn=0.11		False
	21	0.5609		0.6038		0.2355		0.1458		0.821	0.8041		tp=0.64, tn=0.05, fp=0.27, fn=0.046		False
	22	0.5624		0.5995		0.2371		0.1798		0.8222	0.7965		tp=0.61, tn=0.08, fp=0.23, fn=0.079		False
	23	0.5617		0.6105		0.2218		0.1567		0.8196	0.797		tp=0.62, tn=0.061, fp=0.26, fn=0.055		False
	24	0.5614		0.6037		0.231		0.152		0.8198	0.7856		tp=0.6, tn=0.075, fp=0.25, fn=0.078		False
	25	0.5601		0.604		0.2354		0.1706		0.821	0.7903		tp=0.6, tn=0.077, fp=0.25, fn=0.073		False
	26	0.5594		0.6079		0.2368		0.1478		0.8214	0.8022		tp=0.63, tn=0.055, fp=0.26, fn=0.052		False
	27	0.56		0.6045		0.2375		0.1626		0.8207	0.8078		tp=0.65, tn=0.047, fp=0.27, fn=0.035		False
	28	0.5583		0.6139		0.254		0.1462		0.8251	0.7996		tp=0.63, tn=0.052, fp=0.27, fn=0.046		False
	29	0.5573		0.6115		0.2379		0.1684		0.8222	0.7725		tp=0.57, tn=0.1, fp=0.22, fn=0.12		False
	30	0.5574		0.6038		0.2527		0.1772		0.8225	0.7918		tp=0.6, tn=0.08, fp=0.24, fn=0.076		False
	31	0.5574		0.6098		0.2638		0.1487		0.8257	0.8019		tp=0.63, tn=0.052, fp=0.27, fn=0.046		False
	32	0.5539		0.6208		0.2559		0.1597		0.8245	0.8067		tp=0.64, tn=0.046, fp=0.28, fn=0.034		False
	33	0.5575		0.6083		0.255		0.1475		0.8237	0.7977		tp=0.63, tn=0.058, fp=0.26, fn=0.055		False
	34	0.5551		0.6063		0.2407		0.1112		0.8211	0.7831		tp=0.6, tn=0.061, fp=0.26, fn=0.073		False
	35	0.5564		0.6039		0.2453		0.1487		0.8219	0.7883		tp=0.6, tn=0.076, fp=0.24, fn=0.084		False
	36	0.5588		0.6122		0.2527		0.1544		0.8211	0.7989		tp=0.63, tn=0.058, fp=0.26, fn=0.052		False
	37	0.5545		0.6084		0.2478		0.1428		0.8224	0.7939		tp=0.62, tn=0.059, fp=0.26, fn=0.058		False


data			/scratch/asw462/data/levin
input size		300
hidden size		12
learning rate		0.000156638330728
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_108-lr0.00016-h_size12-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5904		0.6393		0		0		0.8427	0.7932		tp=0.66, tn=0, fp=0.34, fn=0		False
	2	0.5735		0.5801		0		0		0.8418	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5655		0.5559		0		0		0.8413	0.8387		tp=0.72, tn=0, fp=0.28, fn=0		False
	4	0.553		0.5837		0.1054		0		0.8427	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	5	0.5439		0.5463		0.1753		0.1295		0.846	0.8443		tp=0.72, tn=0.014, fp=0.26, fn=0.007		True
	6	0.5325		0.5535		0.2224		0.1324		0.8513	0.8361		tp=0.71, tn=0.007, fp=0.28, fn=0		True
	7	0.5249		0.5665		0.2509		0.1732		0.8526	0.8167		tp=0.68, tn=0.014, fp=0.31, fn=0		True
	8	0.5169		0.5577		0.2649		0.1199		0.8546	0.8299		tp=0.7, tn=0.014, fp=0.28, fn=0.007		False
	9	0.5105		0.5639		0.3021		0.203		0.8592	0.827		tp=0.69, tn=0.028, fp=0.28, fn=0.007		True
	10	0.5032		0.5681		0.3466		0.2711		0.8614	0.8161		tp=0.64, tn=0.077, fp=0.25, fn=0.035		True
	11	0.4966		0.545		0.3386		0.3484		0.8621	0.8341		tp=0.65, tn=0.091, fp=0.23, fn=0.028		True
	12	0.4881		0.5238		0.3879		0.3556		0.8699	0.8509		tp=0.68, tn=0.084, fp=0.21, fn=0.028		True
	13	0.4812		0.5266		0.3844		0.2722		0.8689	0.837		tp=0.66, tn=0.077, fp=0.21, fn=0.049		False
	14	0.4787		0.524		0.4066		0.2981		0.8705	0.8398		tp=0.67, tn=0.069, fp=0.23, fn=0.028		False
	15	0.4654		0.5207		0.4324		0.2532		0.8768	0.8128		tp=0.62, tn=0.097, fp=0.21, fn=0.076		False
	16	0.462		0.5518		0.4488		0.2043		0.8772	0.8054		tp=0.62, tn=0.077, fp=0.24, fn=0.063		False
	17	0.4576		0.5376		0.4797		0.2212		0.8824	0.8108		tp=0.62, tn=0.083, fp=0.22, fn=0.069		False
	18	0.4546		0.5391		0.4889		0.1853		0.8823	0.8054		tp=0.62, tn=0.077, fp=0.22, fn=0.077		False
	19	0.4444		0.5371		0.508		0.1946		0.8869	0.8125		tp=0.63, tn=0.076, fp=0.22, fn=0.076		False
	20	0.4385		0.5072		0.514		0.2712		0.8884	0.8304		tp=0.65, tn=0.084, fp=0.21, fn=0.056		False
	21	0.4344		0.5223		0.5169		0.2375		0.8885	0.8282		tp=0.66, tn=0.07, fp=0.22, fn=0.049		False
	22	0.4288		0.5453		0.509		0.3015		0.8861	0.8148		tp=0.62, tn=0.1, fp=0.22, fn=0.056		False
	23	0.4219		0.5317		0.5239		0.2632		0.8899	0.8251		tp=0.64, tn=0.084, fp=0.22, fn=0.056		False
	24	0.4151		0.5518		0.525		0.2329		0.8904	0.8037		tp=0.62, tn=0.084, fp=0.24, fn=0.056		False
	25	0.4104		0.5451		0.5507		0.2276		0.8954	0.8145		tp=0.63, tn=0.084, fp=0.22, fn=0.07		False
	26	0.4121		0.5192		0.5466		0.3393		0.892	0.8208		tp=0.61, tn=0.13, fp=0.2, fn=0.07		False
	27	0.399		0.5097		0.554		0.3028		0.8963	0.8326		tp=0.64, tn=0.098, fp=0.2, fn=0.063		False
	28	0.3908		0.5406		0.5676		0.2175		0.8981	0.8214		tp=0.64, tn=0.077, fp=0.21, fn=0.07		False
	29	0.3897		0.4983		0.5812		0.3049		0.8999	0.8393		tp=0.66, tn=0.091, fp=0.2, fn=0.056		False
	30	0.3853		0.5126		0.594		0.2612		0.9027	0.8304		tp=0.65, tn=0.084, fp=0.2, fn=0.063		False
	31	0.3762		0.5051		0.6083		0.3496		0.9064	0.8387		tp=0.64, tn=0.12, fp=0.17, fn=0.077		False
	32	0.3723		0.4914		0.6149		0.3249		0.9069	0.8311		tp=0.63, tn=0.11, fp=0.19, fn=0.069		False
	33	0.3665		0.4935		0.6228		0.27		0.9093	0.8407		tp=0.66, tn=0.084, fp=0.18, fn=0.07		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		106
learning rate		6.39603607298e&05
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_109-lr6.4e&05-h_size106-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6907		0.6814		0.05897		0.2494		0.4953	0.6667		tp=0.37, tn=0.26, fp=0.18, fn=0.19		True
	2	0.6738		0.6794		0.2944		0.2523		0.5828	0.6043		tp=0.29, tn=0.32, fp=0.13, fn=0.26		True
	3	0.6608		0.6734		0.3659		0.2238		0.693	0.5899		tp=0.29, tn=0.31, fp=0.13, fn=0.27		False
	4	0.6475		0.6632		0.416		0.2976		0.6445	0.6753		tp=0.36, tn=0.29, fp=0.19, fn=0.16		True
	5	0.6352		0.6661		0.4481		0.241		0.7143	0.6056		tp=0.3, tn=0.31, fp=0.13, fn=0.27		False
	6	0.6228		0.659		0.4775		0.272		0.7262	0.6533		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	7	0.6117		0.6607		0.4551		0.2029		0.6835	0.5797		tp=0.28, tn=0.31, fp=0.15, fn=0.26		False
	8	0.6033		0.6504		0.5098		0.2876		0.7572	0.6623		tp=0.35, tn=0.29, fp=0.15, fn=0.2		False
	9	0.5939		0.6543		0.4321		0.2306		0.6191	0.6164		tp=0.31, tn=0.3, fp=0.15, fn=0.24		False
	10	0.5799		0.6381		0.5375		0.3062		0.7676	0.6622		tp=0.34, tn=0.31, fp=0.14, fn=0.21		True
	11	0.567		0.6435		0.5785		0.2469		0.7736	0.64		tp=0.34, tn=0.29, fp=0.16, fn=0.22		False
	12	0.5569		0.637		0.5806		0.2535		0.7783	0.625		tp=0.31, tn=0.31, fp=0.15, fn=0.23		False
	13	0.5465		0.6473		0.5929		0.2508		0.7825	0.6197		tp=0.31, tn=0.31, fp=0.15, fn=0.22		False
	14	0.5359		0.6433		0.5844		0.2357		0.7682	0.6154		tp=0.31, tn=0.31, fp=0.16, fn=0.22		False
	15	0.5271		0.6505		0.6067		0.2439		0.7957	0.6259		tp=0.32, tn=0.29, fp=0.14, fn=0.24		False
	16	0.5159		0.6411		0.6234		0.241		0.7956	0.6154		tp=0.31, tn=0.31, fp=0.15, fn=0.24		False
	17	0.5064		0.6372		0.6144		0.2403		0.7911	0.6494		tp=0.35, tn=0.27, fp=0.19, fn=0.19		False
	18	0.4958		0.6368		0.6508		0.2196		0.8178	0.6216		tp=0.32, tn=0.29, fp=0.17, fn=0.22		False
	19	0.4867		0.6305		0.6714		0.242		0.8198	0.6447		tp=0.34, tn=0.28, fp=0.18, fn=0.2		False
	20	0.4767		0.6496		0.6685		0.2006		0.827	0.5931		tp=0.3, tn=0.29, fp=0.13, fn=0.28		False
	21	0.4664		0.6386		0.6814		0.216		0.8294	0.6364		tp=0.34, tn=0.27, fp=0.17, fn=0.22		False
	22	0.4581		0.6216		0.6778		0.2707		0.8224	0.6623		tp=0.36, tn=0.28, fp=0.16, fn=0.2		False
	23	0.4533		0.6525		0.7213		0.1958		0.8576	0.5816		tp=0.29, tn=0.3, fp=0.14, fn=0.27		False
	24	0.4404		0.6264		0.7037		0.2508		0.8453	0.625		tp=0.31, tn=0.31, fp=0.15, fn=0.22		False
	25	0.4295		0.6378		0.7303		0.2032		0.8585	0.6225		tp=0.33, tn=0.27, fp=0.17, fn=0.22		False
	26	0.4217		0.6314		0.7453		0.257		0.8655	0.649		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	27	0.4126		0.6486		0.7476		0.2401		0.8701	0.5942		tp=0.29, tn=0.32, fp=0.13, fn=0.27		False
	28	0.4057		0.6434		0.7714		0.183		0.8804	0.5986		tp=0.31, tn=0.28, fp=0.18, fn=0.23		False
	29	0.3953		0.6405		0.7744		0.2128		0.8817	0.6014		tp=0.3, tn=0.3, fp=0.15, fn=0.24		False
	30	0.3873		0.6066		0.7806		0.3104		0.8841	0.6839		tp=0.37, tn=0.29, fp=0.16, fn=0.18		True
	31	0.3792		0.6412		0.7892		0.2809		0.8932	0.6232		tp=0.3, tn=0.34, fp=0.14, fn=0.22		False
	32	0.375		0.6115		0.8024		0.2649		0.8934	0.6709		tp=0.37, tn=0.27, fp=0.17, fn=0.19		False
	33	0.3619		0.6594		0.8268		0.2341		0.911	0.5899		tp=0.29, tn=0.31, fp=0.12, fn=0.28		False
	34	0.3571		0.6394		0.8288		0.2814		0.9077	0.6438		tp=0.33, tn=0.31, fp=0.14, fn=0.22		False
	35	0.3483		0.6203		0.8358		0.2938		0.9146	0.6531		tp=0.34, tn=0.31, fp=0.14, fn=0.22		False
	36	0.3414		0.6675		0.8268		0.236		0.911	0.6		tp=0.29, tn=0.31, fp=0.13, fn=0.26		False
	37	0.3341		0.6482		0.8468		0.2782		0.9168	0.6792		tp=0.38, tn=0.27, fp=0.19, fn=0.17		False
	38	0.3271		0.6686		0.8564		0.2596		0.9268	0.6351		tp=0.33, tn=0.29, fp=0.13, fn=0.24		False
	39	0.3218		0.6522		0.8456		0.2982		0.9178	0.6711		tp=0.36, tn=0.29, fp=0.17, fn=0.18		False
	40	0.312		0.6605		0.8567		0.2661		0.9247	0.6345		tp=0.32, tn=0.31, fp=0.15, fn=0.22		False
	41	0.3064		0.6776		0.8742		0.2508		0.9342	0.625		tp=0.31, tn=0.31, fp=0.15, fn=0.22		False
	42	0.3011		0.6341		0.8776		0.3081		0.9352	0.6879		tp=0.38, tn=0.28, fp=0.17, fn=0.17		False
	43	0.294		0.6746		0.8778		0.3099		0.935	0.6528		tp=0.33, tn=0.32, fp=0.13, fn=0.22		False
	44	0.2883		0.6667		0.8827		0.3349		0.9392	0.6712		tp=0.34, tn=0.32, fp=0.13, fn=0.2		True
	45	0.2802		0.6467		0.9051		0.3139		0.9485	0.6879		tp=0.38, tn=0.28, fp=0.17, fn=0.17		False
	46	0.275		0.6825		0.8915		0.2981		0.9439	0.6338		tp=0.31, tn=0.32, fp=0.11, fn=0.25		False
	47	0.2706		0.6366		0.8804		0.3539		0.9368	0.7013		tp=0.38, tn=0.3, fp=0.15, fn=0.17		True
	48	0.2622		0.6773		0.9093		0.2942		0.9527	0.6483		tp=0.33, tn=0.31, fp=0.14, fn=0.22		False
	49	0.2585		0.6859		0.9098		0.2917		0.9522	0.6483		tp=0.33, tn=0.31, fp=0.15, fn=0.21		False
	50	0.2513		0.6387		0.9124		0.3178		0.954	0.6755		tp=0.36, tn=0.3, fp=0.14, fn=0.2		False
	51	0.2454		0.698		0.918		0.2624		0.9573	0.6443		tp=0.34, tn=0.29, fp=0.15, fn=0.22		False
	52	0.2412		0.704		0.9218		0.2669		0.9583	0.6709		tp=0.37, tn=0.27, fp=0.16, fn=0.2		False
	53	0.2359		0.6568		0.9269		0.3552		0.9618	0.6974		tp=0.37, tn=0.31, fp=0.15, fn=0.17		True
	54	0.2309		0.7007		0.9238		0.3141		0.9605	0.6755		tp=0.36, tn=0.3, fp=0.15, fn=0.19		False
	55	0.2263		0.7002		0.9331		0.2929		0.9647	0.6835		tp=0.38, tn=0.27, fp=0.17, fn=0.17		False
	56	0.221		0.7122		0.9267		0.3099		0.9622	0.6528		tp=0.33, tn=0.32, fp=0.13, fn=0.22		False
	57	0.2198		0.6891		0.9305		0.3114		0.963	0.6839		tp=0.37, tn=0.29, fp=0.15, fn=0.19		False
	58	0.2134		0.7092		0.9327		0.2982		0.965	0.6711		tp=0.36, tn=0.29, fp=0.17, fn=0.18		False
	59	0.2076		0.6949		0.9358		0.3345		0.9664	0.68		tp=0.35, tn=0.31, fp=0.15, fn=0.19		False
	60	0.2028		0.7233		0.9388		0.3095		0.9678	0.6575		tp=0.33, tn=0.32, fp=0.15, fn=0.2		False
	61	0.1977		0.7284		0.9475		0.2898		0.9725	0.6434		tp=0.32, tn=0.32, fp=0.15, fn=0.2		False
	62	0.1937		0.707		0.9533		0.3192		0.9756	0.6797		tp=0.36, tn=0.29, fp=0.13, fn=0.21		False
	63	0.1898		0.6997		0.9474		0.322		0.9726	0.6667		tp=0.34, tn=0.31, fp=0.13, fn=0.21		False
	64	0.1866		0.7109		0.9506		0.2993		0.974	0.6667		tp=0.35, tn=0.3, fp=0.17, fn=0.18		False
	65	0.1824		0.7125		0.9533		0.3454		0.9756	0.6803		tp=0.35, tn=0.32, fp=0.14, fn=0.19		False
	66	0.1778		0.6476		0.9593		0.3912		0.9786	0.6986		tp=0.36, tn=0.34, fp=0.12, fn=0.19		True
	67	0.1761		0.7341		0.9533		0.3328		0.9756	0.6667		tp=0.34, tn=0.33, fp=0.14, fn=0.2		False
	68	0.1712		0.7399		0.9533		0.3151		0.9756	0.6711		tp=0.35, tn=0.31, fp=0.15, fn=0.19		False
	69	0.1684		0.7569		0.9503		0.3027		0.9741	0.6575		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	70	0.1639		0.758		0.962		0.3312		0.9802	0.68		tp=0.36, tn=0.31, fp=0.14, fn=0.2		False
	71	0.161		0.7698		0.9593		0.2848		0.9786	0.6667		tp=0.36, tn=0.29, fp=0.16, fn=0.2		False
	72	0.1574		0.7353		0.9622		0.3386		0.9802	0.68		tp=0.35, tn=0.31, fp=0.13, fn=0.2		False
	73	0.1559		0.7437		0.9707		0.3787		0.9848	0.6897		tp=0.35, tn=0.34, fp=0.12, fn=0.2		False
	74	0.1517		0.7292		0.9592		0.3294		0.9787	0.68		tp=0.36, tn=0.31, fp=0.15, fn=0.19		False
	75	0.1482		0.7569		0.965		0.3002		0.9817	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	76	0.1452		0.739		0.965		0.3141		0.9817	0.6755		tp=0.36, tn=0.3, fp=0.15, fn=0.19		False
	77	0.1415		0.7156		0.9679		0.3422		0.9833	0.6887		tp=0.36, tn=0.31, fp=0.15, fn=0.18		False
	78	0.1389		0.7744		0.9679		0.3166		0.9833	0.6711		tp=0.35, tn=0.31, fp=0.15, fn=0.2		False
	79	0.136		0.7559		0.9708		0.346		0.9848	0.6887		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	80	0.1332		0.7607		0.9708		0.3158		0.9848	0.6667		tp=0.34, tn=0.31, fp=0.15, fn=0.19		False
	81	0.1309		0.79		0.9737		0.3479		0.9863	0.6759		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	82	0.1289		0.8147		0.9766		0.2876		0.9879	0.6623		tp=0.35, tn=0.29, fp=0.15, fn=0.2		False
	83	0.125		0.7891		0.9737		0.3336		0.9863	0.6842		tp=0.36, tn=0.31, fp=0.15, fn=0.19		False
	84	0.123		0.7433		0.9738		0.3187		0.9863	0.6711		tp=0.35, tn=0.31, fp=0.14, fn=0.2		False
	85	0.1209		0.761		0.9737		0.3294		0.9863	0.68		tp=0.36, tn=0.31, fp=0.15, fn=0.19		False
	86	0.1183		0.8002		0.9767		0.3187		0.9878	0.6711		tp=0.35, tn=0.31, fp=0.14, fn=0.2		False
	87	0.1164		0.7423		0.9766		0.4322		0.9879	0.7133		tp=0.36, tn=0.36, fp=0.11, fn=0.17		True
	88	0.1136		0.8152		0.9854		0.3145		0.9924	0.6797		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	89	0.1116		0.826		0.9825		0.3273		0.9909	0.6923		tp=0.38, tn=0.29, fp=0.14, fn=0.2		False
	90	0.1098		0.7954		0.9883		0.3431		0.994	0.6846		tp=0.36, tn=0.31, fp=0.15, fn=0.18		False
	91	0.107		0.8102		0.9883		0.3468		0.994	0.6846		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	92	0.1048		0.8114		0.9825		0.3475		0.9909	0.6803		tp=0.35, tn=0.32, fp=0.13, fn=0.2		False
	93	0.1034		0.797		0.9854		0.3454		0.9924	0.6803		tp=0.35, tn=0.32, fp=0.14, fn=0.19		False
	94	0.1027		0.8279		0.9854		0.332		0.9924	0.6757		tp=0.35, tn=0.31, fp=0.14, fn=0.2		False
	95	0.09963		0.8206		0.9883		0.3031		0.994	0.6667		tp=0.35, tn=0.3, fp=0.15, fn=0.2		False
	96	0.09863		0.8628		0.9767		0.3135		0.9878	0.6711		tp=0.35, tn=0.31, fp=0.17, fn=0.17		False
	97	0.09547		0.8379		0.9912		0.327		0.9955	0.6842		tp=0.36, tn=0.3, fp=0.15, fn=0.18		False
	98	0.09478		0.8457		0.9941		0.3058		0.997	0.6483		tp=0.33, tn=0.32, fp=0.12, fn=0.23		False
	99	0.09185		0.8388		0.9912		0.3257		0.9955	0.6883		tp=0.37, tn=0.29, fp=0.15, fn=0.18		False
	100	0.09055		0.8806		0.9883		0.3099		0.994	0.6528		tp=0.33, tn=0.32, fp=0.13, fn=0.22		False
	101	0.08913		0.7398		0.9912		0.3575		0.9955	0.6933		tp=0.36, tn=0.31, fp=0.14, fn=0.18		False
	102	0.08634		0.8595		0.9912		0.28		0.9955	0.6533		tp=0.34, tn=0.29, fp=0.14, fn=0.22		False
	103	0.08462		0.8389		0.9912		0.3249		0.9955	0.6883		tp=0.37, tn=0.29, fp=0.16, fn=0.17		False
	104	0.08401		0.8027		0.9912		0.3496		0.9955	0.6846		tp=0.35, tn=0.32, fp=0.14, fn=0.19		False
	105	0.08144		0.8564		0.9941		0.321		0.997	0.6755		tp=0.35, tn=0.31, fp=0.15, fn=0.19		False
	106	0.08032		0.8057		0.9971		0.3591		0.9985	0.7013		tp=0.38, tn=0.31, fp=0.15, fn=0.17		False
	107	0.0795		0.797		0.9971		0.3524		0.9985	0.7051		tp=0.38, tn=0.29, fp=0.15, fn=0.17		False
	108	0.07717		0.8665		0.9971		0.3039		0.9985	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		30
learning rate		0.000130069522105
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_10-lr0.00013-h_size30-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6941		0.6924		-0.0761		0		0.5969	0.6102		tp=0.38, tn=0.15, fp=0.29, fn=0.19		False
	2	0.6909		0.6926		0.1143		0.03858		0.6312	0.5696		tp=0.31, tn=0.21, fp=0.24, fn=0.23		True
	3	0.6882		0.6915		0.1516		0.1314		0.6119	0.5921		tp=0.31, tn=0.25, fp=0.2, fn=0.24		True
	4	0.6859		0.6913		0.2321		0.06076		0.5574	0.4964		tp=0.24, tn=0.28, fp=0.16, fn=0.32		False
	5	0.6834		0.6872		0.2745		0.2093		0.6147	0.6225		tp=0.33, tn=0.28, fp=0.17, fn=0.22		True
	6	0.681		0.6894		0.2984		0.03364		0.5809	0.4		tp=0.17, tn=0.33, fp=0.13, fn=0.38		False
	7	0.6783		0.6875		0.32		0.1383		0.6221	0.5468		tp=0.27, tn=0.29, fp=0.15, fn=0.29		False
	8	0.6755		0.6834		0.3334		0.2307		0.6481	0.6259		tp=0.32, tn=0.29, fp=0.18, fn=0.2		True
	9	0.6728		0.6812		0.3426		0.2124		0.6616	0.6364		tp=0.34, tn=0.27, fp=0.19, fn=0.2		False
	10	0.6697		0.6805		0.3658		0.2129		0.6646	0.5606		tp=0.26, tn=0.34, fp=0.13, fn=0.28		False
	11	0.6668		0.6796		0.3778		0.1896		0.6479	0.5455		tp=0.25, tn=0.33, fp=0.13, fn=0.29		False
	12	0.664		0.6774		0.3767		0.1817		0.6525	0.5931		tp=0.3, tn=0.29, fp=0.17, fn=0.24		False
	13	0.6606		0.676		0.3836		0.1963		0.6708	0.5797		tp=0.28, tn=0.31, fp=0.16, fn=0.24		False
	14	0.6574		0.6735		0.3991		0.2157		0.673	0.5735		tp=0.27, tn=0.32, fp=0.13, fn=0.28		False
	15	0.654		0.6756		0.4168		0.169		0.6826	0.5833		tp=0.29, tn=0.29, fp=0.17, fn=0.25		False
	16	0.6507		0.6717		0.4069		0.1671		0.6902	0.6		tp=0.31, tn=0.27, fp=0.17, fn=0.25		False
	17	0.6471		0.671		0.4287		0.1747		0.689	0.5481		tp=0.26, tn=0.31, fp=0.13, fn=0.29		False
	18	0.6436		0.6691		0.4199		0.2285		0.6837	0.6405		tp=0.34, tn=0.27, fp=0.17, fn=0.21		False
	19	0.6397		0.6652		0.4275		0.3166		0.6986	0.6711		tp=0.35, tn=0.31, fp=0.15, fn=0.2		True
	20	0.6363		0.6728		0.4272		0.216		0.6808	0.5957		tp=0.29, tn=0.31, fp=0.15, fn=0.25		False
	21	0.6323		0.6584		0.4309		0.3583		0.695	0.6892		tp=0.36, tn=0.32, fp=0.14, fn=0.18		True
	22	0.6285		0.6585		0.4574		0.3289		0.7096	0.6757		tp=0.35, tn=0.31, fp=0.15, fn=0.18		False
	23	0.6245		0.6525		0.46		0.3135		0.7221	0.6711		tp=0.35, tn=0.31, fp=0.17, fn=0.17		False
	24	0.6204		0.6583		0.4737		0.2501		0.7106	0.5942		tp=0.28, tn=0.33, fp=0.12, fn=0.27		False
	25	0.6168		0.6503		0.485		0.3294		0.7188	0.6712		tp=0.34, tn=0.32, fp=0.15, fn=0.18		False
	26	0.6126		0.6529		0.4958		0.3031		0.7296	0.6667		tp=0.35, tn=0.3, fp=0.15, fn=0.2		False
	27	0.6084		0.6442		0.4927		0.322		0.7293	0.6475		tp=0.31, tn=0.34, fp=0.13, fn=0.21		False
	28	0.605		0.651		0.4894		0.2817		0.7307	0.6389		tp=0.32, tn=0.31, fp=0.14, fn=0.22		False
	29	0.6007		0.6563		0.4846		0.2639		0.7206	0.6087		tp=0.29, tn=0.33, fp=0.13, fn=0.25		False
	30	0.597		0.6416		0.4924		0.2944		0.7309	0.6434		tp=0.32, tn=0.32, fp=0.14, fn=0.22		False
	31	0.5926		0.6459		0.496		0.2842		0.7287	0.6486		tp=0.34, tn=0.3, fp=0.13, fn=0.23		False
	32	0.5887		0.6423		0.5168		0.3288		0.7393	0.6667		tp=0.34, tn=0.31, fp=0.12, fn=0.22		False
	33	0.5857		0.6437		0.5039		0.3039		0.742	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	34	0.5808		0.6339		0.5127		0.3848		0.747	0.698		tp=0.36, tn=0.32, fp=0.1, fn=0.21		True
	35	0.5769		0.6336		0.5249		0.3292		0.7477	0.6525		tp=0.32, tn=0.34, fp=0.12, fn=0.22		False
	36	0.573		0.6402		0.5291		0.3146		0.744	0.6479		tp=0.32, tn=0.33, fp=0.13, fn=0.22		False
	37	0.569		0.6414		0.5571		0.3091		0.7548	0.6377		tp=0.31, tn=0.34, fp=0.13, fn=0.22		False
	38	0.565		0.6526		0.5486		0.25		0.7594	0.6351		tp=0.33, tn=0.29, fp=0.15, fn=0.22		False
	39	0.5614		0.6411		0.5538		0.3075		0.7676	0.6711		tp=0.35, tn=0.3, fp=0.15, fn=0.2		False
	40	0.5575		0.6336		0.5612		0.322		0.7627	0.6667		tp=0.34, tn=0.31, fp=0.13, fn=0.21		False
	41	0.5542		0.6369		0.5691		0.3047		0.7707	0.6528		tp=0.33, tn=0.32, fp=0.15, fn=0.2		False
	42	0.5503		0.638		0.5752		0.322		0.7731	0.6667		tp=0.34, tn=0.31, fp=0.13, fn=0.21		False
	43	0.5466		0.6223		0.5722		0.3178		0.7719	0.6755		tp=0.36, tn=0.3, fp=0.14, fn=0.2		False
	44	0.5433		0.6405		0.5693		0.2657		0.77	0.6395		tp=0.33, tn=0.3, fp=0.15, fn=0.22		False
	45	0.539		0.631		0.5867		0.3002		0.7807	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	46	0.5352		0.6377		0.5865		0.2612		0.7814	0.6395		tp=0.33, tn=0.3, fp=0.16, fn=0.21		False
	47	0.5319		0.603		0.5981		0.3447		0.7889	0.6846		tp=0.36, tn=0.31, fp=0.14, fn=0.19		False
	48	0.5287		0.6451		0.596		0.2789		0.7837	0.6389		tp=0.32, tn=0.31, fp=0.15, fn=0.22		False
	49	0.5261		0.6422		0.6008		0.2566		0.7939	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	50	0.5225		0.6408		0.5992		0.3062		0.7843	0.6622		tp=0.34, tn=0.31, fp=0.14, fn=0.21		False
	51	0.5179		0.6322		0.6047		0.302		0.7887	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	52	0.5145		0.6267		0.6167		0.2886		0.7943	0.6577		tp=0.34, tn=0.3, fp=0.15, fn=0.2		False
	53	0.5116		0.6184		0.6214		0.3129		0.8031	0.6797		tp=0.36, tn=0.29, fp=0.15, fn=0.19		False
	54	0.5092		0.6398		0.6206		0.2508		0.7937	0.625		tp=0.31, tn=0.31, fp=0.15, fn=0.22		False
	55	0.5048		0.6156		0.6216		0.3013		0.8012	0.6667		tp=0.35, tn=0.3, fp=0.15, fn=0.2		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		24
learning rate		0.00354917257362
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_110-lr0.0035-h_size24-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6212		0.6239		0.0151		0		0.8159	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.605		0.6307		0.05457		0.05596		0.8184	0.8092		tp=0.68, tn=0.0015, fp=0.32, fn=0		True
	3	0.5777		0.6245		0.1684		0.07409		0.8222	0.8054		tp=0.66, tn=0.018, fp=0.3, fn=0.018		True
	4	0.5424		0.616		0.2849		0.05998		0.8288	0.7971		tp=0.64, tn=0.028, fp=0.29, fn=0.038		False
	5	0.5219		0.6701		0.3118		0.05223		0.8311	0.8015		tp=0.65, tn=0.021, fp=0.3, fn=0.028		False
	6	0.4789		0.641		0.4362		0.1467		0.8486	0.807		tp=0.65, tn=0.039, fp=0.28, fn=0.028		True
	7	0.4434		0.6708		0.5039		0.1321		0.8598	0.8059		tp=0.65, tn=0.043, fp=0.27, fn=0.04		False
	8	0.4284		0.6672		0.5063		0.1031		0.859	0.7451		tp=0.53, tn=0.099, fp=0.22, fn=0.15		False
	9	0.3971		0.6941		0.5714		0.204		0.873	0.7184		tp=0.47, tn=0.17, fp=0.15, fn=0.22		True
	10	0.3697		0.7376		0.6237		0.1626		0.8865	0.7173		tp=0.48, tn=0.15, fp=0.17, fn=0.2		False
	11	0.3427		0.7453		0.6574		0.157		0.8954	0.7495		tp=0.53, tn=0.12, fp=0.2, fn=0.16		False
	12	0.3219		0.7685		0.6937		0.1797		0.9057	0.7232		tp=0.48, tn=0.15, fp=0.16, fn=0.21		False
	13	0.2959		0.7989		0.7323		0.1595		0.9176	0.7508		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	14	0.2795		0.7967		0.7483		0.1687		0.9226	0.7588		tp=0.54, tn=0.12, fp=0.2, fn=0.14		False
	15	0.2725		0.8611		0.7606		0.1587		0.9258	0.7786		tp=0.58, tn=0.089, fp=0.23, fn=0.098		False
	16	0.2565		0.85		0.7724		0.1888		0.9305	0.7668		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	17	0.2306		0.8587		0.8122		0.2079		0.942	0.7459		tp=0.51, tn=0.15, fp=0.17, fn=0.18		True
	18	0.2222		0.9332		0.8179		0.2272		0.9439	0.7191		tp=0.46, tn=0.18, fp=0.14, fn=0.22		True
	19	0.2064		0.9453		0.839		0.1819		0.9504	0.7497		tp=0.52, tn=0.13, fp=0.19, fn=0.16		False
	20	0.1959		0.9703		0.8533		0.1804		0.9546	0.7782		tp=0.57, tn=0.1, fp=0.21, fn=0.11		False
	21	0.1957		0.9688		0.8435		0.1927		0.952	0.7582		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	22	0.1823		1		0.8641		0.1895		0.9584	0.7646		tp=0.54, tn=0.12, fp=0.19, fn=0.14		False
	23	0.1747		0.9519		0.8701		0.1872		0.9602	0.7495		tp=0.52, tn=0.13, fp=0.18, fn=0.17		False
	24	0.1626		1.012		0.8795		0.2117		0.963	0.7516		tp=0.51, tn=0.14, fp=0.17, fn=0.17		False
	25	0.1571		1.084		0.891		0.1543		0.9666	0.756		tp=0.54, tn=0.11, fp=0.2, fn=0.14		False
	26	0.1511		1.069		0.8932		0.2098		0.9672	0.7522		tp=0.52, tn=0.14, fp=0.17, fn=0.17		False
	27	0.1402		1.075		0.9007		0.1776		0.9697	0.7526		tp=0.53, tn=0.13, fp=0.19, fn=0.16		False
	28	0.1355		1.02		0.9067		0.1745		0.9713	0.7389		tp=0.51, tn=0.14, fp=0.18, fn=0.18		False
	29	0.1236		1.151		0.92		0.1927		0.9755	0.7407		tp=0.5, tn=0.14, fp=0.17, fn=0.18		False
	30	0.1326		1.083		0.9082		0.2		0.9719	0.7481		tp=0.51, tn=0.14, fp=0.18, fn=0.17		False
	31	0.1377		1.095		0.908		0.2156		0.972	0.758		tp=0.52, tn=0.14, fp=0.18, fn=0.16		False
	32	0.1246		1.159		0.9173		0.2319		0.9747	0.7514		tp=0.51, tn=0.16, fp=0.17, fn=0.17		True
	33	0.1197		1.171		0.9211		0.1802		0.9759	0.7521		tp=0.53, tn=0.13, fp=0.19, fn=0.16		False
	34	0.1124		1.172		0.9306		0.1972		0.9788	0.7448		tp=0.51, tn=0.14, fp=0.18, fn=0.17		False
	35	0.1375		1.213		0.905		0.2046		0.9711	0.7489		tp=0.51, tn=0.14, fp=0.18, fn=0.16		False
	36	0.1134		1.193		0.9278		0.1864		0.9779	0.7438		tp=0.51, tn=0.14, fp=0.18, fn=0.17		False
	37	0.1041		1.243		0.9376		0.2058		0.981	0.7381		tp=0.49, tn=0.15, fp=0.17, fn=0.18		False
	38	0.09817		1.26		0.9411		0.1796		0.982	0.7465		tp=0.52, tn=0.13, fp=0.19, fn=0.16		False
	39	0.0997		1.233		0.9399		0.1827		0.9816	0.7705		tp=0.56, tn=0.11, fp=0.2, fn=0.13		False
	40	0.0972		1.239		0.9393		0.1692		0.9815	0.7886		tp=0.59, tn=0.087, fp=0.22, fn=0.098		False
	41	0.1073		1.283		0.9284		0.212		0.9782	0.7583		tp=0.53, tn=0.14, fp=0.18, fn=0.16		False
	42	0.09565		1.287		0.9424		0.2298		0.9824	0.7554		tp=0.52, tn=0.15, fp=0.17, fn=0.17		False
	43	0.09627		1.276		0.9428		0.2122		0.9825	0.744		tp=0.5, tn=0.15, fp=0.17, fn=0.17		False
	44	0.09141		1.318		0.9428		0.1883		0.9826	0.7432		tp=0.51, tn=0.14, fp=0.18, fn=0.17		False
	45	0.09152		1.317		0.9398		0.1843		0.9816	0.7683		tp=0.55, tn=0.11, fp=0.21, fn=0.13		False
	46	0.08954		1.433		0.9462		0.2258		0.9836	0.7342		tp=0.48, tn=0.17, fp=0.15, fn=0.2		False
	47	0.08305		1.407		0.9497		0.1922		0.9847	0.7421		tp=0.51, tn=0.14, fp=0.18, fn=0.17		False
	48	0.08999		1.299		0.9467		0.2035		0.9837	0.7652		tp=0.54, tn=0.13, fp=0.19, fn=0.14		False
	49	0.08729		1.431		0.9436		0.1914		0.9828	0.7564		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	50	0.07987		1.366		0.9554		0.2045		0.9864	0.7746		tp=0.56, tn=0.12, fp=0.21, fn=0.12		False
	51	0.0878		1.54		0.9423		0.1976		0.9824	0.712		tp=0.46, tn=0.17, fp=0.16, fn=0.21		False
	52	0.09066		1.486		0.9419		0.188		0.9823	0.7695		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	53	0.08699		1.423		0.9475		0.2047		0.984	0.7611		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		174
learning rate		0.000769235777643
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_111-lr0.00077-h_size174-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6886		0.6769		0.04138		0.2029		0.517	0.4655		tp=0.19, tn=0.38, fp=0.076, fn=0.35		True
	2	0.652		0.6701		0.2725		0.1468		0.6508	0.3585		tp=0.13, tn=0.39, fp=0.056, fn=0.42		False
	3	0.6204		0.6411		0.3483		0.2562		0.606	0.7111		tp=0.44, tn=0.19, fp=0.25, fn=0.11		True
	4	0.583		0.6171		0.4471		0.3491		0.6957	0.7458		tp=0.46, tn=0.22, fp=0.21, fn=0.1		True
	5	0.5484		0.6247		0.485		0.2626		0.7188	0.675		tp=0.38, tn=0.26, fp=0.17, fn=0.19		False
	6	0.5131		0.6317		0.5574		0.2694		0.7756	0.6623		tp=0.36, tn=0.28, fp=0.17, fn=0.2		False
	7	0.4763		0.6457		0.6134		0.324		0.7937	0.7374		tp=0.46, tn=0.21, fp=0.23, fn=0.098		False
	8	0.4627		0.6857		0.5832		0.3484		0.7829	0.7345		tp=0.45, tn=0.22, fp=0.25, fn=0.077		False
	9	0.4358		0.6205		0.6013		0.2845		0.7976	0.6988		tp=0.41, tn=0.24, fp=0.2, fn=0.15		False
	10	0.4015		0.6353		0.6979		0.302		0.8418	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	11	0.3716		0.6865		0.7252		0.2607		0.8536	0.679		tp=0.38, tn=0.25, fp=0.2, fn=0.17		False
	12	0.3559		0.7409		0.7391		0.3005		0.8633	0.6331		tp=0.31, tn=0.34, fp=0.13, fn=0.23		False
	13	0.3322		0.7409		0.7658		0.2881		0.8765	0.6914		tp=0.39, tn=0.26, fp=0.17, fn=0.17		False
	14	0.3107		0.7606		0.7829		0.3175		0.8875	0.7108		tp=0.41, tn=0.25, fp=0.2, fn=0.13		False
	15	0.298		0.7697		0.7864		0.2557		0.8919	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	16	0.2811		0.789		0.8068		0.2567		0.8985	0.6829		tp=0.39, tn=0.24, fp=0.18, fn=0.18		False
	17	0.2607		0.8439		0.8416		0.2313		0.9179	0.6358		tp=0.34, tn=0.28, fp=0.17, fn=0.22		False
	18	0.2492		0.8262		0.8592		0.2425		0.9273	0.6494		tp=0.35, tn=0.27, fp=0.17, fn=0.21		False
	19	0.2363		0.9253		0.8446		0.2086		0.9208	0.6174		tp=0.32, tn=0.28, fp=0.16, fn=0.24		False
	20	0.2257		0.8531		0.8591		0.3099		0.9275	0.6839		tp=0.37, tn=0.29, fp=0.17, fn=0.17		False
	21	0.2384		0.9509		0.8305		0.2234		0.9105	0.6497		tp=0.36, tn=0.26, fp=0.2, fn=0.19		False
	22	0.2186		0.991		0.874		0.2639		0.9344	0.649		tp=0.34, tn=0.29, fp=0.15, fn=0.22		False
	23	0.1934		0.9399		0.8975		0.2959		0.9466	0.6795		tp=0.37, tn=0.28, fp=0.16, fn=0.19		False
	24	0.1845		1.046		0.9035		0.3013		0.9495	0.6667		tp=0.35, tn=0.3, fp=0.15, fn=0.2		False
	25	0.1774		1.09		0.909		0.2817		0.9531	0.6832		tp=0.38, tn=0.26, fp=0.18, fn=0.17		False


data			/scratch/asw462/data/levin
input size		300
hidden size		50
learning rate		0.000199970980877
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_112-lr0.0002-h_size50-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5953		0.6051		0		0		0.8402	0.8245		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.5725		0.5773		0.04298		0		0.8412	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	3	0.5639		0.5788		0.06113		0.123		0.8409	0.8347		tp=0.71, tn=0.014, fp=0.27, fn=0.007		True
	4	0.5559		0.5838		0.1127		0.1821		0.8436	0.8354		tp=0.69, tn=0.035, fp=0.25, fn=0.021		True
	5	0.5486		0.6011		0.1427		0.1999		0.8432	0.8255		tp=0.68, tn=0.035, fp=0.27, fn=0.014		True
	6	0.5456		0.5647		0.2036		0.1768		0.8484	0.839		tp=0.69, tn=0.042, fp=0.23, fn=0.035		False
	7	0.5426		0.5823		0.1948		0.179		0.8457	0.824		tp=0.67, tn=0.042, fp=0.26, fn=0.028		False
	8	0.5368		0.6186		0.2315		0.1412		0.8507	0.7965		tp=0.63, tn=0.049, fp=0.28, fn=0.042		False
	9	0.5326		0.6069		0.2576		0.1581		0.853	0.8122		tp=0.65, tn=0.049, fp=0.26, fn=0.042		False
	10	0.53		0.5766		0.2711		0.2009		0.8546	0.8261		tp=0.66, tn=0.056, fp=0.24, fn=0.042		True
	11	0.5263		0.5775		0.2631		0.2454		0.8523	0.839		tp=0.69, tn=0.049, fp=0.24, fn=0.021		True
	12	0.5249		0.5639		0.2891		0.1829		0.8544	0.8368		tp=0.69, tn=0.035, fp=0.25, fn=0.021		False
	13	0.5206		0.5901		0.3109		0.2362		0.858	0.8073		tp=0.62, tn=0.091, fp=0.22, fn=0.07		False
	14	0.5142		0.6109		0.2975		0.2		0.8557	0.8174		tp=0.66, tn=0.049, fp=0.27, fn=0.028		False
	15	0.5121		0.5892		0.3216		0.2712		0.8587	0.8282		tp=0.65, tn=0.076, fp=0.23, fn=0.042		True
	16	0.5049		0.5819		0.3122		0.2192		0.8576	0.8161		tp=0.64, tn=0.077, fp=0.22, fn=0.063		False
	17	0.499		0.5687		0.3442		0.3324		0.8625	0.8458		tp=0.67, tn=0.084, fp=0.21, fn=0.035		True
	18	0.5014		0.5709		0.3503		0.3028		0.8621	0.8356		tp=0.66, tn=0.084, fp=0.22, fn=0.042		False
	19	0.494		0.5823		0.3319		0.1663		0.861	0.8106		tp=0.64, tn=0.062, fp=0.24, fn=0.062		False
	20	0.4948		0.5543		0.3538		0.2315		0.8624	0.8246		tp=0.65, tn=0.069, fp=0.23, fn=0.049		False
	21	0.4843		0.5753		0.3685		0.1971		0.8662	0.8246		tp=0.66, tn=0.063, fp=0.22, fn=0.056		False
	22	0.4816		0.562		0.3678		0.2449		0.8662	0.8198		tp=0.64, tn=0.084, fp=0.22, fn=0.063		False
	23	0.4821		0.5485		0.3902		0.2516		0.8676	0.8448		tp=0.69, tn=0.063, fp=0.21, fn=0.042		False
	24	0.4805		0.5718		0.3752		0.2112		0.8654	0.7867		tp=0.58, tn=0.1, fp=0.22, fn=0.098		False
	25	0.479		0.5525		0.3858		0.3146		0.8652	0.8472		tp=0.68, tn=0.077, fp=0.21, fn=0.035		False
	26	0.4806		0.5583		0.3858		0.2175		0.8653	0.8214		tp=0.64, tn=0.077, fp=0.21, fn=0.07		False
	27	0.4713		0.5383		0.4243		0.1968		0.8709	0.8161		tp=0.63, tn=0.083, fp=0.18, fn=0.1		False
	28	0.4661		0.5638		0.4194		0.2951		0.8717	0.8304		tp=0.65, tn=0.084, fp=0.22, fn=0.042		False
	29	0.4614		0.5479		0.4474		0.2449		0.876	0.8333		tp=0.66, tn=0.07, fp=0.22, fn=0.049		False
	30	0.4617		0.5435		0.4227		0.3381		0.8727	0.8522		tp=0.69, tn=0.077, fp=0.21, fn=0.028		True
	31	0.4566		0.5499		0.4214		0.1683		0.871	0.7982		tp=0.61, tn=0.084, fp=0.2, fn=0.1		False
	32	0.4491		0.5409		0.4479		0.2432		0.8774	0.8019		tp=0.59, tn=0.11, fp=0.18, fn=0.11		False
	33	0.4518		0.5519		0.415		0.2308		0.8677	0.8		tp=0.6, tn=0.1, fp=0.2, fn=0.097		False
	34	0.4469		0.5415		0.4414		0.2533		0.8735	0.8165		tp=0.62, tn=0.098, fp=0.2, fn=0.084		False
	35	0.4385		0.5498		0.4513		0.2682		0.8778	0.8165		tp=0.62, tn=0.098, fp=0.21, fn=0.07		False
	36	0.4429		0.5374		0.4749		0.2601		0.8786	0.8		tp=0.59, tn=0.12, fp=0.19, fn=0.1		False
	37	0.435		0.5663		0.4661		0.1868		0.8787	0.8		tp=0.62, tn=0.077, fp=0.24, fn=0.07		False
	38	0.432		0.5663		0.4673		0.2197		0.8788	0.7981		tp=0.59, tn=0.1, fp=0.19, fn=0.11		False
	39	0.4265		0.5538		0.4868		0.2019		0.8819	0.8108		tp=0.63, tn=0.077, fp=0.22, fn=0.07		False
	40	0.4263		0.5419		0.4926		0.1952		0.8824	0.8037		tp=0.62, tn=0.084, fp=0.22, fn=0.084		False
	41	0.424		0.5685		0.5014		0.2043		0.8847	0.7982		tp=0.61, tn=0.084, fp=0.24, fn=0.07		False
	42	0.4231		0.5892		0.4791		0.1874		0.8801	0.781		tp=0.57, tn=0.1, fp=0.2, fn=0.12		False
	43	0.4164		0.5345		0.4961		0.2252		0.8831	0.8073		tp=0.61, tn=0.097, fp=0.19, fn=0.097		False
	44	0.4156		0.5807		0.5086		0.2458		0.8864	0.8297		tp=0.66, tn=0.063, fp=0.24, fn=0.035		False
	45	0.4123		0.5754		0.5024		0.2218		0.885	0.8037		tp=0.62, tn=0.084, fp=0.24, fn=0.063		False
	46	0.4055		0.5378		0.5353		0.2569		0.891	0.8075		tp=0.6, tn=0.11, fp=0.18, fn=0.1		False
	47	0.4057		0.5347		0.5114		0.2857		0.886	0.8186		tp=0.62, tn=0.11, fp=0.18, fn=0.091		False
	48	0.3975		0.5504		0.5451		0.2201		0.8935	0.8073		tp=0.62, tn=0.091, fp=0.21, fn=0.084		False
	49	0.4023		0.5579		0.5223		0.3147		0.888	0.8058		tp=0.58, tn=0.14, fp=0.17, fn=0.1		False
	50	0.394		0.5601		0.5448		0.284		0.8914	0.8203		tp=0.62, tn=0.1, fp=0.2, fn=0.077		False
	51	0.3945		0.529		0.5396		0.2813		0.8923	0.8075		tp=0.6, tn=0.12, fp=0.19, fn=0.09		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		32
learning rate		0.000173830314093
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_113-lr0.00017-h_size32-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6934		0.6883		-0.03513		0.1401		0.2581	0.4839		tp=0.21, tn=0.34, fp=0.12, fn=0.33		True
	2	0.6847		0.6811		0.1272		0.1667		0.6351	0.7053		tp=0.47, tn=0.14, fp=0.29, fn=0.1		True
	3	0.6794		0.6815		0.2718		0.2542		0.6026	0.5865		tp=0.27, tn=0.34, fp=0.12, fn=0.27		True
	4	0.6745		0.6772		0.3086		0.1823		0.5825	0.6282		tp=0.34, tn=0.25, fp=0.21, fn=0.2		False
	5	0.6685		0.6795		0.3284		0.1507		0.6769	0.5571		tp=0.27, tn=0.29, fp=0.15, fn=0.28		False
	6	0.6637		0.6788		0.3346		0.2186		0.5735	0.5		tp=0.21, tn=0.37, fp=0.084, fn=0.34		False
	7	0.6583		0.6711		0.3829		0.2239		0.6547	0.6497		tp=0.36, tn=0.26, fp=0.18, fn=0.2		False
	8	0.6546		0.6731		0.3372		0.2369		0.6367	0.5714		tp=0.27, tn=0.34, fp=0.11, fn=0.29		False
	9	0.65		0.6726		0.3847		0.2127		0.6903	0.6069		tp=0.31, tn=0.29, fp=0.15, fn=0.24		False
	10	0.6439		0.6727		0.39		0.191		0.6429	0.5755		tp=0.28, tn=0.31, fp=0.15, fn=0.27		False
	11	0.639		0.6697		0.4313		0.2055		0.6921	0.5957		tp=0.29, tn=0.31, fp=0.17, fn=0.22		False
	12	0.6338		0.6666		0.4373		0.2224		0.6952	0.6164		tp=0.31, tn=0.29, fp=0.16, fn=0.23		False
	13	0.6292		0.6594		0.4338		0.301		0.697	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.23		True
	14	0.6237		0.662		0.4392		0.2175		0.6873	0.6316		tp=0.34, tn=0.27, fp=0.17, fn=0.22		False
	15	0.6191		0.6688		0.4632		0.2319		0.7136	0.6		tp=0.29, tn=0.31, fp=0.14, fn=0.25		False
	16	0.6156		0.6599		0.4199		0.2632		0.708	0.6395		tp=0.33, tn=0.3, fp=0.15, fn=0.22		False
	17	0.6094		0.6663		0.4414		0.2232		0.6644	0.5972		tp=0.3, tn=0.29, fp=0.12, fn=0.29		False
	18	0.6036		0.6618		0.4747		0.1922		0.7225	0.6027		tp=0.31, tn=0.29, fp=0.17, fn=0.23		False
	19	0.6001		0.6619		0.4374		0.1934		0.716	0.563		tp=0.27, tn=0.32, fp=0.14, fn=0.27		False
	20	0.5952		0.6563		0.467		0.1899		0.7102	0.6081		tp=0.31, tn=0.28, fp=0.18, fn=0.22		False
	21	0.5885		0.6707		0.4716		0.1569		0.7239	0.5373		tp=0.25, tn=0.31, fp=0.14, fn=0.29		False
	22	0.5853		0.65		0.4872		0.1832		0.7235	0.5693		tp=0.27, tn=0.31, fp=0.16, fn=0.25		False
	23	0.5786		0.6582		0.4815		0.172		0.7195	0.5833		tp=0.29, tn=0.29, fp=0.16, fn=0.26		False
	24	0.5741		0.6627		0.5011		0.1185		0.7377	0.5429		tp=0.27, tn=0.29, fp=0.17, fn=0.28		False
	25	0.5688		0.6465		0.4989		0.1963		0.7307	0.5797		tp=0.28, tn=0.31, fp=0.16, fn=0.24		False
	26	0.5646		0.6488		0.5098		0.1853		0.7427	0.563		tp=0.27, tn=0.32, fp=0.15, fn=0.26		False
	27	0.559		0.6629		0.5051		0.1606		0.7222	0.5481		tp=0.26, tn=0.31, fp=0.15, fn=0.27		False
	28	0.5541		0.6442		0.5201		0.2239		0.7397	0.6497		tp=0.36, tn=0.26, fp=0.18, fn=0.2		False
	29	0.554		0.6584		0.5039		0.1767		0.7412	0.5612		tp=0.27, tn=0.3, fp=0.13, fn=0.29		False
	30	0.5495		0.6602		0.4742		0.172		0.7391	0.5674		tp=0.28, tn=0.29, fp=0.14, fn=0.29		False
	31	0.5449		0.636		0.5525		0.1877		0.7421	0.6184		tp=0.33, tn=0.27, fp=0.18, fn=0.22		False
	32	0.5367		0.6708		0.5129		0.1534		0.75	0.5441		tp=0.26, tn=0.31, fp=0.15, fn=0.29		False
	33	0.5311		0.6457		0.5402		0.2285		0.7528	0.6111		tp=0.31, tn=0.3, fp=0.15, fn=0.24		False
	34	0.5266		0.6329		0.5423		0.2156		0.7585	0.5899		tp=0.29, tn=0.31, fp=0.15, fn=0.25		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		11
learning rate		0.000622449950512
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_114-lr0.00062-h_size11-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5848		0.5674		0.1784		0.2716		0.8199	0.821		tp=0.64, tn=0.083, fp=0.23, fn=0.046		True
	2	0.5663		0.5667		0.2684		0.2748		0.8256	0.8223		tp=0.64, tn=0.077, fp=0.24, fn=0.037		True
	3	0.5574		0.5666		0.2728		0.2874		0.8252	0.8137		tp=0.61, tn=0.11, fp=0.22, fn=0.065		True
	4	0.5505		0.5653		0.2988		0.2879		0.8305	0.817		tp=0.62, tn=0.096, fp=0.23, fn=0.053		True
	5	0.5431		0.5698		0.3128		0.2812		0.8324	0.818		tp=0.63, tn=0.086, fp=0.24, fn=0.043		False
	6	0.5386		0.565		0.332		0.2872		0.8355	0.82		tp=0.63, tn=0.093, fp=0.22, fn=0.052		False
	7	0.5329		0.5751		0.3436		0.272		0.8353	0.8184		tp=0.63, tn=0.084, fp=0.24, fn=0.046		False
	8	0.5253		0.5755		0.3561		0.269		0.8397	0.8075		tp=0.61, tn=0.1, fp=0.22, fn=0.067		False
	9	0.5222		0.5682		0.3742		0.2902		0.8421	0.8212		tp=0.63, tn=0.092, fp=0.23, fn=0.049		True
	10	0.5148		0.5777		0.374		0.2592		0.8412	0.7976		tp=0.58, tn=0.12, fp=0.19, fn=0.1		False
	11	0.5101		0.5773		0.3917		0.2696		0.8457	0.8147		tp=0.63, tn=0.09, fp=0.23, fn=0.053		False
	12	0.5048		0.5778		0.404		0.2738		0.8475	0.8166		tp=0.63, tn=0.092, fp=0.23, fn=0.055		False
	13	0.501		0.575		0.3992		0.2572		0.8458	0.8154		tp=0.63, tn=0.089, fp=0.22, fn=0.059		False
	14	0.4962		0.5792		0.4211		0.2713		0.8511	0.8016		tp=0.59, tn=0.12, fp=0.2, fn=0.092		False
	15	0.4888		0.5822		0.4295		0.2393		0.852	0.8142		tp=0.63, tn=0.087, fp=0.22, fn=0.068		False
	16	0.4895		0.6035		0.4313		0.2405		0.8518	0.8133		tp=0.64, tn=0.073, fp=0.25, fn=0.041		False
	17	0.4837		0.5887		0.4501		0.2463		0.856	0.7972		tp=0.59, tn=0.11, fp=0.21, fn=0.089		False
	18	0.4819		0.5832		0.4441		0.2631		0.8554	0.8028		tp=0.6, tn=0.11, fp=0.21, fn=0.087		False
	19	0.4751		0.603		0.4539		0.2328		0.8564	0.7911		tp=0.58, tn=0.11, fp=0.2, fn=0.1		False
	20	0.4749		0.5976		0.4573		0.251		0.8568	0.7996		tp=0.59, tn=0.11, fp=0.21, fn=0.084		False
	21	0.4702		0.6016		0.4677		0.2799		0.8599	0.7971		tp=0.58, tn=0.13, fp=0.19, fn=0.11		False
	22	0.4693		0.5944		0.4679		0.2608		0.8593	0.8117		tp=0.62, tn=0.095, fp=0.22, fn=0.064		False
	23	0.4656		0.5987		0.4764		0.2503		0.86	0.802		tp=0.6, tn=0.1, fp=0.22, fn=0.079		False
	24	0.4665		0.5986		0.4728		0.2513		0.8605	0.8078		tp=0.61, tn=0.095, fp=0.23, fn=0.067		False
	25	0.4611		0.5912		0.4855		0.2433		0.8622	0.8047		tp=0.6, tn=0.1, fp=0.21, fn=0.086		False
	26	0.4584		0.6002		0.4843		0.2558		0.862	0.8098		tp=0.61, tn=0.098, fp=0.22, fn=0.071		False
	27	0.4606		0.6003		0.4738		0.2608		0.8593	0.8		tp=0.59, tn=0.12, fp=0.2, fn=0.093		False
	28	0.4508		0.6095		0.4926		0.2679		0.8645	0.8008		tp=0.59, tn=0.12, fp=0.2, fn=0.09		False
	29	0.4588		0.6103		0.4774		0.2417		0.8598	0.8039		tp=0.61, tn=0.093, fp=0.23, fn=0.067		False
	30	0.4481		0.6118		0.4988		0.3073		0.866	0.8017		tp=0.57, tn=0.14, fp=0.18, fn=0.11		True
	31	0.449		0.6116		0.508		0.2998		0.8676	0.8065		tp=0.59, tn=0.13, fp=0.19, fn=0.09		False
	32	0.4437		0.6259		0.5084		0.2114		0.8677	0.7925		tp=0.59, tn=0.099, fp=0.22, fn=0.092		False
	33	0.4449		0.6278		0.5069		0.2397		0.8669	0.8051		tp=0.61, tn=0.092, fp=0.23, fn=0.067		False
	34	0.4422		0.6146		0.5077		0.2471		0.8673	0.802		tp=0.6, tn=0.1, fp=0.21, fn=0.081		False
	35	0.4398		0.6275		0.5145		0.2478		0.869	0.7988		tp=0.59, tn=0.11, fp=0.22, fn=0.083		False
	36	0.438		0.6161		0.5129		0.2421		0.8688	0.7919		tp=0.58, tn=0.11, fp=0.21, fn=0.096		False
	37	0.4331		0.6309		0.5262		0.2627		0.8719	0.814		tp=0.62, tn=0.093, fp=0.22, fn=0.062		False
	38	0.4334		0.6285		0.5305		0.2551		0.873	0.7927		tp=0.58, tn=0.12, fp=0.2, fn=0.1		False
	39	0.4292		0.6256		0.5356		0.2681		0.8742	0.8056		tp=0.6, tn=0.11, fp=0.2, fn=0.087		False
	40	0.4282		0.6137		0.539		0.2661		0.8744	0.8048		tp=0.6, tn=0.11, fp=0.21, fn=0.084		False
	41	0.426		0.6298		0.5383		0.3027		0.8746	0.8053		tp=0.59, tn=0.13, fp=0.19, fn=0.096		False
	42	0.4259		0.6306		0.5357		0.2582		0.8734	0.8124		tp=0.62, tn=0.095, fp=0.22, fn=0.067		False
	43	0.4223		0.6429		0.5385		0.2538		0.8744	0.8176		tp=0.63, tn=0.083, fp=0.23, fn=0.053		False
	44	0.4197		0.6346		0.5422		0.2605		0.8754	0.809		tp=0.61, tn=0.099, fp=0.22, fn=0.07		False
	45	0.4224		0.6407		0.5253		0.3101		0.8715	0.7979		tp=0.57, tn=0.15, fp=0.18, fn=0.11		True
	46	0.414		0.6459		0.5545		0.2552		0.8778	0.7988		tp=0.59, tn=0.11, fp=0.21, fn=0.086		False
	47	0.413		0.6494		0.5561		0.2521		0.8791	0.7947		tp=0.58, tn=0.12, fp=0.2, fn=0.098		False
	48	0.4076		0.6541		0.5637		0.241		0.8802	0.8008		tp=0.6, tn=0.1, fp=0.22, fn=0.078		False
	49	0.4062		0.6334		0.5682		0.3025		0.8813	0.8061		tp=0.59, tn=0.13, fp=0.18, fn=0.097		False
	50	0.4117		0.6319		0.5478		0.2761		0.8761	0.8076		tp=0.6, tn=0.11, fp=0.2, fn=0.086		False
	51	0.4037		0.6518		0.5686		0.2428		0.8818	0.8074		tp=0.61, tn=0.093, fp=0.22, fn=0.07		False
	52	0.3994		0.658		0.5749		0.2804		0.8833	0.7908		tp=0.56, tn=0.14, fp=0.18, fn=0.12		False
	53	0.3978		0.6607		0.5783		0.2695		0.8834	0.8064		tp=0.6, tn=0.11, fp=0.21, fn=0.08		False
	54	0.3938		0.6509		0.5915		0.2702		0.8875	0.8071		tp=0.6, tn=0.11, fp=0.21, fn=0.08		False
	55	0.3948		0.664		0.5803		0.2799		0.8842	0.7857		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	56	0.394		0.6545		0.5901		0.2696		0.8864	0.8		tp=0.59, tn=0.12, fp=0.2, fn=0.095		False
	57	0.3895		0.6494		0.5815		0.2844		0.8846	0.81		tp=0.6, tn=0.12, fp=0.2, fn=0.084		False
	58	0.3886		0.6548		0.6036		0.2652		0.8907	0.7935		tp=0.57, tn=0.13, fp=0.2, fn=0.1		False
	59	0.3843		0.6574		0.5921		0.3079		0.8875	0.8077		tp=0.59, tn=0.13, fp=0.19, fn=0.095		False
	60	0.3816		0.6654		0.6077		0.2901		0.8912	0.795		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	61	0.3799		0.6594		0.6052		0.3231		0.8904	0.8046		tp=0.58, tn=0.14, fp=0.18, fn=0.099		True
	62	0.3764		0.6687		0.6096		0.3218		0.892	0.8066		tp=0.58, tn=0.14, fp=0.18, fn=0.098		False
	63	0.3757		0.6549		0.6157		0.3127		0.8932	0.8045		tp=0.58, tn=0.14, fp=0.18, fn=0.1		False
	64	0.374		0.6561		0.6167		0.3227		0.8933	0.8082		tp=0.58, tn=0.14, fp=0.18, fn=0.096		False
	65	0.3711		0.6547		0.6162		0.3078		0.8936	0.8069		tp=0.59, tn=0.13, fp=0.19, fn=0.089		False
	66	0.3661		0.6742		0.6304		0.3023		0.8969	0.7979		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	67	0.3705		0.6955		0.618		0.243		0.8936	0.7976		tp=0.59, tn=0.11, fp=0.21, fn=0.086		False
	68	0.3646		0.685		0.6341		0.2954		0.8976	0.8092		tp=0.6, tn=0.12, fp=0.2, fn=0.086		False
	69	0.3608		0.6905		0.6374		0.3102		0.8988	0.8065		tp=0.59, tn=0.13, fp=0.19, fn=0.089		False
	70	0.3579		0.6758		0.6458		0.2904		0.9007	0.802		tp=0.58, tn=0.13, fp=0.18, fn=0.11		False
	71	0.3563		0.6903		0.6422		0.2849		0.9001	0.8044		tp=0.59, tn=0.12, fp=0.2, fn=0.089		False
	72	0.353		0.6817		0.6481		0.2675		0.9015	0.8048		tp=0.6, tn=0.11, fp=0.21, fn=0.083		False
	73	0.3494		0.6839		0.6539		0.2846		0.9029	0.8064		tp=0.59, tn=0.12, fp=0.2, fn=0.089		False
	74	0.3473		0.691		0.6534		0.31		0.9031	0.8037		tp=0.58, tn=0.13, fp=0.19, fn=0.09		False
	75	0.3464		0.6918		0.6579		0.3085		0.9037	0.7958		tp=0.56, tn=0.15, fp=0.17, fn=0.11		False
	76	0.3426		0.6938		0.6687		0.3297		0.9067	0.8042		tp=0.57, tn=0.15, fp=0.17, fn=0.11		True
	77	0.3421		0.6999		0.6559		0.3189		0.9033	0.8094		tp=0.59, tn=0.13, fp=0.19, fn=0.092		False
	78	0.3417		0.7042		0.6629		0.2931		0.9049	0.7963		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	79	0.3368		0.6904		0.6757		0.2593		0.9084	0.8048		tp=0.6, tn=0.11, fp=0.2, fn=0.087		False
	80	0.3431		0.7096		0.6613		0.2874		0.9045	0.804		tp=0.59, tn=0.12, fp=0.2, fn=0.089		False
	81	0.3312		0.6982		0.6792		0.3409		0.9094	0.8174		tp=0.6, tn=0.14, fp=0.18, fn=0.089		True
	82	0.33		0.6922		0.6831		0.3013		0.9103	0.8132		tp=0.6, tn=0.12, fp=0.19, fn=0.083		False
	83	0.3295		0.7067		0.684		0.3371		0.9106	0.7935		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	84	0.3235		0.713		0.6864		0.3074		0.9111	0.8109		tp=0.6, tn=0.13, fp=0.19, fn=0.086		False
	85	0.3221		0.7072		0.6924		0.323		0.9127	0.8041		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	86	0.3186		0.6991		0.6993		0.2824		0.9147	0.8012		tp=0.59, tn=0.12, fp=0.2, fn=0.093		False
	87	0.3182		0.7145		0.7012		0.3367		0.915	0.8042		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	88	0.3166		0.7434		0.6938		0.3199		0.9131	0.7901		tp=0.55, tn=0.16, fp=0.16, fn=0.13		False
	89	0.3101		0.7327		0.7059		0.2578		0.9163	0.8008		tp=0.59, tn=0.11, fp=0.2, fn=0.09		False
	90	0.3106		0.741		0.7116		0.3157		0.9177	0.7958		tp=0.56, tn=0.15, fp=0.17, fn=0.12		False
	91	0.3072		0.7147		0.717		0.3184		0.9193	0.8046		tp=0.58, tn=0.14, fp=0.17, fn=0.11		False
	92	0.3047		0.7189		0.7187		0.328		0.9197	0.7987		tp=0.56, tn=0.16, fp=0.16, fn=0.12		False
	93	0.3021		0.7291		0.7164		0.2885		0.9189	0.808		tp=0.6, tn=0.12, fp=0.19, fn=0.092		False
	94	0.3025		0.7428		0.7218		0.3213		0.9202	0.8012		tp=0.57, tn=0.15, fp=0.18, fn=0.11		False
	95	0.2985		0.7495		0.7209		0.3245		0.9203	0.8017		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	96	0.296		0.7645		0.7313		0.2697		0.9229	0.8024		tp=0.59, tn=0.12, fp=0.2, fn=0.087		False
	97	0.2973		0.7447		0.7199		0.3525		0.92	0.8017		tp=0.56, tn=0.17, fp=0.16, fn=0.12		True
	98	0.2915		0.7307		0.7301		0.3466		0.9226	0.8055		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	99	0.2901		0.7419		0.7455		0.3123		0.9268	0.8097		tp=0.59, tn=0.13, fp=0.19, fn=0.089		False
	100	0.2879		0.7487		0.7366		0.3017		0.9242	0.8061		tp=0.59, tn=0.13, fp=0.19, fn=0.095		False
	101	0.2874		0.7528		0.7436		0.3328		0.9262	0.7865		tp=0.53, tn=0.17, fp=0.15, fn=0.15		False
	102	0.2827		0.736		0.748		0.3183		0.9274	0.8029		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	103	0.281		0.763		0.7472		0.2762		0.9272	0.802		tp=0.59, tn=0.12, fp=0.2, fn=0.095		False
	104	0.2811		0.763		0.748		0.2751		0.9273	0.8028		tp=0.59, tn=0.12, fp=0.2, fn=0.093		False
	105	0.2767		0.7771		0.7475		0.3019		0.9272	0.7983		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	106	0.275		0.7895		0.755		0.2702		0.9293	0.7934		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	107	0.2725		0.7826		0.7574		0.2924		0.9299	0.7895		tp=0.56, tn=0.15, fp=0.17, fn=0.13		False
	108	0.2713		0.7656		0.759		0.333		0.9301	0.8046		tp=0.57, tn=0.15, fp=0.16, fn=0.11		False
	109	0.2695		0.7895		0.7614		0.3131		0.9309	0.7889		tp=0.55, tn=0.16, fp=0.17, fn=0.13		False
	110	0.2659		0.7889		0.7701		0.3351		0.9334	0.7927		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	111	0.2634		0.7826		0.7621		0.3071		0.9311	0.7937		tp=0.56, tn=0.15, fp=0.17, fn=0.12		False
	112	0.2622		0.7788		0.7687		0.3188		0.933	0.8086		tp=0.59, tn=0.14, fp=0.18, fn=0.093		False
	113	0.26		0.8023		0.7804		0.3019		0.9361	0.7992		tp=0.57, tn=0.14, fp=0.19, fn=0.099		False
	114	0.2558		0.7988		0.7798		0.2933		0.9361	0.8004		tp=0.58, tn=0.13, fp=0.19, fn=0.098		False
	115	0.2561		0.7618		0.777		0.3412		0.9351	0.7987		tp=0.56, tn=0.16, fp=0.16, fn=0.12		False
	116	0.2533		0.7706		0.7819		0.336		0.9365	0.8013		tp=0.56, tn=0.16, fp=0.16, fn=0.12		False
	117	0.2533		0.8232		0.7775		0.2963		0.9354	0.8008		tp=0.58, tn=0.13, fp=0.18, fn=0.1		False
	118	0.2489		0.7916		0.7937		0.3181		0.9399	0.7906		tp=0.55, tn=0.16, fp=0.16, fn=0.13		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		100
learning rate		0.00081799739408
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_115-lr0.00082-h_size100-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7		0.7029		-0.0106		0.1384		0.3385	0.3107		tp=0.11, tn=0.39, fp=0.042, fn=0.45		True
	2	0.6926		0.7018		-0.005209		0.1748		0.4382	0.32		tp=0.11, tn=0.41, fp=0.035, fn=0.44		True
	3	0.69		0.6825		0.03761		-0.002187		0.4751	0.686		tp=0.5, tn=0.049, fp=0.39, fn=0.063		False
	4	0.6863		0.6966		0.07164		0.153		0.4177	0.3366		tp=0.12, tn=0.41, fp=0.049, fn=0.42		False
	5	0.686		0.6885		0.06781		0.1309		0.3298	0.4628		tp=0.2, tn=0.35, fp=0.11, fn=0.34		False
	6	0.6896		0.6997		0.08397		0.1724		0.4496	0.3462		tp=0.13, tn=0.4, fp=0.042, fn=0.43		False
	7	0.6849		0.6954		0.115		0.1731		0.595	0.3725		tp=0.13, tn=0.42, fp=0.056, fn=0.39		False
	8	0.686		0.6962		0.09623		0.1818		0.4823	0.3689		tp=0.13, tn=0.41, fp=0.049, fn=0.41		True
	9	0.6889		0.6932		0.02368		0.2251		0.4399	0.4		tp=0.15, tn=0.41, fp=0.042, fn=0.4		True
	10	0.6835		0.6854		0.08413		-0.04848		0.4356	0.5488		tp=0.31, tn=0.17, fp=0.31, fn=0.21		False
	11	0.6835		0.6972		0.09342		0.2206		0.446	0.4364		tp=0.17, tn=0.4, fp=0.056, fn=0.38		False
	12	0.6923		0.7054		0.04947		0.1983		0.4815	0.3689		tp=0.13, tn=0.41, fp=0.042, fn=0.41		False
	13	0.6805		0.6954		0.1075		0.2474		0.5612	0.4786		tp=0.2, tn=0.38, fp=0.056, fn=0.37		True
	14	0.68		0.6861		0.1134		-0.02324		0.4366	0.5943		tp=0.36, tn=0.14, fp=0.32, fn=0.17		False
	15	0.6793		0.6828		0.09009		-0.06398		0.4663	0.5698		tp=0.34, tn=0.14, fp=0.32, fn=0.2		False
	16	0.6829		0.6907		0.06217		-0.03263		0.426	0.6354		tp=0.43, tn=0.084, fp=0.38, fn=0.11		False
	17	0.6872		0.6881		0.05271		-0.04905		0.4873	0.5375		tp=0.3, tn=0.18, fp=0.27, fn=0.24		False
	18	0.6813		0.6912		0.06232		0.1429		0.5308	0.5468		tp=0.27, tn=0.29, fp=0.15, fn=0.29		False
	19	0.6769		0.7046		0.1138		0.1828		0.5452	0.3853		tp=0.15, tn=0.38, fp=0.049, fn=0.42		False
	20	0.676		0.7028		0.1546		0.1302		0.4965	0.459		tp=0.2, tn=0.34, fp=0.1, fn=0.36		False
	21	0.6735		0.6941		0.1264		-0.05906		0.5155	0.5223		tp=0.29, tn=0.19, fp=0.26, fn=0.27		False
	22	0.6727		0.6972		0.09966		0.1476		0.5032	0.4839		tp=0.21, tn=0.34, fp=0.11, fn=0.34		False
	23	0.6838		0.696		0.06396		-0.003477		0.4838	0.5977		tp=0.36, tn=0.15, fp=0.3, fn=0.19		False
	24	0.6762		0.701		0.06974		-0.04441		0.4837	0.6731		tp=0.49, tn=0.035, fp=0.42, fn=0.056		False
	25	0.6751		0.741		0.1497		0.139		0.5697	0.1395		tp=0.042, tn=0.44, fp=0.007, fn=0.51		False
	26	0.685		0.7288		0.1307		0.1579		0.5702	0.1609		tp=0.049, tn=0.44, fp=0.007, fn=0.5		False
	27	0.6807		0.7094		0.05745		0.1469		0.4702	0.3333		tp=0.12, tn=0.41, fp=0.049, fn=0.43		False
	28	0.6722		0.6881		0.1473		-0.02432		0.5338	0.561		tp=0.32, tn=0.17, fp=0.29, fn=0.22		False
	29	0.6718		0.6849		0.1237		-0.01157		0.4826	0.6417		tp=0.42, tn=0.11, fp=0.31, fn=0.16		False
	30	0.6699		0.7152		0.1465		0.1407		0.5663	0.303		tp=0.1, tn=0.41, fp=0.042, fn=0.44		False
	31	0.6719		0.6983		0.1432		-0.03349		0.4767	0.5409		tp=0.3, tn=0.19, fp=0.27, fn=0.24		False
	32	0.6799		0.7042		0.08086		0.1307		0.5221	0.3333		tp=0.12, tn=0.41, fp=0.056, fn=0.42		False
	33	0.6777		0.7071		0.07858		0.07131		0.486	0.4603		tp=0.2, tn=0.32, fp=0.15, fn=0.33		False
	34	0.6705		0.7007		0.1412		0.1029		0.5953	0.539		tp=0.27, tn=0.28, fp=0.17, fn=0.28		False


data			/scratch/asw462/data/levin
input size		300
hidden size		167
learning rate		0.000257143929518
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_116-lr0.00026-h_size167-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5882		0.5793		-0.02925		0		0.8369	0.834		tp=0.72, tn=0, fp=0.28, fn=0		False
	2	0.5711		0.5858		0		0		0.8412	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	3	0.5573		0.5807		0		0		0.843	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	4	0.5455		0.5628		0.04351		0		0.8444	0.8468		tp=0.73, tn=0, fp=0.27, fn=0		False
	5	0.5412		0.5889		0.1173		0			0.843	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	6	0.5329		0.5896		0.1566		0.1606		0.8443	0.8255		tp=0.67, tn=0.042, fp=0.25, fn=0.035		True
	7	0.5185		0.5768		0.2177		0.1259		0.8487	0.8216		tp=0.69, tn=0.007, fp=0.3, fn=0		False
	8	0.5091		0.5779		0.2609		0.2624		0.852	0.8312		tp=0.67, tn=0.056, fp=0.25, fn=0.021		True
	9	0.4952		0.5706		0.2719		0.2383		0.8529	0.8305		tp=0.69, tn=0.035, fp=0.27, fn=0.007		False
	10	0.4802		0.5501		0.331		0.1829		0.8628	0.8368		tp=0.69, tn=0.035, fp=0.25, fn=0.021		False
	11	0.4741		0.5791		0.3421		0.2592		0.8626	0.8291		tp=0.67, tn=0.049, fp=0.26, fn=0.014		False
	12	0.4618		0.5634		0.4011		0.2878		0.8693	0.8511		tp=0.7, tn=0.056, fp=0.22, fn=0.021		True
	13	0.4557		0.5799		0.4102		0.19		0.8697	0.834		tp=0.69, tn=0.042, fp=0.24, fn=0.028		False
	14	0.4477		0.5794		0.4572		0.1596		0.8768	0.824		tp=0.67, tn=0.042, fp=0.25, fn=0.035		False
	15	0.4421		0.5717		0.4857		0.1474		0.8819	0.8368		tp=0.7, tn=0.028, fp=0.25, fn=0.021		False
	16	0.4289		0.5462		0.4766		0.3056		0.8801	0.8295		tp=0.63, tn=0.11, fp=0.17, fn=0.091		True
	17	0.4222		0.6044		0.4895		0.1547		0.8825	0.8089		tp=0.64, tn=0.063, fp=0.23, fn=0.07		False
	18	0.4201		0.5885		0.4919		0.2865		0.8816	0.8095		tp=0.59, tn=0.13, fp=0.16, fn=0.12		False
	19	0.411		0.6004		0.5109		0.3224		0.8835	0.8241		tp=0.62, tn=0.11, fp=0.2, fn=0.063		True
	20	0.4078		0.6135		0.507		0.3224		0.8851	0.819		tp=0.6, tn=0.13, fp=0.15, fn=0.11		True
	21	0.4004		0.6491		0.5384		0.3051		0.8887	0.8131		tp=0.61, tn=0.11, fp=0.22, fn=0.063		False
	22	0.3926		0.6746		0.548		0.217		0.8927	0.8261		tp=0.66, tn=0.056, fp=0.24, fn=0.035		False
	23	0.3822		0.6604		0.5628		0.2554		0.8951	0.8198		tp=0.64, tn=0.084, fp=0.22, fn=0.056		False
	24	0.3775		0.6341		0.5774		0.2428		0.897	0.8319		tp=0.66, tn=0.077, fp=0.2, fn=0.063		False
	25	0.3706		0.6625		0.6068		0.2071		0.9042	0.8297		tp=0.66, tn=0.069, fp=0.2, fn=0.069		False
	26	0.3698		0.7455		0.5962		0.2803		0.9016	0.8198		tp=0.64, tn=0.084, fp=0.24, fn=0.042		False
	27	0.3674		0.6568		0.6041		0.3511		0.9011	0.843		tp=0.66, tn=0.098, fp=0.2, fn=0.042		True
	28	0.3566		0.7059		0.5973		0.2719		0.9022	0.8182		tp=0.63, tn=0.091, fp=0.22, fn=0.056		False
	29	0.3621		0.6246		0.6001		0.3309		0.9006	0.8402		tp=0.64, tn=0.11, fp=0.16, fn=0.084		False
	30	0.3505		0.6309		0.6294		0.3267		0.9074	0.8364		tp=0.64, tn=0.1, fp=0.19, fn=0.063		False
	31	0.3474		0.6715		0.6401		0.3166		0.9116	0.8407		tp=0.66, tn=0.09, fp=0.2, fn=0.049		False
	32	0.3389		0.7142		0.6527		0.261		0.9129	0.8235		tp=0.64, tn=0.091, fp=0.2, fn=0.07		False
	33	0.3363		0.6906		0.6377		0.3536		0.9091	0.8333		tp=0.63, tn=0.12, fp=0.19, fn=0.063		True
	34	0.3263		0.7252		0.6615		0.2964		0.9151	0.8341		tp=0.65, tn=0.091, fp=0.2, fn=0.056		False
	35	0.3205		0.6633		0.6751		0.3596		0.9189	0.8455		tp=0.65, tn=0.11, fp=0.17, fn=0.063		True
	36	0.3271		0.7026		0.6536		0.3107		0.9124	0.8295		tp=0.63, tn=0.11, fp=0.17, fn=0.084		False
	37	0.3219		0.6923		0.6699		0.35		0.916	0.8402		tp=0.64, tn=0.11, fp=0.18, fn=0.063		False
	38	0.3176		0.7509		0.6633		0.4021		0.9149	0.8411		tp=0.62, tn=0.14, fp=0.17, fn=0.069		True
	39	0.3131		0.719		0.6658		0.3431		0.9148	0.8246		tp=0.61, tn=0.13, fp=0.17, fn=0.091		False
	40	0.31		0.751		0.691		0.3235		0.9213	0.8295		tp=0.63, tn=0.11, fp=0.19, fn=0.07		False
	41	0.3035		0.7555		0.6852		0.3359		0.9205	0.8416		tp=0.65, tn=0.1, fp=0.18, fn=0.063		False
	42	0.3085		0.7767		0.6605		0.1863		0.9142	0.7411		tp=0.51, tn=0.14, fp=0.15, fn=0.21		False
	43	0.305		0.7966		0.6789		0.3224		0.9183	0.819		tp=0.6, tn=0.13, fp=0.15, fn=0.11		False
	44	0.3039		0.75		0.6685		0.2939		0.915	0.8		tp=0.57, tn=0.14, fp=0.15, fn=0.14		False
	45	0.2938		0.7664		0.6936		0.3166		0.9222	0.8295		tp=0.63, tn=0.11, fp=0.18, fn=0.077		False
	46	0.293		0.7454		0.6832		0.3258		0.9188	0.802		tp=0.57, tn=0.15, fp=0.14, fn=0.14		False
	47	0.2979		0.8093		0.6957		0.2682		0.9202	0.8485		tp=0.69, tn=0.07, fp=0.2, fn=0.049		False
	48	0.2965		0.7801		0.6755		0.253		0.9177	0.8		tp=0.59, tn=0.12, fp=0.17, fn=0.12		False
	49	0.285		0.7664		0.7102		0.3486		0.9247	0.8482		tp=0.66, tn=0.098, fp=0.19, fn=0.049		False
	50	0.2853		0.845		0.7074		0.3071		0.9252	0.8241		tp=0.62, tn=0.11, fp=0.19, fn=0.077		False
	51	0.2842		0.894		0.7084		0.284		0.9234	0.8057		tp=0.59, tn=0.12, fp=0.18, fn=0.1		False
	52	0.2794		0.8664		0.699		0.2981		0.9241	0.8		tp=0.57, tn=0.14, fp=0.17, fn=0.12		False
	53	0.2817		0.8865		0.6956		0.3087		0.9211	0.8257		tp=0.63, tn=0.1, fp=0.2, fn=0.063		False
	54	0.2761		0.8524		0.7126		0.2757		0.9259	0.8038		tp=0.59, tn=0.13, fp=0.17, fn=0.12		False
	55	0.2821		0.8288		0.7078		0.3582		0.9236	0.8302		tp=0.62, tn=0.13, fp=0.17, fn=0.084		False
	56	0.2744		0.9107		0.6939		0.3212		0.9215	0.8208		tp=0.61, tn=0.13, fp=0.17, fn=0.091		False
	57	0.2684		0.8934		0.742		0.3228		0.9326	0.8224		tp=0.61, tn=0.12, fp=0.17, fn=0.09		False
	58	0.2705		0.7492		0.7209		0.3756		0.9275	0.8622		tp=0.68, tn=0.1, fp=0.15, fn=0.063		False
	59	0.2627		0.8943		0.7397		0.2934		0.933	0.7921		tp=0.56, tn=0.15, fp=0.16, fn=0.13		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		13
learning rate		0.00322345243292
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_117-lr0.0032-h_size13-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6939		0.6859		0.06273		0.1516		0.5648	0.2902		tp=0.094, tn=0.44, fp=0.038, fn=0.42		True
	2	0.6659		0.667		0.2108		0.1606		0.6198	0.6318		tp=0.36, tn=0.23, fp=0.24, fn=0.17		True
	3	0.6361		0.6589		0.2629		0.22		0.6412	0.6622		tp=0.38, tn=0.23, fp=0.24, fn=0.15		True
	4	0.6062		0.6753		0.3499		0.1946		0.6866	0.6652		tp=0.4, tn=0.2, fp=0.27, fn=0.13		False
	5	0.5776		0.675		0.394		0.2506		0.7095	0.5924		tp=0.28, tn=0.34, fp=0.13, fn=0.26		True
	6	0.5674		0.6799		0.4108		0.2337		0.7113	0.6574		tp=0.36, tn=0.26, fp=0.21, fn=0.17		False
	7	0.5662		0.7232		0.4035		0.1129		0.7158	0.378		tp=0.14, tn=0.39, fp=0.085, fn=0.38		False
	8	0.5369		0.6879		0.4604		0.2384		0.7347	0.6621		tp=0.37, tn=0.25, fp=0.21, fn=0.17		False
	9	0.5205		0.6995		0.4925		0.2096		0.7549	0.628		tp=0.33, tn=0.27, fp=0.2, fn=0.19		False
	10	0.4964		0.7032		0.5244		0.2299		0.7686	0.6411		tp=0.34, tn=0.27, fp=0.2, fn=0.18		False
	11	0.477		0.7863		0.5538		0.2607		0.7826	0.5763		tp=0.26, tn=0.35, fp=0.11, fn=0.28		True
	12	0.4557		0.7152		0.5793		0.2402		0.7959	0.659		tp=0.37, tn=0.26, fp=0.23, fn=0.15		False
	13	0.4366		0.7372		0.616		0.2142		0.8133	0.6222		tp=0.32, tn=0.28, fp=0.2, fn=0.19		False
	14	0.421		0.8043		0.6171		0.2087		0.8134	0.6244		tp=0.33, tn=0.28, fp=0.19, fn=0.21		False
	15	0.4081		0.8348		0.629		0.1962		0.8191	0.6005		tp=0.3, tn=0.29, fp=0.18, fn=0.22		False
	16	0.386		0.8533		0.6654		0.2097		0.8384	0.6225		tp=0.33, tn=0.28, fp=0.18, fn=0.21		False
	17	0.3694		0.8919		0.6964		0.2041		0.8518	0.6139		tp=0.32, tn=0.29, fp=0.19, fn=0.21		False
	18	0.3423		0.847		0.7218		0.2051		0.864	0.6419		tp=0.35, tn=0.25, fp=0.22, fn=0.17		False
	19	0.3299		0.8928		0.7312		0.2003		0.8684	0.6025		tp=0.3, tn=0.3, fp=0.18, fn=0.22		False
	20	0.2942		0.9228		0.7809		0.2448		0.8931	0.6388		tp=0.33, tn=0.29, fp=0.18, fn=0.19		False
	21	0.293		0.9776		0.775		0.2463		0.8902	0.654		tp=0.35, tn=0.27, fp=0.19, fn=0.18		False
	22	0.2635		0.9834		0.8119		0.2542		0.9084	0.6166		tp=0.3, tn=0.32, fp=0.15, fn=0.23		False
	23	0.258		1.016		0.8225		0.2082		0.9136	0.6244		tp=0.33, tn=0.28, fp=0.2, fn=0.2		False
	24	0.2345		1.044		0.8529		0.2357		0.9279	0.6303		tp=0.33, tn=0.29, fp=0.18, fn=0.2		False
	25	0.2148		1.067		0.8694		0.21		0.9359	0.6096		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	26	0.2052		1.07		0.8889		0.2124		0.9453	0.6111		tp=0.31, tn=0.3, fp=0.19, fn=0.2		False
	27	0.1898		1.116		0.8943		0.2234		0.9482	0.6512		tp=0.36, tn=0.26, fp=0.21, fn=0.18		False
	28	0.1859		1.186		0.8943		0.1943		0.9482	0.6338		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	29	0.1705		1.22		0.9138		0.1537		0.9577	0.615		tp=0.34, tn=0.24, fp=0.23, fn=0.19		False
	30	0.1582		1.172		0.9196		0.2007		0.9604	0.6195		tp=0.32, tn=0.28, fp=0.19, fn=0.21		False
	31	0.1518		1.207		0.925		0.2452		0.9632	0.637		tp=0.33, tn=0.29, fp=0.18, fn=0.19		False
	32	0.1428		1.232		0.938		0.2592		0.9696	0.5995		tp=0.28, tn=0.34, fp=0.14, fn=0.24		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		115
learning rate		7.92795169704e&05
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_118-lr7.9e&05-h_size115-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6907		0.685		0.05976		0.1225		0.5519	0.6256		tp=0.36, tn=0.2, fp=0.27, fn=0.17		True
	2	0.6841		0.6826		0.1093		0.09668		0.6208	0.5215		tp=0.25, tn=0.3, fp=0.18, fn=0.27		False
	3	0.6804		0.6776		0.1358		0.1576		0.5779	0.6598		tp=0.41, tn=0.17, fp=0.3, fn=0.12		True
	4	0.6771		0.6775		0.1598		0.1247		0.5973	0.6427		tp=0.39, tn=0.18, fp=0.29, fn=0.14		False
	5	0.6753		0.6765		0.1589		0.09968		0.6193	0.5823		tp=0.31, tn=0.24, fp=0.25, fn=0.2		False
	6	0.6733		0.6778		0.1646		0.0817		0.6016	0.5917		tp=0.33, tn=0.21, fp=0.27, fn=0.19		False
	7	0.6719		0.6725		0.1647		0.1314		0.6034	0.6147		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	8	0.6706		0.674		0.18		0.1199		0.6096	0.6171		tp=0.35, tn=0.21, fp=0.26, fn=0.17		False
	9	0.6688		0.6739		0.1914		0.1136		0.6187	0.6109		tp=0.35, tn=0.21, fp=0.26, fn=0.18		False
	10	0.6679		0.6767		0.1867		0.08202		0.6184	0.5782		tp=0.31, tn=0.23, fp=0.24, fn=0.21		False
	11	0.6663		0.6735		0.1902		0.1291		0.6132	0.6202		tp=0.35, tn=0.21, fp=0.26, fn=0.17		False
	12	0.6652		0.6739		0.2022		0.1055		0.6256	0.5967		tp=0.33, tn=0.23, fp=0.24, fn=0.2		False
	13	0.6639		0.6704		0.2096		0.1285		0.6209	0.6216		tp=0.35, tn=0.22, fp=0.25, fn=0.18		False
	14	0.663		0.6728		0.2094		0.09685		0.629	0.5995		tp=0.33, tn=0.22, fp=0.24, fn=0.2		False
	15	0.6613		0.6693		0.2181		0.1469		0.6297	0.6405		tp=0.38, tn=0.2, fp=0.28, fn=0.15		False
	16	0.661		0.6779		0.2199		0.09184		0.6341	0.6		tp=0.34, tn=0.21, fp=0.27, fn=0.18		False
	17	0.6594		0.668		0.2064		0.1218		0.6283	0.5778		tp=0.3, tn=0.26, fp=0.22, fn=0.22		False
	18	0.6589		0.6729		0.2186		0.09781		0.6246	0.6081		tp=0.35, tn=0.21, fp=0.26, fn=0.18		False
	19	0.657		0.6707		0.2209		0.1134		0.6312	0.6055		tp=0.34, tn=0.22, fp=0.25, fn=0.19		False
	20	0.6564		0.6774		0.2107		0.1224		0.6318	0.5778		tp=0.3, tn=0.26, fp=0.21, fn=0.23		False
	21	0.6558		0.6704		0.23		0.1175		0.6345	0.5924		tp=0.32, tn=0.24, fp=0.23, fn=0.21		False
	22	0.6542		0.6702		0.2303		0.124		0.6312	0.6101		tp=0.34, tn=0.23, fp=0.24, fn=0.19		False
	23	0.6541		0.677		0.2223		0.1325		0.6332	0.6233		tp=0.36, tn=0.21, fp=0.27, fn=0.16		False
	24	0.6525		0.6705		0.2437		0.1287		0.6478	0.575		tp=0.29, tn=0.27, fp=0.2, fn=0.23		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		29
learning rate		0.000464576280433
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_119-lr0.00046-h_size29-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6933		0.6915		0.005827		0.07785		0.5802	0.28		tp=0.098, tn=0.4, fp=0.056, fn=0.45		True
	2	0.6807		0.6787		0.1499		0.271		0.3165	0.7174		tp=0.46, tn=0.17, fp=0.29, fn=0.077		True
	3	0.6692		0.6829		0.3013		0.1695		0.6789	0.5481		tp=0.26, tn=0.31, fp=0.14, fn=0.29		False
	4	0.6558		0.6779		0.337		0.1915		0.5863	0.5312		tp=0.24, tn=0.34, fp=0.12, fn=0.3		False
	5	0.6457		0.6835		0.3772		0.1246		0.6502	0.5324		tp=0.26, tn=0.29, fp=0.14, fn=0.31		False
	6	0.6338		0.6696		0.413		0.2691		0.71	0.6345		tp=0.32, tn=0.31, fp=0.14, fn=0.23		False
	7	0.6245		0.6756		0.4		0.1381		0.6555	0.48		tp=0.21, tn=0.34, fp=0.11, fn=0.34		False
	8	0.6092		0.657		0.436		0.2038		0.6862	0.5972		tp=0.3, tn=0.29, fp=0.15, fn=0.26		False
	9	0.5982		0.6608		0.4652		0.1745		0.7044	0.5652		tp=0.27, tn=0.31, fp=0.15, fn=0.27		False
	10	0.5847		0.6618		0.4658		0.1752		0.7191	0.5714		tp=0.28, tn=0.3, fp=0.15, fn=0.27		False
	11	0.572		0.6462		0.4842		0.172		0.7224	0.5674		tp=0.28, tn=0.29, fp=0.14, fn=0.29		False
	12	0.5632		0.6556		0.4903		0.1946		0.7247	0.5972		tp=0.3, tn=0.29, fp=0.17, fn=0.24		False
	13	0.5528		0.6482		0.4598		0.1658		0.7169	0.6289		tp=0.35, tn=0.24, fp=0.19, fn=0.22		False
	14	0.5365		0.6894		0.4981		0.1362		0.7413	0.4961		tp=0.22, tn=0.32, fp=0.12, fn=0.34		False
	15	0.5274		0.6837		0.5282		0.1155		0.7473	0.5113		tp=0.24, tn=0.31, fp=0.15, fn=0.31		False
	16	0.5141		0.6552		0.533		0.2057		0.7428	0.6027		tp=0.31, tn=0.29, fp=0.15, fn=0.25		False
	17	0.5021		0.694		0.5627		0.1586		0.7753	0.5231		tp=0.24, tn=0.33, fp=0.13, fn=0.3		False
	18	0.4901		0.6702		0.5638		0.2037		0.7654	0.6543		tp=0.37, tn=0.24, fp=0.21, fn=0.18		False
	19	0.486		0.6715		0.5716		0.1966		0.7754	0.6369		tp=0.35, tn=0.25, fp=0.18, fn=0.22		False
	20	0.475		0.6822		0.5776		0.1865		0.7771	0.6184		tp=0.33, tn=0.27, fp=0.22, fn=0.19		False
	21	0.4611		0.6978		0.6057		0.12		0.7861	0.5772		tp=0.3, tn=0.26, fp=0.2, fn=0.24		False
	22	0.452		0.6928		0.6128		0.1912		0.7963	0.5522		tp=0.26, tn=0.32, fp=0.13, fn=0.29		False
	23	0.4421		0.7003		0.6394		0.1266		0.8099	0.5772		tp=0.3, tn=0.26, fp=0.19, fn=0.24		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		134
learning rate		0.00141425874937
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_11-lr0.0014-h_size134-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6802		0.6343		0.1329		0.2531		0.5369	0.7079		tp=0.44, tn=0.2, fp=0.25, fn=0.11		True
	2	0.6321		0.6083		0.3188		0.3265		0.6453	0.7391		tp=0.48, tn=0.19, fp=0.27, fn=0.07		True
	3	0.6195		0.6081		0.2798		0.3334		0.6621	0.6525		tp=0.32, tn=0.34, fp=0.11, fn=0.23		True
	4	0.6244		0.604		0.2925		0.3451		0.6156	0.716		tp=0.41, tn=0.27, fp=0.16, fn=0.16		True
	5	0.578		0.6462		0.3959		0.2565		0.7117	0.4404		tp=0.17, tn=0.41, fp=0.042, fn=0.38		False
	6	0.5438		0.5867		0.4438		0.3651		0.7214	0.7134		tp=0.39, tn=0.29, fp=0.17, fn=0.15		True
	7	0.5201		0.5951		0.4959		0.3708		0.7448	0.7594		tp=0.5, tn=0.19, fp=0.26, fn=0.056		True
	8	0.5572		0.5965		0.3874		0.381		0.6904	0.7732		tp=0.52, tn=0.17, fp=0.27, fn=0.042		True
	9	0.5158		0.6366		0.4697		0.3466		0.7326	0.5902		tp=0.25, tn=0.4, fp=0.07, fn=0.28		False
	10	0.4673		0.6144		0.5729		0.3284		0.7859	0.6842		tp=0.36, tn=0.3, fp=0.15, fn=0.19		False
	11	0.4478		0.7304		0.6025		0.2876		0.8012	0.5		tp=0.2, tn=0.39, fp=0.049, fn=0.36		False
	12	0.492		0.6958		0.5162		0.2953		0.7541	0.5528		tp=0.24, tn=0.38, fp=0.07, fn=0.31		False
	13	0.4627		0.6568		0.5423		0.2913		0.7658	0.6531		tp=0.34, tn=0.31, fp=0.15, fn=0.21		False
	14	0.4072		0.6385		0.6636		0.3027		0.8306	0.6575		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	15	0.3919		0.6546		0.6399		0.3474		0.8183	0.7125		tp=0.4, tn=0.28, fp=0.16, fn=0.16		False
	16	0.3789		0.7015		0.6627		0.3029		0.8233	0.6389		tp=0.32, tn=0.32, fp=0.11, fn=0.25		False
	17	0.3773		0.705		0.6425		0.325		0.819	0.6324		tp=0.3, tn=0.35, fp=0.1, fn=0.24		False
	18	0.3321		0.7205		0.719		0.3438		0.858	0.6803		tp=0.35, tn=0.32, fp=0.15, fn=0.18		False
	19	0.3165		0.975		0.7309		0.1496		0.8643	0.4138		tp=0.17, tn=0.36, fp=0.07, fn=0.41		False
	20	0.3737		0.8671		0.6595		0.3155		0.8248	0.7461		tp=0.5, tn=0.15, fp=0.29, fn=0.049		False
	21	0.3313		0.8911		0.7007		0.2588		0.8464	0.5042		tp=0.21, tn=0.38, fp=0.063, fn=0.35		False
	22	0.3219		0.7757		0.722		0.3291		0.8597	0.7186		tp=0.42, tn=0.25, fp=0.2, fn=0.13		False
	23	0.2959		0.9824		0.7688		0.2384		0.883	0.4602		tp=0.18, tn=0.39, fp=0.056, fn=0.37		False
	24	0.3321		1.264		0.6921		0.1923		0.8387	0.3168		tp=0.11, tn=0.41, fp=0.028, fn=0.45		False
	25	0.3094		0.8029		0.7566		0.3486		0.8759	0.6887		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	26	0.2825		0.7809		0.7713		0.3169		0.8836	0.7037		tp=0.4, tn=0.27, fp=0.17, fn=0.16		False
	27	0.2685		0.9212		0.7861		0.2973		0.8912	0.6383		tp=0.31, tn=0.33, fp=0.13, fn=0.22		False
	28	0.2369		0.9607		0.8564		0.3336		0.9268	0.5984		tp=0.27, tn=0.38, fp=0.077, fn=0.28		False
	29	0.2344		0.8919		0.8181		0.3119		0.9069	0.6797		tp=0.36, tn=0.29, fp=0.16, fn=0.18		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		13
learning rate		0.000470153056175
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_120-lr0.00047-h_size13-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6957		0.6859		-0.007905		-0.06905		0.2899	0.6794		tp=0.49, tn=0.042, fp=0.38, fn=0.083		False
	2	0.6939		0.6938		0.02825		0.1053		0.523	0.367		tp=0.14, tn=0.38, fp=0.077, fn=0.41		True
	3	0.6903		0.6937		0.06686		0.09321		0.287	0.367		tp=0.14, tn=0.38, fp=0.084, fn=0.4		False
	4	0.6898		0.6876		0.05889		0.1291		0.3992	0.4961		tp=0.22, tn=0.32, fp=0.13, fn=0.33		True
	5	0.6892		0.6891		0.0625		0.1722		0.374	0.4576		tp=0.19, tn=0.36, fp=0.084, fn=0.36		True
	6	0.6896		0.6876		0.03933		0.1849		0.3786	0.4706		tp=0.2, tn=0.36, fp=0.084, fn=0.36		True
	7	0.6876		0.694		0.09639		0.1517		0.3889	0.4071		tp=0.16, tn=0.37, fp=0.07, fn=0.4		False
	8	0.6879		0.6899		0.09423		0.1261		0.4232	0.45		tp=0.19, tn=0.35, fp=0.1, fn=0.36		False
	9	0.6875		0.6933		0.06833		0.09244		0.3212	0.375		tp=0.15, tn=0.36, fp=0.084, fn=0.41		False
	10	0.6869		0.6878		0.07212		0.1339		0.3931	0.464		tp=0.2, tn=0.33, fp=0.098, fn=0.37		False
	11	0.6893		0.6911		0.06259		0.1667		0.2895	0.437		tp=0.18, tn=0.35, fp=0.07, fn=0.4		False
	12	0.6865		0.6858		0.1149		0.1441		0.615	0.4754		tp=0.2, tn=0.35, fp=0.11, fn=0.34		False
	13	0.685		0.6926		0.06337		0.1333		0.3457	0.3964		tp=0.15, tn=0.38, fp=0.077, fn=0.39		False
	14	0.6853		0.6897		0.09311		0.1705		0.3857	0.4444		tp=0.18, tn=0.36, fp=0.077, fn=0.38		False
	15	0.6855		0.6871		0.0914		0.1867		0.3254	0.4576		tp=0.19, tn=0.37, fp=0.076, fn=0.37		True
	16	0.6863		0.687		0.06336		0.1223		0.4718	0.5429		tp=0.27, tn=0.29, fp=0.16, fn=0.29		False
	17	0.6852		0.6895		0.08927		0.2129		0.3453	0.4464		tp=0.17, tn=0.39, fp=0.063, fn=0.37		True
	18	0.6827		0.6872		0.1054		0.1743		0.4078	0.4918		tp=0.21, tn=0.36, fp=0.1, fn=0.33		False
	19	0.6831		0.6861		0.1107		0.2306		0.3896	0.4874		tp=0.2, tn=0.38, fp=0.069, fn=0.35		True
	20	0.6854		0.6887		0.08846		0.215		0.5606	0.4746		tp=0.2, tn=0.37, fp=0.07, fn=0.36		False
	21	0.6828		0.6965		0.1028		0.1754		0.3304	0.3654		tp=0.13, tn=0.41, fp=0.049, fn=0.41		False
	22	0.6823		0.6864		0.1283		-0.0413		0.459	0.5521		tp=0.31, tn=0.17, fp=0.26, fn=0.25		False
	23	0.682		0.6871		0.1146		0.179		0.4215	0.4793		tp=0.2, tn=0.36, fp=0.091, fn=0.35		False
	24	0.681		0.6946		0.09013		0.1936		0.455	0.4483		tp=0.18, tn=0.38, fp=0.069, fn=0.38		False
	25	0.6824		0.6885		0.1099		0.1155		0.3377	0.5113		tp=0.24, tn=0.31, fp=0.15, fn=0.31		False
	26	0.6815		0.6909		0.0981		0.2105		0.569	0.4828		tp=0.2, tn=0.38, fp=0.084, fn=0.34		False
	27	0.6827		0.6826		0.1169		0.02126		0.3984	0.6		tp=0.36, tn=0.17, fp=0.28, fn=0.2		False
	28	0.6799		0.6948		0.1316		0.1412		0.5569	0.4211		tp=0.17, tn=0.37, fp=0.084, fn=0.38		False
	29	0.679		0.6955		0.09961		0.1866		0.4516	0.4522		tp=0.18, tn=0.38, fp=0.077, fn=0.36		False
	30	0.6788		0.6924		0.1165		0.215		0.4395	0.4746		tp=0.2, tn=0.37, fp=0.07, fn=0.36		False
	31	0.6789		0.6821		0.1116		0.02126		0.4702	0.6		tp=0.36, tn=0.17, fp=0.28, fn=0.2		False
	32	0.6786		0.6849		0.1241		0.06089		0.4735	0.5621		tp=0.3, tn=0.23, fp=0.21, fn=0.26		False
	33	0.6773		0.6889		0.1211		0.1248		0.4708	0.5294		tp=0.25, tn=0.3, fp=0.15, fn=0.29		False
	34	0.6763		0.6915		0.1532		0.0984		0.5294	0.5638		tp=0.29, tn=0.25, fp=0.18, fn=0.27		False
	35	0.6778		0.6949		0.0946		0.1005		0.5172	0.4923		tp=0.22, tn=0.31, fp=0.15, fn=0.31		False
	36	0.6757		0.6963		0.1345		0.175		0.4308	0.4706		tp=0.2, tn=0.36, fp=0.091, fn=0.35		False
	37	0.6762		0.6911		0.1118		0.1659		0.516	0.4522		tp=0.18, tn=0.38, fp=0.091, fn=0.35		False
	38	0.6765		0.6941		0.1213		-0.06425		0.467	0.5399		tp=0.31, tn=0.17, fp=0.3, fn=0.22		False
	39	0.6745		0.7		0.1286		0.1831		0.5547	0.4576		tp=0.19, tn=0.36, fp=0.077, fn=0.37		False
	40	0.6767		0.7077		0.1087		0.1863		0.5121	0.4107		tp=0.16, tn=0.38, fp=0.056, fn=0.41		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		189
learning rate		0.000107730095701
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_121-lr0.00011-h_size189-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6178		0.6492		0.006375		0		0.8159	0.8085		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5903		0.6319		0.06845		0		0.8191	0.8064		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.5727		0.6299		0.1668		0.1051		0.823	0.7906		tp=0.62, tn=0.052, fp=0.27, fn=0.062		True
	4	0.5502		0.6204		0.2385		0.115		0.8292	0.8011		tp=0.64, tn=0.036, fp=0.29, fn=0.033		True
	5	0.5331		0.6444		0.3083		0.05759		0.8367	0.8082		tp=0.67, tn=0.013, fp=0.3, fn=0.015		False
	6	0.5106		0.6202		0.3517		0.1601		0.8429	0.7942		tp=0.61, tn=0.071, fp=0.25, fn=0.071		True
	7	0.4926		0.6427		0.4135		0.1688		0.8517	0.8026		tp=0.63, tn=0.056, fp=0.27, fn=0.044		True
	8	0.4815		0.6512		0.4239		0.1475		0.8513	0.7585		tp=0.55, tn=0.11, fp=0.22, fn=0.13		False
	9	0.4598		0.6535		0.4772		0.1767		0.8622	0.7965		tp=0.61, tn=0.077, fp=0.24, fn=0.074		True
	10	0.4429		0.6627		0.5075		0.1457		0.8683	0.7572		tp=0.54, tn=0.11, fp=0.21, fn=0.13		False
	11	0.4322		0.6798		0.5336		0.1317		0.8738	0.7531		tp=0.54, tn=0.1, fp=0.22, fn=0.14		False
	12	0.4167		0.7123		0.5551		0.1192		0.8782	0.7838		tp=0.6, tn=0.067, fp=0.25, fn=0.081		False
	13	0.4072		0.7308		0.5555		0.1308		0.8775	0.7849		tp=0.6, tn=0.071, fp=0.24, fn=0.084		False
	14	0.3997		0.7221		0.5692		0.1704		0.8811	0.7651		tp=0.55, tn=0.11, fp=0.21, fn=0.12		False
	15	0.3873		0.7214		0.6004		0.163		0.8881	0.7673		tp=0.56, tn=0.11, fp=0.21, fn=0.13		False
	16	0.3811		0.7501		0.6054		0.1282		0.8892	0.773		tp=0.58, tn=0.083, fp=0.23, fn=0.11		False
	17	0.3788		0.7688		0.5989		0.1312		0.8861	0.7566		tp=0.55, tn=0.099, fp=0.23, fn=0.13		False
	18	0.3614		0.7771		0.6306		0.16		0.8954	0.7562		tp=0.54, tn=0.12, fp=0.2, fn=0.15		False
	19	0.3545		0.8024		0.633		0.1693		0.8955	0.7425		tp=0.51, tn=0.13, fp=0.19, fn=0.16		False
	20	0.3497		0.814		0.6371		0.1537		0.896	0.7542		tp=0.54, tn=0.11, fp=0.2, fn=0.15		False
	21	0.3369		0.84		0.6703		0.1707		0.9057	0.7689		tp=0.56, tn=0.11, fp=0.21, fn=0.13		False
	22	0.3339		0.8318		0.6649		0.1878		0.9038	0.7495		tp=0.52, tn=0.13, fp=0.19, fn=0.16		True
	23	0.3299		0.8609		0.6633		0.1662		0.9026	0.7411		tp=0.51, tn=0.13, fp=0.19, fn=0.17		False
	24	0.3229		0.8638		0.6724		0.2018		0.9049	0.7353		tp=0.49, tn=0.15, fp=0.16, fn=0.19		True
	25	0.3263		0.9011		0.6709		0.1569		0.9045	0.7476		tp=0.52, tn=0.12, fp=0.2, fn=0.16		False
	26	0.3138		0.9288		0.6942		0.1808		0.9109	0.7358		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	27	0.3076		0.928		0.694		0.1905		0.9114	0.7399		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	28	0.306		0.9751		0.6992		0.1492		0.9122	0.7508		tp=0.53, tn=0.11, fp=0.21, fn=0.14		False
	29	0.298		0.9722		0.7145		0.1962		0.9164	0.7377		tp=0.5, tn=0.15, fp=0.17, fn=0.19		False
	30	0.294		0.9747		0.7165		0.209		0.9171	0.7361		tp=0.49, tn=0.16, fp=0.16, fn=0.19		True
	31	0.29		1.026		0.7164		0.1959		0.9168	0.7244		tp=0.48, tn=0.16, fp=0.16, fn=0.2		False
	32	0.2879		1.03		0.7221		0.1829		0.9179	0.7683		tp=0.55, tn=0.11, fp=0.2, fn=0.13		False
	33	0.2869		1.048		0.7273		0.1912		0.9201	0.7263		tp=0.48, tn=0.16, fp=0.17, fn=0.2		False
	34	0.2793		1.073		0.7382		0.1519		0.9228	0.733		tp=0.5, tn=0.13, fp=0.19, fn=0.18		False
	35	0.2751		1.119		0.7485		0.1566		0.9258	0.7605		tp=0.55, tn=0.11, fp=0.21, fn=0.13		False
	36	0.2791		1.108		0.7324		0.173		0.9215	0.7311		tp=0.49, tn=0.14, fp=0.18, fn=0.18		False
	37	0.2656		1.105		0.7594		0.2008		0.9287	0.7305		tp=0.48, tn=0.16, fp=0.17, fn=0.19		False
	38	0.2617		1.119		0.7471		0.1843		0.9255	0.7246		tp=0.48, tn=0.15, fp=0.16, fn=0.2		False
	39	0.2615		1.169		0.7624		0.1727		0.9294	0.7106		tp=0.46, tn=0.16, fp=0.16, fn=0.21		False
	40	0.2552		1.194		0.7688		0.1805		0.9316	0.7521		tp=0.53, tn=0.13, fp=0.2, fn=0.15		False
	41	0.2551		1.221		0.774		0.1935		0.9327	0.7146		tp=0.46, tn=0.17, fp=0.15, fn=0.22		False
	42	0.2568		1.243		0.7692		0.1718		0.9316	0.707		tp=0.46, tn=0.16, fp=0.16, fn=0.22		False
	43	0.2495		1.237		0.7668		0.1757		0.9307	0.7099		tp=0.46, tn=0.16, fp=0.16, fn=0.22		False
	44	0.2464		1.258		0.7727		0.1824		0.932	0.7688		tp=0.55, tn=0.11, fp=0.21, fn=0.13		False
	45	0.258		1.249		0.7486		0.1691		0.9254	0.7398		tp=0.51, tn=0.13, fp=0.18, fn=0.17		False
	46	0.2434		1.251		0.7842		0.1982		0.9358	0.7404		tp=0.5, tn=0.15, fp=0.17, fn=0.18		False
	47	0.2367		1.298		0.7913		0.1854		0.9372	0.7399		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	48	0.2319		1.321		0.7876		0.1838		0.9365	0.7391		tp=0.5, tn=0.14, fp=0.18, fn=0.17		False
	49	0.2418		1.325		0.7769		0.1762		0.9334	0.7364		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	50	0.233		1.338		0.797		0.204		0.9392	0.7056		tp=0.45, tn=0.18, fp=0.15, fn=0.23		False
	51	0.2289		1.393		0.8068		0.1676		0.9418	0.7334		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		130
learning rate		0.00398296319997
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_122-lr0.004-h_size130-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7611		0.6251		0.1001		0.2584		0.5127	0.7045		tp=0.43, tn=0.2, fp=0.25, fn=0.11		True
	2	0.5965		0.6048		0.3363		0.4628		0.6715	0.6963		tp=0.33, tn=0.38, fp=0.063, fn=0.22		True
	3	0.5335		0.5832		0.4681		0.4085		0.7355	0.7742		tp=0.5, tn=0.2, fp=0.24, fn=0.056		False
	4	0.4723		0.5597		0.5369		0.468		0.7656	0.7532		tp=0.41, tn=0.33, fp=0.11, fn=0.15		True
	5	0.4065		0.6632		0.6155		0.4158		0.8018	0.6512		tp=0.29, tn=0.39, fp=0.063, fn=0.25		False
	6	0.38		0.6042		0.642		0.4909		0.8163	0.7722		tp=0.43, tn=0.32, fp=0.13, fn=0.13		True
	7	0.3367		0.5696		0.6804		0.5837		0.832	0.8026		tp=0.43, tn=0.36, fp=0.077, fn=0.13		True
	8	0.2163		0.6644		0.865		0.4923		0.9303	0.7692		tp=0.42, tn=0.33, fp=0.13, fn=0.13		False
	9	0.1601		0.8047		0.909		0.4869		0.9532	0.697		tp=0.32, tn=0.4, fp=0.049, fn=0.23		False
	10	0.2324		0.9188		0.8065		0.4407		0.9015	0.6508		tp=0.29, tn=0.41, fp=0.049, fn=0.26		False
	11	0.2038		0.8244		0.8364		0.4635		0.9136	0.7143		tp=0.35, tn=0.37, fp=0.077, fn=0.2		False
	12	0.2181		0.7924		0.804		0.4807		0.9007	0.7613		tp=0.41, tn=0.33, fp=0.11, fn=0.15		False
	13	0.112		0.921		0.9413		0.4521		0.9699	0.7092		tp=0.35, tn=0.36, fp=0.077, fn=0.21		False
	14	0.08753		0.9264		0.9619		0.4787		0.9805	0.7397		tp=0.38, tn=0.36, fp=0.091, fn=0.17		False
	15	0.06413		0.9579		0.9795		0.5054		0.9895	0.7853		tp=0.44, tn=0.31, fp=0.12, fn=0.12		False
	16	0.04098		1.009		0.9941		0.5195		0.997	0.7848		tp=0.43, tn=0.33, fp=0.13, fn=0.11		False
	17	0.04153		1.046		0.9883		0.5456		0.994	0.8072		tp=0.47, tn=0.31, fp=0.14, fn=0.084		False
	18	0.04173		1.173		0.9824		0.4505		0.991	0.726		tp=0.37, tn=0.35, fp=0.098, fn=0.18		False
	19	0.04701		0.9494		0.9736		0.5681		0.9864	0.7974		tp=0.43, tn=0.36, fp=0.084, fn=0.13		False
	20	0.06248		1.356		0.956		0.4931		0.9775	0.7882		tp=0.47, tn=0.28, fp=0.17, fn=0.077		False
	21	0.06434		1.562		0.9589		0.4236		0.9789	0.6167		tp=0.26, tn=0.42, fp=0.042, fn=0.28		False
	22	0.05922		1.192		0.959		0.4519		0.9788	0.7451		tp=0.4, tn=0.33, fp=0.14, fn=0.13		False
	23	0.03124		1.253		0.9883		0.4236		0.994	0.695		tp=0.34, tn=0.36, fp=0.084, fn=0.22		False
	24	0.03049		1.413		0.9883		0.4179		0.994	0.7075		tp=0.36, tn=0.34, fp=0.097, fn=0.2		False
	25	0.01489		1.314		0.9971		0.5327		0.9985	0.7925		tp=0.44, tn=0.33, fp=0.11, fn=0.12		False
	26	0.01402		1.359		0.9971		0.4562		0.9985	0.731		tp=0.37, tn=0.36, fp=0.12, fn=0.15		False
	27	0.01248		1.405		0.9971		0.5373		0.9985	0.7925		tp=0.44, tn=0.33, fp=0.12, fn=0.1		False
	28	0.0125		1.244		1		0.4839		1	0.7483		tp=0.38, tn=0.36, fp=0.11, fn=0.15		False


data			/scratch/asw462/data/levin
input size		300
hidden size		53
learning rate		7.32319064876e&05
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_123-lr7.3e&05-h_size53-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6322		0.6159		-0.01008		0		0.8281	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.588		0.6014		0		0		0.8407	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5807		0.6052		0		0		0.8416	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	4	0.5746		0.5828		0		0		0.8421	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	5	0.5692		0.5873		0		0		0.8435	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	6	0.5674		0.5839		0.01902		0		0.8415	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	7	0.5654		0.566		0.08137		0.06078		0.8424	0.8408		tp=0.72, tn=0.007, fp=0.27, fn=0.007		True
	8	0.5605		0.6111		0.08944		0.04547		0.8425	0.8067		tp=0.67, tn=0.007, fp=0.31, fn=0.007		False
	9	0.5568		0.5992		0.1357		0.1139		0.8455	0.8201		tp=0.69, tn=0.014, fp=0.29, fn=0.007		True
	10	0.5574		0.5672		0.1444		0.1777		0.8438	0.843		tp=0.71, tn=0.021, fp=0.26, fn=0.007		True
	11	0.5534		0.5797		0.128		0.1714		0.845	0.8319		tp=0.69, tn=0.028, fp=0.27, fn=0.014		False
	12	0.551		0.5843		0.1403		0.1771		0.8423	0.8305		tp=0.69, tn=0.035, fp=0.26, fn=0.021		False
	13	0.5516		0.6025		0.1492		0.1242		0.8431	0.8235		tp=0.69, tn=0.021, fp=0.28, fn=0.014		False
	14	0.5478		0.5854		0.16		0.08325		0.8442	0.8347		tp=0.71, tn=0.014, fp=0.27, fn=0.014		False
	15	0.5479		0.6079		0.1624		0.1014		0.8427	0.812		tp=0.66, tn=0.028, fp=0.28, fn=0.028		False
	16	0.5472		0.5814		0.153		0.1346		0.8415	0.8305		tp=0.69, tn=0.035, fp=0.24, fn=0.035		False
	17	0.5385		0.5808		0.1944		0.2068		0.8487	0.8291		tp=0.68, tn=0.042, fp=0.26, fn=0.021		True
	18	0.542		0.5968		0.2042		0.1923		0.8474	0.8155		tp=0.66, tn=0.042, fp=0.28, fn=0.021		False
	19	0.5392		0.5728		0.2282		0.1821		0.8484	0.8354		tp=0.69, tn=0.035, fp=0.25, fn=0.021		False
	20	0.5363		0.591		0.2104		0.1737		0.8483	0.819		tp=0.66, tn=0.042, fp=0.27, fn=0.028		False
	21	0.536		0.5607		0.2589		0.2172		0.8511	0.8326		tp=0.68, tn=0.049, fp=0.24, fn=0.028		True
	22	0.5322		0.5965		0.2371		0.164		0.8506	0.8174		tp=0.66, tn=0.049, fp=0.25, fn=0.042		False
	23	0.5318		0.6084		0.2825		0.07679		0.854	0.8069		tp=0.66, tn=0.028, fp=0.28, fn=0.035		False
	24	0.531		0.5704		0.267		0.2415		0.8528	0.8312		tp=0.67, tn=0.056, fp=0.24, fn=0.028		True
	25	0.53		0.5772		0.2538		0.2172		0.852	0.8326		tp=0.68, tn=0.049, fp=0.24, fn=0.028		False
	26	0.5267		0.5891		0.2909		0.1865		0.8551	0.8225		tp=0.66, tn=0.049, fp=0.25, fn=0.035		False
	27	0.5283		0.5909		0.2849		0.2108		0.854	0.821		tp=0.66, tn=0.056, fp=0.25, fn=0.035		False
	28	0.5273		0.5646		0.2746		0.2298		0.8526	0.8362		tp=0.68, tn=0.056, fp=0.23, fn=0.035		False
	29	0.5228		0.5922		0.2939		0.1882		0.8565	0.8158		tp=0.65, tn=0.056, fp=0.25, fn=0.042		False
	30	0.5224		0.5715		0.2841		0.251		0.854	0.8282		tp=0.66, tn=0.07, fp=0.23, fn=0.042		True
	31	0.5224		0.5757		0.2893		0.2443		0.8557	0.8398		tp=0.68, tn=0.063, fp=0.22, fn=0.042		False
	32	0.5219		0.575		0.2838		0.2233		0.854	0.8312		tp=0.67, tn=0.056, fp=0.24, fn=0.035		False
	33	0.5128		0.5923		0.294		0.2791		0.8587	0.823		tp=0.65, tn=0.076, fp=0.24, fn=0.035		True
	34	0.5156		0.584		0.2942		0.2181		0.8553	0.834		tp=0.68, tn=0.049, fp=0.24, fn=0.028		False
	35	0.5151		0.5664		0.2934		0.3421		0.8581	0.8435		tp=0.67, tn=0.076, fp=0.23, fn=0.021		True
	36	0.5127		0.5717		0.3164		0.2924		0.8598	0.8251		tp=0.64, tn=0.09, fp=0.22, fn=0.049		False
	37	0.5139		0.6038		0.3024		0.2849		0.8543	0.8267		tp=0.65, tn=0.077, fp=0.24, fn=0.035		False
	38	0.5118		0.5592		0.3086		0.3115		0.8565	0.8485		tp=0.69, tn=0.07, fp=0.22, fn=0.028		False
	39	0.5106		0.5769		0.3124		0.3478		0.857	0.8458		tp=0.67, tn=0.084, fp=0.22, fn=0.028		True
	40	0.5089		0.569		0.3109		0.2175		0.8579	0.8214		tp=0.64, tn=0.077, fp=0.21, fn=0.07		False
	41	0.508		0.5783		0.3067		0.3256		0.8549	0.8421		tp=0.67, tn=0.083, fp=0.22, fn=0.035		False
	42	0.5058		0.5658		0.3138		0.2043		0.8568	0.8297		tp=0.66, tn=0.063, fp=0.22, fn=0.056		False
	43	0.5071		0.5762		0.3121		0.3408		0.8552	0.8393		tp=0.66, tn=0.091, fp=0.22, fn=0.035		False
	44	0.5012		0.5818		0.3087		0.1621		0.8577	0.8174		tp=0.65, tn=0.056, fp=0.24, fn=0.056		False
	45	0.4973		0.5432		0.3216		0.3271		0.8599	0.8509		tp=0.68, tn=0.084, fp=0.2, fn=0.042		False
	46	0.4992		0.582		0.3156		0.2595		0.8575	0.823		tp=0.65, tn=0.07, fp=0.24, fn=0.035		False
	47	0.4991		0.5613		0.3503		0.273		0.862	0.8435		tp=0.68, tn=0.07, fp=0.21, fn=0.042		False
	48	0.498		0.5625		0.3266		0.2824		0.8593	0.8304		tp=0.65, tn=0.084, fp=0.22, fn=0.049		False
	49	0.4972		0.5868		0.3414		0.2641		0.8598	0.8128		tp=0.62, tn=0.091, fp=0.23, fn=0.056		False
	50	0.4952		0.5708		0.3479		0.2699		0.8602	0.8235		tp=0.64, tn=0.091, fp=0.21, fn=0.063		False
	51	0.4896		0.5675		0.3335		0.2712		0.8612	0.8304		tp=0.65, tn=0.084, fp=0.21, fn=0.056		False
	52	0.4908		0.5487		0.3442		0.261		0.8623	0.8235		tp=0.64, tn=0.091, fp=0.2, fn=0.07		False
	53	0.4873		0.5874		0.3711		0.3094		0.8656	0.8304		tp=0.65, tn=0.084, fp=0.23, fn=0.035		False
	54	0.4892		0.5849		0.36		0.1943		0.8636	0.8054		tp=0.62, tn=0.077, fp=0.23, fn=0.07		False
	55	0.49		0.5904		0.3597		0.1515		0.8627	0.7964		tp=0.62, tn=0.07, fp=0.24, fn=0.077		False
	56	0.4877		0.5811		0.3617		0.2747		0.8624	0.8251		tp=0.64, tn=0.084, fp=0.22, fn=0.049		False
	57	0.4875		0.5671		0.3602		0.2109		0.8634	0.8178		tp=0.64, tn=0.07, fp=0.23, fn=0.056		False
	58	0.4824		0.5441		0.3658		0.2309		0.8664	0.8384		tp=0.67, tn=0.07, fp=0.2, fn=0.063		False
	59	0.4825		0.5479		0.3886		0.2612		0.8666	0.8304		tp=0.65, tn=0.084, fp=0.2, fn=0.063		False
	60	0.48		0.538		0.3879		0.3154		0.8664	0.8393		tp=0.66, tn=0.091, fp=0.2, fn=0.049		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		125
learning rate		0.000476727919278
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_124-lr0.00048-h_size125-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6879		0.6358		0.1235		0.3476		0.5583	0.637		tp=0.3, tn=0.36, fp=0.091, fn=0.25		True
	2	0.6127		0.6075		0.3781		0.382		0.6635	0.6466		tp=0.3, tn=0.37, fp=0.077, fn=0.25		True
	3	0.5773		0.6118		0.4515		0.3901		0.7205	0.5932		tp=0.24, tn=0.42, fp=0.049, fn=0.29		True
	4	0.5431		0.5639		0.4665		0.4113		0.73	0.7558		tp=0.45, tn=0.25, fp=0.21, fn=0.084		True
	5	0.5172		0.6563		0.4823		0.3439		0.7416	0.4954		tp=0.19, tn=0.43, fp=0.028, fn=0.36		False
	6	0.4883		0.5567		0.5073		0.4941		0.7375	0.7831		tp=0.45, tn=0.29, fp=0.17, fn=0.084		True
	7	0.4453		0.5685		0.6214		0.4983		0.8121	0.7448		tp=0.38, tn=0.37, fp=0.083, fn=0.17		True
	8	0.4105		0.5672		0.6634		0.5077		0.8206	0.7742		tp=0.42, tn=0.34, fp=0.13, fn=0.11		True
	9	0.3807		0.5613		0.7068		0.5314		0.8507	0.7703		tp=0.4, tn=0.36, fp=0.084, fn=0.15		True
	10	0.339		0.5788		0.7623		0.5253		0.8775	0.7763		tp=0.41, tn=0.35, fp=0.098, fn=0.14		False
	11	0.3066		0.6067		0.7916		0.5059		0.8926	0.76		tp=0.4, tn=0.35, fp=0.084, fn=0.17		False
	12	0.2837		0.6107		0.8063		0.4916		0.9	0.7246		tp=0.35, tn=0.38, fp=0.07, fn=0.2		False
	13	0.2629		0.6368		0.8445		0.5208		0.9205	0.7821		tp=0.43, tn=0.34, fp=0.11, fn=0.13		False
	14	0.2323		0.662		0.8861		0.5155		0.9401	0.7465		tp=0.37, tn=0.38, fp=0.07, fn=0.18		False
	15	0.2068		0.6718		0.9091		0.4909		0.953	0.7483		tp=0.38, tn=0.36, fp=0.091, fn=0.17		False
	16	0.1967		0.7376		0.9061		0.5722		0.9517	0.7344		tp=0.33, tn=0.43, fp=0.028, fn=0.21		True
	17	0.1845		0.6309		0.8945		0.5071		0.9451	0.7742		tp=0.42, tn=0.34, fp=0.13, fn=0.12		False
	18	0.165		0.6749		0.9325		0.4887		0.9654	0.7778		tp=0.44, tn=0.31, fp=0.14, fn=0.11		False
	19	0.139		0.717		0.9443		0.4519		0.9712	0.7451		tp=0.4, tn=0.33, fp=0.13, fn=0.14		False
	20	0.1344		0.7553		0.9443		0.4972		0.9713	0.7632		tp=0.41, tn=0.34, fp=0.1, fn=0.15		False
	21	0.1242		0.7552		0.9648		0.5216		0.9819	0.7792		tp=0.42, tn=0.34, fp=0.12, fn=0.12		False
	22	0.1076		0.7848		0.9765		0.5215		0.9879	0.7901		tp=0.44, tn=0.32, fp=0.13, fn=0.1		False
	23	0.1192		0.8492		0.9707		0.4923		0.9849	0.7692		tp=0.42, tn=0.33, fp=0.13, fn=0.13		False
	24	0.09991		0.861		0.9619		0.5065		0.9804	0.7568		tp=0.39, tn=0.36, fp=0.084, fn=0.17		False
	25	0.0952		0.8991		0.9677		0.5204		0.9835	0.7259		tp=0.34, tn=0.4, fp=0.049, fn=0.21		False
	26	0.08531		0.8036		0.9795		0.4865		0.9894	0.7246		tp=0.35, tn=0.38, fp=0.077, fn=0.19		False
	27	0.07055		0.8843		0.9883		0.5426		0.994	0.8049		tp=0.46, tn=0.31, fp=0.11, fn=0.11		False
	28	0.07305		0.9342		0.9853		0.4719		0.9925	0.7467		tp=0.39, tn=0.34, fp=0.1, fn=0.16		False
	29	0.06174		0.9063		0.9912		0.5071		0.9955	0.75		tp=0.38, tn=0.37, fp=0.084, fn=0.17		False
	30	0.0574		0.8706		0.9912		0.4953		0.9955	0.76		tp=0.4, tn=0.35, fp=0.13, fn=0.13		False
	31	0.05361		0.8669		0.9912		0.4945		0.9955	0.7483		tp=0.38, tn=0.36, fp=0.084, fn=0.17		False
	32	0.05055		0.8944		0.9971		0.5058		0.9985	0.7771		tp=0.43, tn=0.33, fp=0.13, fn=0.12		False
	33	0.04974		1.048		0.9971		0.4663		0.9985	0.7194		tp=0.35, tn=0.38, fp=0.091, fn=0.18		False
	34	0.04677		0.8834		0.9971		0.565		0.9985	0.7974		tp=0.43, tn=0.36, fp=0.12, fn=0.098		False
	35	0.04083		1.024		0.9971		0.533		0.9985	0.795		tp=0.45, tn=0.32, fp=0.13, fn=0.098		False
	36	0.03861		1.044		0.9941		0.4956		0.997	0.76		tp=0.4, tn=0.35, fp=0.12, fn=0.13		False
	37	0.03612		1.07		0.9971		0.5189		0.9985	0.7875		tp=0.44, tn=0.32, fp=0.13, fn=0.1		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		48
learning rate		0.00411467958724
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_125-lr0.0041-h_size48-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7099		0.6758		-0.02		0.2259		0.4603	0.6452		tp=0.35, tn=0.27, fp=0.2, fn=0.18		True
	2	0.6426		0.7228		0.2696		0.1296		0.5925	0.268		tp=0.091, tn=0.41, fp=0.035, fn=0.46		False
	3	0.6101		0.6664		0.3364		0.3605		0.6544	0.7486		tp=0.47, tn=0.22, fp=0.23, fn=0.084		True
	4	0.5706		0.6796		0.4151		0.09929		0.6753	0.5324		tp=0.26, tn=0.29, fp=0.18, fn=0.27		False
	5	0.5019		0.7132		0.501		0.1687		0.7424	0.589		tp=0.3, tn=0.28, fp=0.17, fn=0.25		False
	6	0.4528		0.7928		0.5893		0.2679		0.784	0.6977		tp=0.42, tn=0.22, fp=0.25, fn=0.11		False
	7	0.4543		0.8183		0.548		0.1598		0.7674	0.638		tp=0.36, tn=0.22, fp=0.22, fn=0.19		False
	8	0.402		0.8746		0.6424		0.187		0.8111	0.5588		tp=0.27, tn=0.31, fp=0.13, fn=0.29		False
	9	0.3403		0.9798		0.7271		0.1812		0.8597	0.5986		tp=0.31, tn=0.28, fp=0.17, fn=0.24		False
	10	0.346		1.063		0.7036		0.1836		0.8463	0.5714		tp=0.28, tn=0.3, fp=0.14, fn=0.28		False
	11	0.2955		1.167		0.7539		0.1249		0.8708	0.5714		tp=0.29, tn=0.27, fp=0.18, fn=0.26		False
	12	0.2915		1.076		0.7593		0.2974		0.8761	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.22		False
	13	0.2917		1.332		0.7593		0.1967		0.8758	0.5564		tp=0.26, tn=0.33, fp=0.13, fn=0.28		False
	14	0.2301		1.33		0.8298		0.2094		0.9119	0.5672		tp=0.27, tn=0.33, fp=0.13, fn=0.27		False
	15	0.2699		1.493		0.7623		0.1877		0.8782	0.5385		tp=0.24, tn=0.34, fp=0.13, fn=0.29		False
	16	0.2078		1.392		0.8682		0.2906		0.9313	0.6577		tp=0.34, tn=0.3, fp=0.15, fn=0.21		False
	17	0.2078		1.427		0.824		0.2708		0.9085	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.2		False
	18	0.218		1.426		0.8415		0.2516		0.9184	0.6624		tp=0.36, tn=0.27, fp=0.19, fn=0.18		False
	19	0.1607		1.78		0.8915		0.195		0.9445	0.5496		tp=0.25, tn=0.34, fp=0.13, fn=0.28		False
	20	0.1793		1.861		0.8768		0.2291		0.9369	0.5821		tp=0.27, tn=0.34, fp=0.14, fn=0.25		False
	21	0.1529		1.999		0.8914		0.2316		0.9444	0.5606		tp=0.26, tn=0.34, fp=0.1, fn=0.3		False
	22	0.1589		1.848		0.8798		0.2199		0.9376	0.5957		tp=0.29, tn=0.31, fp=0.14, fn=0.26		False
	23	0.1226		2.227		0.9355		0.2125		0.9671	0.528		tp=0.23, tn=0.36, fp=0.1, fn=0.31		False
	24	0.1205		2.032		0.9354		0.2706		0.9669	0.5909		tp=0.27, tn=0.35, fp=0.11, fn=0.27		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		57
learning rate		0.00475982711958
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_126-lr0.0048-h_size57-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5805		0.5736		0.2401		0.2643		0.8204	0.8217		tp=0.65, tn=0.065, fp=0.26, fn=0.027		True
	2	0.5589		0.5677		0.276		0.2442		0.8246	0.8208		tp=0.65, tn=0.059, fp=0.26, fn=0.027		False
	3	0.5466		0.5682		0.3254		0.2523		0.8319	0.812		tp=0.62, tn=0.089, fp=0.23, fn=0.059		False
	4	0.5282		0.5614		0.347		0.2496		0.8345	0.818		tp=0.64, tn=0.068, fp=0.25, fn=0.034		False
	5	0.5216		0.6115		0.3553		0.2605		0.8351	0.7544		tp=0.5, tn=0.17, fp=0.15, fn=0.18		False
	6	0.5102		0.5735		0.3801		0.2504		0.8405	0.8086		tp=0.62, tn=0.093, fp=0.23, fn=0.065		False
	7	0.4942		0.5778		0.4088		0.2758		0.8456	0.8087		tp=0.61, tn=0.11, fp=0.22, fn=0.071		True
	8	0.4947		0.5873		0.4191		0.2954		0.8462	0.8261		tp=0.65, tn=0.081, fp=0.24, fn=0.036		True
	9	0.5026		0.6266		0.4081		0.2306		0.8433	0.7623		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	10	0.4754		0.5894		0.4426		0.3104		0.8525	0.8121		tp=0.6, tn=0.12, fp=0.2, fn=0.081		True
	11	0.4513		0.5982		0.4874		0.3238		0.8617	0.8141		tp=0.6, tn=0.13, fp=0.19, fn=0.084		True
	12	0.444		0.6207		0.519		0.3075		0.8691	0.8195		tp=0.62, tn=0.1, fp=0.22, fn=0.055		False
	13	0.429		0.6787		0.5424		0.2717		0.8747	0.7332		tp=0.47, tn=0.19, fp=0.13, fn=0.21		False
	14	0.4381		0.6116		0.5144		0.3456		0.866	0.7991		tp=0.55, tn=0.17, fp=0.15, fn=0.13		True
	15	0.4038		0.6452		0.5832		0.3104		0.8849	0.8093		tp=0.59, tn=0.13, fp=0.2, fn=0.083		False
	16	0.3978		0.6564		0.5875		0.2983		0.8855	0.8173		tp=0.62, tn=0.11, fp=0.21, fn=0.067		False
	17	0.3763		0.6903		0.6151		0.2861		0.892	0.8064		tp=0.6, tn=0.11, fp=0.21, fn=0.074		False
	18	0.3598		0.6288		0.628		0.3074		0.8949	0.8057		tp=0.59, tn=0.13, fp=0.19, fn=0.09		False
	19	0.3517		0.6889		0.651		0.3222		0.9017	0.8025		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	20	0.3493		0.6912		0.6435		0.3305		0.8988	0.8042		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	21	0.3219		0.7109		0.6937		0.2982		0.9124	0.7933		tp=0.56, tn=0.15, fp=0.17, fn=0.12		False
	22	0.3107		0.7057		0.6982		0.292		0.9133	0.7882		tp=0.55, tn=0.15, fp=0.18, fn=0.12		False
	23	0.3015		0.7164		0.7162		0.3014		0.9181	0.7833		tp=0.54, tn=0.16, fp=0.16, fn=0.13		False
	24	0.2823		0.7575		0.7384		0.3218		0.9241	0.8025		tp=0.57, tn=0.15, fp=0.18, fn=0.11		False
	25	0.2715		0.7328		0.7548		0.3327		0.9287	0.8083		tp=0.58, tn=0.15, fp=0.16, fn=0.11		False
	26	0.2582		0.7658		0.7712		0.3185		0.9331	0.8066		tp=0.58, tn=0.14, fp=0.17, fn=0.1		False
	27	0.2429		0.7854		0.7811		0.2883		0.9358	0.7834		tp=0.55, tn=0.15, fp=0.17, fn=0.13		False
	28	0.2332		0.8224		0.791		0.2878		0.9385	0.7807		tp=0.54, tn=0.16, fp=0.16, fn=0.14		False
	29	0.2363		0.8255		0.785		0.3168		0.9369	0.7932		tp=0.55, tn=0.16, fp=0.16, fn=0.12		False
	30	0.2314		0.8114		0.7983		0.3189		0.9406	0.7949		tp=0.56, tn=0.16, fp=0.16, fn=0.13		False
	31	0.2247		0.8574		0.8073		0.2853		0.9431	0.7955		tp=0.57, tn=0.14, fp=0.17, fn=0.12		False
	32	0.1957		0.9002		0.8406		0.3024		0.9526	0.7988		tp=0.57, tn=0.14, fp=0.17, fn=0.11		False
	33	0.19		0.9124		0.8431		0.289		0.9535	0.7963		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	34	0.1752		0.9469		0.8591		0.3028		0.958	0.7954		tp=0.56, tn=0.15, fp=0.18, fn=0.11		False
	35	0.184		0.9547		0.8527		0.3079		0.9561	0.7958		tp=0.56, tn=0.15, fp=0.17, fn=0.12		False


data			/scratch/asw462/data/levin
input size		300
hidden size		35
learning rate		0.00487204358188
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_127-lr0.0049-h_size35-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6282		0.5707		0.02079		0		0.8329	0.8434		tp=0.73, tn=0, fp=0.27, fn=0		False
	2	0.5406		0.5726		0.1728		0.2108		0.8404	0.821		tp=0.66, tn=0.056, fp=0.25, fn=0.035		True
	3	0.5011		0.53		0.3464		0.2734		0.8584	0.8384		tp=0.67, tn=0.076, fp=0.21, fn=0.049		True
	4	0.459		0.5346		0.4261		0.2662		0.866	0.7902		tp=0.57, tn=0.13, fp=0.18, fn=0.12		False
	5	0.4136		0.5165		0.5107		0.406		0.8864	0.8276		tp=0.59, tn=0.17, fp=0.13, fn=0.12		True
	6	0.3811		0.5067		0.5923		0.3842		0.8995	0.8411		tp=0.63, tn=0.13, fp=0.16, fn=0.077		False
	7	0.3367		0.5545		0.6484		0.3448		0.9135	0.798		tp=0.55, tn=0.17, fp=0.13, fn=0.15		False
	8	0.2887		0.5077		0.7251		0.4282		0.9302	0.8476		tp=0.62, tn=0.15, fp=0.13, fn=0.098		True
	9	0.23		0.5318		0.8046		0.387		0.9495	0.8465		tp=0.64, tn=0.13, fp=0.14, fn=0.091		False
	10	0.2094		0.5463		0.8401		0.4944		0.9572	0.8426		tp=0.58, tn=0.2, fp=0.1, fn=0.11		True
	11	0.1699		0.5273		0.8683		0.5281		0.9647	0.8614		tp=0.61, tn=0.2, fp=0.098, fn=0.098		True
	12	0.1375		0.5607		0.906		0.4436		0.9747	0.83		tp=0.58, tn=0.19, fp=0.12, fn=0.12		False
	13	0.1664		0.5179		0.8478		0.4289		0.9598	0.8333		tp=0.59, tn=0.17, fp=0.12, fn=0.11		False
	14	0.1531		0.5735		0.8914		0.5016		0.9709	0.85		tp=0.59, tn=0.2, fp=0.11, fn=0.098		False
	15	0.1196		0.6144		0.9289		0.4347		0.981	0.8505		tp=0.64, tn=0.14, fp=0.17, fn=0.056		False
	16	0.08912		0.5885		0.9558		0.521		0.988	0.8543		tp=0.59, tn=0.2, fp=0.098, fn=0.1		False
	17	0.09396		0.5666		0.9366		0.5685		0.9827	0.8815		tp=0.65, tn=0.17, fp=0.13, fn=0.042		True
	18	0.07007		0.5855		0.9578		0.5019		0.9885	0.8704		tp=0.66, tn=0.15, fp=0.15, fn=0.042		False
	19	0.06279		0.5464		0.9597		0.5212		0.9889	0.8756		tp=0.66, tn=0.15, fp=0.15, fn=0.035		False
	20	0.05134		0.6784		0.977		0.475		0.9938	0.8558		tp=0.62, tn=0.17, fp=0.13, fn=0.084		False
	21	0.04967		0.5511		0.9662		0.5571		0.9909	0.8738		tp=0.62, tn=0.19, fp=0.097, fn=0.083		False
	22	0.04627		0.6375		0.972		0.5103		0.9923	0.8744		tp=0.65, tn=0.16, fp=0.12, fn=0.069		False
	23	0.04524		0.7045		0.9754		0.5141		0.9933	0.8818		tp=0.68, tn=0.14, fp=0.14, fn=0.042		False
	24	0.03924		0.7153		0.9772		0.5412		0.9937	0.8696		tp=0.63, tn=0.18, fp=0.13, fn=0.056		False
	25	0.03493		0.7357		0.9806		0.5413		0.9947	0.8807		tp=0.67, tn=0.15, fp=0.15, fn=0.028		False
	26	0.03325		0.7285		0.9807		0.5559		0.9947	0.8738		tp=0.63, tn=0.19, fp=0.12, fn=0.063		False
	27	0.03378		0.6819		0.9752		0.5816		0.9933	0.8756		tp=0.62, tn=0.21, fp=0.084, fn=0.091		True
	28	0.03032		0.7433		0.9807		0.5878		0.9947	0.8879		tp=0.66, tn=0.17, fp=0.13, fn=0.035		True
	29	0.02485		0.7012		0.9877		0.5722		0.9966	0.878		tp=0.63, tn=0.2, fp=0.1, fn=0.07		False
	30	0.0245		0.6984		0.9859		0.5914		0.9961	0.8824		tp=0.63, tn=0.2, fp=0.098, fn=0.07		True
	31	0.02265		0.7632		0.9877		0.5704		0.9966	0.878		tp=0.63, tn=0.2, fp=0.098, fn=0.077		False
	32	0.02358		0.8037		0.9859		0.5603		0.9962	0.8837		tp=0.66, tn=0.16, fp=0.14, fn=0.035		False
	33	0.0212		0.8325		0.9876		0.5589		0.9966	0.8826		tp=0.65, tn=0.17, fp=0.12, fn=0.056		False
	34	0.02461		0.7597		0.9825		0.5506		0.9952	0.8657		tp=0.61, tn=0.2, fp=0.11, fn=0.077		False
	35	0.03154		0.8955		0.9788		0.5736		0.9942	0.8687		tp=0.6, tn=0.22, fp=0.098, fn=0.084		False
	36	0.08674		0.8002		0.9227		0.5339		0.9788	0.8708		tp=0.64, tn=0.17, fp=0.13, fn=0.056		False
	37	0.02908		0.8458		0.9807		0.5351		0.9947	0.8785		tp=0.66, tn=0.16, fp=0.13, fn=0.049		False
	38	0.02609		0.8268		0.9842		0.5158		0.9957	0.8641		tp=0.62, tn=0.18, fp=0.11, fn=0.084		False
	39	0.02133		0.8505		0.9877		0.5874		0.9966	0.8879		tp=0.66, tn=0.17, fp=0.14, fn=0.028		False
	40	0.02051		0.8709		0.9877		0.5359		0.9966	0.8683		tp=0.62, tn=0.19, fp=0.1, fn=0.084		False
	41	0.02049		0.8627		0.986		0.5651		0.9961	0.8804		tp=0.64, tn=0.18, fp=0.12, fn=0.056		False
	42	0.01792		0.8091		0.9858		0.5704		0.9962	0.878		tp=0.63, tn=0.2, fp=0.098, fn=0.077		False
	43	0.01794		0.9021		0.9842		0.5699		0.9957	0.8804		tp=0.64, tn=0.18, fp=0.13, fn=0.049		False
	44	0.0207		0.8557		0.9877		0.6053		0.9966	0.891		tp=0.66, tn=0.18, fp=0.13, fn=0.035		True
	45	0.01999		0.779		0.9859		0.5855		0.9962	0.892		tp=0.66, tn=0.18, fp=0.083, fn=0.076		False
	46	0.0183		0.7674		0.9912		0.5968		0.9976	0.8824		tp=0.63, tn=0.2, fp=0.11, fn=0.056		False
	47	0.01668		0.8579		0.993		0.5581		0.9981	0.875		tp=0.64, tn=0.18, fp=0.13, fn=0.049		False
	48	0.01467		0.8828		0.993		0.5581		0.9981	0.875		tp=0.64, tn=0.18, fp=0.13, fn=0.049		False
	49	0.01647		0.9432		0.9912		0.5335		0.9976	0.8869		tp=0.69, tn=0.14, fp=0.14, fn=0.035		False
	50	0.01879		0.8629		0.9912		0.6035		0.9976	0.8889		tp=0.64, tn=0.2, fp=0.1, fn=0.056		False
	51	0.01422		0.7681		0.9948		0.5864		0.9986	0.8846		tp=0.64, tn=0.19, fp=0.097, fn=0.069		False
	52	0.01347		0.7077		0.9965		0.6049		0.999	0.8878		tp=0.64, tn=0.2, fp=0.091, fn=0.07		False
	53	0.01531		0.8722		0.9912		0.5872		0.9976	0.892		tp=0.66, tn=0.17, fp=0.11, fn=0.049		False
	54	0.01516		0.8886		0.993		0.5868		0.9981	0.8868		tp=0.66, tn=0.17, fp=0.13, fn=0.035		False
	55	0.0156		1.037		0.9877		0.5426		0.9966	0.8796		tp=0.66, tn=0.16, fp=0.14, fn=0.042		False
	56	0.01354		0.8491		0.993		0.6		0.9981	0.8835		tp=0.64, tn=0.2, fp=0.13, fn=0.042		False
	57	0.01286		0.8867		0.993		0.5745		0.9981	0.87		tp=0.6, tn=0.22, fp=0.09, fn=0.09		False
	58	0.01412		0.9218		0.9947		0.5629		0.9986	0.8792		tp=0.64, tn=0.19, fp=0.091, fn=0.084		False
	59	0.01294		1.08		0.9948		0.5777		0.9986	0.8738		tp=0.63, tn=0.19, fp=0.15, fn=0.035		False
	60	0.01457		0.8692		0.993		0.5685		0.9981	0.8815		tp=0.65, tn=0.17, fp=0.13, fn=0.042		False
	61	0.01554		1.094		0.9894		0.5685		0.9971	0.8815		tp=0.65, tn=0.17, fp=0.13, fn=0.042		False
	62	0.0133		0.8029		0.9947		0.5921		0.9986	0.894		tp=0.67, tn=0.17, fp=0.12, fn=0.035		False
	63	0.01473		0.8376		0.9947		0.5854		0.9986	0.8857		tp=0.65, tn=0.19, fp=0.11, fn=0.056		False
	64	0.01465		0.7821		0.9947		0.6228		0.9986	0.9023		tp=0.68, tn=0.17, fp=0.11, fn=0.035		True
	65	0.01194		0.971		0.9947		0.5796		0.9986	0.893		tp=0.67, tn=0.17, fp=0.11, fn=0.049		False
	66	0.01404		0.9518		0.9913		0.5844		0.9976	0.8846		tp=0.64, tn=0.19, fp=0.11, fn=0.056		False
	67	0.01284		0.9947		0.993		0.5104		0.9981	0.8654		tp=0.63, tn=0.17, fp=0.12, fn=0.077		False
	68	0.01406		0.8726		0.9948		0.5418		0.9986	0.8837		tp=0.66, tn=0.16, fp=0.12, fn=0.056		False
	69	0.0129		0.9737		0.9947		0.555		0.9986	0.8826		tp=0.66, tn=0.17, fp=0.13, fn=0.049		False
	70	0.01188		1.132		0.993		0.5599		0.9981	0.8738		tp=0.63, tn=0.19, fp=0.13, fn=0.056		False
	71	0.01188		0.8677		0.9947		0.5919		0.9986	0.8846		tp=0.64, tn=0.19, fp=0.11, fn=0.056		False
	72	0.01211		0.8522		0.9947		0.6614		0.9986	0.9108		tp=0.68, tn=0.19, fp=0.098, fn=0.035		True
	73	0.01172		1.156		0.993		0.5263		0.9981	0.8796		tp=0.66, tn=0.15, fp=0.13, fn=0.049		False
	74	0.01196		1.07		0.9947		0.5873		0.9986	0.8857		tp=0.65, tn=0.18, fp=0.13, fn=0.042		False
	75	0.01582		1.177		0.9913		0.5755		0.9976	0.8815		tp=0.65, tn=0.17, fp=0.14, fn=0.035		False
	76	0.0215		0.916		0.9895		0.5082		0.9971	0.8654		tp=0.63, tn=0.17, fp=0.11, fn=0.084		False
	77	0.01574		1.029		0.9948		0.5496		0.9986	0.8571		tp=0.59, tn=0.22, fp=0.077, fn=0.12		False
	78	0.03915		0.9424		0.9703		0.5562		0.9918	0.8657		tp=0.6, tn=0.21, fp=0.1, fn=0.083		False
	79	0.06138		0.7948		0.9466		0.5638		0.9857	0.8792		tp=0.64, tn=0.19, fp=0.098, fn=0.077		False
	80	0.1468		0.7873		0.8562		0.4445		0.9612	0.8187		tp=0.55, tn=0.2, fp=0.1, fn=0.14		False
	81	0.1541		0.6886		0.8524		0.5112		0.9604	0.8807		tp=0.67, tn=0.15, fp=0.13, fn=0.056		False
	82	0.09362		0.849		0.9187		0.3992		0.978	0.8532		tp=0.65, tn=0.13, fp=0.15, fn=0.07		False
	83	0.0717		0.8709		0.9421		0.4973		0.9841	0.8692		tp=0.65, tn=0.15, fp=0.14, fn=0.056		False
	84	0.04302		0.8009		0.9753		0.508		0.9933	0.8485		tp=0.59, tn=0.2, fp=0.11, fn=0.098		False
	85	0.03049		0.8319		0.986		0.5776		0.9961	0.8857		tp=0.65, tn=0.18, fp=0.11, fn=0.056		False
	86	0.02603		0.7535		0.9859		0.5614		0.9962	0.8804		tp=0.64, tn=0.18, fp=0.11, fn=0.063		False
	87	0.02272		0.8137		0.9877		0.5432		0.9966	0.8826		tp=0.66, tn=0.17, fp=0.1, fn=0.07		False
	88	0.02172		0.9119		0.9895		0.5095		0.9971	0.8667		tp=0.64, tn=0.17, fp=0.13, fn=0.063		False
	89	0.02167		0.8376		0.9894		0.572		0.9971	0.8792		tp=0.64, tn=0.19, fp=0.12, fn=0.056		False
	90	0.02269		0.863		0.9859		0.5505		0.9962	0.8738		tp=0.63, tn=0.19, fp=0.1, fn=0.077		False
	91	0.02515		0.8481		0.9822		0.5376		0.9952	0.8683		tp=0.62, tn=0.19, fp=0.11, fn=0.077		False
	92	0.02367		0.8777		0.9841		0.5699		0.9957	0.8804		tp=0.64, tn=0.18, fp=0.13, fn=0.049		False
	93	0.0204		0.9753		0.9895		0.5385		0.9971	0.872		tp=0.64, tn=0.17, fp=0.15, fn=0.042		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		66
learning rate		0.00286565621769
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_128-lr0.0029-h_size66-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.656		0.6189		0.2621		0.401		0.6611	0.7125		tp=0.37, tn=0.33, fp=0.14, fn=0.16		True
	2	0.6288		0.6175		0.3081		0.3306		0.6803	0.6977		tp=0.38, tn=0.28, fp=0.19, fn=0.15		False
	3	0.6106		0.6124		0.3296		0.3156		0.6872	0.6546		tp=0.33, tn=0.33, fp=0.15, fn=0.19		False
	4	0.5987		0.6108		0.3613		0.3208		0.6926	0.6901		tp=0.38, tn=0.28, fp=0.19, fn=0.14		False
	5	0.5805		0.6303		0.4039		0.2839		0.7163	0.6729		tp=0.37, tn=0.28, fp=0.2, fn=0.16		False
	6	0.5716		0.6212		0.3968		0.2953		0.7136	0.6989		tp=0.41, tn=0.24, fp=0.23, fn=0.12		False
	7	0.559		0.6544		0.4295		0.2445		0.7273	0.6005		tp=0.29, tn=0.33, fp=0.15, fn=0.24		False
	8	0.5376		0.6718		0.4565		0.2425		0.7415	0.5739		tp=0.26, tn=0.36, fp=0.13, fn=0.25		False
	9	0.5312		0.6653		0.464		0.2686		0.7436	0.6911		tp=0.41, tn=0.22, fp=0.26, fn=0.11		False
	10	0.5187		0.6973		0.4733		0.2279		0.7491	0.5616		tp=0.25, tn=0.36, fp=0.13, fn=0.26		False
	11	0.5159		0.7555		0.4831		0.2728		0.7508	0.7047		tp=0.44, tn=0.19, fp=0.29, fn=0.077		False
	12	0.4951		0.6731		0.5172		0.277		0.7704	0.6619		tp=0.35, tn=0.29, fp=0.2, fn=0.16		False
	13	0.4732		0.7059		0.5407		0.1923		0.7794	0.6235		tp=0.33, tn=0.26, fp=0.22, fn=0.18		False
	14	0.4606		0.7713		0.5597		0.2753		0.7879	0.524		tp=0.21, tn=0.41, fp=0.077, fn=0.31		False
	15	0.4665		0.6544		0.5408		0.2911		0.7802	0.6618		tp=0.35, tn=0.3, fp=0.18, fn=0.17		False
	16	0.4327		0.765		0.5983		0.2812		0.8069	0.5789		tp=0.25, tn=0.38, fp=0.11, fn=0.26		False
	17	0.4175		0.7854		0.6155		0.3297		0.8135	0.6415		tp=0.31, tn=0.35, fp=0.12, fn=0.22		False
	18	0.4117		0.7983		0.633		0.3017		0.8237	0.5799		tp=0.25, tn=0.38, fp=0.092, fn=0.27		False
	19	0.4047		0.7749		0.6319		0.2456		0.8228	0.6334		tp=0.33, tn=0.3, fp=0.18, fn=0.19		False
	20	0.3711		0.7852		0.6688		0.2614		0.8393	0.6843		tp=0.4, tn=0.24, fp=0.23, fn=0.14		False
	21	0.3666		0.8047		0.6873		0.2381		0.8486	0.6652		tp=0.38, tn=0.24, fp=0.24, fn=0.14		False
	22	0.3339		0.856		0.7364		0.2495		0.8727	0.5918		tp=0.28, tn=0.34, fp=0.13, fn=0.25		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		62
learning rate		5.08103898551e&05
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_129-lr5.1e&05-h_size62-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.621		0.6312		0		0		0.8183	0.8085		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6126		0.6296		0		0		0.8182	0.8085		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.6084		0.6217		0		0		0.8182	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	4	0.6049		0.6207		0		0		0.8182	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	5	0.6013		0.6183		0.02033		0		0.818	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	6	0.5973		0.6115		0.03526		0		0.8186	0.8137		tp=0.69, tn=0, fp=0.31, fn=0		False
	7	0.5941		0.6107		0.02877		0		0.8183	0.8151		tp=0.69, tn=0, fp=0.31, fn=0		False
	8	0.5898		0.626		0.0576		0		0.819	0.8057		tp=0.67, tn=0, fp=0.33, fn=0		False
	9	0.5869		0.6159		0.08047		0.05596		0.8194	0.8092		tp=0.68, tn=0.0015, fp=0.32, fn=0		True
	10	0.5828		0.614		0.07945		0		0.8195	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	11	0.5793		0.616		0.111		0.1247		0.821	0.8099		tp=0.68, tn=0.0074, fp=0.32, fn=0		True
	12	0.5757		0.6089		0.143		0.183		0.8227	0.8186		tp=0.68, tn=0.022, fp=0.3, fn=0.0044		True
	13	0.5723		0.605		0.146		0.1584		0.823	0.8167		tp=0.68, tn=0.016, fp=0.3, fn=0.0029		False
	14	0.5694		0.6071		0.173		0.1758		0.8247	0.8156		tp=0.67, tn=0.03, fp=0.29, fn=0.012		False
	15	0.5664		0.6108		0.1752		0.1662		0.8246	0.8123		tp=0.66, tn=0.03, fp=0.29, fn=0.013		False
	16	0.5633		0.609		0.2069		0.1363		0.8272	0.8123		tp=0.67, tn=0.025, fp=0.29, fn=0.015		False
	17	0.5602		0.6066		0.206		0.1502		0.8268	0.8112		tp=0.66, tn=0.027, fp=0.3, fn=0.013		False
	18	0.5568		0.6044		0.2284		0.1377		0.8287	0.8131		tp=0.66, tn=0.031, fp=0.28, fn=0.022		False
	19	0.5549		0.608		0.2298		0.1278		0.8287	0.8059		tp=0.65, tn=0.036, fp=0.28, fn=0.03		False
	20	0.5521		0.6132		0.2441		0.1435		0.8294	0.7978		tp=0.63, tn=0.049, fp=0.28, fn=0.041		False
	21	0.5495		0.6061		0.254		0.1502		0.8303	0.8052		tp=0.64, tn=0.05, fp=0.27, fn=0.044		False
	22	0.5468		0.6065		0.2668		0.1504		0.8316	0.8085		tp=0.65, tn=0.046, fp=0.27, fn=0.039		False
	23	0.5443		0.6111		0.2779		0.2198		0.8333	0.7992		tp=0.6, tn=0.096, fp=0.22, fn=0.086		True
	24	0.5435		0.6096		0.2861		0.1621		0.8338	0.7996		tp=0.63, tn=0.056, fp=0.27, fn=0.046		False
	25	0.5413		0.6153		0.2945		0.1464		0.8345	0.8052		tp=0.64, tn=0.043, fp=0.28, fn=0.034		False
	26	0.5381		0.6089		0.2925		0.1679		0.8333	0.8019		tp=0.63, tn=0.061, fp=0.26, fn=0.052		False
	27	0.5369		0.6056		0.3063		0.1678		0.8359	0.8079		tp=0.64, tn=0.058, fp=0.25, fn=0.05		False
	28	0.5337		0.6078		0.3172		0.1943		0.8366	0.8049		tp=0.63, tn=0.071, fp=0.25, fn=0.058		False
	29	0.5335		0.6089		0.3067		0.2116		0.8347	0.8088		tp=0.63, tn=0.073, fp=0.24, fn=0.053		False
	30	0.5302		0.6108		0.3277		0.2078		0.8385	0.8016		tp=0.61, tn=0.087, fp=0.22, fn=0.079		False
	31	0.5289		0.6158		0.3317		0.1837		0.8382	0.8045		tp=0.63, tn=0.064, fp=0.26, fn=0.05		False
	32	0.5281		0.613		0.3354		0.2086		0.8391	0.8		tp=0.61, tn=0.086, fp=0.23, fn=0.072		False
	33	0.5259		0.6218		0.3415		0.1724		0.8386	0.8097		tp=0.65, tn=0.05, fp=0.27, fn=0.037		False
	34	0.5241		0.6145		0.3388		0.2004		0.8386	0.7996		tp=0.61, tn=0.077, fp=0.25, fn=0.061		False
	35	0.5219		0.6163		0.3439		0.2065		0.8396	0.7953		tp=0.6, tn=0.09, fp=0.23, fn=0.078		False
	36	0.5218		0.6221		0.3639		0.1616		0.8419	0.7973		tp=0.62, tn=0.064, fp=0.26, fn=0.058		False
	37	0.5198		0.6175		0.3481		0.2072		0.8394	0.805		tp=0.62, tn=0.079, fp=0.24, fn=0.064		False
	38	0.5179		0.6179		0.3714		0.2065		0.8441	0.8106		tp=0.64, tn=0.067, fp=0.25, fn=0.047		False
	39	0.5181		0.6226		0.3569		0.228		0.8395	0.8046		tp=0.62, tn=0.084, fp=0.24, fn=0.061		True
	40	0.5159		0.6223		0.3719		0.1986		0.8427	0.8049		tp=0.62, tn=0.072, fp=0.25, fn=0.058		False
	41	0.515		0.6174		0.3616		0.2194		0.8407	0.8035		tp=0.61, tn=0.086, fp=0.23, fn=0.068		False
	42	0.513		0.6181		0.3678		0.2156		0.8418	0.805		tp=0.62, tn=0.083, fp=0.23, fn=0.067		False
	43	0.5119		0.6067		0.3802		0.2208		0.844	0.8088		tp=0.62, tn=0.083, fp=0.23, fn=0.067		False
	44	0.5099		0.623		0.3849		0.1993		0.8452	0.7969		tp=0.6, tn=0.087, fp=0.23, fn=0.08		False
	45	0.5105		0.6235		0.3714		0.2176		0.842	0.7929		tp=0.59, tn=0.099, fp=0.22, fn=0.086		False
	46	0.5089		0.6264		0.3827		0.2134		0.8433	0.8061		tp=0.62, tn=0.077, fp=0.24, fn=0.058		False
	47	0.5077		0.6257		0.3864		0.2165		0.8445	0.8057		tp=0.62, tn=0.076, fp=0.25, fn=0.053		False
	48	0.5083		0.629		0.3762		0.2022		0.8418	0.7969		tp=0.61, tn=0.084, fp=0.24, fn=0.071		False
	49	0.5063		0.6243		0.3869		0.2112		0.8443	0.798		tp=0.6, tn=0.092, fp=0.22, fn=0.081		False
	50	0.5045		0.6208		0.3967		0.2071		0.8464	0.7884		tp=0.58, tn=0.1, fp=0.22, fn=0.098		False
	51	0.5031		0.6235		0.3911		0.2011		0.8455	0.7953		tp=0.6, tn=0.089, fp=0.23, fn=0.08		False
	52	0.5022		0.6347		0.3984		0.1963		0.8461	0.7937		tp=0.6, tn=0.086, fp=0.24, fn=0.076		False
	53	0.5026		0.634		0.3985		0.2052		0.8462	0.7847		tp=0.58, tn=0.11, fp=0.21, fn=0.1		False
	54	0.5032		0.6289		0.398		0.1884		0.845	0.784		tp=0.58, tn=0.099, fp=0.22, fn=0.1		False
	55	0.5024		0.641		0.4006		0.142		0.846	0.7396		tp=0.52, tn=0.12, fp=0.2, fn=0.17		False
	56	0.501		0.635		0.3986		0.1931		0.8444	0.7901		tp=0.59, tn=0.092, fp=0.23, fn=0.087		False
	57	0.5004		0.6272		0.3986		0.1853		0.8452	0.7853		tp=0.59, tn=0.095, fp=0.22, fn=0.096		False
	58	0.4991		0.6365		0.3885		0.181		0.842	0.7697		tp=0.56, tn=0.11, fp=0.21, fn=0.12		False
	59	0.4993		0.6342		0.3993		0.1985		0.8447	0.7768		tp=0.56, tn=0.11, fp=0.21, fn=0.11		False
	60	0.4983		0.6378		0.406		0.197		0.8459	0.8008		tp=0.62, tn=0.078, fp=0.24, fn=0.067		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		66
learning rate		5.15558645949e&05
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_12-lr5.2e&05-h_size66-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6225		0.6399		0.0147		0		0.8182	0.8039		tp=0.67, tn=0, fp=0.33, fn=0		False
	2	0.6133		0.627		0		0		0.8184	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.6092		0.6187		0		0		0.8182	0.8147		tp=0.69, tn=0, fp=0.31, fn=0		False
	4	0.6055		0.628		0		0		0.818	0.8067		tp=0.68, tn=0, fp=0.32, fn=0		False
	5	0.6022		0.6164		0		0		0.818	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	6	0.5988		0.6168		0.02035		0		0.8184	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	7	0.5946		0.6178		0.04073		0		0.8188	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	8	0.5911		0.6167		0.0513		0		0.8189	0.813		tp=0.68, tn=0, fp=0.32, fn=0		False
	9	0.5882		0.6097		0.05717		0.08084		0.8192	0.8162		tp=0.69, tn=0.003, fp=0.31, fn=0		True
	10	0.5848		0.6117		0.08302		0.1876		0.8193	0.8207		tp=0.68, tn=0.021, fp=0.29, fn=0.003		True
	11	0.5812		0.6089		0.1057		0.08056		0.8209	0.8151		tp=0.69, tn=0.003, fp=0.31, fn=0		False
	12	0.5779		0.6156		0.1207		0.1434		0.8215	0.8111		tp=0.67, tn=0.016, fp=0.31, fn=0.0044		False
	13	0.574		0.6133		0.1334		0.09777		0.8221	0.8131		tp=0.68, tn=0.0044, fp=0.31, fn=0		False
	14	0.5708		0.6079		0.1471		0.1638		0.8226	0.8178		tp=0.68, tn=0.015, fp=0.3, fn=0.0015		False
	15	0.5682		0.6105		0.1638		0.1342		0.824	0.8077		tp=0.65, tn=0.036, fp=0.28, fn=0.028		False
	16	0.5642		0.6115		0.1966		0.1423		0.8268	0.8084		tp=0.66, tn=0.028, fp=0.3, fn=0.016		False
	17	0.5622		0.6146		0.2047		0.1613		0.827	0.8184		tp=0.68, tn=0.012, fp=0.3, fn=0		False
	18	0.5594		0.6077		0.2058		0.1641		0.8267	0.8193		tp=0.68, tn=0.022, fp=0.29, fn=0.0074		False
	19	0.5572		0.6083		0.2367		0.1497		0.8299	0.8063		tp=0.65, tn=0.041, fp=0.28, fn=0.031		False
	20	0.5543		0.6067		0.2361		0.1497		0.829	0.8063		tp=0.65, tn=0.041, fp=0.28, fn=0.031		False
	21	0.5513		0.607		0.2467		0.1345		0.8302	0.8055		tp=0.65, tn=0.04, fp=0.28, fn=0.034		False
	22	0.549		0.6104		0.2509		0.1583		0.8299	0.8071		tp=0.64, tn=0.047, fp=0.27, fn=0.037		False
	23	0.5475		0.6071		0.2704		0.1851		0.8316	0.8097		tp=0.64, tn=0.055, fp=0.26, fn=0.039		False
	24	0.5445		0.6174		0.2727		0.1623		0.8324	0.8124		tp=0.66, tn=0.034, fp=0.29, fn=0.019		False
	25	0.5428		0.603		0.2884		0.1558		0.8336	0.8082		tp=0.65, tn=0.047, fp=0.27, fn=0.039		False
	26	0.5403		0.6068		0.289		0.1793		0.8335	0.8078		tp=0.64, tn=0.055, fp=0.26, fn=0.04		False
	27	0.538		0.608		0.2963		0.2068		0.8346	0.8061		tp=0.62, tn=0.075, fp=0.24, fn=0.059		True
	28	0.536		0.6069		0.3183		0.1861		0.8369	0.8071		tp=0.64, tn=0.061, fp=0.26, fn=0.046		False
	29	0.5344		0.6059		0.3211		0.1907		0.8372	0.8068		tp=0.63, tn=0.067, fp=0.25, fn=0.053		False
	30	0.5316		0.6123		0.3216		0.2248		0.8373	0.8		tp=0.6, tn=0.093, fp=0.23, fn=0.076		True
	31	0.5314		0.6071		0.3365		0.1874		0.8393	0.8049		tp=0.63, tn=0.07, fp=0.24, fn=0.059		False
	32	0.5284		0.6142		0.3315		0.1815		0.8383	0.8075		tp=0.64, tn=0.059, fp=0.26, fn=0.046		False
	33	0.5264		0.6115		0.3329		0.1964		0.8382	0.7988		tp=0.61, tn=0.078, fp=0.24, fn=0.065		False
	34	0.5256		0.612		0.3413		0.198		0.8384	0.8075		tp=0.63, tn=0.065, fp=0.25, fn=0.047		False
	35	0.5233		0.6121		0.3475		0.2049		0.8408	0.8031		tp=0.62, tn=0.077, fp=0.24, fn=0.061		False
	36	0.5218		0.6149		0.3452		0.18		0.8397	0.8027		tp=0.63, tn=0.067, fp=0.25, fn=0.056		False
	37	0.5202		0.6172		0.3546		0.2082		0.8404	0.7965		tp=0.6, tn=0.09, fp=0.23, fn=0.078		False
	38	0.5197		0.621		0.3527		0.1817		0.8391	0.806		tp=0.63, tn=0.061, fp=0.26, fn=0.047		False
	39	0.5179		0.6151		0.3703		0.2165		0.8438	0.8054		tp=0.62, tn=0.086, fp=0.23, fn=0.073		False
	40	0.5161		0.6208		0.3663		0.2079		0.8421	0.8023		tp=0.62, tn=0.08, fp=0.24, fn=0.064		False
	41	0.5149		0.618		0.3723		0.2193		0.8432	0.7941		tp=0.59, tn=0.099, fp=0.22, fn=0.086		False
	42	0.5137		0.6396		0.3795		0.1421		0.8441	0.8007		tp=0.63, tn=0.05, fp=0.27, fn=0.046		False
	43	0.5125		0.6224		0.3774		0.2215		0.8434	0.8004		tp=0.61, tn=0.092, fp=0.23, fn=0.076		False
	44	0.5126		0.6176		0.3667		0.2167		0.8407	0.8088		tp=0.63, tn=0.078, fp=0.24, fn=0.061		False
	45	0.511		0.6278		0.3768		0.1973		0.8431	0.781		tp=0.57, tn=0.11, fp=0.22, fn=0.11		False
	46	0.5103		0.6161		0.3774		0.2102		0.8419	0.8091		tp=0.63, tn=0.071, fp=0.25, fn=0.052		False
	47	0.5084		0.6221		0.383		0.209		0.8437	0.8088		tp=0.63, tn=0.073, fp=0.24, fn=0.055		False
	48	0.5068		0.6256		0.3891		0.1937		0.8457	0.7828		tp=0.58, tn=0.1, fp=0.22, fn=0.099		False
	49	0.5054		0.6305		0.3801		0.2104		0.843	0.8072		tp=0.63, tn=0.071, fp=0.25, fn=0.05		False
	50	0.5067		0.6316		0.3787		0.2045		0.842	0.7905		tp=0.59, tn=0.095, fp=0.23, fn=0.084		False
	51	0.5048		0.6307		0.397		0.2036		0.8457	0.8008		tp=0.62, tn=0.078, fp=0.24, fn=0.062		False


data			/scratch/asw462/data/levin
input size		300
hidden size		46
learning rate		0.000134079119952
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_130-lr0.00013-h_size46-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6051		0.5959		0.04328		0		0.8244	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5777		0.5978		0		0		0.8416	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	3	0.5712		0.58		0		0		0.8416	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	4	0.5612		0.5619		0		0		0.844	0.8434		tp=0.73, tn=0, fp=0.27, fn=0		False
	5	0.5587		0.5633		0		0		0.8422	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	6	0.553		0.567		0		0		0.8416	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	7	0.5443		0.5545		0		0		0.843	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	8	0.5382		0.5615		0.0969		0		0.8443	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	9	0.5346		0.5639		0.1256		0.05176		0.8446	0.8216		tp=0.69, tn=0.007, fp=0.29, fn=0.007		True
	10	0.5243		0.5344		0.1712		0		0.8489	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	11	0.5214		0.5389		0.2034		0		0.8487	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	12	0.515		0.5607		0.1882		0.04801		0.8478	0.8133		tp=0.68, tn=0.0069, fp=0.31, fn=0.0069		False
	13	0.5042		0.5542		0.2746		0		0.8564	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	14	0.4979		0.5363		0.249		0.2116		0.8541	0.8368		tp=0.7, tn=0.028, fp=0.27, fn=0.007		True
	15	0.4928		0.5254		0.3062		0.2116		0.8586	0.8368		tp=0.7, tn=0.028, fp=0.27, fn=0.007		False
	16	0.4847		0.5438		0.3026		0.2975		0.8589	0.8246		tp=0.65, tn=0.069, fp=0.26, fn=0.021		True
	17	0.4817		0.5406		0.3392		0.2046		0.8619	0.8305		tp=0.69, tn=0.035, fp=0.27, fn=0.014		False
	18	0.4755		0.5186		0.3624		0.2946		0.8651	0.8559		tp=0.71, tn=0.056, fp=0.22, fn=0.021		False
	19	0.4674		0.5149		0.3886		0.2836		0.8688	0.8448		tp=0.69, tn=0.063, fp=0.22, fn=0.028		False
	20	0.4616		0.5073		0.4112		0.2907		0.8712	0.8498		tp=0.69, tn=0.063, fp=0.22, fn=0.028		False
	21	0.4525		0.5404		0.4259		0.2016		0.8741	0.824		tp=0.67, tn=0.042, fp=0.27, fn=0.021		False
	22	0.4428		0.5314		0.4462		0.3028		0.8783	0.8356		tp=0.66, tn=0.084, fp=0.22, fn=0.042		True
	23	0.442		0.5084		0.4677		0.3171		0.8825	0.8547		tp=0.7, tn=0.063, fp=0.22, fn=0.021		True
	24	0.4356		0.508		0.4739		0.2294		0.8815	0.8426		tp=0.69, tn=0.049, fp=0.23, fn=0.028		False
	25	0.4306		0.5229		0.4986		0.3157		0.885	0.837		tp=0.66, tn=0.077, fp=0.23, fn=0.028		False
	26	0.4254		0.5134		0.4753		0.3239		0.8815	0.8435		tp=0.67, tn=0.076, fp=0.22, fn=0.028		True
	27	0.4194		0.5172		0.5367		0.2655		0.8924	0.8384		tp=0.67, tn=0.07, fp=0.22, fn=0.042		False
	28	0.4125		0.5086		0.5538		0.4173		0.8961	0.8559		tp=0.66, tn=0.11, fp=0.19, fn=0.035		True
	29	0.4067		0.4883		0.556		0.4121		0.8955	0.8634		tp=0.69, tn=0.098, fp=0.19, fn=0.028		False
	30	0.4003		0.4812		0.564		0.3107		0.8987	0.8407		tp=0.66, tn=0.084, fp=0.21, fn=0.042		False
	31	0.3943		0.5031		0.5785		0.4343		0.9012	0.8507		tp=0.65, tn=0.12, fp=0.2, fn=0.028		True
	32	0.3892		0.4869		0.5886		0.3842		0.9021	0.8533		tp=0.67, tn=0.1, fp=0.19, fn=0.042		False
	33	0.381		0.5162		0.599		0.3324		0.9051	0.8458		tp=0.67, tn=0.084, fp=0.21, fn=0.035		False
	34	0.3784		0.5029		0.609		0.3847		0.9061	0.8341		tp=0.62, tn=0.14, fp=0.17, fn=0.077		False
	35	0.3756		0.5314		0.5961		0.3621		0.9035	0.8333		tp=0.63, tn=0.12, fp=0.2, fn=0.056		False
	36	0.3724		0.5205		0.622		0.3408		0.9077	0.8393		tp=0.66, tn=0.091, fp=0.22, fn=0.035		False
	37	0.3639		0.4856		0.6215		0.404		0.9093	0.8571		tp=0.67, tn=0.1, fp=0.19, fn=0.035		False
	38	0.3593		0.4771		0.6559		0.4088		0.9152	0.8545		tp=0.66, tn=0.12, fp=0.17, fn=0.049		False
	39	0.352		0.5076		0.6498		0.3771		0.9146	0.8455		tp=0.65, tn=0.11, fp=0.19, fn=0.049		False
	40	0.3483		0.5203		0.6708		0.3359		0.919	0.8416		tp=0.65, tn=0.1, fp=0.18, fn=0.063		False
	41	0.3465		0.5181		0.6543		0.3948		0.9149	0.8533		tp=0.67, tn=0.098, fp=0.2, fn=0.028		False
	42	0.3409		0.4969		0.6673		0.463		0.9186	0.8611		tp=0.65, tn=0.14, fp=0.16, fn=0.049		True
	43	0.3372		0.4451		0.6576		0.4679		0.9153	0.8739		tp=0.67, tn=0.13, fp=0.14, fn=0.056		True
	44	0.331		0.4918		0.684		0.4729		0.9217	0.8598		tp=0.64, tn=0.15, fp=0.16, fn=0.049		True
	45	0.3227		0.5302		0.6843		0.3876		0.9225	0.8455		tp=0.65, tn=0.11, fp=0.2, fn=0.042		False
	46	0.3221		0.5106		0.6819		0.4026		0.9217	0.8479		tp=0.64, tn=0.13, fp=0.17, fn=0.056		False
	47	0.3196		0.4998		0.6852		0.438		0.922	0.8491		tp=0.63, tn=0.15, fp=0.16, fn=0.063		False
	48	0.3159		0.5152		0.6857		0.4421		0.9218	0.8571		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False
	49	0.3106		0.5114		0.7144		0.3207		0.9272	0.8349		tp=0.64, tn=0.11, fp=0.17, fn=0.084		False
	50	0.3057		0.512		0.6935		0.4246		0.9236	0.8451		tp=0.63, tn=0.14, fp=0.17, fn=0.056		False
	51	0.302		0.4846		0.7026		0.4333		0.9263	0.8636		tp=0.66, tn=0.13, fp=0.15, fn=0.056		False
	52	0.2994		0.5107		0.7222		0.4308		0.9303	0.8584		tp=0.66, tn=0.13, fp=0.17, fn=0.049		False
	53	0.2938		0.5153		0.7257		0.3876		0.9309	0.8455		tp=0.65, tn=0.11, fp=0.2, fn=0.042		False
	54	0.2941		0.4887		0.6949		0.4163		0.9246	0.8436		tp=0.62, tn=0.15, fp=0.15, fn=0.077		False
	55	0.2903		0.5242		0.7235		0.4308		0.9299	0.8584		tp=0.66, tn=0.13, fp=0.17, fn=0.049		False
	56	0.2864		0.5263		0.7427		0.4328		0.9344	0.8451		tp=0.63, tn=0.14, fp=0.18, fn=0.049		False
	57	0.2828		0.5102		0.7367		0.35		0.9335	0.8402		tp=0.64, tn=0.11, fp=0.18, fn=0.063		False
	58	0.2827		0.5124		0.7302		0.3923		0.9319	0.8571		tp=0.67, tn=0.1, fp=0.18, fn=0.042		False
	59	0.2744		0.5209		0.7539		0.4274		0.9376	0.8491		tp=0.63, tn=0.15, fp=0.15, fn=0.077		False
	60	0.2714		0.5242		0.7587		0.4416		0.939	0.8634		tp=0.68, tn=0.1, fp=0.19, fn=0.021		False
	61	0.2657		0.4933		0.7604		0.4475		0.9381	0.8476		tp=0.62, tn=0.15, fp=0.16, fn=0.063		False
	62	0.2672		0.5298		0.7496		0.422		0.936	0.8545		tp=0.65, tn=0.12, fp=0.17, fn=0.049		False
	63	0.2601		0.5571		0.7711		0.4035		0.9407	0.8357		tp=0.62, tn=0.13, fp=0.2, fn=0.049		False
	64	0.2549		0.5498		0.7787		0.3558		0.9436	0.8387		tp=0.64, tn=0.12, fp=0.17, fn=0.07		False
	65	0.2558		0.5489		0.7868		0.4209		0.9447	0.8532		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		125
learning rate		0.000136339909152
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_131-lr0.00014-h_size125-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6917		0.6875		0.01942		0.1613		0.6041	0.6524		tp=0.39, tn=0.2, fp=0.27, fn=0.14		True
	2	0.6863		0.6844		0.118		0.1792		0.597	0.6294		tp=0.35, tn=0.25, fp=0.23, fn=0.18		True
	3	0.6805		0.6793		0.1744		0.2054		0.6312	0.6867		tp=0.44, tn=0.16, fp=0.31, fn=0.087		True
	4	0.6748		0.6798		0.1977		0.1777		0.6503	0.5668		tp=0.27, tn=0.31, fp=0.17, fn=0.25		False
	5	0.6688		0.6745		0.2227		0.2034		0.6309	0.6485		tp=0.36, tn=0.24, fp=0.23, fn=0.16		False
	6	0.6627		0.6715		0.2363		0.1767		0.6348	0.6653		tp=0.41, tn=0.19, fp=0.28, fn=0.12		False
	7	0.6564		0.6779		0.257		0.1854		0.6615	0.5774		tp=0.28, tn=0.31, fp=0.16, fn=0.25		False
	8	0.6514		0.6715		0.2555		0.1537		0.6352	0.6653		tp=0.42, tn=0.16, fp=0.31, fn=0.11		False
	9	0.6442		0.6669		0.2891		0.1985		0.661	0.6422		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	10	0.6406		0.6711		0.2819		0.1929		0.6543	0.6217		tp=0.33, tn=0.27, fp=0.22, fn=0.18		False
	11	0.6329		0.6717		0.3126		0.1603		0.6684	0.6538		tp=0.39, tn=0.2, fp=0.27, fn=0.15		False
	12	0.628		0.6723		0.3205		0.1481		0.6742	0.6066		tp=0.33, tn=0.25, fp=0.25, fn=0.18		False
	13	0.6231		0.6738		0.3323		0.1271		0.6799	0.6115		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	14	0.6209		0.682		0.3374		0.1519		0.6787	0.6389		tp=0.37, tn=0.2, fp=0.28, fn=0.14		False
	15	0.6154		0.6807		0.3507		0.1871		0.6886	0.5722		tp=0.27, tn=0.32, fp=0.16, fn=0.25		False
	16	0.6115		0.6727		0.3495		0.1458		0.6776	0.6207		tp=0.35, tn=0.23, fp=0.24, fn=0.18		False
	17	0.6086		0.6811		0.3581		0.1108		0.6879	0.577		tp=0.3, tn=0.25, fp=0.23, fn=0.22		False
	18	0.6043		0.6806		0.3653		0.1398		0.6931	0.6089		tp=0.33, tn=0.24, fp=0.23, fn=0.2		False
	19	0.6017		0.6871		0.3747		0.1528		0.697	0.5765		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	20	0.5985		0.6798		0.3748		0.1284		0.6996	0.5854		tp=0.31, tn=0.26, fp=0.22, fn=0.22		False
	21	0.5964		0.6733		0.3776		0.1738		0.6966	0.6005		tp=0.31, tn=0.28, fp=0.2, fn=0.22		False
	22	0.5938		0.688		0.3836		0.1213		0.7021	0.586		tp=0.31, tn=0.25, fp=0.24, fn=0.2		False
	23	0.5925		0.6929		0.3748		0.162		0.6987	0.5816		tp=0.29, tn=0.29, fp=0.18, fn=0.24		False
	24	0.5892		0.6923		0.3966		0.1235		0.7065	0.5952		tp=0.32, tn=0.24, fp=0.23, fn=0.21		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		23
learning rate		0.000292779332444
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_132-lr0.00029-h_size23-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6905		0.6792		0.1116		0.2483		0.5694	0.6207		tp=0.31, tn=0.3, fp=0.13, fn=0.25		True
	2	0.6499		0.6629		0.3381		0.2064		0.5933	0.6957		tp=0.45, tn=0.16, fp=0.3, fn=0.091		False
	3	0.6239		0.6537		0.4628		0.3052		0.7341	0.6434		tp=0.32, tn=0.32, fp=0.12, fn=0.24		True
	4	0.5952		0.6491		0.4714		0.2891		0.7066	0.671		tp=0.36, tn=0.28, fp=0.19, fn=0.16		False
	5	0.5723		0.6421		0.5726		0.2669		0.7704	0.6667		tp=0.36, tn=0.27, fp=0.17, fn=0.19		False
	6	0.5484		0.6313		0.5667		0.3363		0.7673	0.7152		tp=0.41, tn=0.26, fp=0.19, fn=0.14		True
	7	0.5281		0.645		0.5979		0.2755		0.7927	0.6131		tp=0.29, tn=0.34, fp=0.13, fn=0.24		False
	8	0.5106		0.6582		0.6039		0.2829		0.797	0.5455		tp=0.23, tn=0.38, fp=0.077, fn=0.31		False
	9	0.4842		0.6353		0.6375		0.3538		0.805	0.7089		tp=0.39, tn=0.29, fp=0.19, fn=0.13		True
	10	0.4725		0.6329		0.6401		0.3061		0.8075	0.6918		tp=0.38, tn=0.27, fp=0.17, fn=0.17		False
	11	0.4468		0.6467		0.7212		0.1804		0.8558	0.5693		tp=0.27, tn=0.31, fp=0.17, fn=0.24		False
	12	0.4313		0.6519		0.7128		0.184		0.8488	0.5986		tp=0.31, tn=0.28, fp=0.16, fn=0.25		False
	13	0.4095		0.6424		0.7394		0.2686		0.8624	0.6623		tp=0.36, tn=0.28, fp=0.17, fn=0.19		False
	14	0.3917		0.6408		0.7729		0.2892		0.8777	0.6914		tp=0.39, tn=0.26, fp=0.19, fn=0.16		False
	15	0.3738		0.6492		0.8092		0.2885		0.902	0.6286		tp=0.31, tn=0.33, fp=0.13, fn=0.24		False
	16	0.3611		0.6276		0.7978		0.2387		0.8943	0.6538		tp=0.36, tn=0.27, fp=0.18, fn=0.2		False
	17	0.3438		0.6428		0.8389		0.3249		0.9158	0.6883		tp=0.37, tn=0.29, fp=0.17, fn=0.16		False
	18	0.3291		0.6592		0.8538		0.3083		0.9231	0.6277		tp=0.3, tn=0.35, fp=0.12, fn=0.24		False
	19	0.3162		0.658		0.8476		0.3		0.9205	0.6667		tp=0.35, tn=0.3, fp=0.16, fn=0.19		False
	20	0.2999		0.6466		0.8651		0.2922		0.9301	0.6623		tp=0.35, tn=0.29, fp=0.14, fn=0.22		False
	21	0.2866		0.6734		0.9007		0.2477		0.9479	0.6351		tp=0.33, tn=0.29, fp=0.16, fn=0.22		False
	22	0.2721		0.6501		0.9094		0.275		0.9525	0.6533		tp=0.34, tn=0.29, fp=0.15, fn=0.21		False
	23	0.2639		0.6413		0.9066		0.3622		0.9509	0.7205		tp=0.41, tn=0.28, fp=0.17, fn=0.14		True
	24	0.2589		0.6933		0.9037		0.2755		0.9493	0.6579		tp=0.35, tn=0.29, fp=0.18, fn=0.18		False
	25	0.2438		0.6975		0.9182		0.3096		0.9572	0.6575		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	26	0.2362		0.6887		0.9212		0.2772		0.9587	0.6533		tp=0.34, tn=0.29, fp=0.15, fn=0.22		False
	27	0.2176		0.696		0.9417		0.2708		0.9694	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.2		False
	28	0.2074		0.6988		0.9414		0.363		0.9696	0.6849		tp=0.35, tn=0.33, fp=0.13, fn=0.2		True
	29	0.1993		0.6864		0.9533		0.3289		0.9756	0.6883		tp=0.37, tn=0.29, fp=0.14, fn=0.2		False
	30	0.1907		0.7251		0.9532		0.3169		0.9757	0.6575		tp=0.34, tn=0.31, fp=0.12, fn=0.23		False
	31	0.1825		0.7536		0.9504		0.3256		0.974	0.6573		tp=0.33, tn=0.33, fp=0.13, fn=0.22		False
	32	0.1752		0.6931		0.9533		0.332		0.9756	0.6757		tp=0.35, tn=0.31, fp=0.14, fn=0.2		False
	33	0.1697		0.743		0.9533		0.3194		0.9756	0.6667		tp=0.34, tn=0.31, fp=0.14, fn=0.2		False
	34	0.1609		0.7181		0.9563		0.3373		0.9771	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.21		False
	35	0.1568		0.748		0.9622		0.3224		0.9802	0.6525		tp=0.32, tn=0.34, fp=0.13, fn=0.21		False
	36	0.1525		0.7702		0.9563		0.285		0.9771	0.6338		tp=0.31, tn=0.32, fp=0.13, fn=0.23		False
	37	0.1425		0.768		0.9679		0.3594		0.9833	0.6933		tp=0.36, tn=0.31, fp=0.13, fn=0.19		False
	38	0.1381		0.7722		0.9767		0.3325		0.9878	0.6712		tp=0.34, tn=0.32, fp=0.14, fn=0.2		False
	39	0.1337		0.7674		0.9737		0.3575		0.9863	0.6933		tp=0.36, tn=0.31, fp=0.14, fn=0.18		False
	40	0.1248		0.8226		0.9738		0.2817		0.9863	0.6338		tp=0.31, tn=0.32, fp=0.14, fn=0.22		False
	41	0.1196		0.7568		0.9737		0.3887		0.9863	0.6986		tp=0.36, tn=0.34, fp=0.13, fn=0.18		True
	42	0.1146		0.8311		0.9825		0.2938		0.9909	0.6531		tp=0.34, tn=0.31, fp=0.14, fn=0.22		False
	43	0.1101		0.827		0.9854		0.3066		0.9924	0.6667		tp=0.35, tn=0.31, fp=0.15, fn=0.19		False
	44	0.1059		0.8259		0.9883		0.301		0.994	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.23		False
	45	0.1032		0.8207		0.9883		0.2998		0.994	0.6577		tp=0.34, tn=0.3, fp=0.13, fn=0.23		False
	46	0.101		0.8357		0.9854		0.313		0.9924	0.6429		tp=0.31, tn=0.34, fp=0.13, fn=0.22		False
	47	0.09515		0.8605		0.9912		0.2897		0.9955	0.6483		tp=0.33, tn=0.31, fp=0.15, fn=0.2		False
	48	0.09181		0.7919		0.9941		0.3565		0.997	0.6974		tp=0.37, tn=0.31, fp=0.14, fn=0.18		False
	49	0.08708		0.8345		0.9941		0.3091		0.997	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	50	0.0839		0.8655		0.9912		0.3119		0.9955	0.6797		tp=0.36, tn=0.29, fp=0.16, fn=0.18		False
	51	0.08033		0.8766		0.9941		0.2969		0.997	0.6531		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	52	0.07764		0.8894		0.9971		0.2861		0.9985	0.6623		tp=0.35, tn=0.29, fp=0.16, fn=0.2		False
	53	0.0757		0.8617		0.9971		0.3145		0.9985	0.6797		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	54	0.07201		0.919		0.9971		0.2738		0.9985	0.6579		tp=0.35, tn=0.29, fp=0.15, fn=0.21		False
	55	0.07017		0.8839		0.9971		0.2789		0.9985	0.6338		tp=0.31, tn=0.32, fp=0.15, fn=0.22		False
	56	0.06785		0.9504		0.9971		0.2565		0.9985	0.6301		tp=0.32, tn=0.3, fp=0.14, fn=0.24		False
	57	0.06673		0.8702		0.9971		0.3352		0.9985	0.6667		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	58	0.06322		0.9072		0.9971		0.3289		0.9985	0.6757		tp=0.35, tn=0.31, fp=0.15, fn=0.18		False
	59	0.06092		0.9333		0.9971		0.3498		0.9985	0.7089		tp=0.39, tn=0.29, fp=0.15, fn=0.17		False
	60	0.06087		0.966		0.9971		0.3381		0.9985	0.6968		tp=0.38, tn=0.29, fp=0.16, fn=0.17		False
	61	0.05657		0.8641		0.9971		0.34		0.9985	0.6928		tp=0.37, tn=0.3, fp=0.15, fn=0.17		False
	62	0.0548		0.8726		1		0.3194		1	0.6667		tp=0.34, tn=0.31, fp=0.14, fn=0.2		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		15
learning rate		0.000284700635998
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_133-lr0.00028-h_size15-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.626		0.6338		-0.006818		0		0.8109	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6135		0.6303		0		0		0.8182	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.6086		0.6294		0		0		0.818	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	4	0.6031		0.6201		0		0		0.8183	0.8158		tp=0.69, tn=0, fp=0.31, fn=0		False
	5	0.5987		0.6238		0.06049		0.09645		0.819	0.8088		tp=0.68, tn=0.0044, fp=0.32, fn=0		True
	6	0.5936		0.6271		0.08176		0		0.8194	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	7	0.5895		0.6199		0.09707		0.07051		0.8203	0.8085		tp=0.68, tn=0.0044, fp=0.32, fn=0.0015		False
	8	0.5845		0.6117		0.111		0.08112		0.8209	0.8172		tp=0.69, tn=0.003, fp=0.31, fn=0		False
	9	0.5806		0.6125		0.1077		0.07251		0.82	0.8148		tp=0.68, tn=0.0044, fp=0.31, fn=0.0015		False
	10	0.5758		0.613		0.1518		0.1127		0.8227	0.8111		tp=0.67, tn=0.016, fp=0.3, fn=0.0089		True
	11	0.5723		0.6116		0.1745		0.1071		0.8238	0.8037		tp=0.65, tn=0.03, fp=0.29, fn=0.027		False
	12	0.5684		0.6082		0.2115		0.1272		0.8263	0.8168		tp=0.68, tn=0.019, fp=0.29, fn=0.01		True
	13	0.5653		0.6168		0.207		0.1147		0.826	0.8054		tp=0.66, tn=0.022, fp=0.3, fn=0.015		False
	14	0.563		0.6086		0.2188		0.1075		0.8258	0.8073		tp=0.66, tn=0.028, fp=0.29, fn=0.025		False
	15	0.5609		0.6114		0.2471		0.1374		0.8283	0.8119		tp=0.67, tn=0.027, fp=0.29, fn=0.016		True
	16	0.5572		0.6051		0.243		0.162		0.8272	0.8019		tp=0.63, tn=0.065, fp=0.25, fn=0.064		True
	17	0.5561		0.6133		0.2609		0.1368		0.8282	0.8011		tp=0.64, tn=0.044, fp=0.28, fn=0.039		False
	18	0.5534		0.6149		0.2654		0.1611		0.8288	0.7966		tp=0.62, tn=0.062, fp=0.26, fn=0.055		False
	19	0.5517		0.6034		0.2672		0.1654		0.8283	0.7965		tp=0.61, tn=0.072, fp=0.24, fn=0.072		True
	20	0.5511		0.6114		0.2665		0.1691		0.8279	0.8004		tp=0.63, tn=0.061, fp=0.26, fn=0.05		True
	21	0.5495		0.6064		0.284		0.1726		0.8298	0.806		tp=0.64, tn=0.056, fp=0.26, fn=0.044		True
	22	0.5476		0.6195		0.2856		0.1133		0.8285	0.8101		tp=0.66, tn=0.024, fp=0.29, fn=0.018		False
	23	0.5481		0.6042		0.2795		0.1862		0.8286	0.809		tp=0.64, tn=0.059, fp=0.26, fn=0.044		True
	24	0.545		0.6102		0.2916		0.1729		0.8297	0.8045		tp=0.63, tn=0.058, fp=0.26, fn=0.046		False
	25	0.5435		0.6161		0.2966		0.167		0.83	0.8063		tp=0.64, tn=0.052, fp=0.27, fn=0.04		False
	26	0.5438		0.6163		0.2954		0.1608		0.8301	0.7981		tp=0.62, tn=0.061, fp=0.26, fn=0.053		False
	27	0.5427		0.6188		0.3141		0.1408		0.8332	0.7985		tp=0.63, tn=0.055, fp=0.26, fn=0.053		False
	28	0.5409		0.6115		0.2974		0.1931		0.8298	0.7898		tp=0.59, tn=0.089, fp=0.24, fn=0.08		True
	29	0.541		0.6032		0.3067		0.1854		0.8312	0.803		tp=0.63, tn=0.068, fp=0.25, fn=0.056		False
	30	0.5406		0.6154		0.3114		0.1676		0.8307	0.8086		tp=0.64, tn=0.05, fp=0.27, fn=0.039		False
	31	0.5389		0.6196		0.3112		0.1806		0.8314	0.8056		tp=0.64, tn=0.058, fp=0.26, fn=0.043		False
	32	0.5392		0.6188		0.3116		0.1852		0.8302	0.8049		tp=0.63, tn=0.062, fp=0.26, fn=0.047		False
	33	0.5387		0.609		0.3165		0.2208		0.8322	0.7916		tp=0.59, tn=0.1, fp=0.22, fn=0.092		True
	34	0.5393		0.6124		0.3144		0.1753		0.8307	0.7914		tp=0.6, tn=0.081, fp=0.24, fn=0.08		False
	35	0.5379		0.6151		0.3216		0.1912		0.8318	0.7961		tp=0.61, tn=0.077, fp=0.25, fn=0.064		False
	36	0.5383		0.6111		0.3208		0.1933		0.8327	0.8042		tp=0.62, tn=0.077, fp=0.23, fn=0.07		False
	37	0.5368		0.6213		0.3222		0.1686		0.832	0.8011		tp=0.63, tn=0.064, fp=0.25, fn=0.056		False
	38	0.5369		0.6175		0.3121		0.1597		0.8306	0.7899		tp=0.6, tn=0.075, fp=0.24, fn=0.077		False
	39	0.5368		0.6114		0.3163		0.1607		0.8304	0.8008		tp=0.63, tn=0.064, fp=0.25, fn=0.061		False
	40	0.5369		0.6159		0.3245		0.1704		0.832	0.7973		tp=0.62, tn=0.07, fp=0.25, fn=0.064		False
	41	0.5356		0.6155		0.3266		0.1994		0.8328	0.7913		tp=0.6, tn=0.09, fp=0.23, fn=0.08		False
	42	0.5356		0.6116		0.3212		0.2037		0.8308	0.7855		tp=0.58, tn=0.11, fp=0.2, fn=0.11		False
	43	0.5368		0.6089		0.312		0.1801		0.8282	0.7957		tp=0.61, tn=0.079, fp=0.24, fn=0.074		False
	44	0.5344		0.6143		0.3196		0.1877		0.8309	0.8061		tp=0.63, tn=0.065, fp=0.25, fn=0.052		False
	45	0.5354		0.6175		0.3283		0.1991		0.8322	0.8098		tp=0.64, tn=0.064, fp=0.25, fn=0.046		False
	46	0.5353		0.6134		0.318		0.2171		0.8319	0.7838		tp=0.57, tn=0.11, fp=0.2, fn=0.11		False
	47	0.5337		0.6182		0.3276		0.1643		0.8318	0.7996		tp=0.62, tn=0.064, fp=0.25, fn=0.058		False
	48	0.5341		0.618		0.3176		0.1836		0.8309	0.7824		tp=0.58, tn=0.096, fp=0.23, fn=0.098		False
	49	0.5345		0.6218		0.3295		0.1485		0.8327	0.788		tp=0.6, tn=0.073, fp=0.25, fn=0.077		False
	50	0.5343		0.6155		0.3213		0.2036		0.8308	0.8109		tp=0.64, tn=0.064, fp=0.25, fn=0.044		False
	51	0.5347		0.6211		0.3179		0.1666		0.8308	0.7942		tp=0.61, tn=0.071, fp=0.25, fn=0.067		False
	52	0.5339		0.6134		0.328		0.1916		0.8326	0.793		tp=0.6, tn=0.087, fp=0.23, fn=0.081		False
	53	0.5325		0.613		0.3197		0.1832		0.8309	0.7898		tp=0.6, tn=0.086, fp=0.24, fn=0.081		False
	54	0.5331		0.6167		0.3314		0.1663		0.8323	0.7919		tp=0.61, tn=0.076, fp=0.24, fn=0.074		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		61
learning rate		0.000476873075023
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_134-lr0.00048-h_size61-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6923		0.6672		0.07972		0.2204		0.5493	0.6107		tp=0.31, tn=0.3, fp=0.16, fn=0.23		True
	2	0.649		0.6492		0.2342		0.2887		0.6211	0.6699		tp=0.36, tn=0.29, fp=0.17, fn=0.18		True
	3	0.6046		0.6598		0.3624		0.2361		0.6851	0.6825		tp=0.41, tn=0.22, fp=0.25, fn=0.13		False
	4	0.5683		0.668		0.4013		0.2299		0.7054	0.6158		tp=0.31, tn=0.3, fp=0.17, fn=0.21		False
	5	0.5225		0.7101		0.4971		0.1805		0.753	0.6708		tp=0.41, tn=0.18, fp=0.29, fn=0.12		False
	6	0.4979		0.7113		0.5313		0.2214		0.7703	0.643		tp=0.35, tn=0.26, fp=0.21, fn=0.18		False
	7	0.4627		0.8075		0.5769		0.1976		0.7911	0.4747		tp=0.19, tn=0.38, fp=0.087, fn=0.34		False
	8	0.4439		0.7674		0.591		0.1855		0.7988	0.5954		tp=0.3, tn=0.29, fp=0.19, fn=0.22		False
	9	0.4122		0.8208		0.6532		0.1744		0.8307	0.5744		tp=0.28, tn=0.3, fp=0.16, fn=0.26		False
	10	0.3852		0.8789		0.6679		0.2036		0.8372	0.5337		tp=0.23, tn=0.36, fp=0.12, fn=0.28		False
	11	0.3682		0.8587		0.688		0.2457		0.8463	0.6053		tp=0.29, tn=0.32, fp=0.14, fn=0.24		False
	12	0.3532		0.87		0.7028		0.2089		0.8536	0.6225		tp=0.33, tn=0.28, fp=0.21, fn=0.19		False
	13	0.3478		0.9356		0.7063		0.2231		0.856	0.6122		tp=0.31, tn=0.3, fp=0.17, fn=0.22		False
	14	0.3221		0.9629		0.7412		0.1474		0.873	0.5835		tp=0.3, tn=0.27, fp=0.19, fn=0.24		False
	15	0.3069		0.9528		0.7536		0.2229		0.8787	0.6344		tp=0.34, tn=0.28, fp=0.19, fn=0.19		False
	16	0.2973		1.084		0.7678		0.2261		0.8855	0.6724		tp=0.4, tn=0.21, fp=0.28, fn=0.11		False
	17	0.2794		1.061		0.775		0.1942		0.8902	0.601		tp=0.3, tn=0.29, fp=0.18, fn=0.23		False
	18	0.2622		1.075		0.7991		0.1941		0.9013	0.6217		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	19	0.2577		1.09		0.8145		0.2105		0.9091	0.6244		tp=0.33, tn=0.28, fp=0.2, fn=0.19		False
	20	0.2567		1.178		0.8026		0.1635		0.9027	0.5838		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	21	0.2503		1.222		0.8056		0.1988		0.9045	0.5659		tp=0.26, tn=0.33, fp=0.15, fn=0.25		False
	22	0.2326		1.286		0.8328		0.1959		0.9177	0.5864		tp=0.29, tn=0.31, fp=0.17, fn=0.23		False
	23	0.2135		1.288		0.847		0.1995		0.9247	0.6139		tp=0.32, tn=0.28, fp=0.19, fn=0.21		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		179
learning rate		0.000181363389464
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_135-lr0.00018-h_size179-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6957		0.6658		0.05631		0.2318		0.5662	0.685		tp=0.42, tn=0.2, fp=0.27, fn=0.11		True
	2	0.6591		0.6605		0.2422		0.2061		0.6362	0.6333		tp=0.34, tn=0.26, fp=0.21, fn=0.19		False
	3	0.6268		0.6632		0.3464		0.1906		0.6779	0.5424		tp=0.25, tn=0.34, fp=0.13, fn=0.28		False
	4	0.5944		0.6563		0.3948		0.2348		0.7023	0.6321		tp=0.33, tn=0.29, fp=0.19, fn=0.19		True
	5	0.5624		0.6612		0.4497		0.232		0.7319	0.6511		tp=0.36, tn=0.26, fp=0.2, fn=0.18		False
	6	0.5274		0.6709		0.506		0.232		0.7553	0.6444		tp=0.35, tn=0.27, fp=0.2, fn=0.18		False
	7	0.4959		0.7032		0.5522		0.211		0.7777	0.6623		tp=0.38, tn=0.23, fp=0.25, fn=0.14		False
	8	0.4748		0.7142		0.5633		0.2174		0.7856	0.5904		tp=0.28, tn=0.32, fp=0.16, fn=0.24		False
	9	0.4565		0.7085		0.5946		0.2558		0.8001	0.6651		tp=0.37, tn=0.26, fp=0.21, fn=0.16		True
	10	0.4273		0.7515		0.6366		0.1864		0.8218	0.6328		tp=0.35, tn=0.24, fp=0.24, fn=0.17		False
	11	0.4118		0.7598		0.6496		0.2205		0.8278	0.6311		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	12	0.3934		0.7687		0.6649		0.2714		0.8348	0.6728		tp=0.37, tn=0.26, fp=0.22, fn=0.15		True
	13	0.3746		0.8236		0.6951		0.2153		0.8497	0.6111		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	14	0.3634		0.8773		0.6968		0.22		0.851	0.5449		tp=0.24, tn=0.36, fp=0.12, fn=0.28		False
	15	0.351		0.8368		0.711		0.2511		0.858	0.6368		tp=0.33, tn=0.3, fp=0.18, fn=0.2		False
	16	0.3307		0.8828		0.7383		0.195		0.8724	0.6323		tp=0.35, tn=0.25, fp=0.23, fn=0.17		False
	17	0.3188		0.8835		0.7571		0.2154		0.8807	0.6432		tp=0.35, tn=0.26, fp=0.21, fn=0.18		False
	18	0.3047		0.9094		0.7666		0.2038		0.8847	0.5873		tp=0.28, tn=0.32, fp=0.17, fn=0.23		False
	19	0.3027		0.9715		0.7612		0.1625		0.8825	0.5995		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	20	0.2847		0.9671		0.7897		0.2176		0.8969	0.6127		tp=0.31, tn=0.3, fp=0.17, fn=0.22		False
	21	0.2832		1.032		0.7855		0.179		0.8941	0.6154		tp=0.33, tn=0.26, fp=0.22, fn=0.19		False
	22	0.2814		1.036		0.7896		0.1667		0.8964	0.5707		tp=0.28, tn=0.3, fp=0.17, fn=0.25		False
	23	0.2584		1.171		0.8062		0.1864		0.9044	0.526		tp=0.23, tn=0.35, fp=0.12, fn=0.3		False
	24	0.2586		1.082		0.8156		0.1886		0.9094	0.6202		tp=0.33, tn=0.27, fp=0.2, fn=0.21		False
	25	0.2441		1.138		0.8286		0.1983		0.9157	0.5791		tp=0.28, tn=0.32, fp=0.17, fn=0.23		False
	26	0.2341		1.149		0.8346		0.1675		0.919	0.6029		tp=0.32, tn=0.27, fp=0.21, fn=0.21		False
	27	0.2349		1.186		0.8393		0.1912		0.9207	0.6376		tp=0.36, tn=0.24, fp=0.25, fn=0.16		False
	28	0.2267		1.213		0.8399		0.2095		0.9213	0.591		tp=0.29, tn=0.32, fp=0.17, fn=0.23		False
	29	0.2131		1.263		0.857		0.2042		0.9296	0.6229		tp=0.33, tn=0.27, fp=0.22, fn=0.18		False
	30	0.2039		1.276		0.8683		0.2049		0.9356	0.5611		tp=0.26, tn=0.34, fp=0.14, fn=0.27		False
	31	0.2059		1.33		0.8624		0.2016		0.9324	0.6353		tp=0.35, tn=0.26, fp=0.22, fn=0.17		False
	32	0.1967		1.444		0.8671		0.1789		0.9347	0.5393		tp=0.25, tn=0.33, fp=0.14, fn=0.28		False
	33	0.1842		1.394		0.886		0.1944		0.9439	0.6199		tp=0.33, tn=0.27, fp=0.2, fn=0.2		False


data			/scratch/asw462/data/levin
input size		300
hidden size		120
learning rate		0.00289042787208
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_136-lr0.0029-h_size120-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6083		0.5582		0.1017		0.2352		0.8288	0.849		tp=0.72, tn=0.021, fp=0.26, fn=0		True
	2	0.492		0.538		0.3205		0.2865		0.8472	0.8095		tp=0.59, tn=0.13, fp=0.16, fn=0.12		True
	3	0.4491		0.5288		0.4216		0.3143		0.8681	0.8241		tp=0.62, tn=0.11, fp=0.2, fn=0.07		True
	4	0.379		0.5175		0.5657		0.4219		0.8942	0.8505		tp=0.64, tn=0.14, fp=0.15, fn=0.07		True
	5	0.323		0.5889		0.6234		0.3408		0.903	0.8393		tp=0.66, tn=0.091, fp=0.22, fn=0.035		False
	6	0.2687		0.5522		0.7145		0.5008		0.9257	0.8515		tp=0.6, tn=0.19, fp=0.13, fn=0.077		True
	7	0.3133		0.5746		0.6411		0.3231		0.905	0.8435		tp=0.68, tn=0.07, fp=0.23, fn=0.021		False
	8	0.2303		0.8225		0.7492		0.3515		0.9346	0.8485		tp=0.69, tn=0.07, fp=0.23, fn=0.014		False
	9	0.1897		0.5779		0.8219		0.455		0.9523	0.8342		tp=0.58, tn=0.19, fp=0.11, fn=0.12		False
	10	0.138		0.6107		0.8971		0.5033		0.9723	0.8612		tp=0.63, tn=0.17, fp=0.15, fn=0.056		True
	11	0.1158		0.8576		0.9041		0.4301		0.9742	0.8559		tp=0.66, tn=0.11, fp=0.2, fn=0.028		False
	12	0.1001		0.6803		0.9166		0.5428		0.9776	0.8869		tp=0.69, tn=0.14, fp=0.15, fn=0.028		True
	13	0.09593		0.5174		0.9121		0.6729		0.9759	0.9073		tp=0.65, tn=0.22, fp=0.063, fn=0.07		True
	14	0.06394		0.781		0.9664		0.5061		0.9909	0.8394		tp=0.57, tn=0.22, fp=0.1, fn=0.11		False
	15	0.05637		0.7445		0.9682		0.5985		0.9914	0.892		tp=0.66, tn=0.17, fp=0.13, fn=0.035		False
	16	0.04544		0.8276		0.9791		0.5703		0.9942	0.8868		tp=0.66, tn=0.17, fp=0.11, fn=0.056		False
	17	0.103		1.024		0.9115		0.4747		0.976	0.8661		tp=0.67, tn=0.12, fp=0.19, fn=0.021		False
	18	0.07222		0.8659		0.9418		0.5565		0.9841	0.8643		tp=0.6, tn=0.21, fp=0.11, fn=0.077		False
	19	0.05003		0.8263		0.97		0.5104		0.9918	0.8654		tp=0.63, tn=0.17, fp=0.12, fn=0.077		False
	20	0.03307		0.8787		0.9842		0.5603		0.9957	0.8657		tp=0.6, tn=0.21, fp=0.069, fn=0.12		False
	21	0.02624		0.9061		0.9912		0.6484		0.9976	0.9057		tp=0.67, tn=0.19, fp=0.1, fn=0.035		False
	22	0.0296		1.169		0.9789		0.4733		0.9942	0.8571		tp=0.63, tn=0.16, fp=0.14, fn=0.07		False
	23	0.02352		0.9644		0.9895		0.6072		0.9971	0.8889		tp=0.64, tn=0.2, fp=0.11, fn=0.049		False
	24	0.02376		1.015		0.9808		0.5594		0.9947	0.8725		tp=0.62, tn=0.2, fp=0.11, fn=0.07		False
	25	0.01959		1.163		0.9913		0.5509		0.9976	0.8762		tp=0.64, tn=0.17, fp=0.13, fn=0.049		False
	26	0.02586		1.118		0.9876		0.5876		0.9966	0.8835		tp=0.64, tn=0.2, fp=0.1, fn=0.063		False
	27	0.02527		1.133		0.9858		0.5714		0.9962	0.87		tp=0.61, tn=0.21, fp=0.11, fn=0.07		False
	28	0.01804		1.245		0.993		0.5177		0.9981	0.872		tp=0.64, tn=0.17, fp=0.12, fn=0.07		False
	29	0.01608		1.299		0.9947		0.5509		0.9986	0.8762		tp=0.64, tn=0.17, fp=0.13, fn=0.049		False
	30	0.01786		1.257		0.993		0.5823		0.9981	0.8804		tp=0.64, tn=0.18, fp=0.14, fn=0.035		False
	31	0.0167		1.186		0.993		0.5402		0.9981	0.8683		tp=0.62, tn=0.19, fp=0.12, fn=0.07		False
	32	0.01926		1.206		0.993		0.6136		0.9981	0.8952		tp=0.66, tn=0.19, fp=0.1, fn=0.049		False
	33	0.01794		1.208		0.9913		0.5867		0.9976	0.8756		tp=0.62, tn=0.21, fp=0.11, fn=0.063		False
	34	0.01515		1.228		0.9947		0.513		0.9986	0.8732		tp=0.65, tn=0.16, fp=0.13, fn=0.063		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		98
learning rate		0.000256849666036
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_137-lr0.00026-h_size98-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6586		0.6359		0.1826		0.3586		0.6153	0.7387		tp=0.48, tn=0.18, fp=0.3, fn=0.038		True
	2	0.6225		0.6075		0.3177		0.3727		0.6862	0.6755		tp=0.33, tn=0.36, fp=0.13, fn=0.18		True
	3	0.5953		0.612		0.3739		0.3613		0.7078	0.6803		tp=0.34, tn=0.34, fp=0.15, fn=0.17		False
	4	0.5859		0.608		0.3926		0.425		0.7117	0.7018		tp=0.34, tn=0.37, fp=0.12, fn=0.17		True
	5	0.5557		0.6044		0.4469		0.3679		0.7352	0.7438		tp=0.46, tn=0.22, fp=0.24, fn=0.074		False
	6	0.5387		0.5779		0.4646		0.408		0.744	0.7392		tp=0.42, tn=0.29, fp=0.18, fn=0.11		False
	7	0.5165		0.5954		0.5011		0.4487		0.7597	0.7143		tp=0.35, tn=0.38, fp=0.12, fn=0.16		True
	8	0.498		0.5935		0.5293		0.436		0.775	0.7465		tp=0.41, tn=0.3, fp=0.17, fn=0.11		False
	9	0.4803		0.6043		0.5455		0.414		0.7814	0.7311		tp=0.4, tn=0.31, fp=0.17, fn=0.12		False
	10	0.4611		0.5901		0.5671		0.4424		0.791	0.7254		tp=0.37, tn=0.35, fp=0.14, fn=0.14		False
	11	0.4637		0.6461		0.5669		0.4248		0.7902	0.676		tp=0.31, tn=0.39, fp=0.085, fn=0.21		False
	12	0.452		0.6348		0.5742		0.4039		0.7942	0.7489		tp=0.45, tn=0.25, fp=0.23, fn=0.074		False
	13	0.4274		0.6251		0.612		0.3883		0.8121	0.7213		tp=0.39, tn=0.3, fp=0.18, fn=0.13		False
	14	0.41		0.6174		0.6399		0.4144		0.8258	0.7192		tp=0.37, tn=0.33, fp=0.14, fn=0.15		False
	15	0.4061		0.6319		0.6284		0.4129		0.8185	0.7074		tp=0.36, tn=0.35, fp=0.13, fn=0.16		False
	16	0.3996		0.737		0.6389		0.3731		0.8235	0.7445		tp=0.47, tn=0.2, fp=0.27, fn=0.051		False
	17	0.3807		0.6749		0.6822		0.3669		0.845	0.6501		tp=0.3, tn=0.37, fp=0.1, fn=0.22		False
	18	0.3702		0.6755		0.6804		0.3991		0.844	0.7294		tp=0.41, tn=0.29, fp=0.19, fn=0.11		False
	19	0.3714		0.6718		0.6856		0.3733		0.8463	0.6995		tp=0.36, tn=0.32, fp=0.16, fn=0.15		False
	20	0.357		0.6856		0.707		0.3515		0.8571	0.7083		tp=0.39, tn=0.28, fp=0.19, fn=0.13		False
	21	0.3483		0.6812		0.7095		0.3804		0.8587	0.6839		tp=0.34, tn=0.35, fp=0.12, fn=0.19		False
	22	0.3482		0.7238		0.6992		0.3774		0.8522	0.7293		tp=0.42, tn=0.27, fp=0.2, fn=0.11		False
	23	0.3578		0.7113		0.6815		0.3429		0.844	0.6923		tp=0.37, tn=0.3, fp=0.17, fn=0.16		False
	24	0.3384		0.7305		0.7242		0.3481		0.8655	0.694		tp=0.37, tn=0.31, fp=0.17, fn=0.16		False
	25	0.3252		0.7575		0.7276		0.3871		0.8666	0.7357		tp=0.43, tn=0.27, fp=0.2, fn=0.1		False
	26	0.3091		0.7703		0.7482		0.3154		0.8763	0.6811		tp=0.36, tn=0.29, fp=0.18, fn=0.16		False
	27	0.3063		0.7669		0.7655		0.3339		0.8856	0.6597		tp=0.32, tn=0.34, fp=0.15, fn=0.19		False
	28	0.306		0.8049		0.7524		0.3277		0.8787	0.6733		tp=0.35, tn=0.32, fp=0.16, fn=0.17		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		155
learning rate		0.000338266357919
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_138-lr0.00034-h_size155-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6833		0.6738		0.1314		0.1264		0.6055	0.6079		tp=0.34, tn=0.23, fp=0.24, fn=0.19		True
	2	0.6746		0.6738		0.1755		0.09952		0.6115	0.5473		tp=0.27, tn=0.28, fp=0.2, fn=0.25		False
	3	0.6684		0.6752		0.1901		0.0833		0.6112	0.5841		tp=0.32, tn=0.22, fp=0.26, fn=0.19		False
	4	0.6655		0.6746		0.1957		0.1371		0.626	0.5517		tp=0.27, tn=0.3, fp=0.19, fn=0.24		True
	5	0.6604		0.6697		0.2146		0.1543		0.6289	0.5966		tp=0.31, tn=0.27, fp=0.21, fn=0.21		True
	6	0.658		0.6752		0.2149		0.1791		0.6263	0.668		tp=0.42, tn=0.17, fp=0.32, fn=0.097		True
	7	0.6537		0.6659		0.2234		0.1369		0.6323	0.6038		tp=0.33, tn=0.24, fp=0.24, fn=0.19		False
	8	0.6508		0.675		0.2432		0.1422		0.6425	0.6297		tp=0.36, tn=0.21, fp=0.27, fn=0.15		False
	9	0.6496		0.6841		0.2452		0.1557		0.6392	0.6785		tp=0.44, tn=0.14, fp=0.33, fn=0.09		False
	10	0.6449		0.681		0.2436		0.1038		0.6419	0.6009		tp=0.34, tn=0.22, fp=0.26, fn=0.19		False
	11	0.6434		0.6852		0.2633		0.1345		0.6525	0.6362		tp=0.37, tn=0.2, fp=0.28, fn=0.15		False
	12	0.6386		0.6979		0.2814		0.1381		0.6559	0.6571		tp=0.41, tn=0.16, fp=0.33, fn=0.11		False
	13	0.6375		0.6794		0.2552		0.1611		0.6431	0.6351		tp=0.36, tn=0.23, fp=0.24, fn=0.17		False
	14	0.6368		0.6888		0.272		0.1227		0.6553	0.6219		tp=0.36, tn=0.21, fp=0.26, fn=0.17		False
	15	0.6338		0.6929		0.2751		0.1103		0.6545	0.6247		tp=0.37, tn=0.19, fp=0.28, fn=0.16		False
	16	0.6322		0.7017		0.279		0.1198		0.653	0.632		tp=0.37, tn=0.19, fp=0.29, fn=0.15		False
	17	0.633		0.6953		0.2733		0.1393		0.6568	0.5882		tp=0.31, tn=0.26, fp=0.21, fn=0.22		False
	18	0.6273		0.7058		0.2879		0.1199		0.6597	0.6171		tp=0.35, tn=0.21, fp=0.26, fn=0.17		False
	19	0.6277		0.684		0.2862		0.1823		0.6622	0.598		tp=0.31, tn=0.28, fp=0.18, fn=0.23		True
	20	0.6277		0.7131		0.2989		0.1112		0.6627	0.6373		tp=0.39, tn=0.17, fp=0.31, fn=0.13		False
	21	0.6247		0.6927		0.2955		0.158		0.6621	0.6058		tp=0.32, tn=0.26, fp=0.22, fn=0.2		False
	22	0.6232		0.7279		0.3046		0.1245		0.6693	0.6504		tp=0.41, tn=0.15, fp=0.34, fn=0.1		False
	23	0.6297		0.7201		0.2765		0.07478		0.6519	0.61		tp=0.36, tn=0.18, fp=0.29, fn=0.16		False
	24	0.6202		0.7021		0.3026		0.1058		0.6646	0.6277		tp=0.37, tn=0.19, fp=0.28, fn=0.16		False
	25	0.6223		0.6972		0.3045		0.1619		0.6674	0.5816		tp=0.29, tn=0.29, fp=0.2, fn=0.22		False
	26	0.6189		0.7128		0.3008		0.08108		0.6633	0.6242		tp=0.38, tn=0.17, fp=0.31, fn=0.15		False
	27	0.6206		0.7012		0.3021		0.08888		0.6682	0.6207		tp=0.37, tn=0.18, fp=0.29, fn=0.16		False
	28	0.6187		0.7005		0.3045		0.169		0.6676	0.5831		tp=0.29, tn=0.29, fp=0.18, fn=0.23		False
	29	0.6216		0.714		0.2914		0.06235		0.6575	0.6039		tp=0.35, tn=0.18, fp=0.3, fn=0.17		False
	30	0.6223		0.7063		0.2984		0.1264		0.6588	0.6288		tp=0.37, tn=0.2, fp=0.29, fn=0.15		False
	31	0.6159		0.7102		0.2985		0.1074		0.6655	0.6208		tp=0.36, tn=0.2, fp=0.26, fn=0.18		False
	32	0.6158		0.7067		0.3137		0.1675		0.6659	0.6049		tp=0.32, tn=0.27, fp=0.2, fn=0.22		False
	33	0.618		0.7176		0.3062		0.1578		0.6684	0.6058		tp=0.32, tn=0.26, fp=0.2, fn=0.21		False
	34	0.614		0.7277		0.3126		0.08515		0.6712	0.621		tp=0.37, tn=0.17, fp=0.31, fn=0.15		False
	35	0.6133		0.7212		0.3174		0.1109		0.672	0.6387		tp=0.39, tn=0.17, fp=0.31, fn=0.13		False
	36	0.6116		0.7148		0.3251		0.09141		0.6745	0.6054		tp=0.35, tn=0.2, fp=0.28, fn=0.17		False
	37	0.6154		0.7213		0.3017		0.1424		0.667	0.5405		tp=0.26, tn=0.31, fp=0.16, fn=0.27		False
	38	0.6116		0.7189		0.3209		0.07517		0.669	0.6194		tp=0.37, tn=0.18, fp=0.29, fn=0.16		False
	39	0.6098		0.7223		0.3246		0.1289		0.6768	0.5512		tp=0.27, tn=0.29, fp=0.18, fn=0.26		False
	40	0.6117		0.7151		0.3179		0.1394		0.6701	0.5862		tp=0.3, tn=0.27, fp=0.22, fn=0.21		False


data			/scratch/asw462/data/levin
input size		300
hidden size		39
learning rate		0.000378677533222
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_139-lr0.00038-h_size39-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5804		0.5496		0.02811		0		0.8358	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	2	0.5348		0.546		0.1867		0.2685		0.8482	0.8362		tp=0.68, tn=0.056, fp=0.24, fn=0.021		True
	3	0.5122		0.5445		0.3131		0.2772		0.8561	0.8165		tp=0.62, tn=0.098, fp=0.22, fn=0.063		True
	4	0.4781		0.5545		0.3809		0.2701		0.8665	0.834		tp=0.69, tn=0.042, fp=0.27, fn=0.007		False
	5	0.465		0.5621		0.4078		0.1674		0.8705	0.785		tp=0.59, tn=0.091, fp=0.22, fn=0.1		False
	6	0.444		0.5475		0.4442		0.2292		0.8764	0.8056		tp=0.61, tn=0.098, fp=0.2, fn=0.091		False
	7	0.4313		0.5356		0.4703		0.2965		0.8784	0.8311		tp=0.64, tn=0.1, fp=0.17, fn=0.084		True
	8	0.4		0.5295		0.5545		0.2799		0.8956	0.8235		tp=0.64, tn=0.091, fp=0.22, fn=0.056		False
	9	0.3832		0.5018		0.5639		0.3221		0.8953	0.8444		tp=0.66, tn=0.097, fp=0.18, fn=0.062		True
	10	0.3655		0.5159		0.6031		0.2582		0.9035	0.8333		tp=0.66, tn=0.07, fp=0.22, fn=0.042		False
	11	0.3497		0.5303		0.6288		0.4164		0.9092	0.8259		tp=0.58, tn=0.17, fp=0.1, fn=0.14		True
	12	0.3374		0.5166		0.6457		0.388		0.9121	0.8309		tp=0.6, tn=0.15, fp=0.12, fn=0.13		False
	13	0.3185		0.4952		0.6874		0.4214		0.9214	0.8436		tp=0.62, tn=0.15, fp=0.16, fn=0.07		True
	14	0.2923		0.5064		0.7316		0.4066		0.9314	0.8465		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	15	0.2887		0.5296		0.7113		0.3928		0.9267	0.8426		tp=0.64, tn=0.13, fp=0.18, fn=0.056		False
	16	0.2592		0.5007		0.7792		0.4568		0.9432	0.8624		tp=0.65, tn=0.14, fp=0.15, fn=0.056		True
	17	0.2512		0.487		0.7846		0.4921		0.9447	0.8692		tp=0.65, tn=0.15, fp=0.13, fn=0.063		True
	18	0.2299		0.5136		0.8072		0.4752		0.95	0.8585		tp=0.64, tn=0.15, fp=0.15, fn=0.056		False
	19	0.226		0.4869		0.8021		0.4922		0.949	0.8716		tp=0.66, tn=0.14, fp=0.15, fn=0.042		True
	20	0.2058		0.5166		0.848		0.4665		0.9599	0.8664		tp=0.66, tn=0.14, fp=0.15, fn=0.056		False
	21	0.1989		0.5139		0.8337		0.5055		0.957	0.8756		tp=0.66, tn=0.15, fp=0.14, fn=0.049		True
	22	0.1825		0.4865		0.8703		0.4879		0.9653	0.8704		tp=0.66, tn=0.15, fp=0.14, fn=0.056		False
	23	0.1896		0.5569		0.8596		0.4897		0.9632	0.88		tp=0.69, tn=0.12, fp=0.16, fn=0.028		False
	24	0.1834		0.5047		0.8485		0.5688		0.9598	0.8837		tp=0.66, tn=0.16, fp=0.15, fn=0.028		True
	25	0.1622		0.5504		0.8825		0.4817		0.9688	0.8664		tp=0.66, tn=0.14, fp=0.16, fn=0.042		False
	26	0.1499		0.5539		0.9182		0.4463		0.9781	0.8462		tp=0.62, tn=0.16, fp=0.15, fn=0.077		False
	27	0.1439		0.4269		0.9109		0.5671		0.9762	0.8879		tp=0.66, tn=0.17, fp=0.12, fn=0.049		False
	28	0.1334		0.5339		0.922		0.5037		0.979	0.8692		tp=0.65, tn=0.15, fp=0.15, fn=0.049		False
	29	0.1242		0.5189		0.9343		0.5418		0.9823	0.8837		tp=0.66, tn=0.16, fp=0.12, fn=0.056		False
	30	0.1207		0.4955		0.9365		0.5104		0.9828	0.8654		tp=0.63, tn=0.17, fp=0.12, fn=0.077		False
	31	0.1157		0.5244		0.9506		0.5351		0.9866	0.8785		tp=0.66, tn=0.16, fp=0.13, fn=0.049		False
	32	0.1127		0.5138		0.9522		0.5445		0.9871	0.8848		tp=0.67, tn=0.15, fp=0.13, fn=0.042		False
	33	0.1071		0.5762		0.9454		0.4834		0.9851	0.8488		tp=0.6, tn=0.18, fp=0.14, fn=0.076		False
	34	0.09816		0.5176		0.9613		0.5385		0.9894	0.872		tp=0.64, tn=0.17, fp=0.15, fn=0.042		False
	35	0.09211		0.5914		0.9648		0.4973		0.9904	0.8692		tp=0.65, tn=0.15, fp=0.14, fn=0.056		False
	36	0.0979		0.552		0.9528		0.553		0.987	0.8696		tp=0.63, tn=0.18, fp=0.15, fn=0.042		False
	37	0.08748		0.5376		0.9613		0.5651		0.9894	0.8804		tp=0.64, tn=0.18, fp=0.12, fn=0.056		False
	38	0.08482		0.5073		0.9717		0.555		0.9923	0.8826		tp=0.66, tn=0.17, fp=0.13, fn=0.049		False
	39	0.08146		0.5935		0.9632		0.5162		0.9899	0.8796		tp=0.66, tn=0.15, fp=0.12, fn=0.063		False
	40	0.07496		0.6063		0.9682		0.5062		0.9914	0.8679		tp=0.64, tn=0.16, fp=0.14, fn=0.056		False
	41	0.06849		0.6088		0.977		0.521		0.9938	0.8641		tp=0.62, tn=0.18, fp=0.13, fn=0.07		False
	42	0.06948		0.6164		0.9737		0.533		0.9928	0.8796		tp=0.66, tn=0.15, fp=0.14, fn=0.042		False
	43	0.06712		0.5782		0.9717		0.5656		0.9923	0.8792		tp=0.64, tn=0.19, fp=0.1, fn=0.07		False
	44	0.06303		0.5422		0.9773		0.5178		0.9937	0.8732		tp=0.65, tn=0.16, fp=0.13, fn=0.056		False
	45	0.06105		0.668		0.9771		0.5161		0.9938	0.8571		tp=0.61, tn=0.19, fp=0.13, fn=0.07		False


data			/scratch/asw462/data/levin
input size		300
hidden size		35
learning rate		0.00419835651845
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_13-lr0.0042-h_size35-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5999		0.6013		0.00493		0		0.8329	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.5681		0.5712		0.1442		0.2085		0.8426	0.8326		tp=0.67, tn=0.056, fp=0.23, fn=0.042		True
	3	0.5345		0.5596		0.2733		0.2009		0.8489	0.8261		tp=0.66, tn=0.056, fp=0.24, fn=0.042		False
	4	0.5113		0.5954		0.2751		0.1262		0.8466	0.8395		tp=0.71, tn=0.014, fp=0.27, fn=0.007		False
	5	0.4723		0.6308		0.3817		0.1067		0.864	0.8052		tp=0.65, tn=0.042, fp=0.26, fn=0.049		False
	6	0.4432		0.6396		0.4743		0.2269		0.878	0.8214		tp=0.64, tn=0.077, fp=0.22, fn=0.063		True
	7	0.4446		0.6157		0.4603		0.3465		0.8736	0.8318		tp=0.62, tn=0.13, fp=0.17, fn=0.084		True
	8	0.3957		0.644		0.5839		0.3071		0.8978	0.8241		tp=0.62, tn=0.11, fp=0.19, fn=0.077		False
	9	0.4017		0.7189		0.5202		0.313		0.8817	0.8348		tp=0.67, tn=0.063, fp=0.25, fn=0.014		False
	10	0.3894		0.6316		0.5228		0.1867		0.8821	0.8261		tp=0.66, tn=0.056, fp=0.23, fn=0.049		False
	11	0.3539		0.7269		0.6109		0.2842		0.9014	0.8113		tp=0.6, tn=0.12, fp=0.18, fn=0.098		False
	12	0.3276		0.7245		0.641		0.2956		0.9118	0.8241		tp=0.62, tn=0.11, fp=0.17, fn=0.091		False
	13	0.3326		0.7341		0.6111		0.2946		0.9016	0.8326		tp=0.64, tn=0.098, fp=0.19, fn=0.07		False
	14	0.301		0.7049		0.687		0.3444		0.9204	0.8387		tp=0.64, tn=0.12, fp=0.16, fn=0.084		False
	15	0.2847		0.7784		0.6845		0.2978		0.9183	0.8186		tp=0.62, tn=0.11, fp=0.2, fn=0.077		False
	16	0.2679		0.78		0.7274		0.3114		0.9289	0.8134		tp=0.59, tn=0.13, fp=0.16, fn=0.11		False
	17	0.2744		0.7906		0.6922		0.2988		0.9208	0.8169		tp=0.61, tn=0.12, fp=0.18, fn=0.091		False
	18	0.2657		0.7954		0.7248		0.3365		0.9276	0.8279		tp=0.62, tn=0.12, fp=0.19, fn=0.07		False
	19	0.2211		0.6766		0.789		0.4053		0.9447	0.8584		tp=0.66, tn=0.13, fp=0.14, fn=0.077		True
	20	0.2109		0.9063		0.8004		0.3217		0.9469	0.8039		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	21	0.1908		0.8784		0.8185		0.3474		0.9523	0.7876		tp=0.53, tn=0.18, fp=0.13, fn=0.15		False
	22	0.1967		1.008		0.7981		0.1908		0.9471	0.7358		tp=0.5, tn=0.15, fp=0.15, fn=0.2		False
	23	0.1721		0.9463		0.8474		0.3285		0.9589	0.819		tp=0.6, tn=0.13, fp=0.17, fn=0.098		False
	24	0.1448		0.8889		0.8833		0.365		0.9692	0.8195		tp=0.59, tn=0.15, fp=0.15, fn=0.11		False
	25	0.1376		0.9766		0.899		0.37		0.9727	0.8341		tp=0.62, tn=0.14, fp=0.14, fn=0.1		False
	26	0.1206		1.067		0.919		0.3149		0.9779	0.8279		tp=0.62, tn=0.12, fp=0.16, fn=0.098		False
	27	0.1096		0.94		0.9344		0.3398		0.9823	0.8333		tp=0.62, tn=0.12, fp=0.15, fn=0.097		False
	28	0.1225		0.8896		0.9036		0.4172		0.9744	0.8571		tp=0.65, tn=0.13, fp=0.14, fn=0.077		True
	29	0.1019		1.211		0.9272		0.3166		0.9804	0.8295		tp=0.63, tn=0.11, fp=0.18, fn=0.077		False
	30	0.09634		1.058		0.9454		0.295		0.9851	0.8224		tp=0.62, tn=0.12, fp=0.14, fn=0.13		False
	31	0.08934		0.977		0.9492		0.4432		0.986	0.8545		tp=0.64, tn=0.15, fp=0.15, fn=0.07		True
	32	0.08982		1.046		0.9434		0.4321		0.9847	0.8519		tp=0.64, tn=0.13, fp=0.17, fn=0.049		False
	33	0.08194		1.274		0.9485		0.3117		0.9862	0.8378		tp=0.65, tn=0.098, fp=0.19, fn=0.063		False
	34	0.06942		1.206		0.9646		0.3138		0.9904	0.796		tp=0.56, tn=0.15, fp=0.14, fn=0.15		False
	35	0.08313		1.211		0.9509		0.3402		0.9865	0.8079		tp=0.57, tn=0.15, fp=0.15, fn=0.12		False
	36	0.06468		1.149		0.9612		0.3982		0.9894	0.8451		tp=0.63, tn=0.14, fp=0.14, fn=0.091		False
	37	0.04935		1.212		0.9771		0.3809		0.9938	0.8426		tp=0.63, tn=0.13, fp=0.15, fn=0.083		False
	38	0.04491		1.326		0.9806		0.3212		0.9947	0.8208		tp=0.61, tn=0.13, fp=0.17, fn=0.091		False
	39	0.04448		1.156		0.9807		0.388		0.9947	0.8545		tp=0.65, tn=0.12, fp=0.13, fn=0.09		False
	40	0.04411		1.116		0.9877		0.4333		0.9966	0.8476		tp=0.62, tn=0.15, fp=0.14, fn=0.084		False
	41	0.04208		1.256		0.9808		0.3813		0.9947	0.8252		tp=0.59, tn=0.15, fp=0.15, fn=0.098		False
	42	0.03533		1.373		0.9895		0.334		0.9971	0.8333		tp=0.63, tn=0.12, fp=0.17, fn=0.084		False
	43	0.03457		1.277		0.9859		0.4107		0.9962	0.8365		tp=0.61, tn=0.15, fp=0.15, fn=0.084		False
	44	0.03221		1.324		0.9876		0.3716		0.9966	0.8269		tp=0.6, tn=0.15, fp=0.15, fn=0.098		False
	45	0.03396		1.369		0.9912		0.39		0.9976	0.8325		tp=0.61, tn=0.15, fp=0.16, fn=0.084		False
	46	0.03965		1.284		0.9806		0.4219		0.9947	0.8505		tp=0.64, tn=0.14, fp=0.15, fn=0.07		False
	47	0.02864		1.259		0.9877		0.3868		0.9966	0.8396		tp=0.62, tn=0.14, fp=0.15, fn=0.091		False
	48	0.02902		1.24		0.9826		0.3738		0.9952	0.8357		tp=0.62, tn=0.13, fp=0.17, fn=0.077		False
	49	0.02773		1.512		0.9894		0.3396		0.9971	0.8333		tp=0.63, tn=0.12, fp=0.17, fn=0.077		False
	50	0.02521		1.379		0.9912		0.3645		0.9976	0.8357		tp=0.62, tn=0.13, fp=0.15, fn=0.091		False
	51	0.02648		1.454		0.9894		0.438		0.9971	0.8491		tp=0.63, tn=0.15, fp=0.16, fn=0.063		False
	52	0.02577		1.283		0.9895		0.3724		0.9971	0.8479		tp=0.64, tn=0.13, fp=0.13, fn=0.098		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		178
learning rate		0.0019703214412
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_140-lr0.002-h_size178-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6691		0.6251		0.2288		0.2969		0.635	0.6253		tp=0.3, tn=0.35, fp=0.14, fn=0.22		True
	2	0.6242		0.6033		0.3077		0.362		0.6691	0.7449		tp=0.47, tn=0.21, fp=0.26, fn=0.066		True
	3	0.5817		0.5709		0.3922		0.4096		0.7107	0.7439		tp=0.43, tn=0.28, fp=0.19, fn=0.1		True
	4	0.5514		0.5824		0.4342		0.3894		0.7278	0.7373		tp=0.43, tn=0.27, fp=0.21, fn=0.1		False
	5	0.5148		0.5724		0.4965		0.4384		0.7552	0.7386		tp=0.39, tn=0.33, fp=0.14, fn=0.14		True
	6	0.4728		0.5886		0.5544		0.3874		0.783	0.697		tp=0.35, tn=0.34, fp=0.13, fn=0.18		False
	7	0.4481		0.5939		0.5775		0.4017		0.7921	0.7097		tp=0.37, tn=0.34, fp=0.14, fn=0.16		False
	8	0.4133		0.7127		0.6296		0.3823		0.8199	0.7495		tp=0.49, tn=0.19, fp=0.28, fn=0.041		False
	9	0.373		0.6391		0.665		0.3644		0.8362	0.7248		tp=0.42, tn=0.27, fp=0.2, fn=0.12		False
	10	0.3344		0.6239		0.7187		0.3941		0.8619	0.7401		tp=0.43, tn=0.27, fp=0.2, fn=0.1		False
	11	0.2812		0.6602		0.7791		0.4209		0.8916	0.7395		tp=0.41, tn=0.31, fp=0.16, fn=0.13		False
	12	0.2502		0.7181		0.8015		0.3875		0.9027	0.7015		tp=0.36, tn=0.33, fp=0.15, fn=0.16		False
	13	0.2405		0.8122		0.8157		0.4129		0.9096	0.7562		tp=0.47, tn=0.23, fp=0.24, fn=0.059		False
	14	0.2128		0.8335		0.8487		0.395		0.9255	0.7136		tp=0.38, tn=0.32, fp=0.16, fn=0.14		False
	15	0.1532		0.9274		0.9155		0.3906		0.9584	0.7354		tp=0.42, tn=0.28, fp=0.19, fn=0.11		False
	16	0.1294		0.9002		0.9397		0.4026		0.9703	0.7212		tp=0.38, tn=0.32, fp=0.15, fn=0.14		False
	17	0.1198		0.9793		0.9332		0.381		0.9672	0.7156		tp=0.39, tn=0.31, fp=0.16, fn=0.14		False
	18	0.09824		0.9945		0.9616		0.3828		0.9811	0.7087		tp=0.37, tn=0.32, fp=0.16, fn=0.15		False
	19	0.08382		0.9854		0.9716		0.4235		0.986	0.7295		tp=0.39, tn=0.33, fp=0.14, fn=0.15		False
	20	0.0733		1.082		0.9716		0.3818		0.986	0.7156		tp=0.39, tn=0.31, fp=0.17, fn=0.14		False
	21	0.07109		1.132		0.9752		0.374		0.9878	0.695		tp=0.36, tn=0.33, fp=0.15, fn=0.16		False
	22	0.06127		1.103		0.9852		0.4239		0.9927	0.708		tp=0.35, tn=0.36, fp=0.12, fn=0.17		False
	23	0.05626		1.17		0.9858		0.4071		0.993	0.71		tp=0.36, tn=0.34, fp=0.13, fn=0.17		False
	24	0.04871		1.221		0.9882		0.4021		0.9942	0.7097		tp=0.37, tn=0.34, fp=0.14, fn=0.16		False
	25	0.04677		1.215		0.9882		0.414		0.9942	0.722		tp=0.38, tn=0.33, fp=0.14, fn=0.15		False
	26	0.04268		1.22		0.9905		0.4024		0.9953	0.6927		tp=0.34, tn=0.36, fp=0.12, fn=0.18		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		70
learning rate		7.34896271982e&05
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_141-lr7.3e&05-h_size70-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6256		0.6269		0		0		0.8182	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6114		0.6195		0		0		0.8191	0.8137		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.6083		0.6233		0		0.0556		0.8183	0.8074		tp=0.68, tn=0.0015, fp=0.32, fn=0		True
	4	0.6063		0.6174		0.01383		0.07947		0.8179	0.811		tp=0.68, tn=0.003, fp=0.32, fn=0		True
	5	0.6032		0.6182		0.03336		0.001482		0.8185	0.806		tp=0.67, tn=0.0015, fp=0.32, fn=0.003		False
	6	0.6017		0.6096		0.06341		0.09807		0.8185	0.8138		tp=0.68, tn=0.0044, fp=0.31, fn=0		True
	7	0.5998		0.6058		0.06929		0.06388		0.8191	0.8124		tp=0.68, tn=0.0089, fp=0.31, fn=0.0074		False
	8	0.5986		0.6039		0.08117		0.1271		0.8191	0.8182		tp=0.68, tn=0.018, fp=0.29, fn=0.0089		True
	9	0.5972		0.612		0.08028		0.1128		0.8189	0.8072		tp=0.66, tn=0.019, fp=0.31, fn=0.012		False
	10	0.5962		0.604		0.09366		0.1044		0.8188	0.8146		tp=0.68, tn=0.015, fp=0.3, fn=0.0089		False
	11	0.5952		0.6078		0.09164		0.1013		0.8184	0.8118		tp=0.67, tn=0.013, fp=0.31, fn=0.0074		False
	12	0.5942		0.6136		0.103		0.1301		0.8193	0.8083		tp=0.67, tn=0.019, fp=0.31, fn=0.0089		True
	13	0.5927		0.6089		0.1056		0.1317		0.8194	0.8101		tp=0.67, tn=0.021, fp=0.3, fn=0.01		True
	14	0.5916		0.6061		0.1146		0.1153		0.8194	0.8136		tp=0.67, tn=0.018, fp=0.3, fn=0.01		False
	15	0.5907		0.611		0.117		0.1218		0.8204	0.81		tp=0.67, tn=0.018, fp=0.3, fn=0.0089		False
	16	0.5906		0.61		0.1265		0.1303		0.8203	0.8086		tp=0.67, tn=0.018, fp=0.31, fn=0.0074		False
	17	0.5897		0.6011		0.1389		0.1559		0.8208	0.8183		tp=0.67, tn=0.027, fp=0.29, fn=0.013		True
	18	0.5881		0.6048		0.1367		0.1392		0.8208	0.8105		tp=0.66, tn=0.03, fp=0.29, fn=0.019		False
	19	0.5871		0.6115		0.1434		0.1322		0.8213	0.8083		tp=0.66, tn=0.024, fp=0.3, fn=0.013		False
	20	0.5873		0.6031		0.1369		0.1469		0.8202	0.8127		tp=0.66, tn=0.03, fp=0.29, fn=0.018		False
	21	0.5862		0.6017		0.1335		0.1525		0.8204	0.8141		tp=0.67, tn=0.027, fp=0.29, fn=0.013		False
	22	0.5858		0.6054		0.1484		0.1351		0.8204	0.8102		tp=0.66, tn=0.031, fp=0.29, fn=0.022		False
	23	0.5842		0.5972		0.1383		0.1701		0.8205	0.8196		tp=0.67, tn=0.036, fp=0.27, fn=0.021		True
	24	0.5847		0.5971		0.1464		0.1607		0.8204	0.817		tp=0.67, tn=0.034, fp=0.28, fn=0.021		False
	25	0.5837		0.599		0.1412		0.154		0.8192	0.8117		tp=0.66, tn=0.037, fp=0.28, fn=0.025		False
	26	0.583		0.603		0.1411		0.1412		0.8194	0.8091		tp=0.66, tn=0.032, fp=0.29, fn=0.022		False
	27	0.5822		0.6006		0.1606		0.1482		0.8212	0.8106		tp=0.66, tn=0.037, fp=0.28, fn=0.027		False
	28	0.5816		0.6034		0.1446		0.155		0.8191	0.8073		tp=0.65, tn=0.037, fp=0.29, fn=0.024		False
	29	0.5806		0.6029		0.1519		0.1724		0.8197	0.8111		tp=0.65, tn=0.046, fp=0.27, fn=0.031		True
	30	0.5801		0.605		0.1566		0.1687		0.8195	0.8089		tp=0.65, tn=0.044, fp=0.28, fn=0.03		False
	31	0.5802		0.6077		0.1562		0.1725		0.8193	0.8099		tp=0.66, tn=0.036, fp=0.29, fn=0.018		True
	32	0.5793		0.6034		0.1562		0.157		0.8189	0.8113		tp=0.66, tn=0.036, fp=0.28, fn=0.022		False
	33	0.5785		0.6011		0.1575		0.1864		0.82	0.8118		tp=0.65, tn=0.046, fp=0.28, fn=0.027		True
	34	0.5782		0.601		0.1648		0.1472		0.82	0.8095		tp=0.65, tn=0.037, fp=0.28, fn=0.027		False
	35	0.5778		0.6027		0.1559		0.1787		0.8185	0.81		tp=0.65, tn=0.044, fp=0.28, fn=0.027		False
	36	0.5765		0.6074		0.1555		0.1775		0.8183	0.8074		tp=0.65, tn=0.046, fp=0.28, fn=0.028		False
	37	0.5763		0.6019		0.1674		0.15		0.8199	0.8073		tp=0.65, tn=0.037, fp=0.29, fn=0.025		False
	38	0.5764		0.5997		0.1595		0.181		0.8183	0.8136		tp=0.66, tn=0.043, fp=0.28, fn=0.025		False
	39	0.5752		0.6011		0.1651		0.1672		0.8199	0.8041		tp=0.63, tn=0.056, fp=0.26, fn=0.046		False
	40	0.575		0.6015		0.1628		0.1499		0.8186	0.8059		tp=0.64, tn=0.047, fp=0.27, fn=0.04		False
	41	0.5745		0.5963		0.1662		0.1665		0.8176	0.8128		tp=0.66, tn=0.043, fp=0.27, fn=0.03		False
	42	0.5733		0.6048		0.1787		0.1679		0.82	0.8056		tp=0.64, tn=0.05, fp=0.27, fn=0.037		False
	43	0.5737		0.5993		0.1666		0.1509		0.8191	0.8037		tp=0.64, tn=0.052, fp=0.27, fn=0.046		False
	44	0.5729		0.6046		0.1776		0.1862		0.8188	0.8104		tp=0.65, tn=0.047, fp=0.28, fn=0.028		False
	45	0.5726		0.5957		0.1687		0.1846		0.8182	0.8147		tp=0.66, tn=0.046, fp=0.27, fn=0.028		False
	46	0.5717		0.5952		0.165		0.1605		0.8181	0.8128		tp=0.66, tn=0.041, fp=0.27, fn=0.03		False
	47	0.5717		0.5989		0.1758		0.1606		0.8191	0.8103		tp=0.65, tn=0.04, fp=0.28, fn=0.027		False
	48	0.5714		0.5978		0.1719		0.1783		0.8185	0.8132		tp=0.66, tn=0.04, fp=0.28, fn=0.022		False
	49	0.5711		0.5985		0.1837		0.169		0.8201	0.8019		tp=0.62, tn=0.066, fp=0.25, fn=0.062		False
	50	0.571		0.599		0.1801		0.1551		0.8179	0.8078		tp=0.65, tn=0.044, fp=0.27, fn=0.034		False
	51	0.5701		0.6001		0.1873		0.1513		0.8204	0.797		tp=0.62, tn=0.061, fp=0.26, fn=0.058		False
	52	0.5689		0.5965		0.1885		0.1538		0.8199	0.8056		tp=0.64, tn=0.05, fp=0.27, fn=0.043		False
	53	0.5692		0.5979		0.1883		0.159		0.8188	0.8096		tp=0.65, tn=0.043, fp=0.28, fn=0.031		False
	54	0.5688		0.6001		0.1927		0.1363		0.8201	0.803		tp=0.64, tn=0.043, fp=0.28, fn=0.037		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		138
learning rate		0.00165108741298
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_142-lr0.0017-h_size138-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5771		0.5659		0.2206		0.2871		0.8185	0.8205		tp=0.63, tn=0.095, fp=0.22, fn=0.055		True
	2	0.5523		0.5666		0.2893		0.2823		0.8278	0.8263		tp=0.65, tn=0.075, fp=0.24, fn=0.034		False
	3	0.54		0.5886		0.3165		0.1927		0.831	0.8179		tp=0.67, tn=0.039, fp=0.28, fn=0.018		False
	4	0.5278		0.5726		0.3464		0.2826		0.8356	0.8		tp=0.58, tn=0.13, fp=0.19, fn=0.1		False
	5	0.5182		0.5768		0.3608		0.2487		0.8377	0.8217		tp=0.65, tn=0.065, fp=0.25, fn=0.033		False
	6	0.5105		0.5902		0.3946		0.2491		0.8442	0.7927		tp=0.58, tn=0.12, fp=0.2, fn=0.11		False
	7	0.4979		0.5933		0.4018		0.237		0.8445	0.7952		tp=0.59, tn=0.11, fp=0.21, fn=0.092		False
	8	0.486		0.6071		0.4232		0.2613		0.8485	0.8171		tp=0.64, tn=0.077, fp=0.25, fn=0.04		False
	9	0.4843		0.6135		0.425		0.2656		0.8486	0.8186		tp=0.64, tn=0.08, fp=0.24, fn=0.043		False
	10	0.4755		0.5975		0.4554		0.284		0.8555	0.808		tp=0.6, tn=0.12, fp=0.2, fn=0.089		False
	11	0.463		0.6035		0.4657		0.2518		0.8574	0.7956		tp=0.58, tn=0.12, fp=0.2, fn=0.099		False
	12	0.4632		0.5951		0.4728		0.2675		0.8594	0.8048		tp=0.6, tn=0.11, fp=0.21, fn=0.083		False
	13	0.4564		0.6132		0.482		0.2813		0.8601	0.8129		tp=0.61, tn=0.1, fp=0.22, fn=0.064		False
	14	0.4583		0.6461		0.4722		0.312		0.8584	0.7786		tp=0.53, tn=0.17, fp=0.15, fn=0.15		True
	15	0.4353		0.6633		0.5175		0.2704		0.8684	0.8036		tp=0.59, tn=0.12, fp=0.2, fn=0.089		False
	16	0.432		0.7008		0.5209		0.2632		0.8695	0.8175		tp=0.64, tn=0.079, fp=0.24, fn=0.041		False
	17	0.4206		0.645		0.5336		0.3027		0.8724	0.8		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	18	0.4136		0.6776		0.5501		0.2753		0.8761	0.8048		tp=0.6, tn=0.11, fp=0.21, fn=0.076		False
	19	0.3965		0.6625		0.5739		0.3032		0.8824	0.8073		tp=0.59, tn=0.13, fp=0.19, fn=0.092		False
	20	0.3894		0.6835		0.5863		0.3155		0.8852	0.8089		tp=0.59, tn=0.13, fp=0.19, fn=0.087		True
	21	0.3801		0.6717		0.6031		0.3283		0.8894	0.791		tp=0.55, tn=0.17, fp=0.15, fn=0.14		True
	22	0.3718		0.7417		0.6103		0.2422		0.891	0.7486		tp=0.5, tn=0.16, fp=0.15, fn=0.18		False
	23	0.3569		0.7064		0.6307		0.3062		0.8962	0.8089		tp=0.59, tn=0.13, fp=0.19, fn=0.087		False
	24	0.3489		0.7573		0.6407		0.2449		0.899	0.7992		tp=0.6, tn=0.11, fp=0.22, fn=0.083		False
	25	0.3333		0.7468		0.6641		0.318		0.905	0.8078		tp=0.59, tn=0.14, fp=0.19, fn=0.093		False
	26	0.3274		0.7507		0.6778		0.2639		0.9082	0.7893		tp=0.57, tn=0.13, fp=0.19, fn=0.12		False
	27	0.3148		0.7956		0.6978		0.2372		0.9137	0.7968		tp=0.59, tn=0.11, fp=0.2, fn=0.099		False
	28	0.3105		0.7335		0.6948		0.323		0.9128	0.8029		tp=0.57, tn=0.15, fp=0.18, fn=0.1		False
	29	0.2894		0.8272		0.7191		0.2927		0.919	0.8024		tp=0.58, tn=0.13, fp=0.19, fn=0.095		False
	30	0.2885		0.8045		0.7318		0.3294		0.9227	0.8		tp=0.56, tn=0.16, fp=0.17, fn=0.12		True
	31	0.2834		0.789		0.7217		0.278		0.9194	0.8095		tp=0.6, tn=0.11, fp=0.2, fn=0.08		False
	32	0.2729		0.8525		0.7459		0.264		0.9267	0.7905		tp=0.57, tn=0.13, fp=0.18, fn=0.12		False
	33	0.2486		0.8201		0.7769		0.3052		0.9351	0.8012		tp=0.57, tn=0.14, fp=0.17, fn=0.12		False
	34	0.2417		0.8599		0.7892		0.342		0.9382	0.7859		tp=0.53, tn=0.18, fp=0.14, fn=0.15		True
	35	0.2299		0.8938		0.8014		0.2947		0.9418	0.8		tp=0.58, tn=0.13, fp=0.19, fn=0.099		False
	36	0.2202		0.8742		0.808		0.3309		0.9436	0.797		tp=0.56, tn=0.16, fp=0.15, fn=0.13		False
	37	0.2177		0.8627		0.8134		0.3361		0.9451	0.8067		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	38	0.2081		0.9212		0.825		0.3323		0.9483	0.8013		tp=0.56, tn=0.16, fp=0.17, fn=0.11		False
	39	0.1991		0.9191		0.8376		0.3209		0.9517	0.7983		tp=0.56, tn=0.15, fp=0.16, fn=0.12		False
	40	0.1931		0.9719		0.8398		0.3184		0.9526	0.7906		tp=0.55, tn=0.16, fp=0.16, fn=0.13		False
	41	0.1841		1.005		0.8491		0.3092		0.9551	0.8061		tp=0.59, tn=0.13, fp=0.19, fn=0.093		False
	42	0.178		1.032		0.8558		0.311		0.9571	0.8012		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	43	0.1667		1.026		0.8731		0.2979		0.9621	0.782		tp=0.54, tn=0.16, fp=0.16, fn=0.14		False
	44	0.1573		1.047		0.885		0.311		0.9655	0.7872		tp=0.54, tn=0.16, fp=0.16, fn=0.13		False
	45	0.1572		1.048		0.8783		0.3588		0.9636	0.8038		tp=0.56, tn=0.17, fp=0.15, fn=0.12		True
	46	0.1421		1.066		0.899		0.3261		0.9697	0.8098		tp=0.58, tn=0.14, fp=0.18, fn=0.099		False
	47	0.142		1.1		0.9007		0.3415		0.9702	0.8087		tp=0.58, tn=0.15, fp=0.16, fn=0.11		False
	48	0.134		1.101		0.9043		0.323		0.9712	0.7852		tp=0.54, tn=0.17, fp=0.15, fn=0.14		False
	49	0.1265		1.074		0.914		0.3166		0.9741	0.7808		tp=0.53, tn=0.17, fp=0.15, fn=0.15		False
	50	0.1224		1.176		0.9139		0.3385		0.974	0.8042		tp=0.57, tn=0.16, fp=0.17, fn=0.11		False
	51	0.1206		1.16		0.92		0.311		0.9759	0.7849		tp=0.54, tn=0.16, fp=0.15, fn=0.15		False
	52	0.1197		1.234		0.9166		0.3308		0.9747	0.8126		tp=0.59, tn=0.14, fp=0.19, fn=0.087		False
	53	0.1114		1.21		0.9265		0.3323		0.9778	0.8008		tp=0.56, tn=0.16, fp=0.16, fn=0.12		False
	54	0.1117		1.198		0.9218		0.31		0.9763	0.7703		tp=0.51, tn=0.18, fp=0.14, fn=0.16		False
	55	0.1079		1.178		0.9266		0.3403		0.9778	0.8046		tp=0.57, tn=0.16, fp=0.16, fn=0.12		False
	56	0.09563		1.331		0.9453		0.2907		0.9834	0.8056		tp=0.59, tn=0.12, fp=0.2, fn=0.084		False
	57	0.09866		1.281		0.9406		0.3218		0.9819	0.8082		tp=0.58, tn=0.14, fp=0.18, fn=0.098		False
	58	0.0926		1.277		0.948		0.3198		0.9842	0.7757		tp=0.52, tn=0.18, fp=0.14, fn=0.16		False
	59	0.08834		1.302		0.9419		0.3564		0.9824	0.8109		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	60	0.08948		1.347		0.9463		0.289		0.9837	0.7803		tp=0.54, tn=0.16, fp=0.16, fn=0.15		False
	61	0.08699		1.306		0.9453		0.357		0.9834	0.8109		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	62	0.08124		1.322		0.9519		0.3415		0.9854	0.8004		tp=0.56, tn=0.16, fp=0.16, fn=0.12		False
	63	0.07789		1.317		0.9576		0.3409		0.987	0.7904		tp=0.54, tn=0.17, fp=0.15, fn=0.14		False
	64	0.08072		1.339		0.9545		0.325		0.9861	0.8008		tp=0.57, tn=0.15, fp=0.16, fn=0.12		False
	65	0.06964		1.373		0.9667		0.3186		0.9898	0.7844		tp=0.54, tn=0.17, fp=0.15, fn=0.14		False
	66	0.06959		1.37		0.968		0.3296		0.9902	0.794		tp=0.55, tn=0.16, fp=0.15, fn=0.13		False


data			/scratch/asw462/data/levin
input size		300
hidden size		148
learning rate		0.000304220726819
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_143-lr0.0003-h_size148-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5823		0.5819		0.05676		0		0.8427	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	2	0.5671		0.576		0		0		0.8426	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5633		0.5542		0		0		0.8416	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	4	0.5436		0.5874		0.06134		0		0.8439	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	5	0.5362		0.5778		0.167		-0.05503		0.8454	0.8182		tp=0.69, tn=0, fp=0.3, fn=0.007		False
	6	0.5215		0.5791		0.2031		0.04962		0.8493	0.8167		tp=0.69, tn=0.007, fp=0.3, fn=0.007		True
	7	0.5124		0.5996		0.2737		0.1586		0.8545	0.817		tp=0.67, tn=0.028, fp=0.29, fn=0.014		True
	8	0.4966		0.5737		0.2781		0.2446		0.8552	0.8376		tp=0.69, tn=0.049, fp=0.24, fn=0.021		True
	9	0.492		0.6244		0.3375		0.1259		0.86	0.8216		tp=0.69, tn=0.007, fp=0.3, fn=0		False
	10	0.4823		0.6036		0.3638		0.123		0.8644	0.8347		tp=0.71, tn=0.014, fp=0.27, fn=0.007		False
	11	0.4666		0.5742		0.3885		0.2681		0.8678	0.8148		tp=0.62, tn=0.1, fp=0.2, fn=0.084		True
	12	0.4592		0.6067		0.4117		0.1179		0.8695	0.8018		tp=0.64, tn=0.049, fp=0.26, fn=0.056		False
	13	0.4432		0.6057		0.4435		0.179		0.8774	0.824		tp=0.67, tn=0.042, fp=0.26, fn=0.028		False
	14	0.4417		0.5516		0.4589		0.2365		0.8758	0.8412		tp=0.69, tn=0.056, fp=0.22, fn=0.035		False
	15	0.431		0.6209		0.4607		0.3062		0.8793	0.8058		tp=0.58, tn=0.14, fp=0.15, fn=0.13		True
	16	0.4229		0.5999		0.512		0.2931		0.8861	0.8257		tp=0.63, tn=0.1, fp=0.19, fn=0.077		False
	17	0.4127		0.6002		0.5161		0.2298		0.8865	0.8362		tp=0.68, tn=0.056, fp=0.23, fn=0.035		False
	18	0.4057		0.6352		0.5198		0.2855		0.8865	0.8219		tp=0.63, tn=0.098, fp=0.21, fn=0.063		False
	19	0.398		0.6223		0.5271		0.2712		0.8872	0.8251		tp=0.64, tn=0.09, fp=0.21, fn=0.062		False
	20	0.3988		0.6626		0.5463		0.2349		0.8916	0.7981		tp=0.59, tn=0.1, fp=0.21, fn=0.091		False
	21	0.385		0.6508		0.553		0.3107		0.8939	0.8169		tp=0.61, tn=0.12, fp=0.2, fn=0.077		True
	22	0.3811		0.6454		0.5716		0.2912		0.8964	0.8235		tp=0.64, tn=0.091, fp=0.22, fn=0.049		False
	23	0.3722		0.6913		0.5869		0.3052		0.9	0.8186		tp=0.62, tn=0.11, fp=0.2, fn=0.07		False
	24	0.366		0.6693		0.6025		0.2662		0.9015	0.7902		tp=0.57, tn=0.13, fp=0.18, fn=0.12		False
	25	0.3669		0.7094		0.5851		0.2363		0.8973	0.77		tp=0.54, tn=0.14, fp=0.17, fn=0.15		False
	26	0.3669		0.7258		0.5939		0.2192		0.9002	0.8161		tp=0.64, tn=0.077, fp=0.22, fn=0.063		False
	27	0.3598		0.6716		0.5801		0.3443		0.897	0.8279		tp=0.62, tn=0.12, fp=0.2, fn=0.063		True
	28	0.3535		0.684		0.6199		0.2865		0.9042	0.8095		tp=0.59, tn=0.13, fp=0.16, fn=0.12		False
	29	0.3508		0.7289		0.585		0.2417		0.8974	0.7864		tp=0.57, tn=0.13, fp=0.18, fn=0.13		False
	30	0.3414		0.6659		0.6488		0.3486		0.9124	0.8482		tp=0.66, tn=0.098, fp=0.19, fn=0.049		True
	31	0.3391		0.6833		0.6335		0.2401		0.9092	0.77		tp=0.54, tn=0.14, fp=0.13, fn=0.19		False
	32	0.338		0.799		0.636		0.3111		0.9071	0.8219		tp=0.62, tn=0.1, fp=0.22, fn=0.056		False
	33	0.3278		0.677		0.6532		0.3575		0.9136	0.8213		tp=0.59, tn=0.15, fp=0.15, fn=0.1		True
	34	0.3225		0.783		0.6872		0.3287		0.9196	0.8257		tp=0.63, tn=0.1, fp=0.22, fn=0.049		False
	35	0.3188		0.7356		0.6636		0.3446		0.9152	0.8416		tp=0.65, tn=0.1, fp=0.19, fn=0.056		False
	36	0.3101		0.7348		0.6523		0.3448		0.9132	0.823		tp=0.6, tn=0.14, fp=0.15, fn=0.11		False
	37	0.3244		0.7956		0.6237		0.3036		0.9048	0.8273		tp=0.64, tn=0.098, fp=0.21, fn=0.056		False
	38	0.3065		0.7277		0.6835		0.3612		0.9178	0.8286		tp=0.61, tn=0.14, fp=0.15, fn=0.098		True
	39	0.3012		0.7083		0.6773		0.3189		0.9175	0.8364		tp=0.64, tn=0.1, fp=0.18, fn=0.07		False
	40	0.3026		0.7637		0.688		0.381		0.9203	0.8286		tp=0.6, tn=0.15, fp=0.17, fn=0.083		True
	41	0.3017		0.836		0.6762		0.1092		0.9175	0.7016		tp=0.47, tn=0.13, fp=0.16, fn=0.24		False
	42	0.2945		0.7333		0.6872		0.4172		0.9195	0.8571		tp=0.65, tn=0.13, fp=0.14, fn=0.077		True
	43	0.2901		0.7846		0.725		0.2473		0.9286	0.8165		tp=0.62, tn=0.098, fp=0.19, fn=0.091		False
	44	0.2874		0.8311		0.6989		0.3291		0.9231	0.8039		tp=0.57, tn=0.15, fp=0.15, fn=0.12		False
	45	0.293		0.7788		0.6868		0.3205		0.9194	0.8295		tp=0.62, tn=0.12, fp=0.17, fn=0.09		False
	46	0.2882		0.8426		0.7086		0.2414		0.9235	0.7526		tp=0.51, tn=0.15, fp=0.13, fn=0.21		False
	47	0.2863		0.8819		0.7092		0.3404		0.9232	0.8295		tp=0.63, tn=0.11, fp=0.2, fn=0.056		False
	48	0.2883		0.8682		0.7139		0.2571		0.9256	0.8148		tp=0.62, tn=0.1, fp=0.18, fn=0.098		False
	49	0.2778		0.8901		0.7147		0.2744		0.9264	0.8057		tp=0.59, tn=0.12, fp=0.19, fn=0.098		False
	50	0.2901		0.8842		0.6862		0.3182		0.9186	0.8169		tp=0.6, tn=0.12, fp=0.19, fn=0.083		False
	51	0.2719		0.9289		0.7137		0.2904		0.9258	0.7941		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	52	0.2819		0.8657		0.7196		0.3493		0.9261	0.8349		tp=0.64, tn=0.11, fp=0.2, fn=0.056		False
	53	0.277		0.8732		0.712		0.2741		0.9261	0.8113		tp=0.6, tn=0.12, fp=0.16, fn=0.12		False
	54	0.2716		0.8257		0.7207		0.2931		0.9267	0.8257		tp=0.63, tn=0.1, fp=0.19, fn=0.077		False
	55	0.2682		0.9603		0.732		0.2842		0.9311	0.8113		tp=0.6, tn=0.12, fp=0.18, fn=0.098		False
	56	0.2684		0.9366		0.7189		0.3335		0.9273	0.8116		tp=0.59, tn=0.14, fp=0.18, fn=0.091		False
	57	0.2605		0.899		0.7266		0.322		0.9288	0.8393		tp=0.65, tn=0.097, fp=0.19, fn=0.056		False
	58	0.2543		0.8822		0.7315		0.3392		0.9305	0.8098		tp=0.58, tn=0.15, fp=0.17, fn=0.098		False
	59	0.2612		0.8638		0.7419		0.3929		0.9326	0.8545		tp=0.66, tn=0.12, fp=0.16, fn=0.063		False
	60	0.2646		0.9208		0.7059		0.3164		0.9231	0.798		tp=0.56, tn=0.15, fp=0.15, fn=0.13		False
	61	0.2559		1.007		0.7505		0.3009		0.935	0.8		tp=0.57, tn=0.14, fp=0.17, fn=0.11		False
	62	0.2562		0.9783		0.744		0.2872		0.9337	0.8019		tp=0.58, tn=0.13, fp=0.17, fn=0.12		False
	63	0.2606		0.8338		0.7368		0.3707		0.931	0.852		tp=0.66, tn=0.11, fp=0.17, fn=0.062		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		164
learning rate		0.00117096125421
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_144-lr0.0012-h_size164-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6118		0.6278		0.01353		0		0.8135	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5849		0.6107		0.1705		0.1216		0.8178	0.8104		tp=0.67, tn=0.016, fp=0.31, fn=0.0074		True
	3	0.5724		0.6129		0.2197		0.1357		0.8213	0.8098		tp=0.66, tn=0.027, fp=0.29, fn=0.016		True
	4	0.5524		0.6087		0.2815		0.1823		0.8262	0.8011		tp=0.62, tn=0.071, fp=0.25, fn=0.062		True
	5	0.5453		0.6071		0.2953		0.1774		0.8265	0.7958		tp=0.61, tn=0.077, fp=0.24, fn=0.072		False
	6	0.5362		0.6017		0.3151		0.1712		0.8275	0.8112		tp=0.65, tn=0.053, fp=0.26, fn=0.043		False
	7	0.5281		0.6164		0.3351		0.1772		0.8323	0.7841		tp=0.58, tn=0.095, fp=0.22, fn=0.1		False
	8	0.521		0.6283		0.3466		0.1776		0.8319	0.7702		tp=0.56, tn=0.11, fp=0.21, fn=0.12		False
	9	0.5203		0.6518		0.3534		0.1623		0.8327	0.7301		tp=0.49, tn=0.14, fp=0.18, fn=0.19		False
	10	0.5093		0.613		0.38		0.181		0.84	0.8123		tp=0.65, tn=0.055, fp=0.26, fn=0.041		False
	11	0.4976		0.63		0.3998		0.1762		0.843	0.7886		tp=0.59, tn=0.087, fp=0.23, fn=0.09		False
	12	0.4905		0.6347		0.4192		0.2228		0.8464	0.8065		tp=0.63, tn=0.073, fp=0.25, fn=0.046		True
	13	0.4946		0.6445		0.401		0.2048		0.8421	0.8091		tp=0.63, tn=0.067, fp=0.25, fn=0.047		False
	14	0.4777		0.6362		0.4332		0.1913		0.8495	0.7894		tp=0.59, tn=0.09, fp=0.23, fn=0.084		False
	15	0.4693		0.6507		0.4581		0.178		0.8553	0.7779		tp=0.57, tn=0.099, fp=0.22, fn=0.11		False
	16	0.4615		0.648		0.4799		0.193		0.8596	0.7906		tp=0.59, tn=0.09, fp=0.23, fn=0.084		False
	17	0.4506		0.6628		0.477		0.1771		0.8577	0.7842		tp=0.59, tn=0.092, fp=0.23, fn=0.095		False
	18	0.4309		0.6488		0.5191		0.1935		0.8678	0.7981		tp=0.61, tn=0.079, fp=0.24, fn=0.067		False
	19	0.4298		0.6492		0.5328		0.1965		0.8721	0.7558		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	20	0.4127		0.6782		0.5456		0.1884		0.8745	0.7708		tp=0.56, tn=0.11, fp=0.2, fn=0.13		False
	21	0.3951		0.672		0.5799		0.2342		0.883	0.789		tp=0.58, tn=0.12, fp=0.2, fn=0.11		True
	22	0.3811		0.6747		0.5981		0.196		0.8875	0.784		tp=0.58, tn=0.099, fp=0.23, fn=0.095		False
	23	0.367		0.7005		0.6137		0.233		0.8917	0.8058		tp=0.61, tn=0.089, fp=0.23, fn=0.067		False
	24	0.3561		0.7871		0.6342		0.1588		0.896	0.8089		tp=0.65, tn=0.049, fp=0.27, fn=0.04		False
	25	0.3334		0.6911		0.6685		0.2618		0.9055	0.774		tp=0.54, tn=0.15, fp=0.18, fn=0.14		True
	26	0.3234		0.7668		0.6718		0.2332		0.9056	0.7552		tp=0.51, tn=0.15, fp=0.16, fn=0.17		False
	27	0.3131		0.8019		0.6903		0.1809		0.9105	0.8049		tp=0.63, tn=0.065, fp=0.25, fn=0.055		False
	28	0.2869		0.7488		0.7294		0.2425		0.9214	0.7762		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	29	0.2769		0.7502		0.7417		0.2443		0.9248	0.7582		tp=0.52, tn=0.16, fp=0.16, fn=0.17		False
	30	0.2555		0.7878		0.7817		0.2647		0.9357	0.7867		tp=0.56, tn=0.14, fp=0.18, fn=0.12		True
	31	0.2429		0.8126		0.7826		0.2326		0.9359	0.7636		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	32	0.2238		0.8851		0.8186		0.2338		0.946	0.7874		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	33	0.204		0.8453		0.8516		0.2383		0.9554	0.7844		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	34	0.195		0.8559		0.8545		0.2396		0.9564	0.7784		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	35	0.1883		0.8759		0.8585		0.2375		0.9575	0.7779		tp=0.55, tn=0.13, fp=0.18, fn=0.13		False
	36	0.1662		0.8895		0.8906		0.2688		0.967	0.7943		tp=0.57, tn=0.13, fp=0.19, fn=0.11		True
	37	0.1542		0.9001		0.9069		0.2296		0.9718	0.771		tp=0.54, tn=0.13, fp=0.18, fn=0.14		False
	38	0.1437		0.9263		0.9162		0.2276		0.9745	0.7794		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	39	0.1354		0.9487		0.927		0.279		0.9779	0.7417		tp=0.48, tn=0.19, fp=0.13, fn=0.2		True
	40	0.1228		0.9969		0.9363		0.2436		0.9805	0.7787		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	41	0.1175		0.9614		0.9467		0.2375		0.9837	0.7779		tp=0.55, tn=0.13, fp=0.18, fn=0.13		False
	42	0.1025		1.087		0.9541		0.25		0.986	0.7952		tp=0.59, tn=0.11, fp=0.21, fn=0.089		False
	43	0.09572		1.05		0.9589		0.2273		0.9874	0.7651		tp=0.53, tn=0.14, fp=0.18, fn=0.14		False
	44	0.09267		1.059		0.9576		0.2671		0.987	0.7793		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	45	0.08711		1.086		0.9706		0.2548		0.991	0.7838		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	46	0.08581		1.102		0.9632		0.25		0.9888	0.7669		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	47	0.07892		1.152		0.9706		0.2573		0.991	0.802		tp=0.59, tn=0.11, fp=0.2, fn=0.093		False
	48	0.06707		1.106		0.9818		0.2592		0.9944	0.791		tp=0.57, tn=0.13, fp=0.2, fn=0.11		False
	49	0.06654		1.341		0.9788		0.262		0.9935	0.8098		tp=0.61, tn=0.096, fp=0.23, fn=0.064		False
	50	0.06391		1.146		0.9749		0.2546		0.9923	0.7741		tp=0.54, tn=0.14, fp=0.17, fn=0.14		False
	51	0.05911		1.201		0.9836		0.2531		0.995	0.7821		tp=0.56, tn=0.13, fp=0.18, fn=0.13		False
	52	0.05759		1.323		0.9784		0.2539		0.9934	0.7931		tp=0.58, tn=0.12, fp=0.21, fn=0.096		False
	53	0.05265		1.237		0.9857		0.2545		0.9956	0.7872		tp=0.56, tn=0.13, fp=0.18, fn=0.12		False
	54	0.05111		1.238		0.9845		0.2617		0.9952	0.7525		tp=0.5, tn=0.17, fp=0.15, fn=0.18		False
	55	0.05203		1.305		0.9806		0.2561		0.994	0.7885		tp=0.57, tn=0.13, fp=0.2, fn=0.11		False
	56	0.04584		1.276		0.9844		0.2633		0.9952	0.774		tp=0.54, tn=0.15, fp=0.17, fn=0.14		False
	57	0.04417		1.354		0.987		0.2256		0.996	0.7747		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	58	0.04547		1.37		0.9853		0.279		0.9955	0.7857		tp=0.55, tn=0.14, fp=0.18, fn=0.12		True
	59	0.04471		1.488		0.9853		0.2237		0.9955	0.782		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	60	0.04092		1.399		0.9883		0.2575		0.9964	0.7846		tp=0.56, tn=0.13, fp=0.18, fn=0.13		False
	61	0.04044		1.385		0.9866		0.2411		0.9959	0.7611		tp=0.52, tn=0.15, fp=0.16, fn=0.16		False
	62	0.04412		1.441		0.9836		0.2349		0.995	0.765		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	63	0.04163		1.44		0.984		0.2365		0.9951	0.7822		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	64	0.04772		1.338		0.9805		0.2794		0.994	0.7887		tp=0.56, tn=0.14, fp=0.17, fn=0.13		True
	65	0.03766		1.449		0.9879		0.2385		0.9963	0.7726		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	66	0.03716		1.499		0.987		0.2553		0.996	0.7893		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	67	0.03791		1.508		0.9888		0.2321		0.9965	0.7915		tp=0.58, tn=0.11, fp=0.2, fn=0.1		False
	68	0.04283		1.429		0.9801		0.2535		0.9939	0.7759		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	69	0.037		1.543		0.9858		0.2628		0.9956	0.7959		tp=0.58, tn=0.12, fp=0.2, fn=0.099		False
	70	0.03329		1.623		0.987		0.2426		0.996	0.7873		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	71	0.03185		1.579		0.9892		0.2545		0.9967	0.7955		tp=0.58, tn=0.12, fp=0.2, fn=0.1		False
	72	0.033		1.463		0.9883		0.25		0.9964	0.7728		tp=0.54, tn=0.14, fp=0.17, fn=0.14		False
	73	0.03321		1.523		0.9879		0.2596		0.9963	0.7867		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	74	0.03584		1.6		0.9866		0.2873		0.9959	0.8024		tp=0.59, tn=0.13, fp=0.2, fn=0.093		True
	75	0.03614		1.524		0.9866		0.2602		0.9959	0.791		tp=0.57, tn=0.13, fp=0.2, fn=0.11		False
	76	0.03203		1.521		0.9892		0.252		0.9967	0.7803		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	77	0.03247		1.643		0.984		0.2687		0.9951	0.7896		tp=0.56, tn=0.13, fp=0.18, fn=0.12		False
	78	0.03003		1.612		0.9879		0.2549		0.9963	0.7881		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	79	0.03242		1.608		0.9883		0.2366		0.9964	0.7673		tp=0.53, tn=0.14, fp=0.18, fn=0.14		False
	80	0.03363		1.582		0.9883		0.2788		0.9964	0.79		tp=0.56, tn=0.14, fp=0.19, fn=0.11		False
	81	0.03444		1.617		0.9849		0.2528		0.9954	0.7889		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	82	0.03256		1.61		0.9879		0.2078		0.9963	0.7459		tp=0.51, tn=0.15, fp=0.17, fn=0.17		False
	83	0.03534		1.647		0.9844		0.2413		0.9952	0.7801		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	84	0.03492		1.605		0.9849		0.2391		0.9954	0.7878		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	85	0.02905		1.575		0.9905		0.263		0.9971	0.7871		tp=0.56, tn=0.13, fp=0.18, fn=0.12		False
	86	0.02833		1.763		0.9909		0.2784		0.9972	0.7926		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	87	0.0376		1.542		0.9857		0.2437		0.9956	0.7666		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	88	0.03566		1.471		0.9857		0.2375		0.9956	0.7779		tp=0.55, tn=0.13, fp=0.18, fn=0.13		False
	89	0.03051		1.617		0.9875		0.2637		0.9961	0.7884		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	90	0.02675		1.561		0.9896		0.2461		0.9968	0.7725		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	91	0.02774		1.618		0.9914		0.2448		0.9973	0.7747		tp=0.55, tn=0.14, fp=0.19, fn=0.13		False
	92	0.02827		1.745		0.9875		0.2808		0.9962	0.8084		tp=0.6, tn=0.12, fp=0.2, fn=0.086		False
	93	0.02798		1.725		0.9879		0.242		0.9963	0.7878		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	94	0.02788		1.899		0.9892		0.2408		0.9967	0.7932		tp=0.58, tn=0.11, fp=0.21, fn=0.092		False
	95	0.03104		1.691		0.984		0.2735		0.9951	0.8076		tp=0.6, tn=0.11, fp=0.2, fn=0.089		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		11
learning rate		0.00216022190551
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_145-lr0.0022-h_size11-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6211		0.6243		0.01116		0		0.8181	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6005		0.6155		0.05795		0.07963		0.8185	0.809		tp=0.67, tn=0.016, fp=0.3, fn=0.015		True
	3	0.5828		0.6083		0.1671		0.08106		0.8211	0.8		tp=0.65, tn=0.031, fp=0.29, fn=0.037		True
	4	0.5736		0.6157		0.2076		0.1589		0.8214	0.813		tp=0.67, tn=0.027, fp=0.29, fn=0.012		True
	5	0.5618		0.6156		0.242		0.1388		0.8227	0.8077		tp=0.65, tn=0.036, fp=0.28, fn=0.027		False
	6	0.5535		0.6157		0.2785		0.1682		0.828	0.7907		tp=0.6, tn=0.08, fp=0.24, fn=0.081		True
	7	0.5485		0.6099		0.2968		0.1599		0.8292	0.7883		tp=0.6, tn=0.08, fp=0.24, fn=0.086		False
	8	0.5465		0.6079		0.2945		0.1858		0.8272	0.7849		tp=0.58, tn=0.096, fp=0.22, fn=0.099		True
	9	0.541		0.5999		0.3001		0.2103		0.8274	0.8083		tp=0.63, tn=0.07, fp=0.25, fn=0.049		True
	10	0.5331		0.6081		0.3276		0.1935		0.833	0.8093		tp=0.64, tn=0.056, fp=0.27, fn=0.037		False
	11	0.5318		0.6045		0.3342		0.2479		0.8349	0.8138		tp=0.63, tn=0.08, fp=0.24, fn=0.049		True
	12	0.524		0.6125		0.3439		0.175		0.8357	0.7719		tp=0.56, tn=0.11, fp=0.21, fn=0.12		False
	13	0.5216		0.6018		0.353		0.2181		0.837	0.8016		tp=0.61, tn=0.092, fp=0.22, fn=0.08		False
	14	0.5158		0.6144		0.3674		0.1677		0.8401	0.7734		tp=0.57, tn=0.099, fp=0.22, fn=0.11		False
	15	0.5097		0.6063		0.3771		0.205		0.841	0.805		tp=0.62, tn=0.079, fp=0.24, fn=0.065		False
	16	0.5071		0.6023		0.3833		0.2443		0.8432	0.8093		tp=0.62, tn=0.089, fp=0.23, fn=0.062		False
	17	0.5003		0.6225		0.3997		0.1964		0.8463	0.8105		tp=0.64, tn=0.061, fp=0.26, fn=0.043		False
	18	0.4923		0.6045		0.4211		0.2232		0.8496	0.8016		tp=0.61, tn=0.092, fp=0.23, fn=0.076		False
	19	0.4843		0.6143		0.4256		0.2044		0.851	0.7961		tp=0.6, tn=0.09, fp=0.23, fn=0.081		False
	20	0.4812		0.6156		0.4345		0.1998		0.852	0.7684		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	21	0.4719		0.6144		0.4464		0.1871		0.8543	0.7816		tp=0.58, tn=0.1, fp=0.21, fn=0.11		False
	22	0.4638		0.6157		0.4616		0.2128		0.8582	0.7896		tp=0.59, tn=0.1, fp=0.22, fn=0.093		False
	23	0.4592		0.6266		0.472		0.2387		0.8595	0.8047		tp=0.61, tn=0.092, fp=0.23, fn=0.066		False
	24	0.4488		0.6292		0.4834		0.2217		0.8618	0.8008		tp=0.61, tn=0.087, fp=0.24, fn=0.067		False
	25	0.4378		0.6368		0.5209		0.2302		0.8708	0.7948		tp=0.59, tn=0.1, fp=0.22, fn=0.087		False
	26	0.4335		0.6209		0.5083		0.2357		0.8673	0.7984		tp=0.6, tn=0.1, fp=0.21, fn=0.087		False
	27	0.4248		0.6279		0.5292		0.2008		0.8718	0.7864		tp=0.58, tn=0.1, fp=0.21, fn=0.11		False
	28	0.4139		0.6526		0.5565		0.2174		0.8779	0.8035		tp=0.61, tn=0.087, fp=0.23, fn=0.072		False
	29	0.4039		0.641		0.5772		0.2011		0.8834	0.7789		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	30	0.3969		0.6487		0.5773		0.2126		0.8834	0.7908		tp=0.59, tn=0.1, fp=0.22, fn=0.092		False
	31	0.3846		0.6793		0.6012		0.2025		0.8891	0.7901		tp=0.59, tn=0.095, fp=0.23, fn=0.086		False
	32	0.3762		0.6631		0.6129		0.1951		0.8922	0.7618		tp=0.54, tn=0.13, fp=0.2, fn=0.14		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		74
learning rate		0.0014396233085
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_146-lr0.0014-h_size74-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6174		0.6223		0.003542		0		0.8111	0.812		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5681		0.6584		0.2227		0.1068		0.8237	0.7198		tp=0.49, tn=0.12, fp=0.2, fn=0.19		True
	3	0.5411		0.7052		0.29		0.06		0.824	0.805		tp=0.66, tn=0.015, fp=0.31, fn=0.016		False
	4	0.4859		0.638		0.435		0.1806		0.8506	0.777		tp=0.57, tn=0.1, fp=0.22, fn=0.11		True
	5	0.4535		0.6621		0.4765		0.1718		0.8555	0.7907		tp=0.6, tn=0.08, fp=0.24, fn=0.079		False
	6	0.4172		0.6961		0.5331		0.1677		0.8696	0.7854		tp=0.59, tn=0.086, fp=0.23, fn=0.09		False
	7	0.3815		0.7669		0.609		0.2054		0.889	0.7445		tp=0.51, tn=0.15, fp=0.18, fn=0.17		True
	8	0.3573		0.8714		0.6199		0.1679		0.8908	0.661		tp=0.4, tn=0.19, fp=0.13, fn=0.28		False
	9	0.3212		0.7796		0.6653		0.1595		0.9028	0.7428		tp=0.52, tn=0.13, fp=0.19, fn=0.17		False
	10	0.287		0.8432		0.7196		0.2165		0.9177	0.7462		tp=0.5, tn=0.15, fp=0.17, fn=0.17		True
	11	0.2605		0.895		0.7605		0.2001		0.9293	0.7876		tp=0.59, tn=0.099, fp=0.22, fn=0.096		False
	12	0.2207		0.9479		0.8109		0.1872		0.9435	0.7556		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	13	0.2078		0.8657		0.8156		0.2228		0.9447	0.7602		tp=0.53, tn=0.14, fp=0.18, fn=0.15		True
	14	0.1736		1.028		0.8649		0.2115		0.9592	0.7637		tp=0.54, tn=0.13, fp=0.18, fn=0.15		False
	15	0.1592		1.047		0.8772		0.2076		0.9626	0.7522		tp=0.52, tn=0.14, fp=0.18, fn=0.16		False
	16	0.1387		1.184		0.9051		0.2185		0.971	0.7829		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	17	0.1153		1.174		0.9263		0.2184		0.9775	0.747		tp=0.51, tn=0.15, fp=0.17, fn=0.17		False
	18	0.1095		1.22		0.9311		0.2216		0.979	0.7607		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	19	0.1002		1.307		0.9351		0.1939		0.9801	0.6979		tp=0.44, tn=0.18, fp=0.14, fn=0.24		False
	20	0.09205		1.329		0.945		0.2229		0.9832	0.7607		tp=0.53, tn=0.14, fp=0.18, fn=0.16		True
	21	0.07327		1.298		0.9619		0.2433		0.9883	0.7707		tp=0.54, tn=0.14, fp=0.18, fn=0.14		True
	22	0.07192		1.329		0.9624		0.2561		0.9885	0.7714		tp=0.53, tn=0.15, fp=0.17, fn=0.14		True
	23	0.06118		1.336		0.9697		0.2243		0.9907	0.757		tp=0.52, tn=0.15, fp=0.17, fn=0.16		False
	24	0.06848		1.402		0.9676		0.2547		0.9901	0.7825		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	25	0.05693		1.514		0.9719		0.251		0.9914	0.7791		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	26	0.05346		1.451		0.9736		0.2576		0.9919	0.7709		tp=0.53, tn=0.15, fp=0.17, fn=0.15		True
	27	0.0539		1.54		0.9758		0.2357		0.9926	0.7439		tp=0.49, tn=0.16, fp=0.16, fn=0.18		False
	28	0.0511		1.616		0.9745		0.2462		0.9922	0.7848		tp=0.56, tn=0.13, fp=0.2, fn=0.11		False
	29	0.04689		1.595		0.9784		0.256		0.9934	0.7754		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	30	0.04358		1.511		0.981		0.2454		0.9942	0.7679		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	31	0.0516		1.711		0.9736		0.2195		0.9919	0.7761		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	32	0.04459		1.72		0.9775		0.2341		0.9931	0.7758		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	33	0.0406		1.663		0.9831		0.2259		0.9948	0.7591		tp=0.52, tn=0.15, fp=0.17, fn=0.16		False
	34	0.03793		1.696		0.9793		0.2619		0.9936	0.7735		tp=0.54, tn=0.15, fp=0.17, fn=0.15		True
	35	0.0373		1.71		0.9823		0.2418		0.9946	0.7568		tp=0.51, tn=0.16, fp=0.16, fn=0.17		False
	36	0.03726		1.766		0.9827		0.2259		0.9947	0.7287		tp=0.47, tn=0.17, fp=0.15, fn=0.21		False
	37	0.04117		1.693		0.981		0.2149		0.9942	0.765		tp=0.54, tn=0.13, fp=0.19, fn=0.14		False
	38	0.04498		1.696		0.9754		0.2297		0.9924	0.7797		tp=0.56, tn=0.13, fp=0.19, fn=0.13		False
	39	0.03952		1.824		0.9823		0.2127		0.9946	0.7731		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	40	0.03799		1.82		0.9805		0.1996		0.994	0.7719		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	41	0.04121		1.765		0.9801		0.2561		0.9939	0.763		tp=0.52, tn=0.16, fp=0.16, fn=0.16		False
	42	0.04354		1.857		0.9758		0.2117		0.9926	0.7735		tp=0.55, tn=0.12, fp=0.2, fn=0.12		False
	43	0.05128		1.648		0.9727		0.2241		0.9917	0.7453		tp=0.5, tn=0.16, fp=0.16, fn=0.18		False
	44	0.04202		1.688		0.9788		0.2808		0.9935	0.776		tp=0.53, tn=0.16, fp=0.17, fn=0.14		True
	45	0.04166		1.738		0.9805		0.2411		0.994	0.7739		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	46	0.03708		1.76		0.9836		0.246		0.995	0.7743		tp=0.54, tn=0.14, fp=0.18, fn=0.13		False
	47	0.03268		1.791		0.9849		0.243		0.9954	0.7544		tp=0.51, tn=0.16, fp=0.16, fn=0.17		False
	48	0.03272		1.809		0.9844		0.2368			0.9952	0.7722		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	49	0.0302		1.823		0.9844		0.2262		0.9952	0.7428		tp=0.5, tn=0.16, fp=0.16, fn=0.19		False
	50	0.02948		1.741		0.9849		0.2398		0.9954	0.7694		tp=0.54, tn=0.14, fp=0.17, fn=0.15		False
	51	0.02941		1.872		0.9866		0.2343		0.9959	0.7673		tp=0.53, tn=0.14, fp=0.18, fn=0.14		False
	52	0.03226		1.743		0.9866		0.2409		0.9959	0.7653		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	53	0.03536		1.742		0.9806		0.2323		0.994	0.7581		tp=0.52, tn=0.15, fp=0.17, fn=0.16		False
	54	0.05327		1.427		0.9679		0.2473		0.9902	0.7296		tp=0.47, tn=0.18, fp=0.14, fn=0.21		False
	55	0.06207		1.63		0.9645		0.2147		0.9891	0.7816		tp=0.57, tn=0.12, fp=0.2, fn=0.12		False
	56	0.03404		1.761		0.9844		0.2156		0.9952	0.7519		tp=0.51, tn=0.15, fp=0.17, fn=0.17		False
	57	0.03074		1.728		0.9879		0.2316		0.9963	0.7495		tp=0.51, tn=0.16, fp=0.16, fn=0.18		False
	58	0.02738		1.762		0.9883		0.2187		0.9964	0.758		tp=0.52, tn=0.14, fp=0.18, fn=0.15		False
	59	0.03189		1.862		0.987		0.2148		0.996	0.7663		tp=0.54, tn=0.13, fp=0.19, fn=0.14		False
	60	0.02522		1.787		0.9901		0.26		0.9969	0.7681		tp=0.53, tn=0.15, fp=0.16, fn=0.15		False
	61	0.0244		1.742		0.9901		0.2185		0.9969	0.7671		tp=0.54, tn=0.13, fp=0.18, fn=0.14		False
	62	0.02527		1.761		0.9905		0.2464		0.9971	0.7689		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	63	0.02581		1.812		0.9883		0.2565		0.9964	0.7767		tp=0.54, tn=0.14, fp=0.17, fn=0.15		False
	64	0.02516		1.804		0.9896		0.2205		0.9968	0.7546		tp=0.52, tn=0.15, fp=0.17, fn=0.17		False
	65	0.02713		1.826		0.9905		0.218		0.9971	0.7532		tp=0.52, tn=0.15, fp=0.17, fn=0.17		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		14
learning rate		0.000395740656028
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_147-lr0.0004-h_size14-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6916		0.6773		0.04321		0.1181		0.5831	0.6947		tp=0.51, tn=0.046, fp=0.43, fn=0.021		True
	2	0.669		0.6681		0.1784		0.2355		0.6132	0.6011		tp=0.29, tn=0.33, fp=0.16, fn=0.22		True
	3	0.6458		0.6597		0.2955		0.2161		0.6635	0.6031		tp=0.3, tn=0.31, fp=0.17, fn=0.23		False
	4	0.6165		0.6529		0.3772		0.2155		0.6954	0.6203		tp=0.32, tn=0.29, fp=0.18, fn=0.21		False
	5	0.5883		0.661		0.4268		0.1844		0.717	0.652		tp=0.38, tn=0.22, fp=0.26, fn=0.15		False
	6	0.5616		0.668		0.4628		0.1768		0.7351	0.658		tp=0.39, tn=0.21, fp=0.26, fn=0.15		False
	7	0.5464		0.6733		0.4746		0.1771		0.7415	0.5691		tp=0.27, tn=0.31, fp=0.17, fn=0.25		False
	8	0.5193		0.6855		0.5243		0.2195		0.7655	0.6465		tp=0.36, tn=0.25, fp=0.23, fn=0.16		False
	9	0.4921		0.6898		0.5638		0.1667		0.786	0.6068		tp=0.32, tn=0.26, fp=0.2, fn=0.21		False
	10	0.4755		0.7083		0.5739		0.2031		0.7903	0.6608		tp=0.38, tn=0.22, fp=0.25, fn=0.15		False
	11	0.4511		0.7214		0.6289		0.2292		0.8172	0.6158		tp=0.31, tn=0.3, fp=0.17, fn=0.22		False
	12	0.4367		0.7421		0.6342		0.2423		0.8195	0.573		tp=0.26, tn=0.35, fp=0.12, fn=0.27		True
	13	0.4233		0.779		0.6384		0.2052		0.8212	0.5562		tp=0.25, tn=0.34, fp=0.14, fn=0.27		False
	14	0.4043		0.7373		0.6578		0.235		0.8311	0.6231		tp=0.32, tn=0.3, fp=0.18, fn=0.2		False
	15	0.3931		0.7537		0.675		0.2171		0.8394	0.6127		tp=0.31, tn=0.3, fp=0.18, fn=0.22		False
	16	0.3834		0.7825		0.6886		0.2081		0.8469	0.6435		tp=0.36, tn=0.25, fp=0.23, fn=0.17		False
	17	0.364		0.8054		0.7105		0.2443		0.8567	0.5962		tp=0.28, tn=0.34, fp=0.15, fn=0.23		True
	18	0.3507		0.81		0.7311		0.228		0.8675	0.6377		tp=0.34, tn=0.28, fp=0.2, fn=0.19		False
	19	0.3464		0.7961		0.7389		0.2449		0.8721	0.6166		tp=0.3, tn=0.32, fp=0.17, fn=0.21		True
	20	0.3329		0.8582		0.7489		0.1978		0.8755	0.6303		tp=0.34, tn=0.26, fp=0.23, fn=0.17		False
	21	0.319		0.843		0.7707		0.2403		0.8874	0.6337		tp=0.33, tn=0.29, fp=0.18, fn=0.2		False
	22	0.3148		0.8772		0.7672		0.237		0.8851	0.6558		tp=0.36, tn=0.26, fp=0.22, fn=0.16		False
	23	0.3079		0.9291		0.7613		0.175		0.8819	0.5945		tp=0.3, tn=0.28, fp=0.19, fn=0.22		False
	24	0.307		0.9253		0.7613		0.2025		0.883	0.6041		tp=0.3, tn=0.3, fp=0.19, fn=0.21		False
	25	0.286		0.9262		0.7955		0.2283		0.8992	0.6216		tp=0.32, tn=0.3, fp=0.18, fn=0.21		False
	26	0.282		0.9199		0.8009		0.2083		0.9026	0.6298		tp=0.34, tn=0.27, fp=0.22, fn=0.18		False
	27	0.2693		1.023		0.8097		0.1854		0.9062	0.5628		tp=0.26, tn=0.33, fp=0.16, fn=0.25		False
	28	0.2827		0.9559		0.7897		0.2155		0.8967	0.6071		tp=0.3, tn=0.3, fp=0.17, fn=0.22		False
	29	0.2583		1.007		0.8258		0.2072		0.9146	0.6298		tp=0.34, tn=0.27, fp=0.21, fn=0.19		False
	30	0.253		1.057		0.8281		0.1935		0.9159	0.6472		tp=0.37, tn=0.23, fp=0.25, fn=0.15		False
	31	0.2429		1.03		0.8228		0.2045		0.9127	0.6578		tp=0.38, tn=0.23, fp=0.24, fn=0.15		False
	32	0.2521		1.035		0.8145		0.1956		0.9083	0.6372		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	33	0.2491		1.075		0.8156		0.2087		0.9094	0.6225		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	34	0.2393		1.167		0.8328		0.1868		0.9181	0.5589		tp=0.26, tn=0.33, fp=0.15, fn=0.26		False
	35	0.2288		1.121		0.8345		0.1706		0.9189	0.5852		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	36	0.2211		1.163		0.8458		0.2339		0.924	0.6114		tp=0.3, tn=0.31, fp=0.17, fn=0.22		False
	37	0.2093		1.152		0.8605		0.2189		0.9314	0.5808		tp=0.27, tn=0.34, fp=0.16, fn=0.23		False
	38	0.2059		1.24		0.8694		0.2102		0.9358	0.5486		tp=0.25, tn=0.35, fp=0.13, fn=0.28		False
	39	0.2059		1.264		0.8677		0.2054		0.9352	0.5806		tp=0.28, tn=0.32, fp=0.16, fn=0.24		False
	40	0.2158		1.283		0.8446		0.1652		0.9236	0.5729		tp=0.28, tn=0.3, fp=0.18, fn=0.24		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		123
learning rate		0.00366131246837
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_148-lr0.0037-h_size123-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7413		0.6743		0.1145		0.1342		0.5106	0.724		tp=0.56, tn=0.014, fp=0.43, fn=0		True
	2	0.603		0.5598		0.3291		0.3842		0.6627	0.7067		tp=0.37, tn=0.32, fp=0.14, fn=0.17		True
	3	0.587		0.6062		0.3819		0.4149		0.6892	0.6116		tp=0.26, tn=0.41, fp=0.042, fn=0.29		True
	4	0.495		0.5566		0.551		0.4174		0.765	0.7453		tp=0.42, tn=0.29, fp=0.15, fn=0.14		True
	5	0.497		0.5682		0.5101		0.4781		0.7496	0.6923		tp=0.31, tn=0.41, fp=0.056, fn=0.22		True
	6	0.3738		0.5696		0.6892		0.5253		0.8418	0.7763		tp=0.41, tn=0.35, fp=0.098, fn=0.14		True
	7	0.2813		0.6092		0.7747		0.5014		0.881	0.7853		tp=0.45, tn=0.31, fp=0.13, fn=0.11		False
	8	0.2487		0.862		0.8093		0.4617		0.9023	0.6087		tp=0.24, tn=0.44, fp=0.021, fn=0.29		False
	9	0.2488		0.7922		0.8005		0.4857		0.8967	0.6923		tp=0.31, tn=0.41, fp=0.049, fn=0.23		False
	10	0.1554		0.7777		0.9003		0.4982		0.9485	0.7662		tp=0.41, tn=0.34, fp=0.098, fn=0.15		False
	11	0.118		0.8713		0.9238		0.5032		0.9605	0.7929		tp=0.47, tn=0.29, fp=0.16, fn=0.084		False
	12	0.09315		0.9109		0.956		0.4615		0.9773	0.7417		tp=0.39, tn=0.34, fp=0.098, fn=0.17		False
	13	0.07782		0.9173		0.956		0.5012		0.9774	0.7465		tp=0.37, tn=0.38, fp=0.098, fn=0.15		False
	14	0.07451		0.94		0.9473		0.4594		0.9731	0.7383		tp=0.38, tn=0.34, fp=0.1, fn=0.17		False
	15	0.0614		1.085		0.9736		0.476		0.9864	0.7702		tp=0.43, tn=0.31, fp=0.15, fn=0.11		False
	16	0.04188		1.085		0.9853		0.4841		0.9925	0.7068		tp=0.33, tn=0.4, fp=0.063, fn=0.21		False
	17	0.04069		1.148		0.9854		0.4909		0.9924	0.7722		tp=0.43, tn=0.32, fp=0.13, fn=0.13		False
	18	0.1625		1.487		0.8682		0.387		0.9313	0.7582		tp=0.48, tn=0.21, fp=0.24, fn=0.063		False
	19	0.1655		1.264		0.8739		0.4588		0.9355	0.6866		tp=0.32, tn=0.38, fp=0.056, fn=0.24		False
	20	0.06863		1.157		0.9619		0.5141		0.9803	0.7552		tp=0.38, tn=0.38, fp=0.098, fn=0.15		False
	21	0.0288		1.163		0.9941		0.5099		0.997	0.7712		tp=0.41, tn=0.34, fp=0.1, fn=0.14		False
	22	0.02508		1.23		0.9971		0.5219		0.9985	0.7792		tp=0.42, tn=0.34, fp=0.11, fn=0.13		False
	23	0.01661		1.261		0.9971		0.4751		0.9985	0.7432		tp=0.38, tn=0.35, fp=0.098, fn=0.17		False
	24	0.013		1.299		1		0.5115		1	0.7651		tp=0.4, tn=0.36, fp=0.1, fn=0.14		False
	25	0.01304		1.354		0.9971		0.5		0.9985	0.76		tp=0.4, tn=0.35, fp=0.098, fn=0.15		False
	26	0.01384		1.298		0.9971		0.5229		0.9985	0.7763		tp=0.41, tn=0.35, fp=0.11, fn=0.13		False
	27	0.01286		1.359		0.9971		0.4909		0.9985	0.7483		tp=0.38, tn=0.36, fp=0.091, fn=0.17		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		25
learning rate		0.00160934154972
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_149-lr0.0016-h_size25-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6875		0.6756		0.06361		0.1428		0.477	0.5811		tp=0.3, tn=0.27, fp=0.17, fn=0.27		True
	2	0.6452		0.69		0.3204		0.1994		0.6588	0.4655		tp=0.19, tn=0.38, fp=0.077, fn=0.36		True
	3	0.6166		0.687		0.3965		0.213		0.6688	0.5082		tp=0.22, tn=0.36, fp=0.091, fn=0.33		True
	4	0.5845		0.7627		0.4277		0.1266		0.6958	0.2745		tp=0.097, tn=0.39, fp=0.035, fn=0.48		False
	5	0.581		0.6868		0.4032		0.1282		0.6688	0.5224		tp=0.24, tn=0.31, fp=0.15, fn=0.3		False
	6	0.5378		0.664		0.4688		0.2626		0.727	0.675		tp=0.38, tn=0.26, fp=0.19, fn=0.17		True
	7	0.501		0.6655		0.5592		0.2838		0.7508	0.7093		tp=0.43, tn=0.22, fp=0.22, fn=0.13		True
	8	0.4937		0.7577		0.5198		0.1658		0.7639	0.4706		tp=0.2, tn=0.36, fp=0.098, fn=0.34		False
	9	0.4647		0.7036		0.5607		0.196		0.7553	0.6667		tp=0.39, tn=0.22, fp=0.22, fn=0.17		False
	10	0.4292		0.8462		0.6215		0.1915		0.806	0.4918		tp=0.21, tn=0.36, fp=0.091, fn=0.34		False
	11	0.4113		0.726		0.6313		0.2065		0.8025	0.65		tp=0.36, tn=0.24, fp=0.18, fn=0.21		False
	12	0.3954		0.7758		0.6365		0.1951		0.808	0.6369		tp=0.35, tn=0.25, fp=0.2, fn=0.2		False
	13	0.3677		0.8423		0.7039		0.1877		0.8495	0.5931		tp=0.3, tn=0.29, fp=0.15, fn=0.26		False
	14	0.3444		0.8274		0.7216		0.2127		0.8536	0.5957		tp=0.29, tn=0.31, fp=0.15, fn=0.24		False
	15	0.3453		0.8945		0.7362		0.1672		0.8615	0.6289		tp=0.35, tn=0.24, fp=0.23, fn=0.18		False
	16	0.3078		0.9385		0.7741		0.1562		0.8828	0.5793		tp=0.29, tn=0.28, fp=0.17, fn=0.26		False
	17	0.2983		1.017		0.7682		0.1363		0.8808	0.5333		tp=0.25, tn=0.31, fp=0.15, fn=0.29		False
	18	0.2908		1.12		0.777		0.1437		0.8848	0.5152		tp=0.24, tn=0.31, fp=0.13, fn=0.32		False
	19	0.3004		1.208		0.7476		0.1217		0.8693	0.459		tp=0.2, tn=0.34, fp=0.11, fn=0.35		False
	20	0.2746		1.179		0.7947		0.1606		0.8933	0.5303		tp=0.24, tn=0.32, fp=0.13, fn=0.3		False
	21	0.2459		1.041		0.8364		0.2692		0.9136	0.6294		tp=0.31, tn=0.31, fp=0.14, fn=0.23		False
	22	0.2524		1.073		0.8181		0.2364		0.9061	0.6582		tp=0.36, tn=0.26, fp=0.19, fn=0.19		False
	23	0.2693		1.142		0.7829		0.1977		0.8875	0.646		tp=0.36, tn=0.24, fp=0.21, fn=0.19		False
	24	0.2839		1.239		0.7334		0.1494		0.8598	0.6296		tp=0.36, tn=0.22, fp=0.24, fn=0.18		False
	25	0.2599		1.206		0.8004		0.1884		0.897	0.6503		tp=0.37, tn=0.23, fp=0.22, fn=0.18		False
	26	0.2364		1.36		0.839		0.2333		0.9183	0.5581		tp=0.25, tn=0.35, fp=0.11, fn=0.29		False
	27	0.2302		1.161		0.8357		0.2708		0.9152	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.2		False
	28	0.2003		1.342		0.8768		0.1958		0.9362	0.5931		tp=0.3, tn=0.29, fp=0.14, fn=0.27		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		58
learning rate		0.000941474468602
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_14-lr0.00094-h_size58-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6973		0.6839		0.01134		0.1859		0.5427	0.4713		tp=0.19, tn=0.39, fp=0.095, fn=0.33		True
	2	0.6819		0.6753		0.1165		0.1896		0.5784	0.634		tp=0.35, tn=0.25, fp=0.23, fn=0.18		True
	3	0.6706		0.6725		0.1784		0.1829		0.5992	0.6441		tp=0.37, tn=0.23, fp=0.24, fn=0.17		False
	4	0.6687		0.6892		0.1682		0.1084		0.5979	0.3933		tp=0.15, tn=0.38, fp=0.092, fn=0.37		False
	5	0.6543		0.7074		0.2167		0.1066		0.6239	0.3566		tp=0.13, tn=0.4, fp=0.077, fn=0.39		False
	6	0.6446		0.6804		0.2535		0.2006		0.6349	0.6518		tp=0.37, tn=0.23, fp=0.26, fn=0.14		True
	7	0.6484		0.692		0.2399		0.1056		0.6324	0.472		tp=0.21, tn=0.34, fp=0.14, fn=0.32		False
	8	0.6335		0.6704		0.2873		0.2186		0.649	0.6545		tp=0.37, tn=0.25, fp=0.22, fn=0.16		True
	9	0.6311		0.686		0.2973		0.1378		0.6636	0.5842		tp=0.3, tn=0.27, fp=0.21, fn=0.23		False
	10	0.6363		0.6943		0.2606		0.1214		0.6377	0.4943		tp=0.22, tn=0.33, fp=0.14, fn=0.31		False
	11	0.627		0.6969		0.2859		0.103		0.6521	0.5056		tp=0.23, tn=0.32, fp=0.17, fn=0.28		False
	12	0.6216		0.6806		0.312		0.1836		0.6649	0.6169		tp=0.33, tn=0.27, fp=0.2, fn=0.2		False
	13	0.6132		0.7195		0.3298		0.1181		0.6721	0.6667		tp=0.44, tn=0.12, fp=0.35, fn=0.084		False
	14	0.6196		0.7208		0.3102		0.0905		0.6628	0.4485		tp=0.19, tn=0.35, fp=0.13, fn=0.33		False
	15	0.6106		0.7049		0.3203		0.101		0.6667	0.5124		tp=0.24, tn=0.31, fp=0.18, fn=0.28		False
	16	0.6055		0.7339		0.3327		0.09518		0.6738	0.4214		tp=0.17, tn=0.36, fp=0.11, fn=0.36		False
	17	0.6091		0.7137		0.3315		0.07544		0.673	0.4524		tp=0.19, tn=0.33, fp=0.14, fn=0.33		False
	18	0.6063		0.708		0.3494		0.127		0.6789	0.635		tp=0.38, tn=0.19, fp=0.29, fn=0.14		False
	19	0.6018		0.7046		0.3268		0.1507		0.6743	0.6081		tp=0.33, tn=0.25, fp=0.23, fn=0.19		False
	20	0.6036		0.7047		0.3281		0.105		0.6688	0.5189		tp=0.25, tn=0.3, fp=0.16, fn=0.29		False
	21	0.5956		0.7162		0.3564		0.1293		0.6859	0.5771		tp=0.3, tn=0.27, fp=0.2, fn=0.24		False
	22	0.5888		0.7139		0.3628		0.1089		0.6902	0.5191		tp=0.24, tn=0.31, fp=0.17, fn=0.28		False
	23	0.5948		0.7202		0.3535		0.1234		0.682	0.6236		tp=0.36, tn=0.21, fp=0.26, fn=0.17		False
	24	0.593		0.7055		0.357		0.1609		0.6834	0.6301		tp=0.35, tn=0.23, fp=0.24, fn=0.18		False
	25	0.5889		0.7296		0.386		0.09092		0.6982	0.4629		tp=0.2, tn=0.34, fp=0.14, fn=0.32		False
	26	0.5863		0.7502		0.373		0.06969		0.6926	0.4471		tp=0.19, tn=0.32, fp=0.14, fn=0.35		False
	27	0.5774		0.7215		0.3972		0.09397		0.7042	0.5241		tp=0.25, tn=0.29, fp=0.18, fn=0.27		False
	28	0.5799		0.7005		0.3666		0.1532		0.6905	0.6043		tp=0.32, tn=0.26, fp=0.23, fn=0.2		False
	29	0.5661		0.7147		0.3966		0.1301		0.7041	0.5474		tp=0.27, tn=0.3, fp=0.18, fn=0.26		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		147
learning rate		0.000184157718962
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_150-lr0.00018-h_size147-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6898		0.6926		0.09393		0.09402		0.6432	0.6		tp=0.34, tn=0.22, fp=0.24, fn=0.2		True
	2	0.6786		0.6905		0.2232		0.1103		0.5516	0.4677		tp=0.2, tn=0.34, fp=0.13, fn=0.34		True
	3	0.6712		0.6902		0.2094		0.1183		0.5312	0.5255		tp=0.25, tn=0.29, fp=0.15, fn=0.31		True
	4	0.6648		0.6936		0.2221		0.09759		0.562	0.5		tp=0.23, tn=0.31, fp=0.15, fn=0.31		False
	5	0.66		0.7001		0.2303		0.04938		0.5815	0.4928		tp=0.24, tn=0.27, fp=0.16, fn=0.33		False
	6	0.6561		0.6975		0.2402		0.0866		0.5705	0.4962		tp=0.23, tn=0.3, fp=0.15, fn=0.31		False
	7	0.6531		0.7048		0.2168		0.06872		0.5513	0.5072		tp=0.24, tn=0.28, fp=0.17, fn=0.31		False
	8	0.649		0.6897		0.251		0.08694		0.5946	0.5479		tp=0.28, tn=0.26, fp=0.18, fn=0.28		False
	9	0.6464		0.703		0.2541		0.095		0.5929	0.5		tp=0.24, tn=0.29, fp=0.13, fn=0.34		False
	10	0.6437		0.699		0.2658		0.06612		0.6019	0.4925		tp=0.23, tn=0.29, fp=0.17, fn=0.31		False
	11	0.6404		0.6924		0.2545		0.1408		0.5863	0.5333		tp=0.25, tn=0.31, fp=0.15, fn=0.29		True
	12	0.6375		0.6873		0.2687		0.1152		0.6041	0.5429		tp=0.27, tn=0.29, fp=0.17, fn=0.27		False
	13	0.635		0.6883		0.2749		0.1471		0.6035	0.5401		tp=0.26, tn=0.3, fp=0.14, fn=0.3		True
	14	0.6327		0.6866		0.2954		0.1752		0.6178	0.589		tp=0.3, tn=0.28, fp=0.15, fn=0.27		True
	15	0.6293		0.6876		0.2923		0.1986		0.6193	0.5588		tp=0.27, tn=0.31, fp=0.12, fn=0.3		True
	16	0.6259		0.6972		0.2953		0.1116		0.619	0.5324		tp=0.26, tn=0.29, fp=0.17, fn=0.28		False
	17	0.6238		0.6881		0.2922		0.1633		0.624	0.5734		tp=0.29, tn=0.29, fp=0.15, fn=0.27		False
	18	0.6213		0.6757		0.3072		0.1317		0.6242	0.5152		tp=0.24, tn=0.31, fp=0.14, fn=0.31		False
	19	0.6182		0.6826		0.322		0.2003		0.6328	0.5915		tp=0.29, tn=0.3, fp=0.15, fn=0.25		True
	20	0.6148		0.683		0.3306		0.2203		0.6524	0.6164		tp=0.31, tn=0.29, fp=0.17, fn=0.22		True
	21	0.612		0.6821		0.3307		0.1846		0.6545	0.5874		tp=0.29, tn=0.29, fp=0.16, fn=0.25		False
	22	0.6101		0.69		0.3277		0.1563		0.6382	0.5906		tp=0.31, tn=0.27, fp=0.18, fn=0.24		False
	23	0.6074		0.6762		0.3423		0.2284		0.6585	0.6358		tp=0.34, tn=0.28, fp=0.2, fn=0.19		True
	24	0.6046		0.688		0.354		0.1444		0.6573	0.5263		tp=0.24, tn=0.32, fp=0.15, fn=0.29		False
	25	0.6013		0.6793		0.3511		0.2143		0.6626	0.6364		tp=0.34, tn=0.27, fp=0.17, fn=0.22		False
	26	0.599		0.6796		0.351		0.2158		0.6574	0.6316		tp=0.34, tn=0.27, fp=0.17, fn=0.22		False
	27	0.5956		0.677		0.3408		0.2284		0.6686	0.6316		tp=0.33, tn=0.28, fp=0.15, fn=0.24		False
	28	0.5927		0.6838		0.3659		0.216		0.6625	0.5957		tp=0.29, tn=0.31, fp=0.15, fn=0.25		False
	29	0.5907		0.6699		0.393		0.2626		0.6709	0.675		tp=0.38, tn=0.26, fp=0.19, fn=0.17		True
	30	0.5867		0.6793		0.3758		0.2443		0.6854	0.6207		tp=0.31, tn=0.3, fp=0.14, fn=0.24		False
	31	0.5855		0.6757		0.3835		0.2295		0.6719	0.6309		tp=0.33, tn=0.29, fp=0.19, fn=0.2		False
	32	0.5816		0.6797		0.3805		0.2158		0.6759	0.6316		tp=0.34, tn=0.27, fp=0.17, fn=0.22		False
	33	0.5794		0.6666		0.4011		0.286		0.6832	0.6577		tp=0.34, tn=0.3, fp=0.17, fn=0.19		True
	34	0.5769		0.6794		0.407		0.2322		0.6921	0.6056		tp=0.3, tn=0.31, fp=0.14, fn=0.25		False
	35	0.5744		0.6763		0.3808		0.2649		0.6817	0.6443		tp=0.34, tn=0.29, fp=0.15, fn=0.22		False
	36	0.5737		0.6543		0.4153		0.3193		0.6743	0.7		tp=0.39, tn=0.27, fp=0.16, fn=0.17		True
	37	0.5716		0.6464		0.3743		0.2814		0.6899	0.6286		tp=0.31, tn=0.33, fp=0.14, fn=0.22		False
	38	0.5661		0.6887		0.4247		0.2499		0.6957	0.6667		tp=0.37, tn=0.26, fp=0.17, fn=0.2		False
	39	0.5634		0.687		0.3967		0.2127		0.6971	0.5957		tp=0.29, tn=0.31, fp=0.15, fn=0.24		False
	40	0.5616		0.6655		0.4373		0.3363		0.6952	0.68		tp=0.35, tn=0.31, fp=0.14, fn=0.19		True
	41	0.5587		0.6663		0.4042		0.2917		0.6938	0.6483		tp=0.33, tn=0.31, fp=0.15, fn=0.21		False
	42	0.5564		0.6774		0.4422		0.2662		0.7077	0.6294		tp=0.31, tn=0.31, fp=0.15, fn=0.22		False
	43	0.5531		0.6619		0.4422		0.2669		0.7095	0.6709		tp=0.37, tn=0.27, fp=0.16, fn=0.2		False
	44	0.5519		0.6709		0.422		0.2378		0.7046	0.5625		tp=0.25, tn=0.36, fp=0.12, fn=0.27		False
	45	0.5508		0.687		0.4426		0.2614		0.7156	0.649		tp=0.34, tn=0.29, fp=0.15, fn=0.22		False
	46	0.549		0.669		0.4746		0.2557		0.7242	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	47	0.5448		0.6705		0.4686		0.2764		0.722	0.6286		tp=0.31, tn=0.33, fp=0.15, fn=0.21		False
	48	0.5464		0.6935		0.4307		0.1983		0.7078	0.5385		tp=0.24, tn=0.34, fp=0.12, fn=0.3		False
	49	0.5427		0.6811		0.4459		0.3096		0.7192	0.6575		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	50	0.5394		0.6793		0.4659		0.2758		0.7174	0.6486		tp=0.34, tn=0.3, fp=0.15, fn=0.21		False
	51	0.538		0.6703		0.4583		0.3061		0.7049	0.6918		tp=0.38, tn=0.27, fp=0.17, fn=0.17		False
	52	0.5384		0.6811		0.4546		0.3086		0.7232	0.6277		tp=0.3, tn=0.34, fp=0.11, fn=0.24		False
	53	0.5305		0.6688		0.4834		0.2942		0.7341	0.6483		tp=0.33, tn=0.31, fp=0.14, fn=0.22		False
	54	0.5279		0.6766		0.4863		0.3169		0.7336	0.6429		tp=0.31, tn=0.34, fp=0.12, fn=0.23		False
	55	0.5278		0.651		0.4955		0.3062		0.7312	0.6622		tp=0.34, tn=0.31, fp=0.14, fn=0.21		False
	56	0.5268		0.6937		0.4776		0.2309		0.7311	0.5714		tp=0.27, tn=0.34, fp=0.12, fn=0.28		False
	57	0.5226		0.6868		0.4805		0.2867		0.733	0.6389		tp=0.32, tn=0.32, fp=0.14, fn=0.22		False
	58	0.519		0.6857		0.5068		0.3139		0.7447	0.6277		tp=0.3, tn=0.34, fp=0.1, fn=0.25		False
	59	0.5166		0.682		0.4989		0.3225		0.7307	0.6573		tp=0.33, tn=0.33, fp=0.13, fn=0.21		False
	60	0.5158		0.6954		0.4816		0.2519		0.7393	0.5758		tp=0.26, tn=0.35, fp=0.11, fn=0.28		False
	61	0.5189		0.6918		0.5021		0.2608		0.731	0.6829		tp=0.39, tn=0.24, fp=0.21, fn=0.15		False


data			/scratch/asw462/data/levin
input size		300
hidden size		87
learning rate		0.000976310764211
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_151-lr0.00098-h_size87-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.58		0.5896		0		0		0.8432	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5499		0.5641		0.04327		0		0.8429	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.5231		0.5388		0.1844		0.1261		0.8457	0.823		tp=0.69, tn=0.0069, fp=0.3, fn=0		True
	4	0.4853		0.5432		0.3453		0.2292		0.8619	0.8205		tp=0.67, tn=0.035, fp=0.29, fn=0.007		True
	5	0.4519		0.5213		0.3943		0.3408		0.8669	0.8393		tp=0.66, tn=0.091, fp=0.22, fn=0.035		True
	6	0.4223		0.5078		0.4744		0.4206		0.8798	0.8493		tp=0.65, tn=0.12, fp=0.2, fn=0.035		True
	7	0.3996		0.5093		0.4992		0.4371		0.8824	0.8476		tp=0.62, tn=0.15, fp=0.15, fn=0.077		True
	8	0.3884		0.5019		0.5238		0.4209		0.882	0.8532		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False
	9	0.3739		0.5407		0.5553		0.3487		0.8929	0.8311		tp=0.64, tn=0.1, fp=0.22, fn=0.042		False
	10	0.3613		0.5106		0.5797		0.4131		0.8969	0.8622		tp=0.68, tn=0.1, fp=0.18, fn=0.035		False
	11	0.3484		0.526		0.6179		0.398		0.9039	0.8293		tp=0.59, tn=0.16, fp=0.13, fn=0.11		False
	12	0.3435		0.5569		0.6035		0.305		0.901	0.8288		tp=0.64, tn=0.097, fp=0.21, fn=0.056		False
	13	0.3323		0.5584		0.6402		0.2921		0.9108	0.7921		tp=0.56, tn=0.15, fp=0.15, fn=0.15		False
	14	0.3274		0.5517		0.6626		0.2991		0.9145	0.8378		tp=0.65, tn=0.1, fp=0.15, fn=0.097		False
	15	0.3154		0.5686		0.6752		0.4126		0.915	0.8532		tp=0.65, tn=0.13, fp=0.17, fn=0.056		False
	16	0.3074		0.5926		0.6729		0.308		0.9166	0.8472		tp=0.67, tn=0.083, fp=0.19, fn=0.049		False
	17	0.3375		0.5583		0.6228		0.4399		0.9039	0.8374		tp=0.59, tn=0.17, fp=0.11, fn=0.12		True
	18	0.3012		0.6112		0.671		0.3068		0.9152	0.8458		tp=0.67, tn=0.084, fp=0.2, fn=0.049		False
	19	0.2925		0.6133		0.6723		0.3518		0.9169	0.7959		tp=0.55, tn=0.17, fp=0.13, fn=0.15		False
	20	0.2973		0.6495		0.6932		0.3224		0.9197	0.8241		tp=0.62, tn=0.11, fp=0.2, fn=0.063		False
	21	0.2907		0.6098		0.6851		0.3461		0.9189	0.8333		tp=0.63, tn=0.12, fp=0.18, fn=0.07		False
	22	0.2859		0.6576		0.7185		0.3263		0.9264	0.8349		tp=0.64, tn=0.11, fp=0.17, fn=0.077		False
	23	0.2743		0.667		0.6916		0.3004		0.9211	0.8257		tp=0.63, tn=0.1, fp=0.2, fn=0.07		False
	24	0.2844		0.6883		0.7203		0.3006		0.9268	0.8077		tp=0.59, tn=0.13, fp=0.17, fn=0.11		False
	25	0.2657		0.715		0.7264		0.3326		0.929	0.8496		tp=0.67, tn=0.091, fp=0.19, fn=0.049		False
	26	0.2624		0.7184		0.7385		0.3565		0.9316	0.804		tp=0.56, tn=0.17, fp=0.15, fn=0.13		False
	27	0.2648		0.6775		0.7326		0.3431		0.9294	0.8246		tp=0.61, tn=0.13, fp=0.17, fn=0.091		False
	28	0.2536		0.6465		0.7482		0.357		0.9339	0.8507		tp=0.66, tn=0.11, fp=0.15, fn=0.077		False
	29	0.256		0.7555		0.726		0.2261		0.928	0.8037		tp=0.6, tn=0.1, fp=0.17, fn=0.12		False
	30	0.2556		0.8076		0.7355		0.3111		0.9306	0.8152		tp=0.6, tn=0.13, fp=0.18, fn=0.091		False
	31	0.2609		0.695		0.721		0.319		0.9269	0.8279		tp=0.62, tn=0.12, fp=0.17, fn=0.091		False
	32	0.2594		0.7076		0.7346		0.4284		0.9298	0.8317		tp=0.59, tn=0.17, fp=0.13, fn=0.1		False
	33	0.2415		0.7791		0.7502		0.3565		0.935	0.804		tp=0.56, tn=0.17, fp=0.15, fn=0.13		False
	34	0.2343		0.7886		0.7701		0.3628		0.9404	0.8195		tp=0.59, tn=0.15, fp=0.13, fn=0.13		False
	35	0.256		0.7726		0.7249		0.3552		0.9275	0.8213		tp=0.59, tn=0.15, fp=0.15, fn=0.11		False
	36	0.2369		0.7954		0.7755		0.3537		0.9399	0.8302		tp=0.62, tn=0.13, fp=0.16, fn=0.091		False
	37	0.2368		0.858		0.7498		0.3624		0.935	0.7959		tp=0.54, tn=0.18, fp=0.12, fn=0.15		False
	38	0.2369		0.9364		0.7547		0.3127		0.9365	0.8077		tp=0.59, tn=0.13, fp=0.19, fn=0.091		False


data			/scratch/asw462/data/levin
input size		300
hidden size		179
learning rate		0.00324137163976
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_152-lr0.0032-h_size179-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.579		0.5835		0.05127		0.09039		0.8403	0.822		tp=0.68, tn=0.028, fp=0.26, fn=0.035		True
	2	0.5509		0.5865		0.1809		0.2431		0.8461	0.8354		tp=0.69, tn=0.035, fp=0.27, fn=0.007		True
	3	0.5358		0.5665		0.237		0.1273		0.847	0.8103		tp=0.65, tn=0.042, fp=0.26, fn=0.042		False
	4	0.5217		0.5828		0.2438		0.1854		0.8438	0.8108		tp=0.63, tn=0.077, fp=0.21, fn=0.084		False
	5	0.5109		0.5839		0.27		0.2624		0.8481	0.8312		tp=0.67, tn=0.056, fp=0.25, fn=0.021		True
	6	0.4926		0.6192		0.3188		0.2314		0.8532	0.8178		tp=0.64, tn=0.076, fp=0.23, fn=0.056		False
	7	0.5267		0.5531		0.2588		0.2172		0.8412	0.8326		tp=0.68, tn=0.049, fp=0.24, fn=0.028		False
	8	0.4876		0.6135		0.3536		0.2277		0.8542	0.8073		tp=0.62, tn=0.091, fp=0.22, fn=0.077		False
	9	0.4663		0.6218		0.3772		0.1515		0.8564	0.7964		tp=0.62, tn=0.07, fp=0.24, fn=0.077		False
	10	0.4899		0.5865		0.3576		0.2141		0.8536	0.8362		tp=0.68, tn=0.056, fp=0.22, fn=0.042		False
	11	0.4486		0.6372		0.3787		0.3049		0.8583	0.8426		tp=0.69, tn=0.049, fp=0.25, fn=0.007		True
	12	0.4578		0.5885		0.3916		0.1753		0.8578	0.8072		tp=0.63, tn=0.07, fp=0.23, fn=0.07		False
	13	0.4613		0.6259		0.4091		0.08584		0.8633	0.75		tp=0.55, tn=0.091, fp=0.2, fn=0.16		False
	14	0.456		0.6292		0.3997		0.226		0.8623	0.7662		tp=0.53, tn=0.14, fp=0.16, fn=0.17		False
	15	0.4432		0.5955		0.446		0.1561		0.8638	0.761		tp=0.55, tn=0.11, fp=0.17, fn=0.17		False
	16	0.4226		0.6564		0.4762		0.1832		0.8729	0.8142		tp=0.64, tn=0.063, fp=0.24, fn=0.056		False
	17	0.4167		0.6978		0.493		0.1494		0.8788	0.7488		tp=0.53, tn=0.12, fp=0.19, fn=0.17		False
	18	0.422		0.6781		0.4808		0.2264		0.875	0.7867		tp=0.58, tn=0.11, fp=0.22, fn=0.097		False
	19	0.424		0.7171		0.4649		0.1524		0.8706	0.807		tp=0.64, tn=0.049, fp=0.27, fn=0.042		False
	20	0.4059		0.7014		0.5037		0.1639		0.8815	0.787		tp=0.59, tn=0.084, fp=0.23, fn=0.091		False
	21	0.4244		0.6912		0.4716		0.1844		0.8708	0.8291		tp=0.68, tn=0.042, fp=0.25, fn=0.028		False
	22	0.4168		0.6252		0.4936		0.1119		0.8774	0.7834		tp=0.59, tn=0.077, fp=0.2, fn=0.13		False
	23	0.3976		0.6636		0.5197		0.1642		0.8827	0.787		tp=0.59, tn=0.09, fp=0.21, fn=0.11		False
	24	0.4149		0.6542		0.4949		0.2033		0.8764	0.8125		tp=0.63, tn=0.076, fp=0.22, fn=0.069		False
	25	0.3933		0.6991		0.5228		0.1235		0.8826	0.7426		tp=0.52, tn=0.11, fp=0.18, fn=0.18		False
	26	0.395		0.6655		0.521		0.1427		0.8814	0.8106		tp=0.64, tn=0.056, fp=0.24, fn=0.063		False
	27	0.3883		0.7283		0.5172		0.0251		0.8829	0.7453		tp=0.55, tn=0.07, fp=0.23, fn=0.15		False
	28	0.3761		0.7362		0.5594		0.2121		0.8885	0.7487		tp=0.51, tn=0.15, fp=0.15, fn=0.19		False
	29	0.4073		0.6559		0.5317		0.2327		0.8843	0.7885		tp=0.57, tn=0.12, fp=0.19, fn=0.12		False
	30	0.3822		0.6853		0.5251		0.192		0.8798	0.7788		tp=0.57, tn=0.11, fp=0.18, fn=0.14		False
	31	0.3832		0.6929		0.5345		0.2522		0.8861	0.7182		tp=0.45, tn=0.19, fp=0.12, fn=0.24		False
	32	0.3723		0.8246		0.5402		0.08697		0.8858	0.8155		tp=0.66, tn=0.035, fp=0.25, fn=0.049		False


data			/scratch/asw462/data/levin
input size		300
hidden size		101
learning rate		0.000273141069386
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_153-lr0.00027-h_size101-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5895		0.6151		-0.01499		0		0.8335	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.5649		0.5955		0		0		0.8407	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.5442		0.5737		0.04336		0		0.8435	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	4	0.5326		0.5509		0.1516		0.1168		0.8446	0.825		tp=0.69, tn=0.014, fp=0.29, fn=0.007		True
	5	0.5148		0.5455		0.1972		0.05617		0.85	0.8313		tp=0.71, tn=0.007, fp=0.28, fn=0.007		False
	6	0.4982		0.5402		0.2869		0.3544		0.8546	0.8416		tp=0.65, tn=0.1, fp=0.2, fn=0.049		True
	7	0.4786		0.5272		0.3514		0.1873		0.864	0.8403		tp=0.7, tn=0.035, fp=0.24, fn=0.021		False
	8	0.4673		0.523		0.4225		0.2919		0.8732	0.8536		tp=0.71, tn=0.042, fp=0.24, fn=0.007		False
	9	0.4441		0.522		0.4316		0.1853		0.8762	0.8305		tp=0.68, tn=0.042, fp=0.25, fn=0.028		False
	10	0.4279		0.5191		0.4658		0.3484		0.8818	0.8472		tp=0.68, tn=0.077, fp=0.22, fn=0.021		False
	11	0.418		0.52		0.4916		0.4022		0.8845	0.8365		tp=0.61, tn=0.15, fp=0.13, fn=0.1		True
	12	0.4035		0.5243		0.5364		0.3819		0.8911	0.8402		tp=0.64, tn=0.12, fp=0.19, fn=0.049		False
	13	0.3869		0.4981		0.5848		0.4112		0.9016	0.8451		tp=0.63, tn=0.14, fp=0.16, fn=0.07		True
	14	0.3767		0.4968		0.5931		0.3455		0.9013	0.8468		tp=0.66, tn=0.1, fp=0.17, fn=0.063		False
	15	0.3649		0.4924		0.6147		0.4126		0.9062	0.8465		tp=0.63, tn=0.14, fp=0.16, fn=0.069		True
	16	0.3479		0.4994		0.6188		0.35		0.9071	0.8402		tp=0.64, tn=0.11, fp=0.18, fn=0.063		False
	17	0.3362		0.4909		0.6469		0.4487		0.9128	0.8545		tp=0.64, tn=0.15, fp=0.15, fn=0.063		True
	18	0.3296		0.4809		0.6654		0.3727		0.9167	0.8621		tp=0.69, tn=0.083, fp=0.19, fn=0.028		False
	19	0.3169		0.5187		0.6653		0.3465		0.9159	0.8318		tp=0.62, tn=0.13, fp=0.17, fn=0.084		False
	20	0.3139		0.4941		0.67		0.3842		0.9172	0.8411		tp=0.63, tn=0.13, fp=0.16, fn=0.077		False
	21	0.2921		0.5128		0.7045		0.4066		0.9258	0.8465		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	22	0.2851		0.5892		0.7374		0.3086		0.9323	0.8319		tp=0.66, tn=0.077, fp=0.24, fn=0.028		False
	23	0.2808		0.5116		0.7382		0.3766		0.9331	0.8387		tp=0.63, tn=0.12, fp=0.18, fn=0.062		False
	24	0.2713		0.5206		0.758		0.367		0.9376	0.8584		tp=0.68, tn=0.098, fp=0.17, fn=0.049		False
	25	0.2639		0.5548		0.7631		0.4545		0.9385	0.8431		tp=0.6, tn=0.17, fp=0.13, fn=0.098		True
	26	0.2715		0.6022		0.7329		0.3317		0.9302	0.8241		tp=0.62, tn=0.11, fp=0.21, fn=0.056		False
	27	0.2417		0.5083		0.7762		0.4655		0.9418	0.8598		tp=0.64, tn=0.15, fp=0.14, fn=0.069		True
	28	0.2346		0.5575		0.8029		0.4556		0.9489	0.8611		tp=0.65, tn=0.14, fp=0.15, fn=0.056		False
	29	0.2313		0.4901		0.7966		0.4003		0.9469	0.8545		tp=0.66, tn=0.12, fp=0.17, fn=0.056		False
	30	0.222		0.5257		0.8028		0.4969		0.9482	0.8679		tp=0.64, tn=0.16, fp=0.13, fn=0.07		True
	31	0.2184		0.5595		0.8221		0.4643		0.9534	0.8517		tp=0.62, tn=0.17, fp=0.13, fn=0.083		False
	32	0.2044		0.5783		0.8498		0.4672		0.9603	0.8517		tp=0.62, tn=0.16, fp=0.15, fn=0.063		False
	33	0.1983		0.6234		0.8399		0.4475		0.958	0.8476		tp=0.62, tn=0.15, fp=0.16, fn=0.063		False
	34	0.2062		0.5664		0.8193		0.445		0.9523	0.8531		tp=0.63, tn=0.15, fp=0.13, fn=0.084		False
	35	0.1912		0.6297		0.8521		0.4055		0.9613	0.8381		tp=0.62, tn=0.15, fp=0.16, fn=0.077		False
	36	0.1807		0.5802		0.8713		0.4607		0.9659	0.8447		tp=0.6, tn=0.17, fp=0.14, fn=0.083		False
	37	0.1814		0.6398		0.8821		0.4329		0.9686	0.8558		tp=0.64, tn=0.14, fp=0.15, fn=0.07		False
	38	0.1774		0.5926		0.866		0.475		0.9644	0.8558		tp=0.62, tn=0.17, fp=0.13, fn=0.084		False
	39	0.1759		0.6189		0.8667		0.436		0.9642	0.8661		tp=0.68, tn=0.11, fp=0.17, fn=0.035		False
	40	0.1777		0.5858		0.8571		0.4602		0.962	0.8585		tp=0.64, tn=0.15, fp=0.13, fn=0.077		False
	41	0.1654		0.669		0.8793		0.4527		0.9676	0.8558		tp=0.64, tn=0.14, fp=0.17, fn=0.049		False
	42	0.1604		0.6692		0.886		0.3842		0.9695	0.8411		tp=0.63, tn=0.13, fp=0.16, fn=0.077		False
	43	0.1553		0.7233		0.8801		0.3992		0.9673	0.8532		tp=0.65, tn=0.13, fp=0.15, fn=0.07		False
	44	0.1521		0.7127		0.8993		0.4421		0.9727	0.8571		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False
	45	0.1471		0.7372		0.8859		0.406		0.9696	0.8451		tp=0.63, tn=0.14, fp=0.15, fn=0.077		False
	46	0.1352		0.7311		0.9095		0.4053		0.9756	0.8532		tp=0.65, tn=0.13, fp=0.16, fn=0.063		False
	47	0.1349		0.7284		0.913		0.3869		0.9766	0.8634		tp=0.69, tn=0.098, fp=0.17, fn=0.042		False
	48	0.1337		0.7724		0.9166		0.4131		0.9775	0.8622		tp=0.68, tn=0.1, fp=0.18, fn=0.035		False
	49	0.136		0.7549		0.9098		0.4908		0.9756	0.8571		tp=0.63, tn=0.16, fp=0.16, fn=0.049		False
	50	0.125		0.7553		0.9199		0.4582		0.9785	0.8531		tp=0.63, tn=0.15, fp=0.15, fn=0.063		False
	51	0.1207		0.5948		0.9343		0.5089		0.9823	0.8744		tp=0.66, tn=0.15, fp=0.13, fn=0.056		True
	52	0.1176		0.7226		0.9379		0.4782		0.9832	0.8571		tp=0.63, tn=0.16, fp=0.15, fn=0.063		False
	53	0.1214		0.888		0.9297		0.4499		0.9807	0.8636		tp=0.66, tn=0.13, fp=0.17, fn=0.042		False
	54	0.1198		0.7938		0.9117		0.4928		0.9761	0.8638		tp=0.64, tn=0.15, fp=0.15, fn=0.049		False
	55	0.1091		0.8127		0.9396		0.386		0.9838	0.8325		tp=0.61, tn=0.15, fp=0.15, fn=0.091		False
	56	0.1047		0.789		0.9472		0.462		0.9856	0.8517		tp=0.62, tn=0.16, fp=0.15, fn=0.07		False
	57	0.1012		0.8793		0.9612		0.4421		0.9894	0.8571		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False
	58	0.1038		0.7708		0.9558		0.4485		0.988	0.8531		tp=0.63, tn=0.15, fp=0.14, fn=0.077		False
	59	0.09623		0.7235		0.9468		0.4596		0.9857	0.8598		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	60	0.09505		0.9293		0.9528		0.4007		0.987	0.8325		tp=0.61, tn=0.15, fp=0.17, fn=0.07		False
	61	0.09353		0.8005		0.9576		0.4582		0.9885	0.8531		tp=0.63, tn=0.15, fp=0.15, fn=0.063		False
	62	0.09379		0.8604		0.9399		0.3847		0.9837	0.8341		tp=0.62, tn=0.14, fp=0.17, fn=0.077		False
	63	0.09145		0.8264		0.956		0.508		0.988	0.8485		tp=0.59, tn=0.2, fp=0.11, fn=0.098		False
	64	0.09006		0.933		0.9593		0.4053		0.989	0.8532		tp=0.65, tn=0.13, fp=0.16, fn=0.063		False
	65	0.08695		0.9066		0.9684		0.438		0.9913	0.8491		tp=0.63, tn=0.15, fp=0.16, fn=0.063		False
	66	0.08433		0.8224		0.9647		0.4709		0.9904	0.8651		tp=0.65, tn=0.15, fp=0.14, fn=0.063		False
	67	0.07634		0.9511		0.9719		0.445		0.9923	0.8558		tp=0.64, tn=0.14, fp=0.16, fn=0.056		False
	68	0.08092		0.9434		0.9668		0.4385		0.9908	0.8624		tp=0.66, tn=0.13, fp=0.15, fn=0.063		False
	69	0.07688		0.8312		0.9626		0.4969		0.99	0.8679		tp=0.64, tn=0.16, fp=0.13, fn=0.07		False
	70	0.07153		0.9866		0.9751		0.4105		0.9933	0.8597		tp=0.66, tn=0.12, fp=0.16, fn=0.056		False
	71	0.07811		0.8814		0.9645		0.4733		0.9904	0.8571		tp=0.63, tn=0.16, fp=0.14, fn=0.07		False
	72	0.06959		1.021		0.9718		0.4541		0.9923	0.8476		tp=0.62, tn=0.15, fp=0.17, fn=0.056		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		46
learning rate		0.000276645115716
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_154-lr0.00028-h_size46-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6933		0.6947		0.07414		0.0002226		0.07955	0.359		tp=0.15, tn=0.33, fp=0.12, fn=0.41		True
	2	0.6842		0.6844		0.2147		0.1548		0.6059	0.6154		tp=0.34, tn=0.24, fp=0.2, fn=0.22		True
	3	0.677		0.6849		0.261		0.1893		0.625	0.604		tp=0.31, tn=0.28, fp=0.16, fn=0.25		True
	4	0.6698		0.6802		0.3074		0.2375		0.6218	0.6259		tp=0.32, tn=0.29, fp=0.15, fn=0.23		True
	5	0.6629		0.6746		0.3221		0.198		0.6107	0.6369		tp=0.35, tn=0.25, fp=0.17, fn=0.22		False
	6	0.6547		0.6741		0.3954		0.2363		0.6771	0.6056		tp=0.3, tn=0.31, fp=0.13, fn=0.26		False
	7	0.6467		0.674		0.3804		0.2323		0.6513	0.5778		tp=0.27, tn=0.33, fp=0.12, fn=0.28		False
	8	0.6377		0.6607		0.4082		0.2782		0.6763	0.6792		tp=0.38, tn=0.27, fp=0.19, fn=0.17		True
	9	0.6294		0.665		0.4128		0.2523		0.6904	0.6043		tp=0.29, tn=0.32, fp=0.13, fn=0.26		False
	10	0.619		0.6529		0.4693		0.3178		0.7026	0.6755		tp=0.36, tn=0.3, fp=0.14, fn=0.2		True
	11	0.61		0.6442		0.4548		0.2669		0.7057	0.6667		tp=0.36, tn=0.27, fp=0.19, fn=0.17		False
	12	0.6003		0.6482		0.4721		0.3382		0.7179	0.6525		tp=0.32, tn=0.34, fp=0.1, fn=0.24		True
	13	0.5893		0.6386		0.5015		0.2891		0.722	0.671		tp=0.36, tn=0.28, fp=0.16, fn=0.19		False
	14	0.5799		0.6358		0.5023		0.246		0.7302	0.6351		tp=0.33, tn=0.29, fp=0.17, fn=0.21		False
	15	0.5699		0.6436		0.4893		0.2322		0.7364	0.6452		tp=0.35, tn=0.27, fp=0.18, fn=0.2		False
	16	0.5597		0.6405		0.5229		0.2605		0.7417	0.6443		tp=0.34, tn=0.29, fp=0.16, fn=0.21		False
	17	0.5505		0.6279		0.5461		0.2649		0.7559	0.6709		tp=0.37, tn=0.27, fp=0.17, fn=0.19		False
	18	0.5408		0.6408		0.5586		0.2333		0.7599	0.6358		tp=0.34, tn=0.28, fp=0.16, fn=0.22		False
	19	0.5314		0.6322		0.5695		0.2669		0.7692	0.6667		tp=0.36, tn=0.27, fp=0.17, fn=0.19		False
	20	0.5233		0.6319		0.5891		0.2667		0.7879	0.6667		tp=0.36, tn=0.27, fp=0.18, fn=0.18		False
	21	0.514		0.6325		0.5848		0.2324		0.7753	0.6309		tp=0.33, tn=0.29, fp=0.17, fn=0.22		False
	22	0.5054		0.6268		0.6184		0.3013		0.7843	0.6667		tp=0.35, tn=0.3, fp=0.15, fn=0.2		False
	23	0.4985		0.6175		0.6214		0.3312		0.8031	0.68		tp=0.36, tn=0.31, fp=0.14, fn=0.2		False
	24	0.488		0.642		0.6316		0.2146		0.8019	0.6316		tp=0.34, tn=0.27, fp=0.18, fn=0.21		False
	25	0.4798		0.6349		0.6419		0.2738		0.8157	0.6579		tp=0.35, tn=0.29, fp=0.15, fn=0.21		False
	26	0.4719		0.6454		0.6456		0.3013		0.8118	0.6667		tp=0.35, tn=0.3, fp=0.15, fn=0.2		False
	27	0.4636		0.6039		0.6617		0.3447		0.8165	0.6846		tp=0.36, tn=0.31, fp=0.14, fn=0.19		True
	28	0.4562		0.6259		0.6711		0.3021		0.8203	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	29	0.4537		0.6562		0.6536		0.2505		0.8278	0.6301		tp=0.32, tn=0.3, fp=0.15, fn=0.22		False
	30	0.4496		0.6473		0.6719		0.217		0.8093	0.6626		tp=0.38, tn=0.24, fp=0.21, fn=0.17		False
	31	0.4387		0.6446		0.6847		0.2636		0.8421	0.6345		tp=0.32, tn=0.31, fp=0.15, fn=0.22		False
	32	0.4286		0.661		0.6937		0.2848		0.8346	0.6667		tp=0.36, tn=0.29, fp=0.16, fn=0.2		False
	33	0.4225		0.6383		0.7114		0.2949		0.8441	0.6795		tp=0.37, tn=0.28, fp=0.17, fn=0.17		False
	34	0.4161		0.64		0.7036		0.2632		0.8472	0.6395		tp=0.33, tn=0.3, fp=0.15, fn=0.22		False
	35	0.4092		0.6342		0.7267		0.2817		0.8513	0.671		tp=0.36, tn=0.28, fp=0.17, fn=0.18		False
	36	0.4036		0.6407		0.7221		0.2425		0.8523	0.6494		tp=0.35, tn=0.27, fp=0.17, fn=0.21		False
	37	0.3985		0.6364		0.7417		0.2566		0.8671	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	38	0.3943		0.6478		0.7311		0.2289		0.8567	0.6358		tp=0.34, tn=0.28, fp=0.18, fn=0.2		False
	39	0.3854		0.6778		0.7542		0.2		0.87	0.6323		tp=0.34, tn=0.26, fp=0.17, fn=0.22		False
	40	0.3847		0.6589		0.7303		0.3506		0.8627	0.6713		tp=0.34, tn=0.34, fp=0.13, fn=0.2		True
	41	0.3805		0.6783		0.7421		0.2146		0.8585	0.6316		tp=0.34, tn=0.27, fp=0.18, fn=0.21		False
	42	0.371		0.6485		0.7372		0.3076		0.8594	0.6918		tp=0.38, tn=0.27, fp=0.19, fn=0.15		False
	43	0.3667		0.6672		0.7686		0.2425		0.8783	0.6494		tp=0.35, tn=0.27, fp=0.17, fn=0.21		False
	44	0.3593		0.6929		0.7712		0.227		0.8811	0.6405		tp=0.34, tn=0.27, fp=0.2, fn=0.19		False
	45	0.3556		0.6871		0.7608		0.2105		0.8719	0.641		tp=0.35, tn=0.26, fp=0.19, fn=0.2		False
	46	0.3495		0.6846		0.7799		0.2307		0.8865	0.6259		tp=0.32, tn=0.29, fp=0.18, fn=0.2		False
	47	0.3443		0.6751		0.7865		0.2799		0.8872	0.6752		tp=0.37, tn=0.27, fp=0.18, fn=0.17		False
	48	0.3408		0.6931		0.7917		0.2312		0.8919	0.6207		tp=0.31, tn=0.3, fp=0.18, fn=0.2		False
	49	0.3344		0.6987		0.7833		0.2516		0.8862	0.6624		tp=0.36, tn=0.27, fp=0.18, fn=0.19		False
	50	0.3318		0.6593		0.7895		0.3092		0.8885	0.6918		tp=0.38, tn=0.27, fp=0.2, fn=0.15		False
	51	0.3276		0.7144		0.8093		0.2531		0.9023	0.6624		tp=0.36, tn=0.27, fp=0.17, fn=0.2		False
	52	0.3198		0.7086		0.7962		0.2521		0.8906	0.6624		tp=0.36, tn=0.27, fp=0.2, fn=0.17		False
	53	0.3201		0.7393		0.821		0.2105		0.9083	0.641		tp=0.35, tn=0.26, fp=0.19, fn=0.2		False
	54	0.3125		0.7189		0.8269		0.254		0.9102	0.6581		tp=0.36, tn=0.27, fp=0.17, fn=0.2		False
	55	0.3087		0.7239		0.8214		0.2531		0.9063	0.6624		tp=0.36, tn=0.27, fp=0.2, fn=0.17		False
	56	0.3051		0.7321		0.8299		0.2412		0.9116	0.6494		tp=0.35, tn=0.27, fp=0.17, fn=0.2		False
	57	0.3004		0.7137		0.8329		0.3114		0.913	0.6797		tp=0.36, tn=0.29, fp=0.17, fn=0.17		False
	58	0.2975		0.6946		0.8213		0.2677		0.9066	0.6667		tp=0.36, tn=0.27, fp=0.17, fn=0.2		False
	59	0.2975		0.7581		0.821		0.2086		0.908	0.6174		tp=0.32, tn=0.28, fp=0.16, fn=0.24		False
	60	0.2909		0.7513		0.8213		0.2405		0.9066	0.6494		tp=0.35, tn=0.27, fp=0.18, fn=0.2		False
	61	0.2847		0.721		0.8445		0.272		0.9198	0.6533		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		69
learning rate		0.000397397243421
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_155-lr0.0004-h_size69-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5799		0.5708		0.1782		0.2859		0.8183	0.8256		tp=0.65, tn=0.077, fp=0.24, fn=0.034		True
	2	0.5598		0.5593		0.2559		0.3237		0.8249	0.8292		tp=0.64, tn=0.096, fp=0.22, fn=0.043		True
	3	0.5502		0.5719		0.2854		0.2433		0.8295	0.8195		tp=0.65, tn=0.067, fp=0.25, fn=0.036		False
	4	0.5434		0.5671		0.3032		0.3193		0.8318	0.8234		tp=0.62, tn=0.11, fp=0.21, fn=0.058		False
	5	0.5352		0.5639		0.3307		0.315		0.8361	0.8231		tp=0.62, tn=0.11, fp=0.21, fn=0.061		False
	6	0.527		0.584		0.3563		0.2391		0.8397	0.81		tp=0.63, tn=0.081, fp=0.24, fn=0.053		False
	7	0.5197		0.5826		0.3671		0.2828		0.8418	0.793		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	8	0.5146		0.5781		0.3938		0.2767		0.8457	0.8091		tp=0.61, tn=0.11, fp=0.21, fn=0.077		False
	9	0.5094		0.5818		0.3882		0.2857		0.845	0.8126		tp=0.61, tn=0.11, fp=0.21, fn=0.071		False
	10	0.5074		0.5857		0.3843		0.2481		0.8418	0.8109		tp=0.62, tn=0.092, fp=0.22, fn=0.067		False
	11	0.4951		0.5996		0.42		0.2961		0.851	0.7846		tp=0.55, tn=0.16, fp=0.17, fn=0.13		False
	12	0.4968		0.5828		0.4181		0.2822		0.8486	0.8149		tp=0.62, tn=0.1, fp=0.21, fn=0.068		False
	13	0.4913		0.6083		0.4158		0.244		0.8479	0.8118		tp=0.63, tn=0.079, fp=0.24, fn=0.047		False
	14	0.4957		0.5957		0.4181		0.2582		0.8476	0.8063		tp=0.61, tn=0.1, fp=0.22, fn=0.071		False
	15	0.4895		0.5913		0.43		0.2617		0.8503	0.7968		tp=0.58, tn=0.12, fp=0.2, fn=0.098		False
	16	0.4819		0.5927		0.4476		0.2357		0.8548	0.8104		tp=0.62, tn=0.089, fp=0.22, fn=0.07		False
	17	0.4806		0.6163		0.4356		0.2868		0.8517	0.7777		tp=0.54, tn=0.16, fp=0.16, fn=0.14		False
	18	0.4772		0.6164		0.4579		0.2625		0.857	0.7837		tp=0.56, tn=0.14, fp=0.18, fn=0.12		False
	19	0.479		0.607		0.4359		0.3039		0.8509	0.7924		tp=0.56, tn=0.15, fp=0.17, fn=0.13		False
	20	0.4763		0.6086		0.4588		0.2417		0.8565	0.8093		tp=0.62, tn=0.09, fp=0.22, fn=0.067		False
	21	0.4733		0.6179		0.4635		0.2434		0.8574	0.8089		tp=0.62, tn=0.09, fp=0.23, fn=0.065		False
	22	0.4661		0.6167		0.4639		0.2458		0.8575	0.7992		tp=0.59, tn=0.11, fp=0.2, fn=0.093		False
	23	0.4672		0.6431		0.4616		0.201		0.856	0.8116		tp=0.64, tn=0.061, fp=0.26, fn=0.041		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		110
learning rate		0.000128543497519
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_156-lr0.00013-h_size110-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6902		0.6834		0.0276		0.2451		0.2264	0.5538		tp=0.25, tn=0.34, fp=0.091, fn=0.31		True
	2	0.6785		0.6766		0.2463		0.2493		0.6506	0.5397		tp=0.24, tn=0.36, fp=0.084, fn=0.32		True
	3	0.6689		0.6667		0.2586		0.2508		0.5776	0.625		tp=0.31, tn=0.31, fp=0.15, fn=0.22		True
	4	0.663		0.6566		0.2631		0.275		0.618	0.6533		tp=0.34, tn=0.29, fp=0.15, fn=0.21		True
	5	0.6553		0.6535		0.2714		0.2509		0.6386	0.6667		tp=0.37, tn=0.26, fp=0.17, fn=0.2		False
	6	0.6505		0.6576		0.2639		0.2605		0.6259	0.625		tp=0.31, tn=0.31, fp=0.13, fn=0.24		False
	7	0.6456		0.634		0.2815		0.3215		0.6555	0.6962		tp=0.38, tn=0.28, fp=0.16, fn=0.17		True
	8	0.6403		0.6474		0.3016		0.2938		0.6561	0.6531		tp=0.34, tn=0.31, fp=0.14, fn=0.22		False
	9	0.6363		0.636		0.3041		0.2877		0.6371	0.6531		tp=0.34, tn=0.31, fp=0.16, fn=0.2		False
	10	0.632		0.6217		0.3202		0.3092		0.6741	0.6918		tp=0.38, tn=0.27, fp=0.2, fn=0.15		False
	11	0.6268		0.6274		0.3173		0.3439		0.6667	0.6471		tp=0.31, tn=0.36, fp=0.11, fn=0.22		True
	12	0.625		0.6086		0.2958		0.3002		0.6396	0.7066		tp=0.41, tn=0.24, fp=0.2, fn=0.14		False
	13	0.6191		0.6241		0.3316		0.398		0.6788	0.6901		tp=0.34, tn=0.35, fp=0.1, fn=0.2		True
	14	0.6151		0.6185		0.3393		0.3386		0.6851	0.6968		tp=0.38, tn=0.29, fp=0.15, fn=0.17		False
	15	0.6102		0.6205		0.3778		0.3284		0.6798	0.6842		tp=0.36, tn=0.3, fp=0.15, fn=0.19		False
	16	0.607		0.6226		0.3561		0.285		0.6865	0.6389		tp=0.32, tn=0.31, fp=0.13, fn=0.23		False
	17	0.6011		0.6089		0.3579		0.2939		0.6848	0.6835		tp=0.38, tn=0.27, fp=0.16, fn=0.19		False
	18	0.5976		0.6072		0.3998		0.3538		0.7113	0.6713		tp=0.34, tn=0.34, fp=0.12, fn=0.21		False
	19	0.5959		0.6047		0.3934		0.3285		0.6942	0.7219		tp=0.43, tn=0.24, fp=0.2, fn=0.13		False
	20	0.5905		0.6154		0.3935		0.3485		0.7077	0.6423		tp=0.31, tn=0.35, fp=0.091, fn=0.25		False
	21	0.5882		0.5869		0.3845		0.3493		0.6893	0.7195		tp=0.41, tn=0.27, fp=0.2, fn=0.13		False
	22	0.5833		0.6059		0.4275		0.358		0.7014	0.6667		tp=0.33, tn=0.35, fp=0.12, fn=0.21		False
	23	0.5755		0.596		0.4493		0.3531		0.7366	0.7013		tp=0.38, tn=0.3, fp=0.17, fn=0.15		False
	24	0.5726		0.5815		0.4175		0.361		0.7086	0.7273		tp=0.42, tn=0.27, fp=0.19, fn=0.13		False
	25	0.5674		0.5953		0.4386		0.376		0.7262	0.6897		tp=0.35, tn=0.34, fp=0.13, fn=0.19		False
	26	0.5631		0.5897		0.452		0.3846		0.7307	0.7105		tp=0.38, tn=0.31, fp=0.13, fn=0.17		False
	27	0.5604		0.5828		0.4313		0.335		0.7122	0.7117		tp=0.41, tn=0.27, fp=0.2, fn=0.13		False
	28	0.5594		0.5918		0.4441		0.3795		0.7283	0.7179		tp=0.39, tn=0.3, fp=0.15, fn=0.15		False
	29	0.5526		0.5851		0.4762		0.3979		0.7379	0.7296		tp=0.4, tn=0.3, fp=0.17, fn=0.13		False
	30	0.5488		0.5979		0.4876		0.4029		0.7541	0.6565		tp=0.3, tn=0.38, fp=0.077, fn=0.24		True
	31	0.5431		0.5817		0.4896		0.3836		0.7395	0.7284		tp=0.41, tn=0.28, fp=0.18, fn=0.12		False
	32	0.5414		0.5933		0.4785		0.389		0.7472	0.7329		tp=0.41, tn=0.29, fp=0.15, fn=0.15		False
	33	0.5359		0.5874		0.5106		0.3761		0.7526	0.725		tp=0.41, tn=0.29, fp=0.16, fn=0.15		False
	34	0.5331		0.5892		0.5061		0.3676		0.754	0.7059		tp=0.38, tn=0.31, fp=0.16, fn=0.15		False
	35	0.5292		0.5869		0.4918		0.3633		0.7478	0.717		tp=0.4, tn=0.29, fp=0.17, fn=0.15		False
	36	0.5261		0.5983		0.5114		0.3447		0.7555	0.6846		tp=0.36, tn=0.31, fp=0.14, fn=0.19		False
	37	0.5214		0.598		0.5215		0.3349		0.763	0.6712		tp=0.34, tn=0.32, fp=0.13, fn=0.2		False
	38	0.5164		0.5761		0.5373		0.4072		0.767	0.7342		tp=0.41, tn=0.3, fp=0.16, fn=0.13		True
	39	0.512		0.6056		0.541		0.3045		0.7708	0.6575		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	40	0.5109		0.5898		0.5523		0.3606		0.7753	0.7205		tp=0.41, tn=0.28, fp=0.16, fn=0.15		False
	41	0.5066		0.6025		0.5497		0.3068		0.7749	0.6575		tp=0.34, tn=0.31, fp=0.14, fn=0.21		False
	42	0.5071		0.5729		0.5551		0.3822		0.7765	0.7105		tp=0.38, tn=0.31, fp=0.15, fn=0.15		False
	43	0.5017		0.6044		0.5545		0.3761		0.7745	0.725		tp=0.41, tn=0.29, fp=0.16, fn=0.15		False
	44	0.4961		0.5852		0.5718		0.4114		0.7821	0.7237		tp=0.38, tn=0.32, fp=0.13, fn=0.16		True
	45	0.4941		0.5731		0.5515		0.4211		0.7727	0.7389		tp=0.41, tn=0.31, fp=0.15, fn=0.14		True
	46	0.4938		0.5793		0.5685		0.3475		0.7861	0.6803		tp=0.35, tn=0.32, fp=0.13, fn=0.2		False
	47	0.4889		0.5721		0.5751		0.3884		0.7852	0.7362		tp=0.42, tn=0.28, fp=0.17, fn=0.13		False
	48	0.4848		0.6079		0.5793		0.3054		0.7901	0.6667		tp=0.35, tn=0.3, fp=0.14, fn=0.21		False
	49	0.4792		0.5844		0.5871		0.3576		0.7917	0.7337		tp=0.43, tn=0.25, fp=0.2, fn=0.12		False
	50	0.4791		0.6134		0.6059		0.3386		0.8035	0.6968		tp=0.38, tn=0.29, fp=0.15, fn=0.17		False
	51	0.4716		0.5887		0.6194		0.3349		0.8121	0.6571		tp=0.32, tn=0.34, fp=0.13, fn=0.2		False
	52	0.4687		0.5875		0.5893		0.4194		0.7904	0.7421		tp=0.41, tn=0.3, fp=0.15, fn=0.14		False
	53	0.4656		0.5717		0.6105		0.4243		0.8035	0.7355		tp=0.4, tn=0.31, fp=0.13, fn=0.16		True
	54	0.4625		0.6206		0.6039		0.2565		0.7976	0.6143		tp=0.3, tn=0.32, fp=0.14, fn=0.24		False
	55	0.4574		0.5865		0.6306		0.3867		0.8125	0.7456		tp=0.44, tn=0.26, fp=0.19, fn=0.11		False
	56	0.4606		0.6146		0.5955		0.3601		0.8023	0.6522		tp=0.31, tn=0.35, fp=0.091, fn=0.24		False
	57	0.4523		0.5692		0.6394		0.3778		0.8167	0.7215		tp=0.4, tn=0.29, fp=0.15, fn=0.15		False
	58	0.4486		0.6004		0.626		0.3251		0.8129	0.6475		tp=0.31, tn=0.34, fp=0.13, fn=0.22		False
	59	0.4501		0.6		0.6164		0.3142		0.8065	0.7143		tp=0.42, tn=0.24, fp=0.2, fn=0.13		False
	60	0.4444		0.6135		0.6161		0.2787		0.8053	0.6438		tp=0.33, tn=0.31, fp=0.15, fn=0.22		False
	61	0.4435		0.5714		0.6353		0.3468		0.818	0.7195		tp=0.41, tn=0.27, fp=0.19, fn=0.13		False
	62	0.4412		0.5876		0.6391		0.3916		0.815	0.7296		tp=0.41, tn=0.29, fp=0.14, fn=0.16		False
	63	0.4384		0.6017		0.6403		0.3598		0.8194	0.7239		tp=0.41, tn=0.27, fp=0.17, fn=0.14		False
	64	0.4316		0.6283		0.6563		0.2791		0.829	0.6074		tp=0.29, tn=0.34, fp=0.12, fn=0.25		False
	65	0.4303		0.6138		0.6403		0.3381		0.8194	0.6667		tp=0.34, tn=0.33, fp=0.13, fn=0.21		False
	66	0.4309		0.6739		0.6464		0.28		0.8228	0.5865		tp=0.27, tn=0.34, fp=0.091, fn=0.29		False
	67	0.4277		0.6001		0.6398		0.3517		0.8218	0.6846		tp=0.35, tn=0.32, fp=0.13, fn=0.19		False
	68	0.4264		0.6291		0.6575		0.3091		0.8272	0.6622		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	69	0.4211		0.6224		0.6601		0.2965		0.8279	0.6667		tp=0.35, tn=0.29, fp=0.14, fn=0.22		False
	70	0.4146		0.5969		0.6543		0.3479		0.8249	0.6759		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	71	0.4169		0.6295		0.669		0.2938		0.8326	0.6531		tp=0.34, tn=0.31, fp=0.14, fn=0.22		False
	72	0.4096		0.592		0.6776		0.3287		0.8363	0.6923		tp=0.38, tn=0.29, fp=0.17, fn=0.17		False
	73	0.4114		0.596		0.6514		0.339		0.8237	0.7186		tp=0.42, tn=0.25, fp=0.22, fn=0.11		False
	74	0.4122		0.6136		0.6607		0.3037		0.8294	0.6957		tp=0.39, tn=0.27, fp=0.17, fn=0.17		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		65
learning rate		6.65142093424e&05
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_157-lr6.7e&05-h_size65-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6958		0.6827		-0.002083		0.1295		0.5	0.7005		tp=0.48, tn=0.1, fp=0.34, fn=0.077		True
	2	0.6812		0.6809		0.2323		0.2533		0.6675	0.6301		tp=0.32, tn=0.3, fp=0.15, fn=0.23		True
	3	0.6697		0.6771		0.3306		0.1865		0.6415	0.5693		tp=0.27, tn=0.31, fp=0.15, fn=0.26		False
	4	0.6587		0.6722		0.3765		0.2291		0.6299	0.5821		tp=0.27, tn=0.34, fp=0.14, fn=0.25		False
	5	0.6476		0.6658		0.4224		0.2605		0.6878	0.6443		tp=0.34, tn=0.29, fp=0.16, fn=0.21		True
	6	0.6376		0.6647		0.4716		0.2199		0.7231	0.5957		tp=0.29, tn=0.31, fp=0.14, fn=0.26		False
	7	0.6281		0.6602		0.4459		0.25		0.7014	0.6351		tp=0.33, tn=0.29, fp=0.15, fn=0.22		False
	8	0.6178		0.6576		0.513		0.2809		0.7422	0.6486		tp=0.34, tn=0.3, fp=0.14, fn=0.22		True
	9	0.6086		0.6499		0.4658		0.3039		0.6782	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		True
	10	0.598		0.6467		0.5215		0.302		0.7355	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	11	0.5901		0.6517		0.5561		0.2861		0.7791	0.6623		tp=0.35, tn=0.29, fp=0.16, fn=0.2		False
	12	0.5791		0.6505		0.5633		0.2535		0.7676	0.6197		tp=0.31, tn=0.31, fp=0.15, fn=0.23		False
	13	0.5702		0.6434		0.5586		0.2809		0.7599	0.6486		tp=0.34, tn=0.3, fp=0.14, fn=0.22		False
	14	0.5612		0.6432		0.5746		0.3096		0.7759	0.6429		tp=0.31, tn=0.34, fp=0.13, fn=0.22		True
	15	0.5519		0.6429		0.5905		0.2722		0.7792	0.6395		tp=0.33, tn=0.3, fp=0.13, fn=0.24		False
	16	0.5432		0.6458		0.6054		0.2847		0.7867	0.6438		tp=0.33, tn=0.31, fp=0.13, fn=0.23		False
	17	0.5342		0.6315		0.6187		0.2594		0.7994	0.649		tp=0.34, tn=0.29, fp=0.16, fn=0.21		False
	18	0.5274		0.6241		0.5987		0.3187		0.7774	0.6711		tp=0.35, tn=0.31, fp=0.14, fn=0.2		True
	19	0.5173		0.6423		0.6332		0.25		0.8086	0.6351		tp=0.33, tn=0.29, fp=0.15, fn=0.22		False
	20	0.5083		0.6393		0.6511		0.23		0.8161	0.6405		tp=0.34, tn=0.27, fp=0.17, fn=0.22		False
	21	0.5005		0.6454		0.6488		0.2309		0.8125	0.6309		tp=0.33, tn=0.29, fp=0.17, fn=0.21		False
	22	0.4925		0.6273		0.6691		0.2795		0.8173	0.6579		tp=0.35, tn=0.29, fp=0.15, fn=0.21		False
	23	0.4863		0.6491		0.6777		0.2075		0.8368	0.6225		tp=0.33, tn=0.27, fp=0.16, fn=0.24		False
	24	0.4783		0.6248		0.6754		0.271		0.8199	0.6533		tp=0.34, tn=0.29, fp=0.18, fn=0.18		False
	25	0.4679		0.6364		0.6889		0.2493		0.8394	0.6259		tp=0.32, tn=0.3, fp=0.14, fn=0.24		False
	26	0.4605		0.6293		0.6896		0.2451		0.8288	0.64		tp=0.34, tn=0.29, fp=0.17, fn=0.21		False
	27	0.4534		0.6365		0.7107		0.2254		0.8546	0.6056		tp=0.3, tn=0.31, fp=0.15, fn=0.24		False
	28	0.4463		0.6332		0.7133		0.2724		0.8416	0.6623		tp=0.36, tn=0.28, fp=0.15, fn=0.21		False
	29	0.4379		0.626		0.7271		0.2451		0.8602	0.64		tp=0.34, tn=0.29, fp=0.17, fn=0.21		False
	30	0.431		0.6324		0.7313		0.2618		0.8562	0.6301		tp=0.32, tn=0.31, fp=0.14, fn=0.24		False
	31	0.4224		0.616		0.7477		0.3066		0.8689	0.6918		tp=0.38, tn=0.27, fp=0.18, fn=0.16		False
	32	0.4162		0.6313		0.7535		0.2649		0.8731	0.6131		tp=0.29, tn=0.34, fp=0.15, fn=0.22		False
	33	0.4101		0.6466		0.7774		0.207		0.8831	0.6122		tp=0.31, tn=0.29, fp=0.17, fn=0.23		False
	34	0.4014		0.6399		0.7774		0.2343		0.8831	0.6309		tp=0.33, tn=0.29, fp=0.16, fn=0.22		False
	35	0.3949		0.6348		0.7954		0.2772		0.8916	0.6533		tp=0.34, tn=0.29, fp=0.15, fn=0.22		False
	36	0.3876		0.6486		0.8122		0.2518		0.9039	0.64		tp=0.34, tn=0.29, fp=0.15, fn=0.23		False
	37	0.3813		0.6544		0.7996		0.2351		0.8917	0.6259		tp=0.32, tn=0.29, fp=0.16, fn=0.22		False
	38	0.3744		0.6403		0.8181		0.2917		0.9066	0.6483		tp=0.33, tn=0.31, fp=0.15, fn=0.21		False
	39	0.3679		0.6421		0.8307		0.2758		0.9102	0.6486		tp=0.34, tn=0.3, fp=0.15, fn=0.21		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		150
learning rate		0.00171144649652
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_158-lr0.0017-h_size150-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6846		0.6787		0.1182		0.08121		0.5887	0.5558		tp=0.29, tn=0.25, fp=0.22, fn=0.24		True
	2	0.6673		0.6846		0.1895		0.1287		0.613	0.6454		tp=0.39, tn=0.18, fp=0.28, fn=0.14		True
	3	0.6622		0.676		0.1949		0.153		0.6183	0.5871		tp=0.3, tn=0.28, fp=0.2, fn=0.22		True
	4	0.6592		0.6738		0.221		0.1326		0.6318	0.6075		tp=0.33, tn=0.24, fp=0.24, fn=0.19		False
	5	0.6527		0.7041		0.2263		0.1181		0.6224	0.6654		tp=0.44, tn=0.13, fp=0.35, fn=0.087		False
	6	0.6494		0.7213		0.2413		0.2061		0.6431	0.4777		tp=0.19, tn=0.39, fp=0.085, fn=0.34		True
	7	0.6493		0.6837		0.2362		0.109		0.6311	0.6005		tp=0.33, tn=0.22, fp=0.26, fn=0.18		False
	8	0.6481		0.6932		0.2388		0.16		0.6382	0.5242		tp=0.24, tn=0.34, fp=0.14, fn=0.29		False
	9	0.639		0.7047		0.2611		0.1174		0.6406	0.6693		tp=0.44, tn=0.12, fp=0.35, fn=0.087		False
	10	0.6408		0.6924		0.2712		0.1237		0.6547	0.5933		tp=0.32, tn=0.25, fp=0.22, fn=0.22		False
	11	0.6363		0.6795		0.2682		0.1389		0.6469	0.6125		tp=0.34, tn=0.24, fp=0.24, fn=0.19		False
	12	0.6349		0.6982		0.2718		0.08043		0.6458	0.632		tp=0.39, tn=0.16, fp=0.32, fn=0.13		False
	13	0.6339		0.7132		0.273		0.06548		0.6508	0.6426		tp=0.41, tn=0.13, fp=0.34, fn=0.12		False
	14	0.6281		0.7106		0.2919		0.1285		0.6585	0.5581		tp=0.28, tn=0.29, fp=0.19, fn=0.25		False
	15	0.6296		0.7015		0.2997		0.1366		0.665	0.5541		tp=0.27, tn=0.3, fp=0.19, fn=0.25		False
	16	0.6344		0.6863		0.2667		0.09057		0.6509	0.6102		tp=0.35, tn=0.2, fp=0.27, fn=0.18		False
	17	0.6277		0.701		0.2895		0.13		0.656	0.6585		tp=0.41, tn=0.16, fp=0.31, fn=0.12		False
	18	0.629		0.6858		0.282		0.191		0.659	0.6089		tp=0.31, tn=0.28, fp=0.2, fn=0.2		False
	19	0.6196		0.7137		0.3079		0.1302		0.6638	0.6667		tp=0.43, tn=0.14, fp=0.34, fn=0.092		False
	20	0.6162		0.7057		0.3109		0.1308		0.6686	0.5854		tp=0.31, tn=0.26, fp=0.22, fn=0.22		False
	21	0.6209		0.6886		0.2974		0.1377		0.6629	0.6297		tp=0.36, tn=0.21, fp=0.27, fn=0.16		False
	22	0.6169		0.7071		0.296		0.1059		0.6579	0.6375		tp=0.39, tn=0.16, fp=0.32, fn=0.13		False
	23	0.6194		0.7558		0.302		0.1578		0.6642	0.4055		tp=0.15, tn=0.41, fp=0.077, fn=0.37		False
	24	0.6259		0.6969		0.3043		0.181		0.6621	0.6205		tp=0.33, tn=0.26, fp=0.22, fn=0.19		False
	25	0.6138		0.7233		0.3061		0.1038		0.6648	0.6532		tp=0.42, tn=0.14, fp=0.33, fn=0.11		False
	26	0.6121		0.6936		0.3318		0.1271		0.6806	0.6115		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	27	0.6095		0.6917		0.328		0.1124		0.6752	0.5948		tp=0.32, tn=0.23, fp=0.24, fn=0.2		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		55
learning rate		0.00351643605993
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_159-lr0.0035-h_size55-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6183		0.6258		0.006041		0		0.8166	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6078		0.6254		0.04084		0.03154		0.8164	0.8043		tp=0.66, tn=0.018, fp=0.29, fn=0.03		True
	3	0.5979		0.6348		0.1177		0.009535		0.8151	0.7795		tp=0.62, tn=0.028, fp=0.3, fn=0.055		False
	4	0.5898		0.6235		0.1386		0.01823		0.8145	0.8029		tp=0.66, tn=0.01, fp=0.31, fn=0.018		False
	5	0.5765		0.6341		0.2072		0.0974		0.8204	0.8117		tp=0.68, tn=0.0044, fp=0.32, fn=0		True
	6	0.5624		0.6499		0.2059		0.08024		0.8179	0.7513		tp=0.55, tn=0.081, fp=0.24, fn=0.12		False
	7	0.5564		0.6358		0.2551		0.06906		0.8239	0.7978		tp=0.65, tn=0.027, fp=0.29, fn=0.033		False
	8	0.5407		0.6396		0.2891		0.09641		0.8289	0.7937		tp=0.63, tn=0.044, fp=0.27, fn=0.053		False
	9	0.5301		0.6308		0.3034		0.138		0.8297	0.7804		tp=0.59, tn=0.08, fp=0.24, fn=0.096		True
	10	0.5153		0.6253		0.3461		0.1439		0.8365	0.8082		tp=0.64, tn=0.052, fp=0.25, fn=0.052		True
	11	0.5018		0.6853		0.3709		0.1242		0.8392	0.7909		tp=0.62, tn=0.053, fp=0.27, fn=0.055		False
	12	0.4839		0.6579		0.3995		0.1055		0.8444	0.7679		tp=0.57, tn=0.08, fp=0.23, fn=0.11		False
	13	0.4661		0.6542		0.4433		0.1693		0.8513	0.8011		tp=0.63, tn=0.062, fp=0.26, fn=0.053		True
	14	0.4453		0.6799		0.4845		0.1737		0.8612	0.7898		tp=0.6, tn=0.083, fp=0.24, fn=0.083		True
	15	0.4221		0.6559		0.5161		0.179		0.8671	0.793		tp=0.6, tn=0.084, fp=0.23, fn=0.086		True
	16	0.4039		0.684		0.5518		0.1877		0.8758	0.7811		tp=0.58, tn=0.1, fp=0.21, fn=0.11		True
	17	0.3861		0.7014		0.5846		0.1671		0.8838	0.7863		tp=0.59, tn=0.083, fp=0.24, fn=0.084		False
	18	0.3529		0.7309		0.623		0.1987		0.8927	0.7772		tp=0.57, tn=0.11, fp=0.21, fn=0.11		True
	19	0.33		0.7811		0.6691		0.2091		0.9052	0.8127		tp=0.64, tn=0.061, fp=0.26, fn=0.039		True
	20	0.3179		0.8002		0.6861		0.1647		0.9098	0.7669		tp=0.56, tn=0.11, fp=0.21, fn=0.13		False
	21	0.2886		0.798		0.7237		0.1363		0.92	0.7469		tp=0.53, tn=0.11, fp=0.2, fn=0.15		False
	22	0.2726		0.8154		0.7467		0.1564		0.9254	0.7304		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	23	0.2532		0.844		0.7733		0.1647		0.9332	0.746		tp=0.52, tn=0.13, fp=0.2, fn=0.15		False
	24	0.24		0.8363		0.7894		0.2186		0.9377	0.7612		tp=0.53, tn=0.14, fp=0.18, fn=0.15		True
	25	0.2157		0.8995		0.8238		0.1968		0.9477	0.7161		tp=0.47, tn=0.17, fp=0.15, fn=0.22		False
	26	0.1983		0.8916		0.8469		0.1595		0.9542	0.7376		tp=0.51, tn=0.13, fp=0.18, fn=0.18		False
	27	0.1875		0.9025		0.8547		0.222		0.9563	0.7625		tp=0.53, tn=0.14, fp=0.18, fn=0.15		True
	28	0.174		0.9087		0.8786		0.1894		0.9633	0.7597		tp=0.54, tn=0.13, fp=0.19, fn=0.14		False
	29	0.1533		0.9762		0.8945		0.2007		0.9682	0.75		tp=0.52, tn=0.14, fp=0.18, fn=0.16		False
	30	0.1468		0.9694		0.9065		0.1875		0.9717	0.7481		tp=0.52, tn=0.14, fp=0.18, fn=0.17		False
	31	0.1289		1.095		0.9244		0.2264		0.9771	0.7907		tp=0.58, tn=0.11, fp=0.21, fn=0.1		True
	32	0.1278		1.096		0.9166		0.2121		0.9747	0.7718		tp=0.55, tn=0.12, fp=0.2, fn=0.12		False
	33	0.1243		1.082		0.9241		0.2162		0.9769	0.7735		tp=0.55, tn=0.12, fp=0.2, fn=0.12		False
	34	0.1137		1.093		0.9354		0.1854		0.9803	0.75		tp=0.52, tn=0.13, fp=0.18, fn=0.16		False
	35	0.114		1.152		0.9206		0.1708		0.9758	0.7106		tp=0.46, tn=0.16, fp=0.16, fn=0.22		False
	36	0.1027		1.192		0.9432		0.2114		0.9827	0.7696		tp=0.55, tn=0.13, fp=0.2, fn=0.13		False
	37	0.09723		1.155		0.9519		0.1922		0.9853	0.7489		tp=0.52, tn=0.14, fp=0.18, fn=0.16		False
	38	0.08904		1.205		0.9506		0.2251		0.9849	0.7554		tp=0.52, tn=0.15, fp=0.17, fn=0.16		False
	39	0.08128		1.184		0.9628		0.2355		0.9886	0.7538		tp=0.51, tn=0.16, fp=0.17, fn=0.17		True
	40	0.07709		1.185		0.9606		0.2729		0.9879	0.7853		tp=0.55, tn=0.14, fp=0.18, fn=0.13		True
	41	0.07523		1.217		0.9649		0.2193		0.9893	0.7653		tp=0.54, tn=0.13, fp=0.19, fn=0.14		False
	42	0.07314		1.243		0.9628		0.238		0.9886	0.7565		tp=0.51, tn=0.15, fp=0.16, fn=0.17		False
	43	0.07075		1.254		0.9637		0.2566		0.9889	0.791		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	44	0.06963		1.363		0.9637		0.2463		0.9889	0.8031		tp=0.6, tn=0.099, fp=0.22, fn=0.074		False
	45	0.0769		1.266		0.9532		0.2114		0.9857	0.7511		tp=0.51, tn=0.15, fp=0.18, fn=0.16		False
	46	0.07926		1.287		0.9546		0.2655		0.9861	0.7766		tp=0.54, tn=0.15, fp=0.17, fn=0.14		False
	47	0.06343		1.388		0.9689		0.2255		0.9905	0.7656		tp=0.53, tn=0.14, fp=0.19, fn=0.14		False
	48	0.05502		1.378		0.9719		0.2211		0.9914	0.7643		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	49	0.05145		1.353		0.9771		0.2448		0.993	0.7856		tp=0.56, tn=0.13, fp=0.18, fn=0.13		False
	50	0.05261		1.461		0.9754		0.2525		0.9924	0.7751		tp=0.54, tn=0.14, fp=0.19, fn=0.13		False
	51	0.05446		1.415		0.9706		0.1777		0.991	0.7305		tp=0.49, tn=0.15, fp=0.17, fn=0.19		False
	52	0.05213		1.542		0.9732		0.2092		0.9918	0.7788		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	53	0.05482		1.424		0.9745		0.2566		0.9922	0.7677		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	54	0.05331		1.364		0.9741		0.2073		0.992	0.744		tp=0.5, tn=0.15, fp=0.17, fn=0.17		False
	55	0.05988		1.476		0.9636		0.2278		0.9889	0.7586		tp=0.52, tn=0.15, fp=0.17, fn=0.16		False
	56	0.06137		1.484		0.9681		0.19		0.9902	0.7527		tp=0.52, tn=0.13, fp=0.18, fn=0.16		False
	57	0.04977		1.473		0.9749		0.2255		0.9923	0.7559		tp=0.52, tn=0.15, fp=0.17, fn=0.16		False
	58	0.04575		1.569		0.9806		0.2325		0.994	0.7519		tp=0.51, tn=0.16, fp=0.16, fn=0.17		False
	59	0.04618		1.641		0.9754		0.2047		0.9924	0.7476		tp=0.51, tn=0.14, fp=0.18, fn=0.17		False
	60	0.04196		1.504		0.9806		0.2205		0.994	0.7671		tp=0.54, tn=0.13, fp=0.18, fn=0.15		False
	61	0.04563		1.575		0.9749		0.2143		0.9923	0.7448		tp=0.5, tn=0.15, fp=0.17, fn=0.18		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		98
learning rate		0.000767214116463
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_15-lr0.00077-h_size98-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6184		0.6261		-0.002273		0.05826		0.8162	0.8078		tp=0.67, tn=0.0074, fp=0.31, fn=0.0059		True
	2	0.5979		0.6108		0.05593		0.09907		0.8183	0.8101		tp=0.66, tn=0.025, fp=0.29, fn=0.024		True
	3	0.5853		0.6093		0.1418		0.1331		0.8189	0.8007		tp=0.64, tn=0.049, fp=0.27, fn=0.047		True
	4	0.5743		0.6127		0.1896		0.1183		0.8193	0.7966		tp=0.63, tn=0.044, fp=0.28, fn=0.044		False
	5	0.5655		0.6129		0.2125		0.1483		0.819	0.8109		tp=0.66, tn=0.033, fp=0.29, fn=0.021		True
	6	0.5609		0.613		0.2417		0.1353		0.821	0.8148		tp=0.67, tn=0.028, fp=0.28, fn=0.019		False
	7	0.5563		0.6115		0.2582		0.1669		0.8238	0.7973		tp=0.62, tn=0.064, fp=0.26, fn=0.055		True
	8	0.5548		0.6169		0.2734		0.2055		0.8246	0.7988		tp=0.61, tn=0.08, fp=0.25, fn=0.062		True
	9	0.55		0.6197		0.275		0.1767		0.8247	0.8038		tp=0.63, tn=0.056, fp=0.27, fn=0.041		False
	10	0.5511		0.6039		0.2851		0.1788		0.8265	0.8004		tp=0.62, tn=0.071, fp=0.25, fn=0.064		False
	11	0.5494		0.6109		0.2861		0.1618		0.8266	0.8038		tp=0.64, tn=0.055, fp=0.26, fn=0.046		False
	12	0.5471		0.6271		0.2918		0.1478		0.8261	0.8124		tp=0.66, tn=0.036, fp=0.28, fn=0.025		False
	13	0.5432		0.62		0.2958		0.1891		0.8265	0.8101		tp=0.64, tn=0.058, fp=0.26, fn=0.041		False
	14	0.5451		0.6132		0.2905		0.2219		0.8263	0.8135		tp=0.64, tn=0.062, fp=0.26, fn=0.036		True
	15	0.5431		0.6163		0.2991		0.2111		0.8269	0.7892		tp=0.59, tn=0.1, fp=0.22, fn=0.095		False
	16	0.5401		0.6038		0.295		0.196		0.8268	0.7941		tp=0.6, tn=0.089, fp=0.23, fn=0.083		False
	17	0.5383		0.6156		0.3087		0.2201		0.8285	0.8102		tp=0.63, tn=0.071, fp=0.25, fn=0.047		False
	18	0.538		0.6102		0.297		0.2065		0.8267	0.8106		tp=0.64, tn=0.067, fp=0.25, fn=0.047		False
	19	0.5346		0.613		0.3184		0.2543		0.8303	0.8245		tp=0.66, tn=0.062, fp=0.25, fn=0.028		True
	20	0.5361		0.6098		0.3161		0.227		0.8291	0.8121		tp=0.63, tn=0.073, fp=0.25, fn=0.047		False
	21	0.5316		0.608		0.3166		0.1634		0.8296	0.7871		tp=0.6, tn=0.08, fp=0.24, fn=0.081		False
	22	0.5305		0.6193		0.3223		0.1874		0.8292	0.7965		tp=0.61, tn=0.076, fp=0.25, fn=0.064		False
	23	0.5285		0.6067		0.3327		0.1976		0.833	0.7897		tp=0.59, tn=0.092, fp=0.23, fn=0.083		False
	24	0.5276		0.6019		0.3321		0.2609		0.8316	0.8208		tp=0.64, tn=0.074, fp=0.24, fn=0.039		True
	25	0.5279		0.6123		0.3275		0.1832		0.8305	0.8		tp=0.62, tn=0.071, fp=0.25, fn=0.061		False
	26	0.5222		0.6013		0.3574		0.2031		0.8376	0.7937		tp=0.6, tn=0.092, fp=0.23, fn=0.083		False
	27	0.5203		0.6126		0.3463		0.2235		0.8347	0.8143		tp=0.64, tn=0.07, fp=0.25, fn=0.046		False
	28	0.5181		0.6037		0.3578		0.2097		0.8378	0.7921		tp=0.59, tn=0.098, fp=0.22, fn=0.089		False
	29	0.5168		0.6033		0.3619		0.2443		0.8363	0.8093		tp=0.62, tn=0.089, fp=0.23, fn=0.062		False
	30	0.5142		0.6119		0.3667		0.1896		0.8385	0.779		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	31	0.5109		0.6196		0.3697		0.1992		0.8392	0.7852		tp=0.58, tn=0.099, fp=0.23, fn=0.093		False
	32	0.5089		0.6199		0.3765		0.1859		0.8397	0.7782		tp=0.57, tn=0.1, fp=0.22, fn=0.11		False
	33	0.5066		0.6131		0.388		0.197		0.8422	0.7881		tp=0.59, tn=0.098, fp=0.22, fn=0.096		False
	34	0.5065		0.6174		0.3761		0.2113		0.8403	0.7945		tp=0.6, tn=0.092, fp=0.23, fn=0.077		False
	35	0.4997		0.6193		0.3887		0.2198		0.8424	0.7992		tp=0.6, tn=0.092, fp=0.23, fn=0.076		False
	36	0.4962		0.6073		0.4204		0.2664		0.8494	0.8202		tp=0.64, tn=0.081, fp=0.23, fn=0.046		True
	37	0.4899		0.6132		0.4155		0.1644		0.8487	0.7683		tp=0.56, tn=0.1, fp=0.21, fn=0.12		False
	38	0.4859		0.6123		0.4329		0.2188		0.8512	0.8016		tp=0.61, tn=0.089, fp=0.23, fn=0.072		False
	39	0.487		0.6273		0.4094		0.2123		0.8457	0.816		tp=0.65, tn=0.056, fp=0.26, fn=0.033		False
	40	0.4791		0.6164		0.445		0.2632		0.8543	0.8155		tp=0.63, tn=0.092, fp=0.22, fn=0.061		False
	41	0.4763		0.6175		0.4444		0.1999		0.8541	0.7844		tp=0.58, tn=0.1, fp=0.22, fn=0.099		False
	42	0.4733		0.634		0.4346		0.1602		0.8509	0.7466		tp=0.52, tn=0.12, fp=0.19, fn=0.16		False
	43	0.4682		0.6247		0.4592		0.1939		0.8571	0.7747		tp=0.56, tn=0.11, fp=0.22, fn=0.11		False
	44	0.4624		0.6188		0.4707		0.1853		0.8598	0.7802		tp=0.57, tn=0.1, fp=0.21, fn=0.12		False
	45	0.4573		0.6229		0.4813		0.2217		0.8614	0.8004		tp=0.61, tn=0.093, fp=0.22, fn=0.078		False
	46	0.4546		0.6202		0.4804		0.2271		0.8615	0.807		tp=0.62, tn=0.09, fp=0.22, fn=0.075		False
	47	0.4471		0.6296		0.4867		0.1827		0.863	0.7648		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	48	0.4406		0.6618		0.5027		0.2329		0.8655	0.8154		tp=0.64, tn=0.068, fp=0.25, fn=0.04		False
	49	0.4346		0.6346		0.5226		0.1961		0.8713	0.7689		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	50	0.4312		0.6322		0.5234		0.1834		0.8704	0.7773		tp=0.57, tn=0.11, fp=0.21, fn=0.12		False
	51	0.4247		0.6394		0.5376		0.2144		0.8738	0.7965		tp=0.6, tn=0.093, fp=0.23, fn=0.08		False
	52	0.4175		0.6433		0.5499		0.1587		0.8774	0.7318		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	53	0.4154		0.6502		0.5569		0.215		0.8788	0.8		tp=0.61, tn=0.09, fp=0.23, fn=0.077		False
	54	0.4066		0.6577		0.5699		0.1947		0.8816	0.7917		tp=0.6, tn=0.09, fp=0.23, fn=0.084		False
	55	0.3999		0.6432		0.5808		0.2026		0.8842	0.7758		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	56	0.3932		0.657		0.5953		0.1815		0.8883	0.7836		tp=0.58, tn=0.096, fp=0.22, fn=0.1		False
	57	0.3857		0.658		0.5993		0.1891		0.8889	0.7852		tp=0.58, tn=0.099, fp=0.21, fn=0.11		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		47
learning rate		0.002313702256
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_160-lr0.0023-h_size47-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7276		0.6807		0.01347		0.1615		0.5151	0.3232		tp=0.11, tn=0.42, fp=0.042, fn=0.43		True
	2	0.6566		0.6523		0.2156		0.2112		0.5687	0.641		tp=0.35, tn=0.26, fp=0.18, fn=0.21		True
	3	0.5986		0.6298		0.3952		0.2655		0.6486	0.6982		tp=0.41, tn=0.23, fp=0.2, fn=0.15		True
	4	0.5602		0.6405		0.4336		0.3748		0.6989	0.625		tp=0.28, tn=0.38, fp=0.07, fn=0.27		True
	5	0.4948		0.6439		0.5219		0.3139		0.7465	0.6277		tp=0.3, tn=0.34, fp=0.1, fn=0.25		False
	6	0.5084		0.6448		0.4745		0.257		0.725	0.649		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	7	0.4017		0.6395		0.6538		0.3294		0.819	0.68		tp=0.36, tn=0.31, fp=0.15, fn=0.19		False
	8	0.3518		0.6239		0.7006		0.4321		0.8455	0.7172		tp=0.36, tn=0.35, fp=0.11, fn=0.17		True
	9	0.3035		0.74		0.7596		0.321		0.8742	0.6154		tp=0.28, tn=0.37, fp=0.1, fn=0.24		False
	10	0.2934		0.8226		0.7633		0.3602		0.8807	0.625		tp=0.28, tn=0.38, fp=0.084, fn=0.25		False
	11	0.2745		0.7842		0.7774		0.3599		0.8831	0.6519		tp=0.31, tn=0.36, fp=0.1, fn=0.22		False
	12	0.1958		0.8997		0.8888		0.3455		0.9435	0.662		tp=0.33, tn=0.34, fp=0.11, fn=0.22		False
	13	0.2164		0.8159		0.8357		0.3944		0.9159	0.7226		tp=0.39, tn=0.31, fp=0.15, fn=0.15		False
	14	0.1905		0.975		0.865		0.3455		0.9303	0.662		tp=0.33, tn=0.34, fp=0.11, fn=0.22		False
	15	0.1411		0.9594		0.9266		0.3734		0.9623	0.6939		tp=0.36, tn=0.33, fp=0.13, fn=0.18		False
	16	0.1221		1.02		0.9472		0.3601		0.973	0.6892		tp=0.36, tn=0.32, fp=0.13, fn=0.19		False
	17	0.1089		1.23		0.9472		0.3187		0.9728	0.6222		tp=0.29, tn=0.35, fp=0.098, fn=0.26		False
	18	0.1059		1.134		0.9473		0.3683		0.9726	0.6933		tp=0.36, tn=0.31, fp=0.11, fn=0.21		False
	19	0.08029		1.19		0.9707		0.3728		0.9849	0.698		tp=0.36, tn=0.32, fp=0.13, fn=0.18		False
	20	0.06736		1.268		0.9736		0.3756		0.9864	0.6939		tp=0.36, tn=0.33, fp=0.13, fn=0.19		False
	21	0.06217		1.387		0.9765		0.332		0.9879	0.6757		tp=0.35, tn=0.31, fp=0.14, fn=0.2		False
	22	0.05526		1.374		0.9824		0.3398		0.991	0.7229		tp=0.42, tn=0.26, fp=0.17, fn=0.15		False
	23	0.04873		1.378		0.9912		0.4105		0.9955	0.7237		tp=0.38, tn=0.32, fp=0.14, fn=0.15		False
	24	0.04672		1.582		0.9883		0.2932		0.994	0.6338		tp=0.31, tn=0.32, fp=0.12, fn=0.24		False
	25	0.04208		1.46		0.9941		0.4115		0.997	0.72		tp=0.38, tn=0.33, fp=0.14, fn=0.15		False
	26	0.03866		1.431		0.9971		0.3554		0.9985	0.7273		tp=0.42, tn=0.27, fp=0.16, fn=0.15		False
	27	0.04413		1.587		0.9912		0.4137		0.9955	0.72		tp=0.38, tn=0.33, fp=0.13, fn=0.17		False
	28	0.0399		1.66		0.9941		0.3293		0.997	0.6573		tp=0.33, tn=0.33, fp=0.12, fn=0.22		False
	29	0.02799		1.577		0.9971		0.378		0.9985	0.7215		tp=0.4, tn=0.29, fp=0.15, fn=0.16		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		62
learning rate		0.000196622205129
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_161-lr0.0002-h_size62-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6107		0.6042		0.04674		0.1009		0.8175	0.8135		tp=0.68, tn=0.01, fp=0.31, fn=0.0044		True
	2	0.6065		0.6004		0.09469		0.1707		0.8197	0.8183		tp=0.67, tn=0.027, fp=0.29, fn=0.01		True
	3	0.6061		0.5996		0.08214		0.1345		0.8182	0.8153		tp=0.68, tn=0.019, fp=0.3, fn=0.0089		False
	4	0.6067		0.6031		0.08996		0.1354		0.8173	0.8143		tp=0.67, tn=0.022, fp=0.29, fn=0.012		False
	5	0.6059		0.6123		0.07487		0.06968		0.8182	0.8085		tp=0.67, tn=0.0059, fp=0.32, fn=0.003		False
	6	0.6059		0.6049		0.08831		0.08696		0.8185	0.8121		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	7	0.6052		0.6051		0.08502		0.1252		0.8191	0.8122		tp=0.67, tn=0.021, fp=0.3, fn=0.012		False
	8	0.6058		0.6091		0.09098		0.08851		0.8173	0.8103		tp=0.68, tn=0.0059, fp=0.32, fn=0.0015		False
	9	0.6048		0.6131		0.09843		0.06968		0.8197	0.8085		tp=0.67, tn=0.0059, fp=0.32, fn=0.003		False
	10	0.6045		0.61		0.08908		0.0861		0.8188	0.8099		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	11	0.6058		0.6062		0.09358		0.05356		0.8186	0.8148		tp=0.68, tn=0.0044, fp=0.31, fn=0.003		False
	12	0.6046		0.6102		0.0801		0.06172		0.8174	0.8075		tp=0.67, tn=0.0089, fp=0.31, fn=0.0074		False
	13	0.6042		0.608		0.09266		0.1055		0.8192	0.8152		tp=0.68, tn=0.0074, fp=0.31, fn=0.0015		False
	14	0.6041		0.6137		0.09601		0.06968		0.819	0.8085		tp=0.67, tn=0.0059, fp=0.32, fn=0.003		False
	15	0.6039		0.6044		0.1017		0.1618		0.8203	0.8162		tp=0.67, tn=0.028, fp=0.29, fn=0.013		False
	16	0.6053		0.6088		0.09669		0.1005		0.817	0.8107		tp=0.68, tn=0.0089, fp=0.31, fn=0.003		False
	17	0.604		0.6062		0.09172		0.1025		0.8197	0.8152		tp=0.68, tn=0.0089, fp=0.31, fn=0.003		False
	18	0.6038		0.6077		0.09385		0.1452		0.8187	0.8161		tp=0.67, tn=0.024, fp=0.29, fn=0.012		False
	19	0.6047		0.6139		0.1043		0.05233		0.8196	0.8113		tp=0.68, tn=0.0044, fp=0.31, fn=0.003		False
	20	0.6037		0.6043		0.08627		0.08885		0.8191	0.8135		tp=0.68, tn=0.01, fp=0.31, fn=0.0059		False
	21	0.6039		0.6088		0.09519		0.101		0.8191	0.8121		tp=0.68, tn=0.0089, fp=0.31, fn=0.003		False
	22	0.6045		0.6154		0.0952		0.08524		0.8195	0.8078		tp=0.67, tn=0.0074, fp=0.32, fn=0.003		False
	23	0.6032		0.6114		0.09713		0.1574		0.8199	0.8112		tp=0.66, tn=0.027, fp=0.3, fn=0.012		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		163
learning rate		8.113208025e&05
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_162-lr8.1e&05-h_size163-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5896		0.576		0.1514		0.3197		0.8214	0.8238		tp=0.63, tn=0.11, fp=0.21, fn=0.053		True
	2	0.5686		0.5654		0.2354		0.2799		0.824	0.8191		tp=0.63, tn=0.086, fp=0.24, fn=0.044		False
	3	0.5628		0.5669		0.2453		0.3023		0.8248	0.8199		tp=0.62, tn=0.1, fp=0.22, fn=0.056		False
	4	0.5576		0.5679		0.2733		0.2333		0.8287	0.8219		tp=0.66, tn=0.059, fp=0.25, fn=0.031		False
	5	0.5549		0.5689		0.2793		0.2837		0.8298	0.8211		tp=0.64, tn=0.087, fp=0.23, fn=0.046		False
	6	0.5496		0.5658		0.2831		0.2588		0.8299	0.82		tp=0.64, tn=0.073, fp=0.25, fn=0.037		False
	7	0.5474		0.5688		0.2902		0.2525		0.8312	0.8182		tp=0.64, tn=0.076, fp=0.24, fn=0.043		False
	8	0.543		0.568		0.3128		0.2507		0.8345	0.8224		tp=0.65, tn=0.067, fp=0.25, fn=0.034		False
	9	0.5409		0.5711		0.3299		0.2627		0.8378	0.8196		tp=0.64, tn=0.074, fp=0.25, fn=0.037		False
	10	0.5364		0.5666		0.3136		0.3155		0.835	0.8227		tp=0.62, tn=0.11, fp=0.2, fn=0.065		False
	11	0.5333		0.5732		0.328		0.2883		0.8359	0.816		tp=0.62, tn=0.1, fp=0.22, fn=0.059		False
	12	0.5312		0.5694		0.3331		0.2972		0.8364	0.8164		tp=0.62, tn=0.1, fp=0.22, fn=0.061		False
	13	0.5254		0.5789		0.3493		0.2626		0.84	0.8164		tp=0.63, tn=0.08, fp=0.24, fn=0.043		False
	14	0.5229		0.5712		0.36		0.3058		0.8423	0.8203		tp=0.62, tn=0.11, fp=0.21, fn=0.059		False
	15	0.5204		0.5774		0.3555		0.2693		0.8403	0.8184		tp=0.63, tn=0.084, fp=0.23, fn=0.047		False
	16	0.5183		0.5723		0.3669		0.2807		0.8427	0.8141		tp=0.62, tn=0.1, fp=0.21, fn=0.068		False
	17	0.5144		0.573		0.3748		0.302		0.8438	0.8196		tp=0.62, tn=0.11, fp=0.21, fn=0.067		False
	18	0.5127		0.5758		0.3751		0.2807		0.8442	0.8167		tp=0.62, tn=0.096, fp=0.22, fn=0.058		False
	19	0.5096		0.5859		0.3881		0.2604		0.8459	0.8196		tp=0.64, tn=0.075, fp=0.24, fn=0.04		False
	20	0.5076		0.5667		0.3931		0.3019		0.8469	0.8225		tp=0.63, tn=0.1, fp=0.21, fn=0.059		False
	21	0.5047		0.5806		0.4033		0.278		0.8486	0.8087		tp=0.6, tn=0.11, fp=0.21, fn=0.076		False
	22	0.5039		0.5829		0.4011		0.2852		0.8474	0.808		tp=0.6, tn=0.11, fp=0.21, fn=0.074		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		25
learning rate		0.000112966063104
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_163-lr0.00011-h_size25-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6921		0.6862		0.0251		0.05365		0.5744	0.6924		tp=0.53, tn=0.0026, fp=0.47, fn=0		True
	2	0.682		0.6802		0.1655		0.1444		0.6281	0.6227		tp=0.35, tn=0.22, fp=0.26, fn=0.17		True
	3	0.6733		0.6792		0.1966		0.05647		0.6166	0.6554		tp=0.45, tn=0.087, fp=0.4, fn=0.072		False
	4	0.6626		0.6748		0.2612		0.08883		0.6457	0.6603		tp=0.44, tn=0.1, fp=0.38, fn=0.072		False
	5	0.6499		0.6708		0.2958		0.2532		0.6714	0.581		tp=0.27, tn=0.35, fp=0.12, fn=0.26		True
	6	0.6384		0.6616		0.3376		0.1806		0.6723	0.6491		tp=0.38, tn=0.21, fp=0.28, fn=0.13		False
	7	0.6239		0.6627		0.3759		0.2206		0.6967	0.6219		tp=0.32, tn=0.29, fp=0.18, fn=0.21		False
	8	0.6129		0.6543		0.4144		0.1984		0.7105	0.6709		tp=0.41, tn=0.2, fp=0.27, fn=0.12		False
	9	0.5985		0.6664		0.4185		0.1794		0.7138	0.5356		tp=0.24, tn=0.34, fp=0.14, fn=0.28		False
	10	0.5867		0.6623		0.4393		0.1988		0.7266	0.6158		tp=0.32, tn=0.28, fp=0.19, fn=0.21		False
	11	0.5741		0.6565		0.4464		0.2134		0.7251	0.5932		tp=0.29, tn=0.31, fp=0.16, fn=0.24		False
	12	0.5603		0.6679		0.49		0.172		0.7486	0.563		tp=0.27, tn=0.31, fp=0.16, fn=0.25		False
	13	0.5503		0.6716		0.4933		0.1917		0.7469	0.6828		tp=0.43, tn=0.16, fp=0.31, fn=0.095		False
	14	0.5399		0.668		0.4995		0.1974		0.7564	0.6355		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	15	0.5274		0.667		0.5421		0.2014		0.7728	0.6301		tp=0.34, tn=0.26, fp=0.21, fn=0.19		False
	16	0.5181		0.6683		0.5355		0.2294		0.7716	0.5914		tp=0.28, tn=0.33, fp=0.15, fn=0.24		False
	17	0.509		0.6749		0.5397		0.197		0.7722	0.6232		tp=0.33, tn=0.27, fp=0.2, fn=0.2		False
	18	0.4976		0.6657		0.5721		0.2188		0.7895	0.6031		tp=0.3, tn=0.31, fp=0.17, fn=0.23		False
	19	0.4888		0.6778		0.5822		0.1971		0.7941	0.5928		tp=0.29, tn=0.3, fp=0.17, fn=0.24		False
	20	0.4808		0.6896		0.5839		0.2153		0.7956	0.6331		tp=0.34, tn=0.27, fp=0.21, fn=0.18		False
	21	0.4716		0.6884		0.59		0.2152		0.7967	0.6185		tp=0.32, tn=0.29, fp=0.19, fn=0.21		False
	22	0.4627		0.7124		0.6082		0.195		0.8071	0.5737		tp=0.27, tn=0.32, fp=0.15, fn=0.25		False
	23	0.4538		0.6952		0.63		0.2195		0.8181	0.5942		tp=0.29, tn=0.32, fp=0.16, fn=0.23		False
	24	0.4484		0.7004		0.6184		0.2212		0.8103	0.6142		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	25	0.4391		0.6927		0.6277		0.2554		0.8164	0.6473		tp=0.34, tn=0.29, fp=0.2, fn=0.18		True
	26	0.431		0.7051		0.6478		0.2275		0.8274	0.6138		tp=0.31, tn=0.31, fp=0.17, fn=0.21		False
	27	0.4246		0.7067		0.6521		0.2614		0.828	0.64		tp=0.33, tn=0.3, fp=0.18, fn=0.19		True
	28	0.4182		0.7382		0.6598		0.2217		0.8309	0.6667		tp=0.38, tn=0.23, fp=0.24, fn=0.15		False
	29	0.4107		0.7224		0.662		0.2113		0.8335	0.5995		tp=0.3, tn=0.31, fp=0.18, fn=0.22		False
	30	0.4069		0.7438		0.6791		0.2052		0.8433	0.5745		tp=0.27, tn=0.33, fp=0.15, fn=0.25		False
	31	0.4011		0.7448		0.6793		0.23		0.8437	0.6527		tp=0.36, tn=0.26, fp=0.21, fn=0.17		False
	32	0.3913		0.7548		0.6826		0.233		0.8438	0.6037		tp=0.29, tn=0.32, fp=0.15, fn=0.23		False
	33	0.3859		0.7535		0.694		0.1794		0.8486	0.6241		tp=0.34, tn=0.25, fp=0.22, fn=0.19		False
	34	0.3795		0.7795		0.7123		0.216		0.8588	0.5658		tp=0.26, tn=0.35, fp=0.14, fn=0.25		False
	35	0.3755		0.769		0.7075		0.2031		0.8556	0.5879		tp=0.29, tn=0.31, fp=0.16, fn=0.24		False
	36	0.3658		0.7457		0.7169		0.235		0.8614	0.6321		tp=0.33, tn=0.29, fp=0.18, fn=0.2		False
	37	0.3617		0.7648		0.7175		0.2181		0.8614	0.6259		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	38	0.3556		0.7968		0.7288		0.1882		0.866	0.6256		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	39	0.3531		0.7772		0.7435		0.2218		0.8739	0.6181		tp=0.32, tn=0.29, fp=0.18, fn=0.21		False
	40	0.345		0.7899		0.7441		0.2234		0.8743	0.6181		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	41	0.3433		0.8007		0.7418		0.2158		0.8723	0.586		tp=0.28, tn=0.33, fp=0.16, fn=0.24		False
	42	0.3428		0.8071		0.7406		0.1927		0.8719	0.618		tp=0.33, tn=0.27, fp=0.19, fn=0.21		False
	43	0.3305		0.8038		0.763		0.2143		0.8831	0.6222		tp=0.32, tn=0.28, fp=0.2, fn=0.19		False
	44	0.3248		0.8318		0.7702		0.2154		0.8868	0.6432		tp=0.35, tn=0.26, fp=0.21, fn=0.18		False
	45	0.3265		0.8273		0.7614		0.2386		0.8839	0.6247		tp=0.32, tn=0.3, fp=0.17, fn=0.22		False
	46	0.3166		0.8364		0.7701		0.2163		0.887	0.6087		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	47	0.315		0.8385		0.7743		0.2263		0.8892	0.6		tp=0.29, tn=0.32, fp=0.16, fn=0.23		False
	48	0.3112		0.8727		0.7808		0.1801		0.8927	0.6098		tp=0.32, tn=0.27, fp=0.19, fn=0.21		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		20
learning rate		0.000650934410193
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_164-lr0.00065-h_size20-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6111		0.614		0.02322		0.01219		0.8183	0.8043		tp=0.67, tn=0.0044, fp=0.32, fn=0.0074		True
	2	0.6012		0.6071		0.07153		0.04387		0.8177	0.8124		tp=0.68, tn=0.0059, fp=0.31, fn=0.0059		True
	3	0.5963		0.6079		0.08707		0.1127		0.8171	0.8125		tp=0.67, tn=0.015, fp=0.3, fn=0.0074		True
	4	0.5923		0.6028		0.1238		0.1369		0.8194	0.8147		tp=0.67, tn=0.024, fp=0.29, fn=0.013		True
	5	0.5895		0.6047		0.1355		0.1599		0.818	0.8137		tp=0.67, tn=0.028, fp=0.29, fn=0.013		True
	6	0.5856		0.6116		0.1369		0.1339		0.819	0.8133		tp=0.67, tn=0.021, fp=0.3, fn=0.01		False
	7	0.5838		0.6039		0.1519		0.1844		0.818	0.7989		tp=0.62, tn=0.069, fp=0.26, fn=0.056		True
	8	0.5814		0.6069		0.1642		0.1636		0.8198	0.7899		tp=0.6, tn=0.075, fp=0.25, fn=0.074		False
	9	0.5802		0.6045		0.1664		0.146		0.8175	0.8045		tp=0.64, tn=0.05, fp=0.26, fn=0.046		False
	10	0.5793		0.6009		0.1762		0.1692		0.8179	0.8103		tp=0.65, tn=0.039, fp=0.28, fn=0.022		False
	11	0.575		0.5955		0.1946		0.1487		0.8203	0.8048		tp=0.64, tn=0.047, fp=0.27, fn=0.04		False
	12	0.5731		0.5992		0.1839		0.1696		0.8193	0.8114		tp=0.65, tn=0.043, fp=0.28, fn=0.028		False
	13	0.5715		0.6003		0.1938		0.1599		0.8189	0.8		tp=0.63, tn=0.062, fp=0.25, fn=0.058		False
	14	0.5718		0.6008		0.1828		0.1552		0.8167	0.7977		tp=0.62, tn=0.059, fp=0.26, fn=0.053		False
	15	0.5686		0.6009		0.2047		0.1696		0.821	0.8114		tp=0.65, tn=0.043, fp=0.28, fn=0.028		False
	16	0.5674		0.5967		0.2119		0.1788		0.8204	0.8104		tp=0.65, tn=0.052, fp=0.27, fn=0.037		False
	17	0.5659		0.6134		0.2164		0.2095		0.8208	0.7859		tp=0.58, tn=0.11, fp=0.22, fn=0.099		True
	18	0.5661		0.5984		0.1951		0.1563		0.817	0.7992		tp=0.62, tn=0.062, fp=0.25, fn=0.059		False
	19	0.5637		0.6072		0.2232		0.1585		0.8218	0.7896		tp=0.61, tn=0.071, fp=0.25, fn=0.068		False
	20	0.5638		0.6054		0.225		0.1686		0.8224	0.8121		tp=0.66, tn=0.041, fp=0.28, fn=0.027		False
	21	0.5633		0.6072		0.2148		0.1687		0.8197	0.7886		tp=0.6, tn=0.083, fp=0.23, fn=0.086		False
	22	0.5629		0.6037		0.2273		0.1633		0.8202	0.8023		tp=0.63, tn=0.059, fp=0.26, fn=0.052		False
	23	0.5615		0.6075		0.2332		0.1866		0.8232	0.8034		tp=0.63, tn=0.062, fp=0.26, fn=0.046		False
	24	0.56		0.5985		0.2287		0.1907		0.8207	0.8068		tp=0.63, tn=0.067, fp=0.25, fn=0.053		False
	25	0.5584		0.6114		0.2283		0.1998		0.8209	0.7746		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	26	0.5578		0.6126		0.2335		0.152		0.8199	0.8048		tp=0.64, tn=0.044, fp=0.28, fn=0.034		False
	27	0.5585		0.615		0.2338		0.1461		0.8218	0.8048		tp=0.64, tn=0.043, fp=0.28, fn=0.034		False
	28	0.5582		0.6039		0.2281		0.1588		0.821	0.7954		tp=0.62, tn=0.067, fp=0.25, fn=0.064		False
	29	0.5569		0.6169		0.2466		0.1324		0.823	0.8106		tp=0.66, tn=0.033, fp=0.28, fn=0.025		False
	30	0.5586		0.6068		0.2475		0.1675		0.8235	0.783		tp=0.59, tn=0.086, fp=0.24, fn=0.087		False
	31	0.5571		0.6189		0.2413		0.1379		0.8206	0.8066		tp=0.65, tn=0.036, fp=0.29, fn=0.027		False
	32	0.5546		0.6057		0.2617		0.144		0.826	0.79		tp=0.61, tn=0.07, fp=0.25, fn=0.076		False
	33	0.5549		0.6148		0.2554		0.1453		0.824	0.8059		tp=0.64, tn=0.044, fp=0.27, fn=0.037		False
	34	0.555		0.5993		0.2479		0.1775		0.8225	0.8093		tp=0.64, tn=0.052, fp=0.27, fn=0.037		False
	35	0.5532		0.6034		0.2531		0.162		0.8239	0.7891		tp=0.6, tn=0.081, fp=0.23, fn=0.089		False
	36	0.5522		0.6073		0.2572		0.145		0.8238	0.8121		tp=0.66, tn=0.04, fp=0.27, fn=0.033		False
	37	0.5505		0.6122		0.2561		0.1278		0.8244	0.7789		tp=0.59, tn=0.076, fp=0.24, fn=0.092		False
	38	0.5517		0.6052		0.2555		0.162		0.8229	0.8015		tp=0.63, tn=0.061, fp=0.26, fn=0.055		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		95
learning rate		0.000433899635493
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_165-lr0.00043-h_size95-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6849		0.6756		0.1071		0.1054		0.5784	0.5797		tp=0.31, tn=0.25, fp=0.24, fn=0.21		True
	2	0.6735		0.6713		0.1671		0.1021		0.612	0.5417		tp=0.27, tn=0.28, fp=0.19, fn=0.26		False
	3	0.6692		0.6764		0.1729		0.1064		0.6054	0.5478		tp=0.27, tn=0.28, fp=0.19, fn=0.25		True
	4	0.6645		0.6703		0.1907		0.1218		0.6147	0.6028		tp=0.33, tn=0.23, fp=0.24, fn=0.2		True
	5	0.6604		0.6693		0.2108		0.1349		0.6238	0.6281		tp=0.36, tn=0.21, fp=0.26, fn=0.17		True
	6	0.655		0.6777		0.2206		0.1738		0.6308	0.6775		tp=0.43, tn=0.16, fp=0.3, fn=0.11		True
	7	0.6535		0.6814		0.2295		0.1178		0.638	0.5246		tp=0.24, tn=0.31, fp=0.18, fn=0.27		False
	8	0.6495		0.6791		0.2168		0.13		0.6283	0.625		tp=0.36, tn=0.21, fp=0.26, fn=0.17		False
	9	0.6489		0.681		0.2473		0.09005		0.6451	0.6022		tp=0.34, tn=0.21, fp=0.27, fn=0.18		False
	10	0.645		0.6817		0.2624		0.1395		0.6496	0.57		tp=0.29, tn=0.28, fp=0.19, fn=0.25		False
	11	0.6402		0.6825		0.2678		0.119		0.6503	0.6051		tp=0.34, tn=0.23, fp=0.25, fn=0.19		False
	12	0.6371		0.6917		0.2736		0.1		0.6519	0.5742		tp=0.3, tn=0.25, fp=0.22, fn=0.23		False
	13	0.639		0.6834		0.2687		0.1371		0.6553	0.6089		tp=0.33, tn=0.24, fp=0.23, fn=0.2		False
	14	0.635		0.6856		0.2826		0.1498		0.658	0.6356		tp=0.37, tn=0.21, fp=0.26, fn=0.16		False
	15	0.6329		0.6896		0.286		0.1309		0.6582	0.6281		tp=0.36, tn=0.21, fp=0.25, fn=0.17		False
	16	0.6298		0.6903		0.286		0.1235		0.658	0.5819		tp=0.3, tn=0.26, fp=0.22, fn=0.21		False
	17	0.6305		0.7005		0.2814		0.1198		0.6626	0.5721		tp=0.29, tn=0.27, fp=0.21, fn=0.23		False
	18	0.6301		0.6936		0.2777		0.1366		0.6532	0.5882		tp=0.31, tn=0.26, fp=0.22, fn=0.22		False
	19	0.6266		0.6896		0.282		0.1663		0.6567	0.5788		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	20	0.6266		0.71		0.2797		0.07439		0.6492	0.6018		tp=0.35, tn=0.19, fp=0.29, fn=0.17		False
	21	0.6244		0.716		0.298		0.09212		0.6655	0.6285		tp=0.38, tn=0.17, fp=0.31, fn=0.14		False
	22	0.6239		0.699		0.2938		0.1216		0.662	0.6272		tp=0.37, tn=0.2, fp=0.28, fn=0.15		False
	23	0.6226		0.714		0.3097		0.1027		0.6695	0.6342		tp=0.38, tn=0.17, fp=0.3, fn=0.14		False
	24	0.6204		0.6957		0.3128		0.1064		0.6708	0.6063		tp=0.34, tn=0.21, fp=0.27, fn=0.17		False
	25	0.6202		0.7043		0.2914		0.116		0.6585	0.6307		tp=0.37, tn=0.19, fp=0.29, fn=0.15		False
	26	0.618		0.7059		0.3045		0.1075		0.6667	0.5986		tp=0.33, tn=0.23, fp=0.25, fn=0.19		False
	27	0.6195		0.7169		0.2998		0.0804		0.6648	0.6161		tp=0.36, tn=0.18, fp=0.29, fn=0.16		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		200
learning rate		0.000549073873026
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_166-lr0.00055-h_size200-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6914		0.6733		0.03873		0.1664		0.5389	0.7002		tp=0.48, tn=0.11, fp=0.35, fn=0.059		True
	2	0.6696		0.676		0.1898		0.165		0.6191	0.5995		tp=0.31, tn=0.27, fp=0.2, fn=0.21		False
	3	0.651		0.6754		0.2543		0.1905		0.6463	0.603		tp=0.31, tn=0.29, fp=0.19, fn=0.22		True
	4	0.6363		0.681		0.2725		0.1364		0.6416	0.6653		tp=0.42, tn=0.16, fp=0.31, fn=0.12		False
	5	0.6246		0.6782		0.3216		0.1587		0.6761	0.5879		tp=0.3, tn=0.28, fp=0.21, fn=0.22		False
	6	0.6151		0.674		0.3422		0.1858		0.6808	0.5975		tp=0.3, tn=0.29, fp=0.19, fn=0.22		False
	7	0.6062		0.6878		0.3564		0.1368		0.6841	0.5981		tp=0.32, tn=0.25, fp=0.22, fn=0.21		False
	8	0.6016		0.7127		0.3712		0.2115		0.695	0.6723		tp=0.41, tn=0.2, fp=0.28, fn=0.11		True
	9	0.6006		0.7011		0.3713		0.1589		0.6988	0.5966		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	10	0.5961		0.7147		0.3625		0.1637		0.687	0.6368		tp=0.36, tn=0.22, fp=0.25, fn=0.16		False
	11	0.5955		0.744		0.3933		0.07699		0.7087	0.4537		tp=0.19, tn=0.34, fp=0.15, fn=0.32		False
	12	0.591		0.719		0.3794		0.1038		0.6983	0.5817		tp=0.31, tn=0.24, fp=0.23, fn=0.22		False
	13	0.5924		0.7515		0.3806		0.1453		0.6983	0.5043		tp=0.22, tn=0.34, fp=0.14, fn=0.3		False
	14	0.589		0.719		0.392		0.1855		0.7027	0.6376		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	15	0.5897		0.743		0.3795		0.1371		0.7003	0.5128		tp=0.23, tn=0.33, fp=0.15, fn=0.29		False
	16	0.5859		0.7239		0.3829		0.1761		0.6997	0.5559		tp=0.26, tn=0.32, fp=0.16, fn=0.26		False
	17	0.5853		0.7151		0.3918		0.1518		0.7042	0.5985		tp=0.32, tn=0.26, fp=0.22, fn=0.2		False
	18	0.586		0.7351		0.3871		0.1496		0.7026	0.5459		tp=0.26, tn=0.31, fp=0.16, fn=0.27		False
	19	0.5823		0.7355		0.3874		0.1572		0.6946	0.6653		tp=0.41, tn=0.17, fp=0.29, fn=0.12		False
	20	0.5805		0.7351		0.3942		0.1621		0.7045	0.6402		tp=0.37, tn=0.21, fp=0.27, fn=0.15		False
	21	0.5822		0.7414		0.3889		0.1592		0.7032	0.627		tp=0.35, tn=0.23, fp=0.25, fn=0.17		False
	22	0.5773		0.7303		0.4109		0.1417		0.7113	0.6014		tp=0.32, tn=0.25, fp=0.22, fn=0.2		False
	23	0.5776		0.7221		0.4103		0.1479		0.7147	0.599		tp=0.32, tn=0.26, fp=0.21, fn=0.21		False
	24	0.5786		0.7208		0.4043		0.1982		0.7131	0.6025		tp=0.3, tn=0.29, fp=0.18, fn=0.22		False
	25	0.5806		0.7391		0.393		0.1292		0.7039	0.5947		tp=0.32, tn=0.25, fp=0.22, fn=0.22		False
	26	0.579		0.7553		0.4031		0.1396		0.7103	0.6377		tp=0.38, tn=0.19, fp=0.29, fn=0.14		False
	27	0.5757		0.7477		0.3985		0.1733		0.706	0.5759		tp=0.28, tn=0.3, fp=0.18, fn=0.24		False
	28	0.5809		0.7407		0.4016		0.1649		0.7126	0.6233		tp=0.34, tn=0.24, fp=0.24, fn=0.18		False
	29	0.5788		0.749		0.4013		0.1153		0.708	0.562		tp=0.28, tn=0.27, fp=0.2, fn=0.25		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		145
learning rate		0.000663778423479
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_167-lr0.00066-h_size145-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6147		0.6119		0.0003436		0.1896		0.8149	0.8209		tp=0.68, tn=0.016, fp=0.3, fn=0		True
	2	0.589		0.6194		0.1305		0.188		0.8192	0.803		tp=0.63, tn=0.068, fp=0.25, fn=0.055		False
	3	0.5735		0.6056		0.2115		0.1986		0.8217	0.8119		tp=0.65, tn=0.055, fp=0.27, fn=0.034		True
	4	0.5564		0.6552		0.2614		0.175		0.8249	0.6818		tp=0.42, tn=0.18, fp=0.14, fn=0.25		False
	5	0.5416		0.6165		0.3057		0.1816		0.8293	0.8097		tp=0.64, tn=0.055, fp=0.26, fn=0.04		False
	6	0.541		0.6137		0.3132		0.1612		0.8291	0.8023		tp=0.63, tn=0.058, fp=0.26, fn=0.05		False
	7	0.5316		0.6412		0.3318		0.1592		0.8326	0.7371		tp=0.51, tn=0.13, fp=0.19, fn=0.17		False
	8	0.529		0.6206		0.3336		0.2107		0.8315	0.8102		tp=0.63, tn=0.068, fp=0.25, fn=0.047		True
	9	0.5235		0.6238		0.3517		0.2108		0.8337	0.8057		tp=0.62, tn=0.075, fp=0.24, fn=0.056		True
	10	0.5219		0.6417		0.3595		0.1819		0.8344	0.8045		tp=0.63, tn=0.062, fp=0.26, fn=0.049		False
	11	0.5119		0.6325		0.3813		0.2144		0.8387	0.8156		tp=0.65, tn=0.059, fp=0.26, fn=0.036		True
	12	0.5055		0.6349		0.3903		0.1777		0.8409	0.7813		tp=0.58, tn=0.092, fp=0.24, fn=0.09		False
	13	0.5047		0.6424		0.3828		0.1939		0.8381	0.7969		tp=0.61, tn=0.08, fp=0.24, fn=0.068		False
	14	0.5026		0.6327		0.3968		0.2034		0.8417	0.7961		tp=0.6, tn=0.087, fp=0.23, fn=0.075		False
	15	0.4985		0.6316		0.4064		0.2107		0.843	0.7796		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	16	0.4987		0.6365		0.4109		0.2091		0.8452	0.8065		tp=0.62, tn=0.078, fp=0.24, fn=0.064		False
	17	0.4893		0.6397		0.4134		0.1797		0.8447	0.7667		tp=0.55, tn=0.11, fp=0.21, fn=0.12		False
	18	0.4915		0.6622		0.4177		0.1653		0.8447	0.7354		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	19	0.4944		0.6743		0.4021		0.1581		0.8403	0.8063		tp=0.64, tn=0.05, fp=0.27, fn=0.041		False
	20	0.4803		0.6522		0.4296		0.1806		0.8481	0.806		tp=0.63, tn=0.062, fp=0.25, fn=0.05		False
	21	0.4713		0.6466		0.4619		0.1571		0.8556	0.7666		tp=0.56, tn=0.1, fp=0.21, fn=0.13		False
	22	0.4796		0.6451		0.4497		0.2006		0.8517	0.7872		tp=0.58, tn=0.1, fp=0.22, fn=0.099		False
	23	0.4662		0.6739		0.4581		0.1793		0.8542	0.7416		tp=0.51, tn=0.14, fp=0.18, fn=0.17		False
	24	0.47		0.6723		0.4563		0.1565		0.8542	0.7338		tp=0.5, tn=0.13, fp=0.19, fn=0.18		False
	25	0.462		0.6592		0.4664		0.2029		0.8557	0.7598		tp=0.53, tn=0.13, fp=0.19, fn=0.14		False
	26	0.4519		0.663		0.4894		0.2118		0.8609	0.7614		tp=0.53, tn=0.13, fp=0.19, fn=0.14		False
	27	0.4489		0.6922		0.4978		0.201		0.8631	0.8075		tp=0.63, tn=0.065, fp=0.26, fn=0.046		False
	28	0.4471		0.6752		0.4853		0.1866		0.8597	0.7977		tp=0.61, tn=0.076, fp=0.25, fn=0.065		False
	29	0.4407		0.6793		0.5007		0.2024		0.8636	0.7211		tp=0.47, tn=0.16, fp=0.15, fn=0.22		False
	30	0.433		0.6708		0.5241		0.2185		0.8706	0.7635		tp=0.53, tn=0.14, fp=0.19, fn=0.14		True
	31	0.4291		0.6885		0.5088		0.1924		0.8659	0.7407		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	32	0.4257		0.6669		0.516		0.2098		0.8671	0.783		tp=0.57, tn=0.11, fp=0.2, fn=0.12		False
	33	0.4076		0.6976		0.5423		0.208		0.8733	0.7949		tp=0.6, tn=0.09, fp=0.23, fn=0.077		False
	34	0.4122		0.6736		0.5393		0.21		0.8724	0.7992		tp=0.61, tn=0.089, fp=0.23, fn=0.077		False
	35	0.3953		0.7012		0.5723		0.2155		0.8809	0.7699		tp=0.55, tn=0.13, fp=0.19, fn=0.14		False
	36	0.3864		0.711		0.5872		0.1926		0.8838	0.7917		tp=0.6, tn=0.089, fp=0.23, fn=0.083		False
	37	0.3796		0.7052		0.5876		0.1996		0.8847	0.7729		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	38	0.3675		0.7218		0.6217		0.2023		0.893	0.7495		tp=0.51, tn=0.14, fp=0.17, fn=0.17		False
	39	0.3625		0.7087		0.6189		0.2097		0.8919	0.7884		tp=0.58, tn=0.1, fp=0.22, fn=0.095		False
	40	0.3564		0.7414		0.6348		0.2081		0.8963	0.7619		tp=0.53, tn=0.13, fp=0.18, fn=0.15		False
	41	0.3445		0.7458		0.6463		0.2036		0.8992	0.7715		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	42	0.3309		0.7685		0.6736		0.2185		0.9064	0.747		tp=0.51, tn=0.15, fp=0.17, fn=0.18		True
	43	0.3231		0.7713		0.6756		0.1943		0.9073	0.7917		tp=0.6, tn=0.089, fp=0.23, fn=0.081		False
	44	0.3117		0.756		0.7027		0.213		0.9144	0.7696		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	45	0.3015		0.7677		0.7224		0.2484		0.9193	0.8071		tp=0.61, tn=0.098, fp=0.22, fn=0.074		True
	46	0.2969		0.7482		0.724		0.2529		0.9198	0.7935		tp=0.58, tn=0.12, fp=0.19, fn=0.11		True
	47	0.2829		0.8015		0.7418		0.2214		0.9246	0.7841		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	48	0.2754		0.8117		0.7476		0.226		0.9264	0.7715		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	49	0.2664		0.7839		0.7667		0.2266		0.9315	0.7448		tp=0.5, tn=0.16, fp=0.16, fn=0.18		False
	50	0.2532		0.8278		0.7796		0.2293		0.9349	0.7728		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	51	0.2484		0.8602		0.7868		0.226		0.937	0.8066		tp=0.62, tn=0.086, fp=0.23, fn=0.067		False
	52	0.237		0.848		0.8041		0.201		0.942	0.7437		tp=0.51, tn=0.15, fp=0.17, fn=0.17		False
	53	0.2271		0.8573		0.8206		0.2523		0.9464	0.798		tp=0.59, tn=0.11, fp=0.21, fn=0.087		False
	54	0.2176		0.8492		0.8338		0.2122		0.9503	0.7609		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	55	0.2102		0.8634		0.8391		0.2416		0.9518	0.777		tp=0.55, tn=0.13, fp=0.18, fn=0.13		False
	56	0.1978		0.8619		0.8638		0.257		0.9591	0.8048		tp=0.6, tn=0.11, fp=0.21, fn=0.083		True
	57	0.1971		0.8939		0.8549		0.2104		0.9565	0.7389		tp=0.49, tn=0.16, fp=0.16, fn=0.19		False
	58	0.1837		0.9309		0.873		0.2252		0.9619	0.7643		tp=0.53, tn=0.14, fp=0.18, fn=0.14		False
	59	0.1719		0.9675		0.8935		0.2267		0.9677	0.8004		tp=0.6, tn=0.098, fp=0.22, fn=0.084		False
	60	0.1696		0.9452		0.8924		0.2227		0.9676	0.7607		tp=0.53, tn=0.14, fp=0.17, fn=0.16		False
	61	0.1644		0.9739		0.8969		0.2389		0.9688	0.7886		tp=0.57, tn=0.12, fp=0.21, fn=0.1		False
	62	0.1562		0.9839		0.9061		0.247		0.9716	0.8074		tp=0.61, tn=0.096, fp=0.22, fn=0.073		False
	63	0.1447		1		0.9205		0.2125		0.9759	0.7787		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	64	0.1364		1.033		0.9289		0.2535		0.9783	0.7791		tp=0.55, tn=0.14, fp=0.19, fn=0.12		False
	65	0.1292		1.117		0.9397		0.231		0.9816	0.8		tp=0.6, tn=0.098, fp=0.22, fn=0.08		False
	66	0.1262		1.035		0.9384		0.2084		0.9812	0.7753		tp=0.56, tn=0.12, fp=0.19, fn=0.13		False
	67	0.1219		1.032		0.9432		0.2304		0.9827	0.7669		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	68	0.1142		1.047		0.9485		0.2419		0.9842	0.7671		tp=0.53, tn=0.15, fp=0.18, fn=0.15		False
	69	0.1066		1.105		0.9563		0.2256		0.9866	0.7679		tp=0.54, tn=0.13, fp=0.19, fn=0.13		False
	70	0.1042		1.074		0.9584		0.2353		0.9873	0.7766		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	71	0.09703		1.104		0.9641		0.2217		0.989	0.7588		tp=0.52, tn=0.14, fp=0.19, fn=0.15		False
	72	0.09204		1.136		0.9688		0.2307		0.9905	0.766		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	73	0.08923		1.105		0.968		0.2405		0.9902	0.7653		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	74	0.08286		1.149		0.9766		0.2317		0.9928	0.784		tp=0.57, tn=0.12, fp=0.2, fn=0.12		False
	75	0.08181		1.164		0.9741		0.2378		0.992	0.7663		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	76	0.07837		1.204		0.9745		0.2628		0.9922	0.7859		tp=0.56, tn=0.13, fp=0.19, fn=0.12		True
	77	0.07472		1.159		0.9771		0.2471		0.993	0.7733		tp=0.54, tn=0.14, fp=0.17, fn=0.15		False
	78	0.07507		1.214		0.9758		0.2169		0.9926	0.7846		tp=0.57, tn=0.11, fp=0.2, fn=0.12		False
	79	0.06613		1.236		0.9831		0.219		0.9948	0.7676		tp=0.54, tn=0.13, fp=0.19, fn=0.13		False
	80	0.06421		1.242		0.984		0.2296		0.9951	0.7665		tp=0.53, tn=0.14, fp=0.18, fn=0.14		False
	81	0.06377		1.277		0.981		0.2478		0.9942	0.7782		tp=0.55, tn=0.13, fp=0.19, fn=0.12		False
	82	0.06315		1.323		0.9805		0.2413		0.994	0.784		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	83	0.05952		1.252		0.981		0.2556		0.9942	0.755		tp=0.51, tn=0.16, fp=0.15, fn=0.17		False
	84	0.05727		1.35		0.9818		0.2296		0.9944	0.7759		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	85	0.05294		1.482		0.9866		0.2438		0.9959	0.8		tp=0.6, tn=0.1, fp=0.22, fn=0.081		False
	86	0.05524		1.391		0.9823		0.2184		0.9946	0.7734		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	87	0.04933		1.399		0.987		0.2423		0.996	0.7801		tp=0.56, tn=0.13, fp=0.2, fn=0.12		False
	88	0.05019		1.391		0.9836		0.2161		0.995	0.758		tp=0.52, tn=0.14, fp=0.18, fn=0.15		False
	89	0.04794		1.448		0.9857		0.2371		0.9956	0.7775		tp=0.55, tn=0.13, fp=0.19, fn=0.12		False
	90	0.04866		1.425		0.9818		0.2411		0.9944	0.7734		tp=0.54, tn=0.14, fp=0.18, fn=0.13		False
	91	0.04671		1.455		0.987		0.2357		0.996	0.7709		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	92	0.04395		1.45		0.9875		0.2208		0.9962	0.7729		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	93	0.04379		1.463		0.987		0.2438		0.996	0.7734		tp=0.54, tn=0.14, fp=0.18, fn=0.13		False
	94	0.04456		1.577		0.9849		0.2252		0.9953	0.7854		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	95	0.04155		1.522		0.9866		0.2415		0.9959	0.7712		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	96	0.03986		1.52		0.987		0.2246		0.996	0.7742		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	97	0.04011		1.489		0.9875		0.2453		0.9961	0.7707		tp=0.54, tn=0.14, fp=0.17, fn=0.14		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		10
learning rate		0.00355626801513
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_168-lr0.0036-h_size10-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7051		0.6871		-0.01386		-0.1013		0.4055	0.6537		tp=0.47, tn=0.035, fp=0.42, fn=0.077		False
	2	0.696		0.6838		0.01187		0.1303		0.4717	0.5921		tp=0.31, tn=0.25, fp=0.23, fn=0.2		True
	3	0.6915		0.6879		0.03976		0.1849		0.397	0.4706		tp=0.2, tn=0.36, fp=0.084, fn=0.36		True
	4	0.6892		0.6938		0.1015		0.139		0.5841	0.3462		tp=0.13, tn=0.4, fp=0.056, fn=0.42		False
	5	0.6885		0.6903		0.08206		0.1807		0.3411	0.4074		tp=0.15, tn=0.4, fp=0.063, fn=0.38		False
	6	0.6868		0.69		0.072		0.1785		0.3977	0.4483		tp=0.18, tn=0.37, fp=0.077, fn=0.37		False
	7	0.6858		0.6963		0.09602		0.181		0.3937	0.3925		tp=0.15, tn=0.4, fp=0.056, fn=0.4		False
	8	0.6915		0.683		0.06036		-0.06821		0.5122	0.6429		tp=0.44, tn=0.07, fp=0.37, fn=0.12		False
	9	0.6866		0.6841		0.08488		0.1646		0.4099	0.5231		tp=0.24, tn=0.33, fp=0.13, fn=0.31		False
	10	0.6889		0.7148		0.06805		0.07076		0.5793	0.1149		tp=0.035, tn=0.43, fp=0.014, fn=0.52		False
	11	0.6846		0.6871		0.08194		-0.04477		0.4	0.6667		tp=0.48, tn=0.049, fp=0.4, fn=0.077		False
	12	0.6838		0.693		0.09502		0.2106		0.5232	0.4655		tp=0.19, tn=0.38, fp=0.07, fn=0.36		True
	13	0.6858		0.6872		0.07246		-0.05669		0.4793	0.6699		tp=0.49, tn=0.028, fp=0.43, fn=0.049		False
	14	0.6877		0.6915		0.06916		0.1254		0.4698	0.4348		tp=0.17, tn=0.37, fp=0.1, fn=0.35		False
	15	0.6865		0.7134		0.0572		0.09083		0.4649	0.3048		tp=0.11, tn=0.38, fp=0.056, fn=0.45		False
	16	0.6805		0.6873		0.1025		0.002733		0.4602	0.6057		tp=0.37, tn=0.15, fp=0.31, fn=0.17		False
	17	0.6787		0.6896		0.1304		0.02278		0.4752	0.566		tp=0.31, tn=0.2, fp=0.24, fn=0.24		False
	18	0.6765		0.6932		0.143		0.1826		0.5589	0.4878		tp=0.21, tn=0.35, fp=0.091, fn=0.35		False
	19	0.6769		0.6855		0.1505		0.02022		0.5434	0.6298		tp=0.4, tn=0.13, fp=0.31, fn=0.15		False
	20	0.6866		0.6988		0.08727		0.1234		0.5309	0.5224		tp=0.24, tn=0.31, fp=0.15, fn=0.29		False
	21	0.6772		0.694		0.09992		0.02126		0.5096	0.6264		tp=0.4, tn=0.13, fp=0.34, fn=0.13		False
	22	0.6773		0.6913		0.1264		-0.01538		0.5123	0.6765		tp=0.48, tn=0.056, fp=0.38, fn=0.077		False
	23	0.6695		0.7638		0.155		0.142		0.5983	0.1412		tp=0.042, tn=0.45, fp=0.007, fn=0.5		False
	24	0.679		0.7032		0.09754		0.03416		0.5484	0.2745		tp=0.098, tn=0.38, fp=0.07, fn=0.45		False
	25	0.6714		0.6891		0.1447		-0.02123		0.5043	0.55		tp=0.31, tn=0.19, fp=0.26, fn=0.24		False
	26	0.6755		0.7094		0.1095		0.09037		0.5556	0.4		tp=0.16, tn=0.36, fp=0.098, fn=0.38		False
	27	0.6791		0.7224		0.0885		0.09814		0.511	0.3423		tp=0.13, tn=0.36, fp=0.063, fn=0.45		False
	28	0.6751		0.7018		0.1293		0.0522		0.5116	0.5278		tp=0.27, tn=0.26, fp=0.21, fn=0.27		False
	29	0.6669		0.7046		0.166		0.08179		0.5657	0.4962		tp=0.23, tn=0.3, fp=0.16, fn=0.31		False
	30	0.6819		0.697		0.1451		0.01661		0.5502	0.6598		tp=0.45, tn=0.091, fp=0.36, fn=0.1		False
	31	0.6682		0.6926		0.2133		0.04975		0.5548	0.6292		tp=0.39, tn=0.15, fp=0.31, fn=0.15		False
	32	0.6659		0.711		0.1711		-0.01988		0.5407	0.4714		tp=0.23, tn=0.25, fp=0.2, fn=0.32		False
	33	0.6655		0.6937		0.1654		0.101		0.5267	0.6667		tp=0.43, tn=0.13, fp=0.32, fn=0.11		False


data			/scratch/asw462/data/levin
input size		300
hidden size		47
learning rate		0.00181393429193
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_169-lr0.0018-h_size47-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5989		0.5778		0.01516		0		0.8324	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5562		0.5612		0.06111		0		0.8428	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	3	0.5332		0.5404		0.1911		0.1301		0.8484	0.8313		tp=0.71, tn=0.007, fp=0.29, fn=0		True
	4	0.4901		0.5131		0.3538		0.2722		0.8645	0.8512		tp=0.72, tn=0.028, fp=0.25, fn=0		True
	5	0.4609		0.4934		0.4144		0.2878		0.8713	0.8511		tp=0.7, tn=0.056, fp=0.22, fn=0.021		True
	6	0.4236		0.5064		0.4848		0.4183		0.8826	0.8571		tp=0.67, tn=0.11, fp=0.19, fn=0.035		True
	7	0.3986		0.5085		0.5163		0.4511		0.8845	0.8597		tp=0.66, tn=0.12, fp=0.19, fn=0.028		True
	8	0.3877		0.4787		0.5454		0.5381		0.8879	0.8848		tp=0.67, tn=0.15, fp=0.13, fn=0.049		True
	9	0.3693		0.5305		0.5814		0.3923		0.8966	0.8571		tp=0.67, tn=0.1, fp=0.18, fn=0.042		False
	10	0.3536		0.4687		0.5899		0.4848		0.8989	0.8778		tp=0.68, tn=0.13, fp=0.14, fn=0.049		False
	11	0.3355		0.4983		0.6415		0.3037		0.9104	0.8547		tp=0.69, tn=0.069, fp=0.2, fn=0.035		False
	12	0.3264		0.5637		0.6438		0.3176		0.9103	0.8311		tp=0.64, tn=0.1, fp=0.2, fn=0.063		False
	13	0.3196		0.5642		0.6787		0.3239		0.918	0.8444		tp=0.66, tn=0.091, fp=0.2, fn=0.049		False
	14	0.3181		0.553		0.6629		0.4531		0.914	0.8531		tp=0.62, tn=0.16, fp=0.12, fn=0.09		False
	15	0.3121		0.5864		0.6812		0.3225		0.9171	0.8522		tp=0.69, tn=0.077, fp=0.2, fn=0.035		False
	16	0.3203		0.6		0.64		0.4045		0.9062	0.8309		tp=0.6, tn=0.15, fp=0.17, fn=0.077		False
	17	0.2994		0.6078		0.6771		0.3682		0.9179	0.8372		tp=0.63, tn=0.13, fp=0.17, fn=0.07		False
	18	0.2934		0.6068		0.6978		0.3176		0.9213	0.8311		tp=0.64, tn=0.1, fp=0.2, fn=0.063		False
	19	0.2831		0.6604		0.7167		0.2718		0.9269	0.8326		tp=0.64, tn=0.098, fp=0.16, fn=0.098		False
	20	0.2895		0.7137		0.6941		0.3028		0.9211	0.8326		tp=0.64, tn=0.098, fp=0.2, fn=0.063		False
	21	0.2752		0.7179		0.7122		0.2691		0.925	0.8219		tp=0.63, tn=0.098, fp=0.2, fn=0.077		False
	22	0.2675		0.7077		0.7404		0.3896		0.932	0.8141		tp=0.57, tn=0.17, fp=0.14, fn=0.12		False
	23	0.271		0.7499		0.706		0.284		0.9229	0.8057		tp=0.59, tn=0.12, fp=0.18, fn=0.1		False
	24	0.2754		0.7098		0.7136		0.3092		0.9239	0.8134		tp=0.59, tn=0.13, fp=0.15, fn=0.12		False
	25	0.2761		0.6758		0.7147		0.3553		0.9264	0.8286		tp=0.61, tn=0.14, fp=0.13, fn=0.12		False
	26	0.2567		0.7251		0.7366		0.3158		0.9318	0.796		tp=0.56, tn=0.15, fp=0.16, fn=0.13		False
	27	0.2515		0.6973		0.7439		0.377		0.933	0.81		tp=0.57, tn=0.17, fp=0.098, fn=0.17		False
	28	0.253		0.7294		0.7507		0.4219		0.935	0.8241		tp=0.57, tn=0.18, fp=0.13, fn=0.12		False
	29	0.2537		0.7161		0.7487		0.3612		0.9336	0.8357		tp=0.62, tn=0.13, fp=0.15, fn=0.098		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		162
learning rate		7.91931778718e&05
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_16-lr7.9e&05-h_size162-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6942		0.6896		0.008124		0.1924		0.2584	0.6705		tp=0.41, tn=0.18, fp=0.3, fn=0.1		True
	2	0.6824		0.6822		0.2532		0.1762		0.6692	0.604		tp=0.31, tn=0.27, fp=0.18, fn=0.23		False
	3	0.6735		0.6866		0.3246		0.1026		0.6429	0.3269		tp=0.12, tn=0.39, fp=0.063, fn=0.43		False
	4	0.6674		0.6814		0.2978		0.156		0.5481	0.5263		tp=0.24, tn=0.31, fp=0.13, fn=0.31		False
	5	0.6592		0.6791		0.3127		0.1975		0.5506	0.4833		tp=0.2, tn=0.36, fp=0.084, fn=0.35		True
	6	0.6516		0.6679		0.3604		0.2078		0.654	0.5606		tp=0.26, tn=0.34, fp=0.13, fn=0.27		True
	7	0.6443		0.6681		0.3586		0.2094		0.6296	0.563		tp=0.27, tn=0.32, fp=0.12, fn=0.29		True
	8	0.638		0.6681		0.3725		0.1458		0.6423	0.5116		tp=0.23, tn=0.33, fp=0.13, fn=0.31		False
	9	0.6303		0.6565		0.3824		0.2687		0.6569	0.6087		tp=0.29, tn=0.33, fp=0.12, fn=0.26		True
	10	0.6245		0.6612		0.3981		0.1646		0.6841	0.5231		tp=0.24, tn=0.33, fp=0.13, fn=0.31		False
	11	0.6171		0.6546		0.3996		0.2852		0.6567	0.6131		tp=0.29, tn=0.34, fp=0.11, fn=0.26		True
	12	0.6108		0.6617		0.4011		0.2021		0.6842	0.5564		tp=0.26, tn=0.33, fp=0.13, fn=0.29		False
	13	0.6038		0.6586		0.4227		0.2244		0.6858	0.6014		tp=0.3, tn=0.3, fp=0.13, fn=0.27		False
	14	0.5971		0.6428		0.4363		0.2582		0.7046	0.5802		tp=0.27, tn=0.35, fp=0.11, fn=0.27		False
	15	0.591		0.6475		0.4366		0.2323		0.6841	0.5778		tp=0.27, tn=0.33, fp=0.12, fn=0.28		False
	16	0.5841		0.6473		0.4716		0.2598		0.7231	0.5865		tp=0.27, tn=0.34, fp=0.11, fn=0.27		False
	17	0.5775		0.6493		0.4663		0.2817		0.7138	0.6389		tp=0.32, tn=0.31, fp=0.14, fn=0.22		False
	18	0.5721		0.6289		0.4805		0.2764		0.7264	0.6438		tp=0.33, tn=0.31, fp=0.15, fn=0.21		False
	19	0.5661		0.6487		0.4768		0.263		0.702	0.6029		tp=0.29, tn=0.34, fp=0.13, fn=0.25		False
	20	0.5596		0.6389		0.4997		0.2939		0.7496	0.6061		tp=0.28, tn=0.36, fp=0.11, fn=0.25		True
	21	0.5528		0.635		0.5161		0.3178		0.7426	0.6755		tp=0.36, tn=0.3, fp=0.14, fn=0.2		True
	22	0.5453		0.6299		0.518		0.324		0.7352	0.6165		tp=0.29, tn=0.36, fp=0.091, fn=0.27		True
	23	0.5396		0.619		0.545		0.3765		0.7626	0.6308		tp=0.29, tn=0.38, fp=0.07, fn=0.27		True
	24	0.5332		0.6261		0.5362		0.2974		0.744	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.22		False
	25	0.5268		0.6175		0.551		0.3099		0.765	0.6528		tp=0.33, tn=0.32, fp=0.13, fn=0.22		False
	26	0.5225		0.6252		0.5422		0.332		0.76	0.6757		tp=0.35, tn=0.31, fp=0.14, fn=0.2		False
	27	0.515		0.6206		0.5634		0.3325		0.7668	0.6712		tp=0.34, tn=0.32, fp=0.14, fn=0.2		False
	28	0.509		0.6237		0.5671		0.3158		0.7658	0.6667		tp=0.34, tn=0.31, fp=0.15, fn=0.19		False
	29	0.5012		0.6394		0.5715		0.3015		0.7801	0.6131		tp=0.29, tn=0.34, fp=0.097, fn=0.27		False
	30	0.4957		0.6114		0.5903		0.285		0.7799	0.6389		tp=0.32, tn=0.31, fp=0.13, fn=0.23		False
	31	0.4902		0.6363		0.6075		0.3208		0.7906	0.6047		tp=0.27, tn=0.37, fp=0.091, fn=0.27		False
	32	0.483		0.5978		0.6158		0.3225		0.7975	0.6573		tp=0.33, tn=0.33, fp=0.13, fn=0.21		False
	33	0.4771		0.6298		0.6188		0.2932		0.7988	0.6338		tp=0.31, tn=0.32, fp=0.12, fn=0.24		False
	34	0.4725		0.6251		0.6226		0.3668		0.7975	0.7097		tp=0.38, tn=0.3, fp=0.15, fn=0.17		False
	35	0.4646		0.648		0.6302		0.3225		0.8091	0.6107		tp=0.28, tn=0.36, fp=0.091, fn=0.27		False
	36	0.4605		0.6127		0.645		0.3096		0.8051	0.6575		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	37	0.4564		0.6427		0.6331		0.3252		0.8115	0.6222		tp=0.29, tn=0.35, fp=0.091, fn=0.27		False
	38	0.45		0.6163		0.66		0.3005		0.8204	0.6331		tp=0.31, tn=0.34, fp=0.13, fn=0.23		False
	39	0.4432		0.6287		0.6568		0.3208		0.8115	0.6377		tp=0.31, tn=0.34, fp=0.11, fn=0.24		False
	40	0.4382		0.6492		0.6573		0.3027		0.818	0.6232		tp=0.3, tn=0.34, fp=0.1, fn=0.26		False
	41	0.4292		0.6255		0.6729		0.3411		0.8239	0.6928		tp=0.37, tn=0.3, fp=0.15, fn=0.18		False
	42	0.4293		0.6265		0.6798		0.2883		0.8254	0.6667		tp=0.36, tn=0.29, fp=0.15, fn=0.21		False
	43	0.4271		0.6195		0.6448		0.3302		0.8164	0.6277		tp=0.3, tn=0.35, fp=0.09, fn=0.26		False
	44	0.4133		0.5942		0.6893		0.3177		0.8364	0.6621		tp=0.34, tn=0.32, fp=0.15, fn=0.2		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		125
learning rate		7.88709167102e&05
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_170-lr7.9e&05-h_size125-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6946		0.6936		0.002028		0.1054		0.0119	0.1798		tp=0.056, tn=0.43, fp=0.021, fn=0.49		True
	2	0.6925		0.692		0.04251		0.08609		0.3106	0.3818		tp=0.15, tn=0.38, fp=0.098, fn=0.38		False
	3	0.6917		0.6914		0.05099		0.1592		0.2812	0.34		tp=0.12, tn=0.42, fp=0.049, fn=0.41		True
	4	0.6912		0.6876		0.05253		0.1966		0.3593	0.4874		tp=0.2, tn=0.37, fp=0.091, fn=0.34		True
	5	0.6908		0.6946		0.05361		0.1859		0.3126	0.3619		tp=0.13, tn=0.4, fp=0.042, fn=0.43		False
	6	0.6905		0.6918		0.06469		0.1323		0.2633	0.437		tp=0.18, tn=0.35, fp=0.091, fn=0.38		False
	7	0.6894		0.6866		0.07161		0.1535		0.4444	0.5		tp=0.22, tn=0.33, fp=0.11, fn=0.34		False
	8	0.6895		0.6906		0.05682		0.1464		0.4558	0.431		tp=0.17, tn=0.36, fp=0.084, fn=0.38		False
	9	0.6899		0.6895		0.04997		0.1526		0.309	0.4211		tp=0.17, tn=0.37, fp=0.077, fn=0.38		False
	10	0.6891		0.6928		0.0885		0.1217		0.3534	0.3964		tp=0.15, tn=0.38, fp=0.084, fn=0.38		False
	11	0.6883		0.6907		0.07625		0.1572		0.3745	0.4286		tp=0.17, tn=0.38, fp=0.084, fn=0.36		False
	12	0.6886		0.6885		0.07778		0.1329		0.446	0.4144		tp=0.16, tn=0.38, fp=0.091, fn=0.36		False
	13	0.6883		0.6946		0.06937		0.1		0.373	0.3784		tp=0.15, tn=0.37, fp=0.084, fn=0.4		False
	14	0.6879		0.6877		0.07505		0.193		0.334	0.4425		tp=0.17, tn=0.38, fp=0.07, fn=0.37		False
	15	0.6909		0.6854		0.009448		0.1305		0.4759	0.48		tp=0.21, tn=0.34, fp=0.12, fn=0.34		False
	16	0.6869		0.6946		0.08014		0.1312		0.3677	0.3894		tp=0.15, tn=0.36, fp=0.07, fn=0.41		False
	17	0.6875		0.6906		0.07547		0.1866		0.3284	0.4522		tp=0.18, tn=0.38, fp=0.077, fn=0.36		False
	18	0.6866		0.6896		0.08249		0.147		0.3882	0.4107		tp=0.16, tn=0.38, fp=0.077, fn=0.38		False
	19	0.6869		0.6919		0.06988		0.1552		0.3603	0.4071		tp=0.16, tn=0.38, fp=0.069, fn=0.4		False
	20	0.688		0.6929		0.07212		0.1343		0.3219	0.3889		tp=0.15, tn=0.39, fp=0.077, fn=0.38		False
	21	0.6862		0.6826		0.06231		0.1737		0.3837	0.4839		tp=0.21, tn=0.34, fp=0.091, fn=0.36		False
	22	0.6867		0.6882		0.08431		0.1799		0.4273	0.4286		tp=0.17, tn=0.38, fp=0.07, fn=0.38		False
	23	0.6861		0.694		0.07397		0.1412		0.3505	0.4211		tp=0.17, tn=0.37, fp=0.084, fn=0.38		False
	24	0.6857		0.6897		0.07692		0.1451		0.3618	0.45		tp=0.19, tn=0.35, fp=0.091, fn=0.37		False
	25	0.6864		0.6901		0.06682		0.1546		0.3491	0.4144		tp=0.16, tn=0.38, fp=0.077, fn=0.38		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		170
learning rate		0.00021519895693
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_171-lr0.00022-h_size170-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6917		0.7279		0.03376		0		0.5434	0		tp=0, tn=0.45, fp=0, fn=0.55		False
	2	0.6315		0.6346		0.3119		0.3033		0.5959	0.7283		tp=0.47, tn=0.18, fp=0.28, fn=0.07		True
	3	0.5944		0.6341		0.4724		0.33		0.7161	0.7152		tp=0.41, tn=0.26, fp=0.19, fn=0.14		True
	4	0.554		0.634		0.537		0.2387		0.7524	0.6538		tp=0.36, tn=0.27, fp=0.18, fn=0.2		False
	5	0.529		0.6334		0.5307		0.3698		0.7516	0.7514		tp=0.48, tn=0.21, fp=0.24, fn=0.07		True
	6	0.4947		0.6217		0.5891		0.3053		0.7866	0.6957		tp=0.39, tn=0.27, fp=0.19, fn=0.15		False
	7	0.4582		0.6365		0.6575		0.2032		0.8175	0.6225		tp=0.33, tn=0.27, fp=0.17, fn=0.22		False
	8	0.42		0.6358		0.7154		0.2443		0.8519	0.6207		tp=0.31, tn=0.3, fp=0.14, fn=0.24		False
	9	0.3903		0.6631		0.7484		0.2687		0.8612	0.6395		tp=0.33, tn=0.3, fp=0.14, fn=0.23		False
	10	0.3543		0.6739		0.818		0.2621		0.9063	0.5985		tp=0.29, tn=0.33, fp=0.11, fn=0.27		False
	11	0.3289		0.6904		0.8096		0.2062		0.9002	0.5496		tp=0.25, tn=0.34, fp=0.12, fn=0.29		False
	12	0.3083		0.681		0.8441		0.2852		0.9151	0.6131		tp=0.29, tn=0.34, fp=0.11, fn=0.26		False
	13	0.2878		0.6797		0.8307		0.3869		0.9102	0.7425		tp=0.43, tn=0.27, fp=0.18, fn=0.12		True
	14	0.2682		0.7181		0.8475		0.2425		0.9222	0.6494		tp=0.35, tn=0.27, fp=0.17, fn=0.21		False
	15	0.233		0.7337		0.907		0.2319		0.9506	0.6405		tp=0.34, tn=0.27, fp=0.16, fn=0.22		False
	16	0.2127		0.673		0.9328		0.3141		0.9649	0.6755		tp=0.36, tn=0.3, fp=0.15, fn=0.19		False
	17	0.1974		0.7343		0.9183		0.302		0.9571	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	18	0.1785		0.7276		0.9445		0.2721		0.971	0.6579		tp=0.35, tn=0.29, fp=0.16, fn=0.2		False
	19	0.1684		0.7654		0.9357		0.2708		0.9665	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.2		False
	20	0.1546		0.7338		0.965		0.3381		0.9817	0.6968		tp=0.38, tn=0.29, fp=0.16, fn=0.17		False
	21	0.1572		0.8629		0.9443		0.2812		0.9713	0.6241		tp=0.31, tn=0.32, fp=0.12, fn=0.25		False
	22	0.1447		0.7843		0.9508		0.3435		0.9739	0.7006		tp=0.38, tn=0.29, fp=0.15, fn=0.18		False
	23	0.1278		0.8318		0.9619		0.3231		0.9803	0.6923		tp=0.38, tn=0.29, fp=0.17, fn=0.17		False
	24	0.1121		0.8729		0.9824		0.301		0.9909	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.23		False
	25	0.103		0.8465		0.9795		0.3538		0.9894	0.6713		tp=0.34, tn=0.34, fp=0.12, fn=0.21		False
	26	0.0957		0.8509		0.9854		0.2989		0.9924	0.6531		tp=0.33, tn=0.31, fp=0.14, fn=0.22		False
	27	0.08904		0.8996		0.9824		0.2886		0.9909	0.6577		tp=0.34, tn=0.3, fp=0.15, fn=0.2		False
	28	0.08537		0.8723		0.9854		0.3201		0.9924	0.7		tp=0.39, tn=0.27, fp=0.15, fn=0.18		False
	29	0.0784		0.8953		0.9941		0.3084		0.997	0.6667		tp=0.35, tn=0.31, fp=0.15, fn=0.2		False
	30	0.07202		0.8774		0.9883		0.332		0.994	0.6757		tp=0.35, tn=0.31, fp=0.14, fn=0.2		False
	31	0.0665		0.917		0.9941		0.3528		0.997	0.7013		tp=0.38, tn=0.3, fp=0.16, fn=0.16		False
	32	0.06231		0.974		0.9971		0.3039		0.9985	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	33	0.05807		1.01		0.9971		0.3014		0.9985	0.6575		tp=0.34, tn=0.31, fp=0.16, fn=0.19		False
	34	0.05661		0.9926		0.9971		0.3812		0.9985	0.725		tp=0.4, tn=0.29, fp=0.15, fn=0.15		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		101
learning rate		0.000401034970418
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_172-lr0.0004-h_size101-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7014		0.7027		-0.01836		0.101		0.5043	0.2828		tp=0.098, tn=0.41, fp=0.049, fn=0.45		True
	2	0.6949		0.6901		0.02756		0.1491		0.2336	0.4444		tp=0.18, tn=0.36, fp=0.091, fn=0.36		True
	3	0.6892		0.7053		0.06859		0.1933		0.51	0.2526		tp=0.084, tn=0.42, fp=0.014, fn=0.48		True
	4	0.6879		0.6859		0.08892		-0.06113		0.2524	0.6321		tp=0.43, tn=0.077, fp=0.38, fn=0.12		False
	5	0.6914		0.6997		0.05506		0.1262		0.5562	0.3396		tp=0.13, tn=0.38, fp=0.056, fn=0.43		False
	6	0.6879		0.6937		0.124		0.1333		0.4772	0.3964		tp=0.15, tn=0.38, fp=0.077, fn=0.39		False
	7	0.6881		0.6829		0.05301		-0.01531		0.3326	0.67		tp=0.47, tn=0.07, fp=0.36, fn=0.098		False
	8	0.6878		0.6865		0.05271		0.1264		0.4174	0.4882		tp=0.22, tn=0.33, fp=0.13, fn=0.33		False
	9	0.6866		0.686		0.1001		-0.05702		0.4375	0.5488		tp=0.31, tn=0.17, fp=0.27, fn=0.24		False
	10	0.6851		0.6913		0.1041		0.1512		0.4256	0.4407		tp=0.18, tn=0.36, fp=0.084, fn=0.38		False
	11	0.683		0.6841		0.1056		-0.01557		0.461	0.6188		tp=0.39, tn=0.13, fp=0.31, fn=0.17		False
	12	0.6841		0.6886		0.09017		0.2476		0.4772	0.5042		tp=0.21, tn=0.38, fp=0.07, fn=0.34		True
	13	0.6844		0.6879		0.0814		0.2115		0.3493	0.4833		tp=0.2, tn=0.37, fp=0.076, fn=0.35		False
	14	0.6876		0.6862		0.07466		-0.0599		0.3396	0.6731		tp=0.49, tn=0.035, fp=0.41, fn=0.063		False
	15	0.6939		0.6986		0.02837		0.174		0.5445	0.381		tp=0.14, tn=0.41, fp=0.056, fn=0.4		False
	16	0.6816		0.688		0.1422		0.03149		0.5494	0.549		tp=0.29, tn=0.22, fp=0.22, fn=0.26		False
	17	0.6846		0.6857		0.07189		0.0086		0.4615	0.6264		tp=0.4, tn=0.13, fp=0.33, fn=0.15		False
	18	0.6787		0.7024		0.1478		0.1944		0.5034	0.4074		tp=0.15, tn=0.4, fp=0.056, fn=0.39		False
	19	0.6794		0.6873		0.1249		-0.0596		0.4601	0.6044		tp=0.38, tn=0.11, fp=0.34, fn=0.17		False
	20	0.6792		0.6905		0.1026		0.09061		0.4583	0.5075		tp=0.24, tn=0.3, fp=0.17, fn=0.29		False
	21	0.6793		0.6932		0.09415		0.1521		0.5096	0.4754		tp=0.2, tn=0.35, fp=0.1, fn=0.34		False
	22	0.6774		0.6921		0.1055		0.08988		0.4685	0.4885		tp=0.22, tn=0.31, fp=0.15, fn=0.32		False
	23	0.6772		0.6911		0.1376		-0.03936		0.408	0.5765		tp=0.34, tn=0.15, fp=0.29, fn=0.22		False
	24	0.692		0.7314		0.04624		0.1579		0.5343	0.1609		tp=0.049, tn=0.44, fp=0.007, fn=0.5		False
	25	0.691		0.7156		0.01051		0.172		0.5363	0.1798		tp=0.056, tn=0.43, fp=0.007, fn=0.5		False
	26	0.6859		0.6847		0.05068		0.006983		0.4505	0.6339		tp=0.41, tn=0.13, fp=0.31, fn=0.16		False
	27	0.6737		0.7064		0.122		0.2014		0.5435	0.4112		tp=0.15, tn=0.41, fp=0.056, fn=0.38		False
	28	0.6779		0.6856		0.09099		0.1282		0.504	0.5594		tp=0.28, tn=0.28, fp=0.17, fn=0.27		False
	29	0.6762		0.6958		0.1227		0.148		0.4453	0.5191		tp=0.24, tn=0.32, fp=0.13, fn=0.31		False
	30	0.6728		0.6904		0.1353		-0.0611		0.4547	0.5647		tp=0.34, tn=0.15, fp=0.31, fn=0.2		False
	31	0.6737		0.6912		0.1239		0.2009		0.5609	0.5		tp=0.21, tn=0.37, fp=0.098, fn=0.32		False
	32	0.673		0.703		0.09915		0.1942		0.5383	0.422		tp=0.16, tn=0.4, fp=0.063, fn=0.38		False
	33	0.6753		0.6849		0.1174		-0.005331		0.5017	0.5882		tp=0.35, tn=0.16, fp=0.29, fn=0.2		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		191
learning rate		0.000615598772626
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_173-lr0.00062-h_size191-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6172		0.6324		0.01255		0		0.8163	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5974		0.6188		0.06942		0.06458		0.8179	0.8061		tp=0.67, tn=0.01, fp=0.31, fn=0.0089		True
	3	0.5851		0.6061		0.1495		0.1543		0.8201	0.8048		tp=0.64, tn=0.049, fp=0.27, fn=0.04		True
	4	0.5725		0.6141		0.2083		0.1358		0.8209	0.8087		tp=0.66, tn=0.033, fp=0.29, fn=0.024		False
	5	0.5676		0.6134		0.2149		0.204		0.817	0.7749		tp=0.56, tn=0.12, fp=0.2, fn=0.12		True
	6	0.5621		0.6193		0.2476		0.1202		0.8239	0.8108		tp=0.67, tn=0.024, fp=0.29, fn=0.016		False
	7	0.5574		0.6172		0.253		0.1384		0.8231	0.8095		tp=0.66, tn=0.034, fp=0.28, fn=0.025		False
	8	0.5584		0.6013		0.2663		0.2163		0.8226	0.8132		tp=0.64, tn=0.07, fp=0.24, fn=0.049		True
	9	0.5525		0.6079		0.2729		0.1886		0.8255	0.8023		tp=0.62, tn=0.071, fp=0.25, fn=0.059		False
	10	0.5528		0.6021		0.2759		0.177		0.8233	0.8134		tp=0.65, tn=0.053, fp=0.26, fn=0.041		False
	11	0.5483		0.6061		0.2852		0.1699		0.8261	0.7969		tp=0.61, tn=0.072, fp=0.24, fn=0.069		False
	12	0.5453		0.6129		0.294		0.183		0.8274	0.7881		tp=0.59, tn=0.093, fp=0.22, fn=0.099		False
	13	0.5458		0.6046		0.2964		0.2278		0.8279	0.7992		tp=0.6, tn=0.096, fp=0.22, fn=0.079		True
	14	0.5475		0.6293		0.2932		0.1694		0.8256	0.8149		tp=0.67, tn=0.033, fp=0.29, fn=0.016		False
	15	0.5429		0.6145		0.3045		0.1844		0.8289	0.7824		tp=0.58, tn=0.099, fp=0.22, fn=0.1		False
	16	0.5453		0.6039		0.3161		0.2074		0.8309	0.7992		tp=0.61, tn=0.084, fp=0.24, fn=0.07		False
	17	0.5427		0.6168		0.3025		0.1657		0.8272	0.77		tp=0.56, tn=0.1, fp=0.22, fn=0.12		False
	18	0.5404		0.5975		0.3104		0.2141		0.8294	0.8114		tp=0.63, tn=0.076, fp=0.23, fn=0.059		False
	19	0.5398		0.6019		0.3141		0.189		0.829	0.8012		tp=0.62, tn=0.077, fp=0.24, fn=0.07		False
	20	0.5399		0.6105		0.298		0.1745		0.826	0.7934		tp=0.61, tn=0.074, fp=0.25, fn=0.067		False
	21	0.5369		0.5954		0.3177		0.2282		0.8309	0.8031		tp=0.61, tn=0.095, fp=0.22, fn=0.08		True
	22	0.537		0.6056		0.3229		0.1765		0.8316	0.7985		tp=0.62, tn=0.073, fp=0.24, fn=0.067		False
	23	0.5336		0.612		0.3089		0.2079		0.8292	0.7826		tp=0.57, tn=0.11, fp=0.21, fn=0.1		False
	24	0.5335		0.6153		0.3191		0.2277		0.8296	0.8143		tp=0.64, tn=0.064, fp=0.26, fn=0.036		False
	25	0.5315		0.6145		0.3232		0.1609		0.8309	0.7911		tp=0.61, tn=0.074, fp=0.25, fn=0.074		False
	26	0.532		0.613		0.3306		0.1936		0.8325	0.7949		tp=0.61, tn=0.081, fp=0.24, fn=0.07		False
	27	0.5312		0.6055		0.3306		0.2058		0.8318	0.8019		tp=0.62, tn=0.077, fp=0.25, fn=0.059		False
	28	0.5252		0.6097		0.349		0.1682		0.8363	0.7817		tp=0.58, tn=0.092, fp=0.22, fn=0.1		False
	29	0.5271		0.6139		0.3321		0.229		0.8316	0.8099		tp=0.63, tn=0.077, fp=0.24, fn=0.052		True
	30	0.5288		0.6051		0.3361		0.2092		0.8331	0.7921		tp=0.59, tn=0.096, fp=0.23, fn=0.086		False
	31	0.5233		0.6279		0.3497		0.1629		0.8352	0.734		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	32	0.5189		0.6145		0.3581		0.1916		0.8354	0.8		tp=0.62, tn=0.077, fp=0.24, fn=0.067		False
	33	0.517		0.6093		0.3665		0.2306		0.8388	0.8069		tp=0.62, tn=0.086, fp=0.23, fn=0.064		True
	34	0.5154		0.6137		0.3609		0.1876		0.8376	0.7778		tp=0.57, tn=0.1, fp=0.22, fn=0.11		False
	35	0.5144		0.6064		0.3622		0.2112		0.8372	0.8027		tp=0.61, tn=0.087, fp=0.22, fn=0.077		False
	36	0.5103		0.6159		0.3753		0.2527		0.8398	0.8195		tp=0.65, tn=0.07, fp=0.25, fn=0.036		True
	37	0.5111		0.6146		0.3923		0.2444		0.8441	0.8104		tp=0.62, tn=0.086, fp=0.23, fn=0.058		False
	38	0.5064		0.6158		0.3779		0.2213		0.8403	0.8019		tp=0.61, tn=0.087, fp=0.23, fn=0.068		False
	39	0.5035		0.6344		0.393		0.2089		0.8433	0.7969		tp=0.61, tn=0.083, fp=0.25, fn=0.064		False
	40	0.5038		0.6056		0.4046		0.2079		0.8459	0.7888		tp=0.58, tn=0.1, fp=0.21, fn=0.1		False
	41	0.5007		0.6564		0.3975		0.2008		0.8436	0.8118		tp=0.65, tn=0.046, fp=0.28, fn=0.022		False
	42	0.4966		0.6213		0.4087		0.2116		0.8474	0.7977		tp=0.6, tn=0.089, fp=0.23, fn=0.074		False
	43	0.4949		0.6348		0.4055		0.2189		0.8458	0.8159		tp=0.65, tn=0.055, fp=0.27, fn=0.028		False
	44	0.4914		0.6126		0.4137		0.2107		0.8481	0.7822		tp=0.57, tn=0.11, fp=0.21, fn=0.1		False
	45	0.4872		0.6253		0.4273		0.2075		0.8498	0.7965		tp=0.6, tn=0.087, fp=0.24, fn=0.072		False
	46	0.4857		0.6172		0.4199		0.2176		0.8481	0.8035		tp=0.61, tn=0.084, fp=0.23, fn=0.067		False
	47	0.48		0.6185		0.4482		0.194		0.855	0.786		tp=0.58, tn=0.1, fp=0.21, fn=0.11		False
	48	0.4778		0.6209		0.4519		0.2207		0.8557	0.7928		tp=0.59, tn=0.1, fp=0.22, fn=0.09		False
	49	0.4719		0.6262		0.4521		0.222		0.8555	0.8023		tp=0.61, tn=0.089, fp=0.23, fn=0.071		False
	50	0.4699		0.6241		0.4457		0.2173		0.8532	0.8092		tp=0.63, tn=0.08, fp=0.23, fn=0.064		False
	51	0.4648		0.6299		0.4679		0.2014		0.8585	0.7937		tp=0.6, tn=0.092, fp=0.23, fn=0.084		False
	52	0.4638		0.6327		0.4639		0.2012		0.8582	0.7949		tp=0.6, tn=0.086, fp=0.24, fn=0.072		False
	53	0.4599		0.6194		0.4693		0.2115		0.8587	0.7718		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	54	0.4556		0.6393		0.4889		0.2295		0.8628	0.7992		tp=0.6, tn=0.096, fp=0.23, fn=0.077		False
	55	0.4481		0.643		0.4895		0.2254		0.8633	0.8107		tp=0.63, tn=0.075, fp=0.24, fn=0.052		False
	56	0.4459		0.6359		0.5048		0.2261		0.867	0.7984		tp=0.6, tn=0.099, fp=0.22, fn=0.086		False
	57	0.4435		0.637		0.4962		0.2194		0.8645	0.7804		tp=0.57, tn=0.12, fp=0.21, fn=0.11		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		163
learning rate		0.000312459006216
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_174-lr0.00031-h_size163-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.619		0.6336		-0.006714		0		0.8156	0.8067		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.603		0.6206		0.04213		0.07457		0.8188	0.8117		tp=0.68, tn=0.0089, fp=0.31, fn=0.0059		True
	3	0.5918		0.6162		0.08593		0.08001		0.8194	0.8131		tp=0.68, tn=0.003, fp=0.31, fn=0		True
	4	0.5838		0.6148		0.1316		0.09518		0.8196	0.8029		tp=0.66, tn=0.019, fp=0.31, fn=0.015		True
	5	0.5711		0.6087		0.186		0.1441		0.8231	0.807		tp=0.65, tn=0.04, fp=0.28, fn=0.031		True
	6	0.5665		0.6056		0.2134		0.1294		0.8231	0.8161		tp=0.67, tn=0.022, fp=0.29, fn=0.013		False
	7	0.5606		0.611		0.2393		0.1367		0.8257	0.8098		tp=0.66, tn=0.033, fp=0.29, fn=0.024		False
	8	0.557		0.6302		0.256		0.07782		0.826	0.8114		tp=0.67, tn=0.015, fp=0.3, fn=0.013		False
	9	0.5556		0.608		0.2655		0.1447		0.8249	0.8022		tp=0.64, tn=0.049, fp=0.27, fn=0.043		True
	10	0.5524		0.6168		0.2762		0.1303		0.8263	0.803		tp=0.64, tn=0.041, fp=0.28, fn=0.037		False
	11	0.55		0.6156		0.2791		0.1478		0.8263	0.803		tp=0.64, tn=0.05, fp=0.27, fn=0.044		True
	12	0.5482		0.6075		0.2832		0.184		0.8265	0.7973		tp=0.61, tn=0.077, fp=0.24, fn=0.07		True
	13	0.5484		0.6082		0.2942		0.1812		0.8267	0.8004		tp=0.62, tn=0.071, fp=0.25, fn=0.062		False
	14	0.5459		0.6165		0.2881		0.1823		0.8264	0.8034		tp=0.63, tn=0.064, fp=0.26, fn=0.05		False
	15	0.5449		0.616		0.2862		0.1581		0.8253	0.7931		tp=0.61, tn=0.068, fp=0.25, fn=0.065		False
	16	0.5435		0.625		0.3004		0.2086		0.828	0.8159		tp=0.65, tn=0.052, fp=0.27, fn=0.028		True
	17	0.5426		0.6092		0.2962		0.2191		0.8273	0.8004		tp=0.61, tn=0.089, fp=0.23, fn=0.071		True
	18	0.5427		0.6121		0.3045		0.177		0.827	0.7934		tp=0.61, tn=0.079, fp=0.24, fn=0.074		False
	19	0.5405		0.6168		0.321		0.1669		0.8316	0.7996		tp=0.62, tn=0.064, fp=0.26, fn=0.056		False
	20	0.5421		0.6182		0.3136		0.16		0.8302	0.7907		tp=0.61, tn=0.072, fp=0.25, fn=0.071		False
	21	0.5407		0.6275		0.3191		0.2186		0.8303	0.8087		tp=0.63, tn=0.065, fp=0.26, fn=0.038		False
	22	0.5416		0.6044		0.2939		0.2115		0.8245	0.7973		tp=0.6, tn=0.092, fp=0.23, fn=0.08		False
	23	0.5412		0.6067		0.3053		0.1794		0.8288	0.8042		tp=0.63, tn=0.068, fp=0.24, fn=0.061		False
	24	0.5398		0.6146		0.3187		0.2189		0.8303	0.7988		tp=0.61, tn=0.09, fp=0.23, fn=0.072		False
	25	0.5392		0.6059		0.318		0.223		0.83	0.7924		tp=0.59, tn=0.11, fp=0.21, fn=0.095		True
	26	0.5379		0.6178		0.3088		0.2131		0.828	0.8145		tp=0.65, tn=0.059, fp=0.26, fn=0.036		False
	27	0.5386		0.6095		0.3083		0.1837		0.828	0.8072		tp=0.63, tn=0.065, fp=0.25, fn=0.055		False
	28	0.5384		0.601		0.3088		0.1761		0.8282	0.7969		tp=0.61, tn=0.079, fp=0.23, fn=0.079		False
	29	0.5398		0.6206		0.3176		0.1877		0.8294	0.8105		tp=0.64, tn=0.056, fp=0.26, fn=0.04		False
	30	0.538		0.6107		0.3164		0.1872		0.8301	0.8065		tp=0.63, tn=0.068, fp=0.24, fn=0.058		False
	31	0.5366		0.619		0.3202		0.1605		0.8312	0.795		tp=0.62, tn=0.066, fp=0.26, fn=0.062		False
	32	0.5368		0.6125		0.3201		0.1947		0.8306	0.7973		tp=0.61, tn=0.083, fp=0.24, fn=0.074		False
	33	0.5357		0.6248		0.3192		0.176		0.8304	0.7977		tp=0.62, tn=0.068, fp=0.26, fn=0.058		False
	34	0.5353		0.6211		0.3302		0.1679		0.8321	0.7883		tp=0.6, tn=0.077, fp=0.25, fn=0.072		False
	35	0.537		0.6346		0.3179		0.215		0.8298	0.8202		tp=0.66, tn=0.047, fp=0.27, fn=0.022		False
	36	0.5342		0.6176		0.3227		0.1739		0.8319	0.775		tp=0.57, tn=0.1, fp=0.22, fn=0.11		False
	37	0.5351		0.6217		0.3158		0.1833		0.8289	0.8057		tp=0.63, tn=0.062, fp=0.26, fn=0.049		False
	38	0.5345		0.6174		0.3198		0.213		0.8291	0.8091		tp=0.63, tn=0.071, fp=0.25, fn=0.05		False
	39	0.5337		0.6215		0.3194		0.1598		0.8308	0.7981		tp=0.62, tn=0.065, fp=0.25, fn=0.062		False
	40	0.5331		0.6248		0.3226		0.2095		0.8309	0.8079		tp=0.63, tn=0.067, fp=0.26, fn=0.044		False
	41	0.5343		0.6179		0.3313		0.1695		0.8324	0.7895		tp=0.6, tn=0.083, fp=0.23, fn=0.086		False
	42	0.5324		0.6159		0.3245		0.2457		0.8316	0.8201		tp=0.65, tn=0.064, fp=0.25, fn=0.031		True
	43	0.5322		0.6178		0.3219		0.1738		0.8305	0.7946		tp=0.61, tn=0.074, fp=0.25, fn=0.068		False
	44	0.5311		0.6141		0.3363		0.1888		0.8336	0.7778		tp=0.57, tn=0.1, fp=0.22, fn=0.11		False
	45	0.5316		0.6384		0.3379		0.1791		0.833	0.8118		tp=0.65, tn=0.043, fp=0.28, fn=0.025		False
	46	0.5308		0.6044		0.3275		0.2126		0.8321	0.8077		tp=0.62, tn=0.08, fp=0.23, fn=0.065		False
	47	0.5296		0.612		0.3246		0.1941		0.8308	0.8031		tp=0.62, tn=0.073, fp=0.25, fn=0.059		False
	48	0.5276		0.6169		0.3492		0.209		0.8358	0.811		tp=0.64, tn=0.068, fp=0.25, fn=0.049		False
	49	0.5288		0.6236		0.3299		0.1904		0.8313	0.8075		tp=0.63, tn=0.064, fp=0.25, fn=0.049		False
	50	0.5271		0.6111		0.33		0.1773		0.8318	0.7783		tp=0.57, tn=0.099, fp=0.22, fn=0.11		False
	51	0.527		0.6162		0.3445		0.1816		0.8341	0.7973		tp=0.61, tn=0.074, fp=0.25, fn=0.065		False
	52	0.5264		0.62		0.3447		0.1792		0.8354	0.7882		tp=0.6, tn=0.084, fp=0.24, fn=0.08		False
	53	0.5246		0.6195		0.3405		0.1774		0.834	0.7992		tp=0.62, tn=0.071, fp=0.25, fn=0.064		False
	54	0.5247		0.6086		0.3432		0.1959		0.8344	0.7996		tp=0.61, tn=0.081, fp=0.23, fn=0.073		False
	55	0.5226		0.615		0.3432		0.183		0.8342	0.7898		tp=0.6, tn=0.084, fp=0.24, fn=0.078		False
	56	0.5208		0.6115		0.36		0.1734		0.838	0.785		tp=0.59, tn=0.089, fp=0.23, fn=0.092		False
	57	0.5218		0.617		0.3547		0.1759		0.8359	0.7809		tp=0.58, tn=0.095, fp=0.23, fn=0.099		False
	58	0.5226		0.6149		0.3403		0.217		0.8338	0.8088		tp=0.63, tn=0.073, fp=0.25, fn=0.05		False
	59	0.5189		0.6165		0.3475		0.2071		0.835	0.7988		tp=0.61, tn=0.084, fp=0.24, fn=0.07		False
	60	0.5202		0.6275		0.3557		0.2166		0.8352	0.8192		tp=0.66, tn=0.052, fp=0.26, fn=0.027		False
	61	0.5181		0.6173		0.3594		0.2117		0.8377	0.8035		tp=0.62, tn=0.08, fp=0.24, fn=0.062		False
	62	0.5145		0.6094		0.362		0.2305		0.838	0.7968		tp=0.6, tn=0.1, fp=0.22, fn=0.083		False
	63	0.5157		0.6026		0.364		0.2256		0.8381	0.7854		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False


data			/scratch/asw462/data/levin
input size		300
hidden size		194
learning rate		5.55000351017e&05
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_175-lr5.6e&05-h_size194-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6132		0.6223		0.02682		0		0.8409	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.5876		0.5966		0		0		0.8402	0.834		tp=0.72, tn=0, fp=0.28, fn=0		False
	3	0.5841		0.5918		0		0		0.8419	0.834		tp=0.72, tn=0, fp=0.28, fn=0		False
	4	0.5842		0.5959		0		0		0.8416	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	5	0.585		0.5922		0		0		0.8412	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	6	0.5846		0.6046		0		0		0.8408	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	7	0.5873		0.6145		0		0		0.8393	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	8	0.5809		0.595		0		0		0.8432	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	9	0.5847		0.6031		0		0		0.8407	0.8245		tp=0.7, tn=0, fp=0.3, fn=0		False
	10	0.5828		0.6116		0		0		0.8416	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	11	0.5787		0.6067		0		0		0.8444	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	12	0.5854		0.6153		0		0		0.8398	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	13	0.5841		0.6144		0		0		0.8402	0.8197		tp=0.69, tn=0, fp=0.31, fn=0		False
	14	0.5818		0.6163		0		0		0.8426	0.8148		tp=0.69, tn=0, fp=0.31, fn=0		False
	15	0.5832		0.6188		0		0		0.8407	0.8197		tp=0.69, tn=0, fp=0.31, fn=0		False
	16	0.5845		0.6026		0		0		0.8402	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	17	0.5847		0.5965		0		0		0.8398	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	18	0.5819		0.6339		0		0		0.8416	0.8033		tp=0.67, tn=0, fp=0.33, fn=0		False
	19	0.5792		0.6011		0		0		0.843	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	20	0.5806		0.5922		0		0		0.8426	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	21	0.5804		0.6096		0		0		0.8426	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		27
learning rate		0.000115660605041
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_176-lr0.00012-h_size27-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6067		0.5896		0.07552		0.1427		0.8189	0.8126		tp=0.67, tn=0.024, fp=0.3, fn=0.012		True
	2	0.5747		0.5736		0.1899		0.2534		0.8225	0.8198		tp=0.65, tn=0.064, fp=0.26, fn=0.028		True
	3	0.5669		0.568		0.2382		0.2848		0.8253	0.8273		tp=0.66, tn=0.07, fp=0.25, fn=0.027		True
	4	0.5643		0.5648		0.2458		0.3002		0.8247	0.8265		tp=0.65, tn=0.083, fp=0.24, fn=0.036		True
	5	0.5621		0.5766		0.2614		0.2827		0.827	0.814		tp=0.62, tn=0.098, fp=0.23, fn=0.056		False
	6	0.5597		0.5666		0.2661		0.3052		0.8265	0.823		tp=0.64, tn=0.09, fp=0.23, fn=0.04		True
	7	0.5569		0.5698		0.2688		0.2981		0.8275	0.8212		tp=0.63, tn=0.092, fp=0.23, fn=0.044		False
	8	0.5535		0.5731		0.2828		0.2642		0.8293	0.8167		tp=0.64, tn=0.077, fp=0.25, fn=0.039		False
	9	0.5525		0.5692		0.2818		0.2446		0.8286	0.8206		tp=0.65, tn=0.067, fp=0.25, fn=0.036		False
	10	0.5494		0.5665		0.29		0.3043		0.8311	0.8239		tp=0.63, tn=0.095, fp=0.22, fn=0.047		False
	11	0.547		0.5711		0.2945		0.2604		0.8309	0.8171		tp=0.64, tn=0.076, fp=0.25, fn=0.039		False
	12	0.5436		0.5695		0.3057		0.2796		0.8335	0.8211		tp=0.63, tn=0.089, fp=0.23, fn=0.05		False
	13	0.5421		0.5646		0.3188		0.2432		0.8351	0.821		tp=0.65, tn=0.068, fp=0.24, fn=0.039		False
	14	0.5397		0.5737		0.3266		0.2661		0.8365	0.8179		tp=0.64, tn=0.081, fp=0.24, fn=0.044		False
	15	0.5372		0.5695		0.3156		0.3198		0.835	0.822		tp=0.62, tn=0.11, fp=0.2, fn=0.064		True
	16	0.5358		0.5737		0.3303		0.2827		0.8367	0.8213		tp=0.64, tn=0.081, fp=0.24, fn=0.039		False
	17	0.534		0.567		0.337		0.2923		0.838	0.8244		tp=0.64, tn=0.089, fp=0.23, fn=0.046		False
	18	0.5306		0.5709		0.3338		0.2956		0.8374	0.8166		tp=0.61, tn=0.11, fp=0.2, fn=0.074		False
	19	0.5295		0.5618		0.3462		0.2881		0.839	0.8251		tp=0.64, tn=0.086, fp=0.23, fn=0.044		False
	20	0.5277		0.5704		0.3483		0.2816		0.8399	0.8159		tp=0.62, tn=0.096, fp=0.22, fn=0.056		False
	21	0.5259		0.5685		0.3453		0.3142		0.8389	0.8197		tp=0.62, tn=0.11, fp=0.21, fn=0.065		False
	22	0.5225		0.5703		0.3525		0.2855		0.8401	0.819		tp=0.63, tn=0.098, fp=0.22, fn=0.059		False
	23	0.5208		0.571		0.3631		0.2752		0.842	0.8206		tp=0.64, tn=0.084, fp=0.23, fn=0.046		False
	24	0.5202		0.5648		0.3577		0.2817		0.8414	0.8233		tp=0.64, tn=0.087, fp=0.23, fn=0.049		False
	25	0.5171		0.5707		0.3715		0.264		0.8439	0.8194		tp=0.64, tn=0.08, fp=0.24, fn=0.044		False
	26	0.5147		0.5724		0.3834		0.2764		0.8457	0.8052		tp=0.6, tn=0.11, fp=0.21, fn=0.081		False
	27	0.5137		0.5738		0.3735		0.2756		0.8437	0.8068		tp=0.6, tn=0.11, fp=0.21, fn=0.081		False
	28	0.512		0.5856		0.3814		0.251		0.8444	0.8119		tp=0.63, tn=0.083, fp=0.24, fn=0.05		False
	29	0.51		0.5797		0.3882		0.2571		0.8461	0.8051		tp=0.6, tn=0.11, fp=0.21, fn=0.08		False
	30	0.5085		0.5794		0.3889		0.2768		0.8461	0.8056		tp=0.6, tn=0.11, fp=0.21, fn=0.081		False
	31	0.5074		0.573		0.3937		0.2702		0.8463	0.8071		tp=0.6, tn=0.11, fp=0.21, fn=0.074		False
	32	0.506		0.582		0.3954		0.2658		0.8473	0.8109		tp=0.62, tn=0.096, fp=0.23, fn=0.062		False
	33	0.5051		0.5804		0.3975		0.2519		0.8473	0.802		tp=0.6, tn=0.1, fp=0.22, fn=0.077		False
	34	0.5025		0.5777		0.4134		0.2578		0.8501	0.8179		tp=0.64, tn=0.081, fp=0.23, fn=0.049		False
	35	0.5		0.5827		0.4061		0.2671		0.8495	0.8028		tp=0.6, tn=0.11, fp=0.22, fn=0.077		False
	36	0.4992		0.5888		0.4152		0.2733		0.851	0.7951		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		134
learning rate		0.00205290882677
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_177-lr0.0021-h_size134-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6857		0.6604		0.1174		0.25		0.5098	0.7236		tp=0.5, tn=0.11, fp=0.35, fn=0.035		True
	2	0.6075		0.6465		0.3755		0.227		0.6835	0.6405		tp=0.34, tn=0.27, fp=0.2, fn=0.19		False
	3	0.5465		0.6919		0.4553		0.2549		0.7265	0.4957		tp=0.2, tn=0.38, fp=0.063, fn=0.35		True
	4	0.4866		0.6341		0.5129		0.3104		0.743	0.6957		tp=0.39, tn=0.27, fp=0.18, fn=0.16		True
	5	0.436		0.6844		0.6099		0.2787		0.8012	0.6438		tp=0.33, tn=0.31, fp=0.15, fn=0.22		False
	6	0.4051		0.6792		0.6094		0.3322		0.7859	0.7152		tp=0.41, tn=0.26, fp=0.2, fn=0.13		True
	7	0.3646		0.7652		0.6749		0.2469		0.8356	0.625		tp=0.31, tn=0.31, fp=0.17, fn=0.21		False
	8	0.304		0.8607		0.7834		0.1879		0.8858	0.5874		tp=0.29, tn=0.29, fp=0.15, fn=0.26		False
	9	0.2765		0.9042		0.8066		0.3025		0.8988	0.7135		tp=0.43, tn=0.23, fp=0.22, fn=0.12		False
	10	0.2723		0.9012		0.8212		0.2895		0.9069	0.6667		tp=0.35, tn=0.29, fp=0.17, fn=0.19		False
	11	0.2462		0.977		0.8357		0.2375		0.9152	0.6259		tp=0.32, tn=0.29, fp=0.15, fn=0.23		False
	12	0.2424		1.09		0.8036		0.1925		0.8974	0.5972		tp=0.3, tn=0.29, fp=0.17, fn=0.23		False
	13	0.192		1.072		0.8564		0.2898		0.9252	0.6434		tp=0.32, tn=0.32, fp=0.15, fn=0.2		False
	14	0.1802		1.117		0.8947		0.3493		0.945	0.7195		tp=0.41, tn=0.27, fp=0.2, fn=0.13		True
	15	0.1635		1.169		0.8975		0.3201		0.9466	0.7		tp=0.39, tn=0.27, fp=0.18, fn=0.15		False
	16	0.154		1.368		0.9004		0.1906		0.9493	0.6133		tp=0.32, tn=0.27, fp=0.17, fn=0.23		False
	17	0.1625		1.301		0.8768		0.2656		0.9364	0.6709		tp=0.37, tn=0.27, fp=0.2, fn=0.17		False
	18	0.1453		1.311		0.9033		0.3163		0.9498	0.7073		tp=0.41, tn=0.26, fp=0.19, fn=0.15		False
	19	0.1169		1.549		0.9357		0.2949		0.9665	0.6795		tp=0.37, tn=0.28, fp=0.17, fn=0.17		False
	20	0.1112		1.6		0.9414		0.2289		0.9696	0.6358		tp=0.34, tn=0.28, fp=0.18, fn=0.2		False
	21	0.0942		1.644		0.959		0.2667		0.9788	0.6667		tp=0.36, tn=0.27, fp=0.18, fn=0.18		False
	22	0.083		1.662		0.9677		0.3131		0.9834	0.6755		tp=0.36, tn=0.3, fp=0.16, fn=0.18		False
	23	0.08026		1.66		0.9619		0.3427		0.9803	0.7195		tp=0.41, tn=0.27, fp=0.17, fn=0.15		False
	24	0.07762		1.836		0.9708		0.2486		0.9848	0.625		tp=0.31, tn=0.31, fp=0.16, fn=0.22		False
	25	0.0754		1.963		0.9736		0.2566		0.9864	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	26	0.06229		2.041		0.9824		0.2758		0.991	0.6486		tp=0.34, tn=0.3, fp=0.15, fn=0.21		False
	27	0.06349		1.922		0.9825		0.275		0.9909	0.6533		tp=0.34, tn=0.29, fp=0.15, fn=0.21		False
	28	0.05786		2.049		0.9766		0.2848		0.9879	0.6667		tp=0.36, tn=0.29, fp=0.16, fn=0.2		False
	29	0.04831		2.248		0.9883		0.2605		0.994	0.6443		tp=0.34, tn=0.29, fp=0.16, fn=0.21		False
	30	0.0442		2.375		0.9912		0.2196		0.9955	0.6216		tp=0.32, tn=0.29, fp=0.17, fn=0.22		False
	31	0.03873		2.343		0.9941		0.258		0.997	0.649		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	32	0.03817		2.279		0.9941		0.3157		0.997	0.6755		tp=0.36, tn=0.3, fp=0.15, fn=0.2		False
	33	0.03183		2.756		0.9971		0.2074		0.9985	0.6069		tp=0.31, tn=0.29, fp=0.17, fn=0.23		False
	34	0.03254		2.625		0.9941		0.2745		0.997	0.6623		tp=0.35, tn=0.28, fp=0.17, fn=0.19		False
	35	0.02808		2.764		0.9971		0.2516		0.9985	0.6624		tp=0.36, tn=0.27, fp=0.18, fn=0.19		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		79
learning rate		0.00284456321528
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_178-lr0.0028-h_size79-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6921		0.694		0.05828		0.07052		0.5743	0.2422		tp=0.079, tn=0.42, fp=0.049, fn=0.45		True
	2	0.667		0.7096		0.1761		0.1085		0.6001	0.3019		tp=0.1, tn=0.42, fp=0.056, fn=0.42		True
	3	0.644		0.6804		0.273		0.1071		0.651	0.5478		tp=0.27, tn=0.28, fp=0.19, fn=0.26		False
	4	0.6293		0.6989		0.2972		0.1834		0.6617	0.4877		tp=0.2, tn=0.37, fp=0.1, fn=0.32		True
	5	0.6237		0.6868		0.3192		0.1877		0.6707	0.5628		tp=0.26, tn=0.33, fp=0.16, fn=0.25		True
	6	0.6078		0.6832		0.3522		0.1225		0.6825	0.6471		tp=0.39, tn=0.18, fp=0.29, fn=0.14		False
	7	0.6181		0.6803		0.3196		0.159		0.676	0.6147		tp=0.33, tn=0.25, fp=0.22, fn=0.19		False
	8	0.5993		0.6979		0.3794		0.1422		0.6986	0.6052		tp=0.33, tn=0.25, fp=0.24, fn=0.19		False
	9	0.5867		0.693		0.3812		0.1453		0.6987	0.5835		tp=0.3, tn=0.27, fp=0.21, fn=0.22		False
	10	0.587		0.7021		0.3741		0.1343		0.6963	0.6038		tp=0.33, tn=0.24, fp=0.24, fn=0.19		False
	11	0.586		0.7156		0.3824		0.1461		0.7007	0.6327		tp=0.37, tn=0.21, fp=0.28, fn=0.15		False
	12	0.5817		0.7326		0.3796		0.1673		0.7024	0.6382		tp=0.36, tn=0.22, fp=0.25, fn=0.16		False
	13	0.5653		0.713		0.4155		0.1286		0.7152	0.6168		tp=0.35, tn=0.22, fp=0.26, fn=0.17		False
	14	0.5604		0.7022		0.4317		0.1601		0.7244	0.611		tp=0.33, tn=0.25, fp=0.22, fn=0.2		False
	15	0.5541		0.7507		0.4276		0.1224		0.7224	0.5362		tp=0.26, tn=0.3, fp=0.17, fn=0.27		False
	16	0.547		0.7178		0.4515		0.19		0.7321	0.6359		tp=0.35, tn=0.24, fp=0.24, fn=0.16		True
	17	0.5308		0.7154		0.4646		0.1907		0.7403	0.5737		tp=0.27, tn=0.32, fp=0.17, fn=0.24		True
	18	0.5177		0.7121		0.4931		0.1756		0.7543	0.595		tp=0.3, tn=0.28, fp=0.2, fn=0.21		False
	19	0.5063		0.7521		0.5172		0.197		0.7649	0.6389		tp=0.35, tn=0.25, fp=0.23, fn=0.17		True
	20	0.4929		0.7568		0.5375		0.1785		0.7753	0.533		tp=0.24, tn=0.34, fp=0.14, fn=0.28		False
	21	0.4776		0.7855		0.5604		0.2168		0.7866	0.6465		tp=0.36, tn=0.26, fp=0.21, fn=0.17		True
	22	0.4581		0.7929		0.5645		0.1957		0.7879	0.573		tp=0.27, tn=0.32, fp=0.16, fn=0.24		False
	23	0.4452		0.7813		0.6046		0.2342		0.806	0.6053		tp=0.29, tn=0.32, fp=0.17, fn=0.21		True
	24	0.4259		0.7875		0.62		0.2395		0.8146	0.6459		tp=0.35, tn=0.28, fp=0.19, fn=0.18		True
	25	0.4074		0.8569		0.6555		0.2373		0.8306	0.6682		tp=0.38, tn=0.24, fp=0.23, fn=0.15		False
	26	0.3968		0.8353		0.6596		0.2437		0.8331	0.6541		tp=0.36, tn=0.27, fp=0.22, fn=0.16		True
	27	0.3738		0.8609		0.701		0.2733		0.8536	0.6651		tp=0.36, tn=0.28, fp=0.19, fn=0.17		True
	28	0.3518		0.8633		0.7347		0.2402		0.8701	0.6542		tp=0.36, tn=0.26, fp=0.23, fn=0.15		False
	29	0.333		0.9272		0.7565		0.2087		0.8798	0.6593		tp=0.38, tn=0.22, fp=0.26, fn=0.14		False
	30	0.3135		0.8994		0.7719		0.2473		0.8882	0.6682		tp=0.38, tn=0.25, fp=0.24, fn=0.14		False
	31	0.2975		0.9102		0.7908		0.2465		0.8969	0.6186		tp=0.31, tn=0.31, fp=0.16, fn=0.22		False
	32	0.2756		0.9881		0.8264		0.1832		0.9145	0.5876		tp=0.29, tn=0.3, fp=0.18, fn=0.23		False
	33	0.2594		0.9637		0.8274		0.204		0.9152	0.6283		tp=0.34, tn=0.27, fp=0.21, fn=0.19		False
	34	0.2431		0.9346		0.8524		0.2917		0.9278	0.6427		tp=0.32, tn=0.32, fp=0.15, fn=0.21		True
	35	0.2175		0.9447		0.8854		0.2675		0.9436	0.6486		tp=0.34, tn=0.3, fp=0.18, fn=0.19		False
	36	0.1985		1.024		0.8942		0.2148		0.9479	0.6577		tp=0.38, tn=0.23, fp=0.24, fn=0.15		False
	37	0.1847		1.047		0.9096		0.2354		0.9555	0.6269		tp=0.32, tn=0.3, fp=0.18, fn=0.21		False
	38	0.1713		1.051		0.9279		0.2475		0.9643	0.626		tp=0.32, tn=0.31, fp=0.17, fn=0.21		False
	39	0.1529		1.074		0.9415		0.1949		0.9711	0.6303		tp=0.34, tn=0.26, fp=0.21, fn=0.19		False
	40	0.1414		1.148		0.9439		0.2473		0.9723	0.6297		tp=0.32, tn=0.3, fp=0.17, fn=0.21		False
	41	0.1375		1.055		0.9456		0.2572		0.9732	0.6651		tp=0.37, tn=0.27, fp=0.2, fn=0.17		False
	42	0.1236		1.211		0.9604		0.2171		0.9805	0.6185		tp=0.32, tn=0.29, fp=0.19, fn=0.2		False
	43	0.11		1.121		0.9728		0.249		0.9866	0.6456		tp=0.34, tn=0.28, fp=0.19, fn=0.18		False
	44	0.1016		1.155		0.9764		0.2084		0.9883	0.6333		tp=0.34, tn=0.27, fp=0.21, fn=0.19		False
	45	0.094		1.193		0.9758		0.2636		0.9881	0.6327		tp=0.32, tn=0.31, fp=0.16, fn=0.21		False
	46	0.08792		1.303		0.9799		0.2062		0.9901	0.6484		tp=0.36, tn=0.24, fp=0.23, fn=0.16		False
	47	0.08177		1.267		0.9775		0.2059		0.9889	0.6192		tp=0.32, tn=0.28, fp=0.2, fn=0.19		False
	48	0.07593		1.235		0.9811		0.2238		0.9907	0.6326		tp=0.33, tn=0.28, fp=0.18, fn=0.2		False
	49	0.07162		1.238		0.984		0.2383		0.9921	0.6459		tp=0.35, tn=0.27, fp=0.21, fn=0.17		False
	50	0.06619		1.263		0.987		0.2585		0.9936	0.662		tp=0.36, tn=0.27, fp=0.21, fn=0.16		False
	51	0.0638		1.319		0.9882		0.2252		0.9942	0.6216		tp=0.32, tn=0.29, fp=0.19, fn=0.19		False
	52	0.0581		1.361		0.9911		0.1988		0.9956	0.6065		tp=0.31, tn=0.29, fp=0.2, fn=0.2		False
	53	0.05489		1.345		0.9894		0.2367		0.9948	0.6493		tp=0.35, tn=0.27, fp=0.2, fn=0.18		False
	54	0.05363		1.343		0.9882		0.244		0.9942	0.6423		tp=0.34, tn=0.28, fp=0.19, fn=0.19		False
	55	0.04953		1.328		0.9882		0.2156		0.9942	0.6295		tp=0.33, tn=0.28, fp=0.21, fn=0.18		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		136
learning rate		0.000383890574905
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_179-lr0.00038-h_size136-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6538		0.6272		0.2457		0.3557		0.6585	0.685		tp=0.35, tn=0.33, fp=0.14, fn=0.18		True
	2	0.6307		0.6263		0.307		0.367		0.6853	0.6915		tp=0.36, tn=0.33, fp=0.14, fn=0.18		True
	3	0.6214		0.6163		0.329		0.3428		0.6934	0.7088		tp=0.4, tn=0.27, fp=0.22, fn=0.11		False
	4	0.6132		0.6487		0.3392		0.3308		0.6972	0.6023		tp=0.26, tn=0.39, fp=0.09, fn=0.26		False
	5	0.6035		0.6284		0.3615		0.325		0.7072	0.67		tp=0.34, tn=0.32, fp=0.16, fn=0.18		False
	6	0.5922		0.6172		0.3933		0.3545		0.7197	0.6897		tp=0.36, tn=0.32, fp=0.16, fn=0.16		False
	7	0.5841		0.6234		0.3903		0.2963		0.7183	0.7066		tp=0.42, tn=0.23, fp=0.25, fn=0.11		False
	8	0.5876		0.6189		0.3864		0.2993		0.7098	0.6822		tp=0.37, tn=0.28, fp=0.2, fn=0.15		False
	9	0.5675		0.6197		0.4127		0.2737		0.7283	0.6619		tp=0.35, tn=0.28, fp=0.19, fn=0.17		False
	10	0.5595		0.6442		0.4188		0.2837		0.7264	0.7042		tp=0.43, tn=0.2, fp=0.28, fn=0.085		False
	11	0.5558		0.6313		0.4307		0.2579		0.7326	0.6727		tp=0.38, tn=0.25, fp=0.23, fn=0.14		False
	12	0.5623		0.6383		0.4241		0.2254		0.7288	0.6652		tp=0.38, tn=0.23, fp=0.24, fn=0.14		False
	13	0.5481		0.709		0.4471		0.307		0.7401	0.538		tp=0.22, tn=0.41, fp=0.064, fn=0.31		False
	14	0.542		0.6548		0.4568		0.1809		0.7443	0.6378		tp=0.36, tn=0.24, fp=0.24, fn=0.17		False
	15	0.5338		0.6648		0.4611		0.2167		0.747	0.6622		tp=0.38, tn=0.23, fp=0.23, fn=0.15		False
	16	0.5326		0.7084		0.476		0.2941		0.7517	0.5789		tp=0.25, tn=0.38, fp=0.095, fn=0.27		False
	17	0.5414		0.6777		0.4403		0.2534		0.7347	0.6121		tp=0.3, tn=0.33, fp=0.15, fn=0.22		False
	18	0.5314		0.6786		0.4778		0.2426		0.7528	0.5989		tp=0.29, tn=0.33, fp=0.14, fn=0.24		False
	19	0.531		0.6848		0.4778		0.2207		0.7532	0.6779		tp=0.41, tn=0.2, fp=0.28, fn=0.11		False
	20	0.5452		0.6666		0.4454		0.225		0.7367	0.6528		tp=0.36, tn=0.25, fp=0.22, fn=0.17		False
	21	0.5273		0.6736		0.4588		0.2391		0.7439	0.6636		tp=0.37, tn=0.25, fp=0.24, fn=0.14		False
	22	0.5148		0.6529		0.4834		0.2889		0.7563	0.6714		tp=0.36, tn=0.28, fp=0.19, fn=0.16		False
	23	0.5175		0.6758		0.4834		0.2696		0.755	0.6416		tp=0.33, tn=0.31, fp=0.17, fn=0.2		False


data			/scratch/asw462/data/levin
input size		300
hidden size		89
learning rate		0.00139283053821
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_17-lr0.0014-h_size89-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5747		0.6007		0.05896		0.122		0.8299	0.8052		tp=0.65, tn=0.042, fp=0.27, fn=0.042		True
	2	0.5367		0.5979		0.2198		0.1702		0.8479	0.7945		tp=0.61, tn=0.077, fp=0.24, fn=0.077		True
	3	0.5313		0.5591		0.2502		0.3304		0.8475	0.8472		tp=0.68, tn=0.077, fp=0.22, fn=0.028		True
	4	0.5207		0.5889		0.249		0.05845		0.8462	0.8361		tp=0.71, tn=0.007, fp=0.27, fn=0.007		False
	5	0.5154		0.5685		0.3128		0.1653		0.8528	0.7926		tp=0.6, tn=0.084, fp=0.22, fn=0.098		False
	6	0.4802		0.5794		0.3739		0.2175		0.8642	0.7867		tp=0.58, tn=0.1, fp=0.22, fn=0.091		False
	7	0.4764		0.5747		0.384		0.2394		0.8637	0.7864		tp=0.57, tn=0.13, fp=0.13, fn=0.17		False
	8	0.4615		0.5508		0.4086		0.3324		0.8654	0.8498		tp=0.69, tn=0.063, fp=0.23, fn=0.014		True
	9	0.4411		0.5115		0.4608		0.3068		0.8762	0.8458		tp=0.67, tn=0.084, fp=0.2, fn=0.049		False
	10	0.4443		0.5767		0.445		0.2708		0.8699	0.7882		tp=0.56, tn=0.14, fp=0.16, fn=0.14		False
	11	0.4196		0.5651		0.5047		0.269		0.8854	0.8111		tp=0.62, tn=0.098, fp=0.22, fn=0.063		False
	12	0.3995		0.6044		0.5306		0.3229		0.8892	0.7749		tp=0.52, tn=0.18, fp=0.14, fn=0.16		False
	13	0.3838		0.5407		0.5409		0.3441		0.8873	0.8496		tp=0.67, tn=0.091, fp=0.2, fn=0.042		True
	14	0.4066		0.6027		0.5228		0.1675		0.883	0.8178		tp=0.64, tn=0.07, fp=0.2, fn=0.091		False
	15	0.4035		0.5792		0.4994		0.3965		0.8799	0.8122		tp=0.56, tn=0.18, fp=0.13, fn=0.13		True
	16	0.4044		0.5692		0.5326		0.288		0.8854	0.8288		tp=0.64, tn=0.091, fp=0.21, fn=0.056		False
	17	0.3672		0.5682		0.5684		0.2275		0.8946	0.8198		tp=0.64, tn=0.084, fp=0.2, fn=0.077		False
	18	0.3504		0.58		0.5968		0.44		0.9	0.8406		tp=0.61, tn=0.16, fp=0.16, fn=0.07		True
	19	0.3304		0.5734		0.6304		0.3572		0.9084	0.8402		tp=0.64, tn=0.12, fp=0.17, fn=0.069		False
	20	0.3299		0.5984		0.6346		0.3635		0.9098	0.8302		tp=0.62, tn=0.13, fp=0.17, fn=0.077		False
	21	0.3286		0.6183		0.6431		0.3493		0.9097	0.8349		tp=0.64, tn=0.11, fp=0.2, fn=0.056		False
	22	0.3545		0.5726		0.6034		0.2856		0.9009	0.8273		tp=0.64, tn=0.098, fp=0.2, fn=0.07		False
	23	0.3348		0.6257		0.6543		0.334		0.9126	0.8333		tp=0.63, tn=0.12, fp=0.17, fn=0.084		False
	24	0.2947		0.587		0.6892		0.4622		0.9212	0.8416		tp=0.59, tn=0.18, fp=0.13, fn=0.098		True
	25	0.3108		0.6283		0.6422		0.2929		0.9094	0.8203		tp=0.62, tn=0.11, fp=0.19, fn=0.083		False
	26	0.291		0.6581		0.7025		0.4477		0.9239	0.8358		tp=0.59, tn=0.18, fp=0.12, fn=0.11		False
	27	0.2788		0.7008		0.7026		0.3025		0.9248	0.8311		tp=0.64, tn=0.1, fp=0.18, fn=0.077		False
	28	0.2754		0.7033		0.6969		0.5009		0.9227	0.8235		tp=0.53, tn=0.24, fp=0.09, fn=0.14		True
	29	0.2962		0.7162		0.6833		0.4184		0.9174	0.8103		tp=0.55, tn=0.19, fp=0.084, fn=0.17		False
	30	0.2773		0.7131		0.7029		0.3154		0.9229	0.8393		tp=0.66, tn=0.091, fp=0.2, fn=0.049		False
	31	0.2838		0.9535		0.6849		0.3266		0.919	0.6824		tp=0.41, tn=0.22, fp=0.049, fn=0.33		False
	32	0.386		0.6731		0.5603		0.4859		0.8853	0.8458		tp=0.59, tn=0.19, fp=0.084, fn=0.13		False
	33	0.2825		0.7137		0.6956		0.3406		0.9213	0.8349		tp=0.64, tn=0.11, fp=0.19, fn=0.063		False
	34	0.2734		0.7231		0.7008		0.3049		0.9232	0.8393		tp=0.66, tn=0.091, fp=0.2, fn=0.056		False
	35	0.2545		0.7559		0.7361		0.4845		0.9321	0.8367		tp=0.57, tn=0.2, fp=0.091, fn=0.13		False
	36	0.2492		0.8181		0.7456		0.3471		0.9341	0.8208		tp=0.61, tn=0.13, fp=0.2, fn=0.063		False
	37	0.2594		0.669		0.7355		0.3596		0.9314	0.8455		tp=0.65, tn=0.11, fp=0.17, fn=0.063		False
	38	0.2348		0.6525		0.7676		0.4005		0.939	0.8545		tp=0.65, tn=0.12, fp=0.15, fn=0.069		False
	39	0.2385		0.7552		0.7525		0.4511		0.9355	0.8447		tp=0.61, tn=0.17, fp=0.14, fn=0.084		False
	40	0.2391		0.7905		0.7766		0.4463		0.9415	0.8447		tp=0.61, tn=0.17, fp=0.13, fn=0.098		False
	41	0.2646		0.779		0.7202		0.4238		0.9269	0.8406		tp=0.61, tn=0.16, fp=0.13, fn=0.1		False
	42	0.2342		0.7659		0.7539		0.3727		0.9361	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.063		False
	43	0.2387		0.8653		0.7671		0.4198		0.9375	0.776		tp=0.5, tn=0.22, fp=0.063, fn=0.22		False
	44	0.2659		0.8797		0.7253		0.4095		0.9274	0.7892		tp=0.51, tn=0.22, fp=0.1, fn=0.17		False
	45	0.2335		0.8251		0.7556		0.3209		0.9356	0.79		tp=0.55, tn=0.16, fp=0.11, fn=0.18		False
	46	0.2388		0.7998		0.7615		0.3687		0.9369	0.8357		tp=0.62, tn=0.13, fp=0.16, fn=0.084		False
	47	0.2109		0.8637		0.786		0.4218		0.9437	0.8421		tp=0.62, tn=0.15, fp=0.15, fn=0.084		False
	48	0.2077		0.8525		0.7973		0.4887		0.9456	0.8529		tp=0.61, tn=0.18, fp=0.12, fn=0.091		False
	49	0.2257		0.9534		0.78		0.4075		0.9423	0.7784		tp=0.5, tn=0.21, fp=0.07, fn=0.22		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		18
learning rate		0.000248584899213
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_180-lr0.00025-h_size18-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6952		0.6896		-0.002859		-0.005826		0.5669	0.6749		tp=0.49, tn=0.038, fp=0.43, fn=0.046		False
	2	0.6907		0.6902		0.04542		0.1625		0.6111	0.3529		tp=0.12, tn=0.43, fp=0.054, fn=0.4		True
	3	0.6877		0.683		0.0824		0.1165		0.5874	0.6239		tp=0.36, tn=0.2, fp=0.27, fn=0.17		False
	4	0.6837		0.6837		0.1175		0.1248		0.5964	0.5778		tp=0.3, tn=0.26, fp=0.23, fn=0.21		False
	5	0.6802		0.6799		0.1527		0.161		0.5935	0.654		tp=0.4, tn=0.18, fp=0.3, fn=0.12		False
	6	0.6768		0.6788		0.1562		0.1938		0.6217	0.5722		tp=0.27, tn=0.32, fp=0.15, fn=0.26		True
	7	0.6732		0.6762		0.1866		0.1609		0.6032	0.5269		tp=0.24, tn=0.33, fp=0.14, fn=0.29		False
	8	0.6699		0.6731		0.1871		0.2122		0.6113	0.6667		tp=0.39, tn=0.22, fp=0.25, fn=0.14		True
	9	0.6648		0.6713		0.2179		0.207		0.6247	0.65		tp=0.37, tn=0.24, fp=0.24, fn=0.16		False
	10	0.6618		0.6769		0.2202		0.1873		0.6267	0.6472		tp=0.37, tn=0.23, fp=0.24, fn=0.16		False
	11	0.6574		0.6747		0.243		0.1528		0.638	0.5926		tp=0.31, tn=0.27, fp=0.21, fn=0.22		False
	12	0.6532		0.6732		0.2529		0.1846		0.6351	0.6131		tp=0.32, tn=0.27, fp=0.2, fn=0.2		False
	13	0.649		0.679		0.266		0.135		0.6523	0.4912		tp=0.21, tn=0.34, fp=0.13, fn=0.31		False
	14	0.6462		0.6677		0.2506		0.1893		0.632	0.6184		tp=0.33, tn=0.27, fp=0.19, fn=0.21		False
	15	0.6455		0.6676		0.2608		0.1855		0.6509	0.6376		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	16	0.6395		0.6678		0.27		0.1868		0.6444	0.6326		tp=0.35, tn=0.25, fp=0.23, fn=0.18		False
	17	0.6373		0.6719		0.2759		0.1932		0.6511	0.5798		tp=0.28, tn=0.32, fp=0.17, fn=0.23		False
	18	0.6334		0.6702		0.306		0.1884		0.6632	0.6291		tp=0.34, tn=0.25, fp=0.23, fn=0.18		False
	19	0.6298		0.6702		0.2854		0.1954		0.6539	0.5842		tp=0.28, tn=0.31, fp=0.17, fn=0.24		False
	20	0.6285		0.6712		0.2908		0.1984		0.652	0.6453		tp=0.36, tn=0.24, fp=0.23, fn=0.17		False
	21	0.6308		0.6703		0.2902		0.1998		0.6514	0.6404		tp=0.35, tn=0.25, fp=0.23, fn=0.17		False
	22	0.6236		0.6865		0.3008		0.1735		0.6596	0.5781		tp=0.28, tn=0.3, fp=0.18, fn=0.24		False
	23	0.6227		0.6729		0.3228		0.1976		0.6663	0.625		tp=0.33, tn=0.27, fp=0.22, fn=0.18		False
	24	0.6241		0.6654		0.2948		0.2105		0.6623	0.645		tp=0.36, tn=0.25, fp=0.21, fn=0.18		False
	25	0.6183		0.6888		0.3132		0.1513		0.6661	0.5185		tp=0.23, tn=0.33, fp=0.14, fn=0.29		False
	26	0.6201		0.69		0.3055		0.1474		0.6615	0.5772		tp=0.29, tn=0.28, fp=0.19, fn=0.23		False
	27	0.6156		0.6813		0.3186		0.1971		0.6649	0.6594		tp=0.39, tn=0.21, fp=0.27, fn=0.13		False
	28	0.6147		0.6845		0.3215		0.1744		0.6705	0.6296		tp=0.35, tn=0.24, fp=0.24, fn=0.17		False
	29	0.6178		0.7023		0.3125		0.123		0.6669	0.507		tp=0.23, tn=0.32, fp=0.15, fn=0.3		False


data			/scratch/asw462/data/levin
input size		300
hidden size		70
learning rate		0.000233547999784
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_181-lr0.00023-h_size70-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.593		0.5888		0.04368		0		0.8428	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5526		0.5865		0.06122		0		0.8433	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.5286		0.5579		0.1821		0.2349		0.845	0.8477		tp=0.72, tn=0.021, fp=0.26, fn=0		True
	4	0.4988		0.5598		0.291		0.2635		0.8574	0.8297		tp=0.66, tn=0.063, fp=0.24, fn=0.028		True
	5	0.4733		0.5362		0.362		0.253		0.8648	0.8452		tp=0.71, tn=0.035, fp=0.25, fn=0.007		False
	6	0.4474		0.5573		0.4173		0.3412		0.8731	0.8421		tp=0.67, tn=0.077, fp=0.23, fn=0.021		True
	7	0.4198		0.5581		0.4877		0.2624		0.8849	0.8219		tp=0.63, tn=0.098, fp=0.19, fn=0.084		False
	8	0.3954		0.5598		0.5581		0.2873		0.8966	0.8165		tp=0.62, tn=0.098, fp=0.22, fn=0.056		False
	9	0.3696		0.5777		0.6123		0.3187		0.9075	0.8058		tp=0.58, tn=0.14, fp=0.18, fn=0.098		False
	10	0.3444		0.572		0.6515		0.3406		0.9146	0.8349		tp=0.64, tn=0.11, fp=0.19, fn=0.063		False
	11	0.3233		0.5375		0.6788		0.3756		0.9207	0.8411		tp=0.63, tn=0.13, fp=0.15, fn=0.091		True
	12	0.2986		0.5638		0.7186		0.3764		0.9288	0.8177		tp=0.58, tn=0.16, fp=0.15, fn=0.1		True
	13	0.2801		0.5765		0.7607		0.372		0.939	0.8177		tp=0.58, tn=0.16, fp=0.13, fn=0.13		False
	14	0.2563		0.6062		0.786		0.3582		0.9455	0.8302		tp=0.62, tn=0.13, fp=0.17, fn=0.084		False
	15	0.2394		0.5451		0.8012		0.4042		0.9489	0.8365		tp=0.61, tn=0.15, fp=0.14, fn=0.098		True
	16	0.2294		0.5851		0.823		0.3444		0.9532	0.8387		tp=0.64, tn=0.12, fp=0.16, fn=0.084		False
	17	0.2095		0.5793		0.842		0.4805		0.9579	0.8638		tp=0.64, tn=0.15, fp=0.14, fn=0.063		True
	18	0.1937		0.6259		0.8838		0.463		0.9694	0.8611		tp=0.65, tn=0.14, fp=0.16, fn=0.049		False
	19	0.1821		0.5687		0.8987		0.5148		0.9729	0.8744		tp=0.66, tn=0.15, fp=0.14, fn=0.049		True
	20	0.1724		0.6572		0.8895		0.3051		0.9706	0.8509		tp=0.68, tn=0.084, fp=0.18, fn=0.056		False
	21	0.1651		0.548		0.9077		0.485		0.9752	0.8626		tp=0.64, tn=0.16, fp=0.13, fn=0.07		False
	22	0.1544		0.6965		0.9182		0.3668		0.9781	0.7831		tp=0.52, tn=0.2, fp=0.11, fn=0.17		False
	23	0.1462		0.5918		0.9		0.5261		0.9735	0.872		tp=0.64, tn=0.17, fp=0.13, fn=0.056		True
	24	0.1327		0.5327		0.9363		0.5634		0.9828	0.8725		tp=0.62, tn=0.2, fp=0.097, fn=0.083		True
	25	0.1234		0.6081		0.9465		0.4615		0.9857	0.8598		tp=0.64, tn=0.15, fp=0.13, fn=0.076		False
	26	0.116		0.7358		0.9557		0.4425		0.9881	0.8462		tp=0.62, tn=0.16, fp=0.14, fn=0.084		False
	27	0.1081		0.6473		0.9593		0.4385		0.989	0.8624		tp=0.66, tn=0.13, fp=0.15, fn=0.063		False
	28	0.1049		0.6725		0.9574		0.523		0.9886	0.8708		tp=0.64, tn=0.17, fp=0.11, fn=0.077		False
	29	0.0957		0.6771		0.9665		0.5297		0.9909	0.8614		tp=0.61, tn=0.2, fp=0.11, fn=0.084		False
	30	0.09125		0.7236		0.9735		0.467		0.9928	0.8488		tp=0.61, tn=0.17, fp=0.12, fn=0.098		False
	31	0.08571		0.6466		0.9753		0.5483		0.9933	0.8815		tp=0.65, tn=0.17, fp=0.084, fn=0.091		False
	32	0.08066		0.7408		0.9735		0.5408		0.9928	0.8586		tp=0.59, tn=0.21, fp=0.1, fn=0.091		False
	33	0.07574		0.6047		0.9791		0.5923		0.9942	0.89		tp=0.65, tn=0.19, fp=0.091, fn=0.07		True
	34	0.07234		0.7306		0.977		0.5045		0.9938	0.8599		tp=0.62, tn=0.18, fp=0.12, fn=0.083		False
	35	0.06871		0.7595		0.9807		0.5304		0.9947	0.8557		tp=0.6, tn=0.2, fp=0.13, fn=0.069		False
	36	0.06571		0.5766		0.9824		0.5265		0.9952	0.8774		tp=0.65, tn=0.17, fp=0.084, fn=0.098		False
	37	0.0601		0.7487		0.9877		0.5332		0.9966	0.8696		tp=0.63, tn=0.18, fp=0.12, fn=0.07		False
	38	0.05638		0.7782		0.9913		0.5422		0.9976	0.86		tp=0.6, tn=0.21, fp=0.1, fn=0.09		False
	39	0.05824		0.7084		0.9859		0.5555		0.9961	0.8725		tp=0.62, tn=0.2, fp=0.091, fn=0.091		False
	40	0.05271		0.7312		0.9878		0.5481		0.9966	0.8657		tp=0.61, tn=0.2, fp=0.098, fn=0.091		False
	41	0.05184		0.6955		0.9877		0.5559		0.9966	0.8725		tp=0.62, tn=0.2, fp=0.084, fn=0.098		False
	42	0.04733		0.8522		0.9894		0.4819		0.9971	0.8458		tp=0.59, tn=0.19, fp=0.12, fn=0.098		False
	43	0.04612		0.8525		0.9877		0.4769		0.9966	0.8626		tp=0.64, tn=0.16, fp=0.11, fn=0.091		False
	44	0.04358		0.8874		0.9912		0.4254		0.9976	0.8406		tp=0.61, tn=0.16, fp=0.13, fn=0.098		False
	45	0.04189		0.8536		0.993		0.5158		0.9981	0.8641		tp=0.62, tn=0.18, fp=0.11, fn=0.084		False
	46	0.0396		0.8336		0.993		0.4824		0.9981	0.8558		tp=0.62, tn=0.17, fp=0.12, fn=0.09		False
	47	0.03825		0.8477		0.9948		0.5318		0.9986	0.8708		tp=0.63, tn=0.18, fp=0.11, fn=0.076		False
	48	0.03568		0.8662		0.9965		0.4747		0.999	0.8473		tp=0.6, tn=0.18, fp=0.12, fn=0.098		False
	49	0.0355		1.015		0.9929		0.4859		0.9981	0.8458		tp=0.59, tn=0.19, fp=0.13, fn=0.084		False
	50	0.03523		0.8515		0.993		0.5217		0.9981	0.8627		tp=0.62, tn=0.19, fp=0.1, fn=0.091		False
	51	0.03303		0.9855		0.9947		0.4517		0.9986	0.8517		tp=0.62, tn=0.16, fp=0.13, fn=0.091		False
	52	0.03587		1.097		0.9912		0.4935		0.9976	0.8612		tp=0.63, tn=0.17, fp=0.13, fn=0.07		False
	53	0.03235		1.002		0.9929		0.4747		0.9981	0.8473		tp=0.6, tn=0.18, fp=0.12, fn=0.098		False
	54	0.02833		0.8736		0.9965		0.5091		0.999	0.8485		tp=0.59, tn=0.2, fp=0.12, fn=0.091		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		154
learning rate		0.000998477105019
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_182-lr0.001-h_size154-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6749		0.7169		0.1602		0.0421		0.564	0.3273		tp=0.13, tn=0.36, fp=0.084, fn=0.43		True
	2	0.6511		0.6981		0.2581		0.08259		0.5606	0.586		tp=0.32, tn=0.22, fp=0.24, fn=0.22		True
	3	0.6422		0.7003		0.2662		0.1152		0.6224	0.5429		tp=0.27, tn=0.29, fp=0.17, fn=0.27		True
	4	0.6312		0.6797		0.2421		0.1758		0.5969	0.6194		tp=0.33, tn=0.26, fp=0.21, fn=0.2		True
	5	0.6132		0.6949		0.3336		0.1175		0.6425	0.4677		tp=0.2, tn=0.34, fp=0.12, fn=0.34		False
	6	0.5994		0.6787		0.3569		0.2445		0.6605	0.6748		tp=0.38, tn=0.24, fp=0.2, fn=0.17		True
	7	0.5881		0.6739		0.3864		0.2691		0.6809	0.6345		tp=0.32, tn=0.31, fp=0.14, fn=0.23		True
	8	0.5742		0.6707		0.4099		0.2692		0.6884	0.6946		tp=0.41, tn=0.24, fp=0.2, fn=0.15		True
	9	0.5656		0.6796		0.3869		0.2535		0.6876	0.6581		tp=0.36, tn=0.27, fp=0.19, fn=0.18		False
	10	0.5545		0.6863		0.4048		0.2557		0.6984	0.6536		tp=0.35, tn=0.28, fp=0.2, fn=0.17		False
	11	0.5422		0.6879		0.4544		0.2505		0.7216	0.5926		tp=0.28, tn=0.34, fp=0.13, fn=0.26		False
	12	0.5375		0.6812		0.4457		0.3551		0.7024	0.6667		tp=0.34, tn=0.33, fp=0.098, fn=0.24		True
	13	0.524		0.6854		0.4804		0.2855		0.7298	0.6951		tp=0.4, tn=0.25, fp=0.18, fn=0.17		False
	14	0.5143		0.725		0.451		0.2923		0.7145	0.5455		tp=0.23, tn=0.38, fp=0.07, fn=0.31		False
	15	0.5078		0.7191		0.5201		0.2989		0.7397	0.6711		tp=0.36, tn=0.29, fp=0.16, fn=0.19		False
	16	0.5133		0.7301		0.4752		0.2817		0.734	0.5625		tp=0.25, tn=0.36, fp=0.077, fn=0.31		False
	17	0.5074		0.7298		0.463		0.2566		0.7248	0.541		tp=0.23, tn=0.38, fp=0.091, fn=0.3		False
	18	0.4944		0.7439		0.4781		0.2079		0.7201	0.5564		tp=0.26, tn=0.33, fp=0.12, fn=0.29		False
	19	0.4797		0.6888		0.5158		0.3131		0.745	0.6755		tp=0.36, tn=0.3, fp=0.16, fn=0.18		False
	20	0.4596		0.7078		0.5598		0.3293		0.7692	0.6573		tp=0.33, tn=0.33, fp=0.12, fn=0.22		False
	21	0.4646		0.7624		0.5186		0.2445		0.7508	0.6154		tp=0.31, tn=0.31, fp=0.14, fn=0.24		False
	22	0.4482		0.6964		0.5687		0.326		0.7735	0.7		tp=0.39, tn=0.28, fp=0.18, fn=0.15		False
	23	0.4429		0.7824		0.5568		0.2556		0.768	0.5926		tp=0.28, tn=0.34, fp=0.12, fn=0.27		False
	24	0.4363		0.7504		0.5744		0.2357		0.7806	0.6358		tp=0.34, tn=0.28, fp=0.15, fn=0.23		False
	25	0.4434		0.7518		0.563		0.209		0.769	0.6456		tp=0.36, tn=0.25, fp=0.21, fn=0.18		False
	26	0.4208		0.8238		0.6039		0.3316		0.797	0.5439		tp=0.22, tn=0.42, fp=0.056, fn=0.31		False
	27	0.4323		0.7505		0.5715		0.292		0.7761	0.6667		tp=0.35, tn=0.29, fp=0.15, fn=0.2		False
	28	0.417		0.7937		0.5982		0.1931		0.7883	0.6818		tp=0.42, tn=0.19, fp=0.26, fn=0.13		False
	29	0.4289		0.7559		0.5891		0.3124		0.7866	0.6622		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	30	0.4065		0.8105		0.6246		0.2285		0.8025	0.6111		tp=0.31, tn=0.3, fp=0.15, fn=0.24		False
	31	0.3996		0.8273		0.6394		0.2565		0.8167	0.6143		tp=0.3, tn=0.32, fp=0.14, fn=0.24		False
	32	0.4021		0.7775		0.6099		0.2424		0.7944	0.6826		tp=0.4, tn=0.23, fp=0.22, fn=0.15		False
	33	0.3863		0.8424		0.66		0.2814		0.8204	0.6294		tp=0.31, tn=0.31, fp=0.12, fn=0.25		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		150
learning rate		0.00223299465646
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_183-lr0.0022-h_size150-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6945		0.6526		0.05137		0.229		0.4651	0.7368		tp=0.54, tn=0.077, fp=0.36, fn=0.021		True
	2	0.6264		0.6394		0.2806		0.3114		0.6248	0.6797		tp=0.36, tn=0.29, fp=0.17, fn=0.17		True
	3	0.5681		0.6441		0.4426		0.2986		0.7156	0.7232		tp=0.45, tn=0.21, fp=0.24, fn=0.1		False
	4	0.4864		0.6974		0.5837		0.2125		0.7795	0.5972		tp=0.3, tn=0.29, fp=0.13, fn=0.27		False
	5	0.4262		0.688		0.6401		0.3042		0.8075	0.6994		tp=0.4, tn=0.26, fp=0.2, fn=0.15		False
	6	0.3954		0.6749		0.6569		0.2799		0.8197	0.6752		tp=0.37, tn=0.27, fp=0.17, fn=0.18		False
	7	0.3458		0.7794		0.7095		0.287		0.8489	0.6577		tp=0.34, tn=0.3, fp=0.16, fn=0.2		False
	8	0.3257		0.8243		0.736		0.2789		0.8624	0.6338		tp=0.31, tn=0.32, fp=0.15, fn=0.22		False
	9	0.3013		0.974		0.7596		0.2127		0.8776	0.5957		tp=0.29, tn=0.31, fp=0.15, fn=0.24		False
	10	0.2479		0.9449		0.821		0.2917		0.9074	0.6875		tp=0.38, tn=0.27, fp=0.19, fn=0.16		False
	11	0.2206		1.05		0.8357		0.2646		0.9149	0.675		tp=0.38, tn=0.26, fp=0.2, fn=0.16		False
	12	0.2077		1.093		0.8415		0.2375		0.9187	0.6259		tp=0.32, tn=0.29, fp=0.15, fn=0.23		False
	13	0.2055		1.208		0.8474		0.2552		0.9212	0.6536		tp=0.35, tn=0.28, fp=0.19, fn=0.18		False
	14	0.236		1.16		0.8006		0.3163		0.896	0.7073		tp=0.41, tn=0.26, fp=0.19, fn=0.15		True
	15	0.2358		1.32		0.7777		0.2058		0.8876	0.65		tp=0.36, tn=0.24, fp=0.2, fn=0.19		False
	16	0.1685		1.307		0.8829		0.2905		0.9388	0.6914		tp=0.39, tn=0.26, fp=0.2, fn=0.15		False
	17	0.1499		1.353		0.8915		0.2051		0.9439	0.6122		tp=0.31, tn=0.29, fp=0.17, fn=0.22		False
	18	0.1394		1.479		0.8885		0.2235		0.9426	0.6267		tp=0.33, tn=0.28, fp=0.15, fn=0.24		False
	19	0.1102		1.508		0.9384		0.2469		0.9682	0.64		tp=0.34, tn=0.29, fp=0.16, fn=0.22		False
	20	0.1036		1.694		0.9472		0.2552		0.973	0.6536		tp=0.35, tn=0.28, fp=0.18, fn=0.19		False
	21	0.09945		1.66		0.9473		0.3016		0.9726	0.6994		tp=0.4, tn=0.26, fp=0.18, fn=0.16		False
	22	0.09578		1.812		0.9443		0.2158		0.9714	0.6316		tp=0.34, tn=0.27, fp=0.17, fn=0.22		False
	23	0.07613		1.924		0.9677		0.2149		0.9835	0.6267		tp=0.33, tn=0.28, fp=0.2, fn=0.2		False
	24	0.08018		2.004		0.9619		0.2669		0.9805	0.6667		tp=0.36, tn=0.27, fp=0.17, fn=0.19		False
	25	0.07069		2.14		0.968		0.2216		0.9832	0.6541		tp=0.36, tn=0.25, fp=0.18, fn=0.2		False
	26	0.06513		2.022		0.9707		0.3142		0.9849	0.6667		tp=0.34, tn=0.31, fp=0.17, fn=0.17		False
	27	0.05661		2.285		0.9853		0.2897		0.9925	0.6483		tp=0.33, tn=0.31, fp=0.15, fn=0.2		False
	28	0.07752		2.242		0.9531		0.2614		0.9758	0.649		tp=0.34, tn=0.29, fp=0.15, fn=0.22		False
	29	0.07032		2.33		0.956		0.272		0.9774	0.6533		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	30	0.06122		2.313		0.9736		0.3178		0.9864	0.6755		tp=0.36, tn=0.3, fp=0.14, fn=0.2		True
	31	0.04396		2.551		0.9883		0.2929		0.9939	0.6835		tp=0.38, tn=0.27, fp=0.17, fn=0.17		False
	32	0.04265		2.339		0.9912		0.2404		0.9955	0.6259		tp=0.32, tn=0.29, fp=0.15, fn=0.24		False
	33	0.03915		2.617		0.9912		0.2876		0.9955	0.6623		tp=0.35, tn=0.29, fp=0.15, fn=0.2		False
	34	0.02689		2.578		0.9971		0.2982		0.9985	0.6711		tp=0.36, tn=0.29, fp=0.17, fn=0.18		False
	35	0.02955		2.869		0.9941		0.2667		0.997	0.6667		tp=0.36, tn=0.27, fp=0.18, fn=0.18		False
	36	0.0301		2.983		0.9971		0.259		0.9985	0.6443		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	37	0.03005		2.906		1		0.25		1	0.6351		tp=0.33, tn=0.29, fp=0.15, fn=0.22		False
	38	0.02587		3.034		0.9971		0.2535		0.9985	0.6581		tp=0.36, tn=0.27, fp=0.18, fn=0.19		False
	39	0.02947		3.161		0.9912		0.2626		0.9955	0.675		tp=0.38, tn=0.26, fp=0.17, fn=0.19		False
	40	0.02211		3.074		0.9941		0.258		0.997	0.649		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	41	0.01999		3.464		0.9971		0.2254		0.9985	0.6452		tp=0.35, tn=0.27, fp=0.19, fn=0.2		False
	42	0.01693		3.342		1		0.2758		1	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.19		False
	43	0.01315		2.898		1		0.2968		1	0.6753		tp=0.36, tn=0.29, fp=0.17, fn=0.18		False
	44	0.01209		3.499		1		0.2597		1	0.6395		tp=0.33, tn=0.3, fp=0.17, fn=0.2		False
	45	0.01213		3.501		1		0.2667		1	0.6667		tp=0.36, tn=0.27, fp=0.18, fn=0.18		False
	46	0.01136		3.632		1		0.2412		1	0.6494		tp=0.35, tn=0.27, fp=0.17, fn=0.2		False
	47	0.01123		3.421		1		0.2799		1	0.6752		tp=0.37, tn=0.27, fp=0.17, fn=0.18		False
	48	0.01073		3.651		1		0.2701		1	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.19		False
	49	0.0135		3.823		1		0.2405		1	0.6494		tp=0.35, tn=0.27, fp=0.18, fn=0.2		False
	50	0.01386		3.385		1		0.2949		1	0.6795		tp=0.37, tn=0.28, fp=0.17, fn=0.17		False
	51	0.01458		3.974		1		0.2361		1	0.6625		tp=0.37, tn=0.25, fp=0.17, fn=0.21		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		18
learning rate		0.000114907759299
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_184-lr0.00011-h_size18-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.694		0.6878		-0.004721		0.1542		0.3734	0.5191		tp=0.24, tn=0.32, fp=0.13, fn=0.31		True
	2	0.6802		0.6784		0.3006		0.2609		0.6781	0.7143		tp=0.45, tn=0.18, fp=0.27, fn=0.091		True
	3	0.6705		0.6787		0.3812		0.2852		0.6855	0.6131		tp=0.29, tn=0.34, fp=0.11, fn=0.26		True
	4	0.6594		0.6724		0.4427		0.2557		0.7013	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	5	0.6502		0.6667		0.4601		0.2828		0.7134	0.6792		tp=0.38, tn=0.27, fp=0.21, fn=0.15		False
	6	0.6396		0.6659		0.4727		0.2568		0.7345	0.625		tp=0.31, tn=0.31, fp=0.14, fn=0.24		False
	7	0.6302		0.6616		0.4953		0.3119		0.7329	0.6797		tp=0.36, tn=0.29, fp=0.16, fn=0.18		True
	8	0.6207		0.6589		0.4944		0.263		0.7129	0.6029		tp=0.29, tn=0.34, fp=0.13, fn=0.25		False
	9	0.6109		0.658		0.504		0.2275		0.7388	0.6405		tp=0.34, tn=0.27, fp=0.18, fn=0.2		False
	10	0.6018		0.6529		0.5486		0.2687		0.7594	0.6187		tp=0.3, tn=0.33, fp=0.14, fn=0.23		False
	11	0.5939		0.6487		0.5422		0.3254		0.76	0.6923		tp=0.38, tn=0.29, fp=0.19, fn=0.15		True
	12	0.5832		0.6559		0.5823		0.2443		0.7727	0.6099		tp=0.3, tn=0.31, fp=0.14, fn=0.24		False
	13	0.5752		0.6438		0.5575		0.2483		0.754	0.6301		tp=0.32, tn=0.3, fp=0.16, fn=0.22		False
	14	0.567		0.6352		0.5715		0.2741		0.7795	0.6486		tp=0.34, tn=0.3, fp=0.16, fn=0.2		False
	15	0.5581		0.6448		0.592		0.2196		0.7756	0.6216		tp=0.32, tn=0.29, fp=0.17, fn=0.22		False
	16	0.5508		0.6341		0.6072		0.2976		0.7919	0.6753		tp=0.36, tn=0.29, fp=0.16, fn=0.19		False
	17	0.5428		0.6361		0.6104		0.246		0.7925	0.6351		tp=0.33, tn=0.29, fp=0.17, fn=0.21		False
	18	0.5331		0.647		0.6136		0.2439		0.7931	0.6259		tp=0.32, tn=0.29, fp=0.14, fn=0.24		False
	19	0.5281		0.637		0.6099		0.2404		0.7944	0.6043		tp=0.29, tn=0.32, fp=0.15, fn=0.24		False
	20	0.5184		0.6221		0.6504		0.2738		0.8033	0.6579		tp=0.35, tn=0.29, fp=0.15, fn=0.21		False
	21	0.511		0.6421		0.6244		0.207		0.8072	0.6122		tp=0.31, tn=0.29, fp=0.17, fn=0.23		False
	22	0.5032		0.6405		0.67		0.2019		0.8161	0.6323		tp=0.34, tn=0.26, fp=0.17, fn=0.23		False
	23	0.4948		0.6289		0.6628		0.272		0.8228	0.6533		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	24	0.4874		0.6402		0.6726		0.2187		0.8245	0.6267		tp=0.33, tn=0.28, fp=0.17, fn=0.22		False
	25	0.4805		0.632		0.677		0.2351		0.8235	0.6259		tp=0.32, tn=0.29, fp=0.16, fn=0.22		False
	26	0.4736		0.6428		0.7124		0.2223		0.8524	0.6316		tp=0.34, tn=0.27, fp=0.15, fn=0.24		False
	27	0.4676		0.6101		0.6937		0.3281		0.8346	0.68		tp=0.36, tn=0.31, fp=0.15, fn=0.18		True
	28	0.459		0.6282		0.7132		0.2282		0.8478	0.6		tp=0.29, tn=0.31, fp=0.15, fn=0.24		False
	29	0.4515		0.6261		0.7224		0.2245		0.8518	0.6216		tp=0.32, tn=0.29, fp=0.15, fn=0.24		False
	30	0.4448		0.6427		0.7506		0.178		0.8706	0.604		tp=0.31, tn=0.27, fp=0.17, fn=0.24		False
	31	0.4384		0.6406		0.742		0.169		0.865	0.5775		tp=0.29, tn=0.29, fp=0.17, fn=0.25		False
	32	0.4323		0.6374		0.7459		0.2884		0.8643	0.6914		tp=0.39, tn=0.26, fp=0.18, fn=0.17		False
	33	0.4254		0.6397		0.7505		0.1963		0.8714	0.6081		tp=0.31, tn=0.28, fp=0.16, fn=0.24		False
	34	0.4177		0.6352		0.7757		0.2171		0.8795	0.6267		tp=0.33, tn=0.28, fp=0.17, fn=0.22		False
	35	0.4121		0.6425		0.7711		0.2114		0.8822	0.6174		tp=0.32, tn=0.28, fp=0.15, fn=0.24		False
	36	0.4054		0.6488		0.7918		0.2122		0.8916	0.5899		tp=0.29, tn=0.31, fp=0.15, fn=0.24		False
	37	0.3987		0.6201		0.7979		0.2969		0.894	0.6531		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	38	0.3932		0.6487		0.8094		0.2363		0.9008	0.6056		tp=0.3, tn=0.31, fp=0.13, fn=0.26		False
	39	0.3865		0.6287		0.81		0.25		0.8995	0.6351		tp=0.33, tn=0.29, fp=0.15, fn=0.22		False
	40	0.3813		0.6377		0.8298		0.2443		0.9129	0.6099		tp=0.3, tn=0.31, fp=0.14, fn=0.24		False
	41	0.3756		0.6409		0.8263		0.2211		0.9057	0.6541		tp=0.36, tn=0.25, fp=0.2, fn=0.19		False
	42	0.369		0.6407		0.8445		0.2483		0.9201	0.6207		tp=0.31, tn=0.3, fp=0.13, fn=0.25		False
	43	0.3629		0.6443		0.8468		0.246		0.9168	0.6351		tp=0.33, tn=0.29, fp=0.17, fn=0.21		False
	44	0.3604		0.6475		0.8478		0.2387		0.9202	0.6538		tp=0.36, tn=0.27, fp=0.18, fn=0.2		False
	45	0.3535		0.636		0.8327		0.2766		0.9138	0.6241		tp=0.31, tn=0.32, fp=0.13, fn=0.24		False
	46	0.3465		0.6501		0.8421		0.2822		0.9169	0.671		tp=0.36, tn=0.28, fp=0.17, fn=0.19		False
	47	0.3401		0.6407		0.8567		0.2379		0.9247	0.6207		tp=0.31, tn=0.3, fp=0.15, fn=0.23		False
	48	0.3351		0.6382		0.8684		0.2892		0.9309	0.6531		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False


data			/scratch/asw462/data/levin
input size		300
hidden size		22
learning rate		0.000158618496725
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_185-lr0.00016-h_size22-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6344		0.5864		-0.001081		0		0.7771	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5818		0.6025		0		0		0.843	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.5802		0.5808		0		0		0.8426	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	4	0.579		0.586		0		0		0.8418	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	5	0.577		0.5775		0		0		0.8416	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	6	0.5743		0.5664		0		0		0.8421	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	7	0.574		0.5902		0		0		0.8402	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	8	0.5723		0.5987		0		0		0.8394	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	9	0.5658		0.5746		0		0		0.843	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	10	0.5661		0.5557		0		0		0.8412	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	11	0.5625		0.5834		0		0		0.8416	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	12	0.5593		0.5888		0		0		0.8426	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	13	0.559		0.5522		0		0		0.8407	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	14	0.5549		0.5627		0		0		0.8412	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	15	0.5483		0.6013		0.06166		0		0.8451	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	16	0.5477		0.5626		0.08618		0		0.8425	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	17	0.5449		0.5771		0.1056		0		0.8432	0.8245		tp=0.7, tn=0, fp=0.3, fn=0		False
	18	0.543		0.5847		0.1141		0		0.8437	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	19	0.537		0.5797		0.1373		0		0.8462	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	20	0.5346		0.5725		0.1567		-0.05595		0.847	0.8133		tp=0.69, tn=0, fp=0.31, fn=0.007		False
	21	0.5308		0.5807		0.1844		-0.05503		0.8484	0.8182		tp=0.69, tn=0, fp=0.3, fn=0.007		False


data			/scratch/asw462/data/levin
input size		300
hidden size		185
learning rate		6.73071996152e&05
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_186-lr6.7e&05-h_size185-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6146		0.6019		-0.005779		0		0.8097	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5791		0.6079		0		0		0.8432	0.8197		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.5785		0.6045		0		0		0.8407	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	4	0.575		0.5982		0		0		0.8399	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	5	0.5663		0.5793		0		0		0.8444	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	6	0.5673		0.5864		0		0		0.8402	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	7	0.5659		0.5817		0		0		0.8389	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	8	0.5619		0.589		0		0		0.8407	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	9	0.5573		0.5866		0		0		0.8421	0.8245		tp=0.7, tn=0, fp=0.3, fn=0		False
	10	0.5524		0.5555		0		0		0.8421	0.8514		tp=0.74, tn=0, fp=0.26, fn=0		False
	11	0.5456		0.5946		0		0		0.843	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	12	0.5468		0.5973		0.04297		0		0.841	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	13	0.5403		0.5968		0.06145		0		0.8443	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	14	0.5405		0.5795		0.1139		0		0.8431	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	15	0.5344		0.5795		0.1147		0		0.845	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	16	0.5309		0.5917		0.1371		0		0.8457	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	17	0.5294		0.5863		0.1559		0		0.8456	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	18	0.5295		0.5818		0.1769		0.0501		0.8446	0.8182		tp=0.69, tn=0.0069, fp=0.3, fn=0.0069		True
	19	0.5193		0.5709		0.1908		0		0.8505	0.8245		tp=0.7, tn=0, fp=0.3, fn=0		False
	20	0.5174		0.5606		0.2066		0		0.8508	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	21	0.5187		0.5808		0.1945		0.1816		0.8465	0.8299		tp=0.7, tn=0.014, fp=0.29, fn=0		True
	22	0.5114		0.5707		0.2243		0.1758		0.8506	0.8368		tp=0.7, tn=0.028, fp=0.26, fn=0.014		False
	23	0.5096		0.5942		0.238		0.1586		0.8517	0.817		tp=0.67, tn=0.028, fp=0.29, fn=0.014		False
	24	0.5072		0.5845		0.2633		0.1199		0.8528	0.8299		tp=0.7, tn=0.014, fp=0.28, fn=0.007		False
	25	0.5031		0.5619		0.2893		0.1738		0.8577	0.8382		tp=0.71, tn=0.021, fp=0.27, fn=0.007		False
	26	0.4983		0.5745		0.2887		0.2388		0.8563	0.8326		tp=0.68, tn=0.049, fp=0.25, fn=0.021		True
	27	0.4955		0.5677		0.3121		0.2696		0.8583	0.8376		tp=0.69, tn=0.049, fp=0.25, fn=0.014		True
	28	0.4947		0.5835		0.3216		0.2073		0.858	0.8319		tp=0.69, tn=0.028, fp=0.27, fn=0.007		False
	29	0.4868		0.586		0.3031		0.2304		0.8588	0.8225		tp=0.66, tn=0.056, fp=0.26, fn=0.028		False
	30	0.4853		0.5624		0.3344		0.1844		0.8624	0.8291		tp=0.68, tn=0.042, fp=0.25, fn=0.028		False
	31	0.4812		0.5942		0.3472		0.203		0.8633	0.827		tp=0.69, tn=0.028, fp=0.28, fn=0.007		False
	32	0.4791		0.5619		0.3359		0.1957		0.8616	0.839		tp=0.69, tn=0.042, fp=0.24, fn=0.028		False
	33	0.4763		0.601		0.33		0.2221		0.8609	0.8174		tp=0.66, tn=0.049, fp=0.27, fn=0.021		False
	34	0.4745		0.5722		0.3664		0.2232		0.8643	0.8376		tp=0.69, tn=0.049, fp=0.24, fn=0.028		False
	35	0.4711		0.5718		0.3477		0.2172		0.8621	0.8326		tp=0.68, tn=0.049, fp=0.24, fn=0.028		False
	36	0.467		0.6025		0.3676		0.1339		0.8652	0.822		tp=0.68, tn=0.028, fp=0.27, fn=0.021		False
	37	0.4635		0.5988		0.3724		0.2065		0.8668	0.824		tp=0.67, tn=0.049, fp=0.26, fn=0.028		False
	38	0.4579		0.5532		0.348		0.1491		0.8648	0.8276		tp=0.67, tn=0.049, fp=0.22, fn=0.056		False
	39	0.4573		0.5858		0.3883		0.2415		0.8689	0.8312		tp=0.67, tn=0.056, fp=0.24, fn=0.028		False
	40	0.4564		0.5889		0.4035		0.2703		0.8695	0.839		tp=0.69, tn=0.049, fp=0.25, fn=0.014		True
	41	0.4523		0.5761		0.4391		0.1494		0.8766	0.8158		tp=0.65, tn=0.056, fp=0.23, fn=0.063		False
	42	0.4518		0.6052		0.3996		0.244		0.8698	0.823		tp=0.65, tn=0.07, fp=0.24, fn=0.042		False
	43	0.4485		0.5755		0.4573		0.2703		0.8771	0.839		tp=0.69, tn=0.049, fp=0.25, fn=0.014		False
	44	0.4436		0.5662		0.4251		0.2113		0.8748	0.8276		tp=0.67, tn=0.049, fp=0.25, fn=0.028		False
	45	0.4398		0.604		0.4547		0.264		0.8793	0.8326		tp=0.68, tn=0.049, fp=0.26, fn=0.014		False
	46	0.4409		0.6206		0.4538		0.2507		0.8772	0.821		tp=0.66, tn=0.056, fp=0.27, fn=0.021		False
	47	0.435		0.5978		0.4627		0.1823		0.8808	0.8326		tp=0.68, tn=0.049, fp=0.23, fn=0.042		False
	48	0.4353		0.5837		0.4573		0.1995		0.8771	0.834		tp=0.68, tn=0.049, fp=0.24, fn=0.035		False
	49	0.4319		0.6177		0.4653		0.1432		0.8789	0.8122		tp=0.65, tn=0.049, fp=0.25, fn=0.049		False
	50	0.4323		0.5908		0.4707		0.2256		0.8794	0.8267		tp=0.65, tn=0.077, fp=0.2, fn=0.07		False
	51	0.4331		0.6316		0.491		0.2195		0.8841	0.8018		tp=0.61, tn=0.091, fp=0.22, fn=0.077		False
	52	0.4291		0.6092		0.4971		0.1778		0.8829	0.8106		tp=0.64, tn=0.062, fp=0.24, fn=0.056		False
	53	0.4237		0.5998		0.4878		0.1494		0.8831	0.8158		tp=0.65, tn=0.056, fp=0.23, fn=0.063		False
	54	0.421		0.6318		0.4937		0.134		0.883	0.7928		tp=0.62, tn=0.063, fp=0.25, fn=0.07		False
	55	0.417		0.6161		0.4811		0.2629		0.8813	0.8214		tp=0.64, tn=0.077, fp=0.24, fn=0.042		False
	56	0.4157		0.6114		0.5136		0.2774		0.8854	0.8203		tp=0.62, tn=0.1, fp=0.19, fn=0.084		True
	57	0.4156		0.6347		0.5075		0.2507		0.8855	0.821		tp=0.66, tn=0.056, fp=0.27, fn=0.021		False
	58	0.411		0.5906		0.5104		0.2582		0.8888	0.8333		tp=0.66, tn=0.07, fp=0.22, fn=0.042		False
	59	0.4102		0.5984		0.5148		0.2856		0.8872	0.8273		tp=0.64, tn=0.098, fp=0.2, fn=0.07		True
	60	0.4099		0.6149		0.5363		0.2814		0.8898	0.8257		tp=0.63, tn=0.1, fp=0.17, fn=0.091		False
	61	0.4042		0.6287		0.534		0.2043		0.89	0.8054		tp=0.62, tn=0.077, fp=0.24, fn=0.063		False
	62	0.4027		0.5979		0.5503		0.2141		0.8939	0.8362		tp=0.68, tn=0.056, fp=0.22, fn=0.042		False
	63	0.3997		0.6164		0.5266		0.2915		0.89	0.8203		tp=0.62, tn=0.1, fp=0.2, fn=0.07		True
	64	0.3996		0.644		0.5671		0.2227		0.8965	0.8108		tp=0.63, tn=0.077, fp=0.24, fn=0.056		False
	65	0.399		0.6043		0.5343		0.2696		0.8899	0.8356		tp=0.66, tn=0.084, fp=0.2, fn=0.063		False
	66	0.3926		0.6167		0.5763		0.2302		0.8992	0.8297		tp=0.66, tn=0.063, fp=0.23, fn=0.042		False
	67	0.3899		0.6108		0.5655		0.244		0.8977	0.8251		tp=0.64, tn=0.084, fp=0.2, fn=0.07		False
	68	0.3907		0.6565		0.5868		0.1699		0.9003	0.8225		tp=0.66, tn=0.049, fp=0.24, fn=0.042		False
	69	0.3891		0.6465		0.5643		0.2371		0.8961	0.8145		tp=0.63, tn=0.084, fp=0.22, fn=0.063		False
	70	0.3855		0.6665		0.5439		0.2798		0.893	0.8075		tp=0.6, tn=0.11, fp=0.21, fn=0.077		False
	71	0.3889		0.612		0.567		0.2712		0.895	0.8304		tp=0.65, tn=0.084, fp=0.21, fn=0.056		False
	72	0.3857		0.632		0.5733		0.2782		0.8972	0.8288		tp=0.64, tn=0.091, fp=0.2, fn=0.063		False
	73	0.3816		0.6667		0.6014		0.2449		0.9027	0.8333		tp=0.66, tn=0.07, fp=0.22, fn=0.049		False
	74	0.3809		0.6261		0.5756		0.2782		0.8987	0.8288		tp=0.64, tn=0.091, fp=0.2, fn=0.063		False
	75	0.3748		0.5839		0.5854		0.397		0.901	0.8571		tp=0.67, tn=0.11, fp=0.17, fn=0.049		True
	76	0.3756		0.6389		0.5958		0.3274		0.9024	0.8393		tp=0.66, tn=0.091, fp=0.21, fn=0.042		False
	77	0.3712		0.7008		0.5845		0.2477		0.9	0.8145		tp=0.63, tn=0.084, fp=0.23, fn=0.056		False
	78	0.3736		0.6676		0.6074		0.3193		0.9045	0.8341		tp=0.65, tn=0.091, fp=0.22, fn=0.042		False
	79	0.369		0.6629		0.6209		0.3145		0.9086	0.8273		tp=0.64, tn=0.098, fp=0.22, fn=0.049		False
	80	0.3666		0.6867		0.6115		0.2877		0.905	0.8075		tp=0.6, tn=0.11, fp=0.22, fn=0.07		False
	81	0.3647		0.6339		0.6152		0.3658		0.9071	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.07		False
	82	0.3667		0.6568		0.6111		0.3346		0.9058	0.8326		tp=0.64, tn=0.098, fp=0.22, fn=0.042		False
	83	0.371		0.6555		0.5922		0.2582		0.9016	0.8235		tp=0.63, tn=0.097, fp=0.18, fn=0.09		False
	84	0.3632		0.6328		0.6291		0.2868		0.9082	0.8341		tp=0.65, tn=0.091, fp=0.2, fn=0.063		False
	85	0.3678		0.6048		0.5951		0.4026		0.9019	0.8479		tp=0.64, tn=0.13, fp=0.17, fn=0.056		True
	86	0.3594		0.6356		0.6199		0.3488		0.9068	0.8444		tp=0.66, tn=0.091, fp=0.21, fn=0.035		False
	87	0.3582		0.668		0.6087		0.2709		0.905	0.837		tp=0.66, tn=0.083, fp=0.19, fn=0.062		False
	88	0.3563		0.6763		0.6211		0.2915		0.9066	0.8203		tp=0.62, tn=0.1, fp=0.2, fn=0.07		False
	89	0.3557		0.7104		0.62		0.2617		0.9076	0.8182		tp=0.63, tn=0.091, fp=0.22, fn=0.063		False
	90	0.3523		0.6669		0.6369		0.3071		0.911	0.8241		tp=0.62, tn=0.11, fp=0.19, fn=0.077		False
	91	0.3481		0.6519		0.6282		0.3107		0.9106	0.8295		tp=0.63, tn=0.11, fp=0.17, fn=0.084		False
	92	0.3482		0.6529		0.6448		0.3544		0.9113	0.8416		tp=0.65, tn=0.1, fp=0.2, fn=0.049		False
	93	0.3467		0.6488		0.6522		0.3329		0.9135	0.8349		tp=0.64, tn=0.11, fp=0.18, fn=0.07		False
	94	0.3469		0.6636		0.6521		0.3328		0.9142	0.8311		tp=0.63, tn=0.11, fp=0.19, fn=0.062		False
	95	0.3438		0.6819		0.6405		0.2793		0.9113	0.8356		tp=0.66, tn=0.084, fp=0.2, fn=0.056		False
	96	0.3429		0.6922		0.6447		0.3314		0.913	0.8295		tp=0.63, tn=0.11, fp=0.2, fn=0.063		False
	97	0.3443		0.6778		0.6561		0.3134		0.915	0.8341		tp=0.65, tn=0.097, fp=0.2, fn=0.056		False
	98	0.3428		0.7114		0.6311		0.2524		0.9075	0.8304		tp=0.65, tn=0.084, fp=0.2, fn=0.07		False
	99	0.3378		0.6816		0.6649		0.3095		0.9163	0.8311		tp=0.64, tn=0.1, fp=0.19, fn=0.07		False
	100	0.3395		0.6944		0.6494		0.3004		0.9138	0.8257		tp=0.63, tn=0.1, fp=0.2, fn=0.07		False
	101	0.3462		0.6215		0.6376		0.3303		0.9088	0.8482		tp=0.66, tn=0.098, fp=0.17, fn=0.063		False
	102	0.3395		0.6984		0.6661		0.2904		0.9162	0.8356		tp=0.66, tn=0.084, fp=0.21, fn=0.049		False
	103	0.344		0.6801		0.6125		0.3544		0.905	0.8295		tp=0.62, tn=0.12, fp=0.2, fn=0.056		False
	104	0.3355		0.639		0.6537		0.3633		0.9137	0.852		tp=0.66, tn=0.1, fp=0.17, fn=0.056		False
	105	0.3359		0.6845		0.6467		0.2877		0.9128	0.8407		tp=0.66, tn=0.084, fp=0.2, fn=0.056		False
	106	0.3325		0.7177		0.6453		0.3201		0.912	0.8224		tp=0.62, tn=0.12, fp=0.19, fn=0.077		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		114
learning rate		0.000600100922706
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_187-lr0.0006-h_size114-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6816		0.6697		0.1288		0.1465		0.6036	0.5951		tp=0.31, tn=0.26, fp=0.22, fn=0.21		True
	2	0.6719		0.673		0.1764		0.135		0.6121	0.6178		tp=0.35, tn=0.23, fp=0.24, fn=0.18		False
	3	0.6642		0.6722		0.2009		0.1482		0.6202	0.599		tp=0.32, tn=0.26, fp=0.22, fn=0.2		True
	4	0.6599		0.6799		0.2097		0.1356		0.6226	0.5183		tp=0.24, tn=0.33, fp=0.15, fn=0.28		False
	5	0.655		0.6798		0.2137		0.1715		0.623	0.6734		tp=0.42, tn=0.16, fp=0.31, fn=0.1		True
	6	0.6511		0.6767		0.2411		0.1608		0.6377	0.611		tp=0.33, tn=0.25, fp=0.23, fn=0.19		False
	7	0.6448		0.6794		0.2471		0.1186		0.6435	0.6014		tp=0.33, tn=0.23, fp=0.24, fn=0.2		False
	8	0.6415		0.6883		0.2638		0.1286		0.6512	0.6286		tp=0.37, tn=0.2, fp=0.28, fn=0.15		False
	9	0.6439		0.6809		0.2457		0.1551		0.6402	0.6386		tp=0.37, tn=0.21, fp=0.26, fn=0.16		False
	10	0.6392		0.6889		0.2611		0.1722		0.6439	0.6491		tp=0.38, tn=0.21, fp=0.26, fn=0.15		True
	11	0.636		0.6868		0.2707		0.1424		0.653	0.6626		tp=0.42, tn=0.16, fp=0.31, fn=0.11		False
	12	0.6335		0.702		0.2806		0.1602		0.6588	0.5553		tp=0.26, tn=0.31, fp=0.17, fn=0.25		False
	13	0.6318		0.6876		0.2706		0.1314		0.6464	0.6216		tp=0.35, tn=0.22, fp=0.25, fn=0.18		False
	14	0.633		0.7027		0.2664		0.09555		0.6459	0.6099		tp=0.35, tn=0.21, fp=0.26, fn=0.18		False
	15	0.6295		0.7018		0.2894		0.1172		0.6574	0.6032		tp=0.33, tn=0.23, fp=0.25, fn=0.19		False
	16	0.6275		0.7011		0.2979		0.1051		0.6629	0.6041		tp=0.34, tn=0.22, fp=0.26, fn=0.19		False
	17	0.6274		0.7459		0.2807		0.1211		0.6561	0.678		tp=0.46, tn=0.11, fp=0.36, fn=0.072		False
	18	0.63		0.693		0.2854		0.145		0.6564	0.601		tp=0.32, tn=0.25, fp=0.22, fn=0.21		False
	19	0.6252		0.6981		0.3026		0.1019		0.6646	0.5915		tp=0.32, tn=0.23, fp=0.24, fn=0.2		False
	20	0.6196		0.7044		0.2902		0.09071		0.6614	0.6223		tp=0.37, tn=0.18, fp=0.29, fn=0.16		False
	21	0.6227		0.7068		0.2949		0.1641		0.6614	0.5838		tp=0.29, tn=0.28, fp=0.18, fn=0.24		False
	22	0.6224		0.7027		0.2948		0.1538		0.6567	0.6114		tp=0.33, tn=0.25, fp=0.22, fn=0.2		False
	23	0.621		0.7175		0.3055		0.1672		0.667	0.5676		tp=0.27, tn=0.31, fp=0.18, fn=0.24		False
	24	0.6202		0.7002		0.2967		0.1266		0.6625	0.5833		tp=0.31, tn=0.26, fp=0.21, fn=0.23		False
	25	0.6186		0.7193		0.3062		0.09579		0.6665	0.6298		tp=0.38, tn=0.17, fp=0.3, fn=0.15		False
	26	0.6157		0.7125		0.3085		0.1443		0.6684	0.5579		tp=0.27, tn=0.3, fp=0.18, fn=0.25		False
	27	0.6174		0.7221		0.3145		0.116		0.6714	0.5435		tp=0.26, tn=0.29, fp=0.19, fn=0.25		False
	28	0.6178		0.717		0.3084		0.074		0.6626	0.6167		tp=0.37, tn=0.17, fp=0.3, fn=0.15		False
	29	0.6236		0.7013		0.286		0.1151		0.6556	0.6019		tp=0.33, tn=0.23, fp=0.24, fn=0.2		False
	30	0.617		0.6999		0.324		0.1112		0.6757	0.591		tp=0.32, tn=0.24, fp=0.24, fn=0.2		False
	31	0.6156		0.7206		0.304		0.1327		0.6697	0.5806		tp=0.3, tn=0.27, fp=0.21, fn=0.23		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		91
learning rate		0.00117934144329
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_188-lr0.0012-h_size91-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.701		0.6777		0.03922		0.1583		0.5489	0.5885		tp=0.3, tn=0.28, fp=0.2, fn=0.22		True
	2	0.6779		0.6713		0.135		0.1883		0.5899	0.6722		tp=0.41, tn=0.18, fp=0.29, fn=0.12		True
	3	0.6694		0.6724		0.1706		0.1628		0.606	0.668		tp=0.42, tn=0.16, fp=0.33, fn=0.095		False
	4	0.6625		0.6714		0.2107		0.1886		0.6208	0.6549		tp=0.38, tn=0.22, fp=0.24, fn=0.16		True
	5	0.6529		0.678		0.237		0.1698		0.6261	0.5909		tp=0.3, tn=0.28, fp=0.19, fn=0.22		False
	6	0.655		0.6844		0.2135		0.1206		0.6271	0.6654		tp=0.44, tn=0.12, fp=0.36, fn=0.079		False
	7	0.642		0.6807		0.2445		0.1595		0.6325	0.59		tp=0.3, tn=0.28, fp=0.19, fn=0.23		False
	8	0.6365		0.6811		0.2593		0.1311		0.6396	0.5685		tp=0.29, tn=0.28, fp=0.19, fn=0.24		False
	9	0.6317		0.6995		0.2771		0.09928		0.6497	0.5354		tp=0.26, tn=0.29, fp=0.19, fn=0.26		False
	10	0.6319		0.6917		0.2623		0.1177		0.6397	0.6705		tp=0.44, tn=0.12, fp=0.35, fn=0.085		False
	11	0.6251		0.6805		0.2836		0.1576		0.6511	0.6479		tp=0.38, tn=0.2, fp=0.27, fn=0.14		False
	12	0.6224		0.694		0.2961		0.1595		0.66	0.6384		tp=0.37, tn=0.22, fp=0.25, fn=0.16		False
	13	0.6156		0.699		0.3104		0.1203		0.6632	0.5042		tp=0.23, tn=0.32, fp=0.15, fn=0.3		False
	14	0.6185		0.698		0.3051		0.1377		0.6565	0.5362		tp=0.26, tn=0.3, fp=0.15, fn=0.29		False
	15	0.6145		0.6884		0.3138		0.1957		0.6688	0.6338		tp=0.35, tn=0.25, fp=0.22, fn=0.18		True
	16	0.6019		0.7033		0.3422		0.1325		0.6762	0.6424		tp=0.38, tn=0.19, fp=0.28, fn=0.15		False
	17	0.6089		0.6925		0.3321		0.08777		0.6751	0.5326		tp=0.26, tn=0.28, fp=0.19, fn=0.27		False
	18	0.5956		0.7037		0.3416		0.1419		0.6769	0.6193		tp=0.35, tn=0.23, fp=0.25, fn=0.18		False
	19	0.5942		0.7462		0.3617		0.1498		0.687	0.3688		tp=0.13, tn=0.41, fp=0.064, fn=0.39		False
	20	0.5855		0.752		0.3682		0.08437		0.691	0.392		tp=0.15, tn=0.38, fp=0.11, fn=0.36		False
	21	0.5822		0.7179		0.373		0.14		0.6922	0.5341		tp=0.25, tn=0.31, fp=0.16, fn=0.28		False
	22	0.5894		0.7019		0.3553		0.1578		0.6822	0.6418		tp=0.37, tn=0.21, fp=0.26, fn=0.15		False
	23	0.5716		0.704		0.3914		0.184		0.7028	0.6035		tp=0.31, tn=0.28, fp=0.2, fn=0.21		False
	24	0.5626		0.7291		0.4161		0.1415		0.7154	0.5043		tp=0.22, tn=0.34, fp=0.14, fn=0.3		False
	25	0.5652		0.7164		0.4155		0.1495		0.7128	0.6306		tp=0.36, tn=0.22, fp=0.25, fn=0.17		False
	26	0.5605		0.7163		0.4115		0.1367		0.7136	0.6019		tp=0.32, tn=0.25, fp=0.23, fn=0.2		False
	27	0.5441		0.7482		0.4545		0.1727		0.7335	0.5429		tp=0.25, tn=0.33, fp=0.14, fn=0.28		False
	28	0.5434		0.7254		0.448		0.1572		0.7285	0.5885		tp=0.3, tn=0.28, fp=0.19, fn=0.23		False
	29	0.5333		0.7659		0.4493		0.139		0.7339	0.5278		tp=0.24, tn=0.32, fp=0.16, fn=0.28		False
	30	0.5336		0.749		0.4586		0.1188		0.7342	0.5323		tp=0.25, tn=0.3, fp=0.17, fn=0.28		False
	31	0.518		0.7518		0.4888		0.165		0.7505	0.5159		tp=0.23, tn=0.34, fp=0.13, fn=0.3		False
	32	0.5144		0.7407		0.4748		0.116		0.7428	0.5845		tp=0.31, tn=0.25, fp=0.24, fn=0.2		False
	33	0.4989		0.74		0.5161		0.1644		0.7605	0.5935		tp=0.31, tn=0.28, fp=0.19, fn=0.22		False
	34	0.4956		0.7435		0.5201		0.1948		0.7641	0.6217		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	35	0.4807		0.7797		0.5534		0.186		0.7816	0.5398		tp=0.24, tn=0.34, fp=0.14, fn=0.28		False
	36	0.4767		0.7625		0.5556		0.09579		0.7816	0.5977		tp=0.33, tn=0.22, fp=0.26, fn=0.19		False


data			/scratch/asw462/data/levin
input size		300
hidden size		90
learning rate		0.00154611608942
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_189-lr0.0015-h_size90-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5905		0.5816		0		0		0.8435	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5638		0.5999		0.1097		-0.0532		0.8434	0.8279		tp=0.71, tn=0, fp=0.29, fn=0.007		False
	3	0.5471		0.5856		0.158		0.05101		0.8478	0.8299		tp=0.7, tn=0.014, fp=0.27, fn=0.021		True
	4	0.5452		0.5849		0.206		0.1242		0.8475	0.8235		tp=0.69, tn=0.021, fp=0.28, fn=0.014		True
	5	0.531		0.5744		0.2047		0.1862		0.8479	0.8246		tp=0.66, tn=0.063, fp=0.22, fn=0.063		True
	6	0.5246		0.5739		0.2557		0.1551		0.847	0.8205		tp=0.67, tn=0.042, fp=0.26, fn=0.035		False
	7	0.5216		0.6306		0.2782		0.1169		0.8505	0.8136		tp=0.67, tn=0.021, fp=0.29, fn=0.014		False
	8	0.4972		0.6738		0.2774		0.01274		0.8542	0.8216		tp=0.69, tn=0.007, fp=0.29, fn=0.014		False
	9	0.5045		0.5889		0.2771		0.2641		0.8479	0.823		tp=0.65, tn=0.076, fp=0.24, fn=0.042		True
	10	0.4823		0.59		0.3344		0.2433		0.8592	0.8462		tp=0.69, tn=0.056, fp=0.22, fn=0.035		False
	11	0.4995		0.6049		0.3241		0.2475		0.8483	0.8093		tp=0.61, tn=0.1, fp=0.19, fn=0.098		False
	12	0.4763		0.6189		0.3323		0.1551		0.8546	0.8205		tp=0.67, tn=0.042, fp=0.26, fn=0.035		False
	13	0.4734		0.6081		0.3613		0.2113		0.8563	0.8276		tp=0.67, tn=0.049, fp=0.25, fn=0.028		False
	14	0.4694		0.6129		0.3689		0.1873		0.8594	0.8403		tp=0.7, tn=0.035, fp=0.24, fn=0.021		False
	15	0.4488		0.6386		0.4005		0.2009		0.8644	0.8261		tp=0.66, tn=0.056, fp=0.24, fn=0.042		False
	16	0.4594		0.5888		0.3894		0.2609		0.8578	0.837		tp=0.66, tn=0.077, fp=0.2, fn=0.056		False
	17	0.4358		0.645		0.4491		0.1945		0.8752	0.821		tp=0.66, tn=0.056, fp=0.24, fn=0.042		False
	18	0.4417		0.6432		0.4395		0.1817		0.8693	0.7907		tp=0.59, tn=0.091, fp=0.22, fn=0.098		False
	19	0.4317		0.6456		0.4371		0.1649		0.8692	0.8089		tp=0.64, tn=0.063, fp=0.24, fn=0.063		False
	20	0.4331		0.6281		0.4611		0.09422		0.874	0.824		tp=0.67, tn=0.042, fp=0.22, fn=0.07		False
	21	0.4393		0.6503		0.454		0.1334		0.8691	0.7573		tp=0.55, tn=0.1, fp=0.19, fn=0.16		False
	22	0.4412		0.6815		0.4215		0.1796		0.8647	0.7647		tp=0.55, tn=0.12, fp=0.17, fn=0.16		False
	23	0.4182		0.616		0.4799		0.2776		0.8741	0.8472		tp=0.68, tn=0.077, fp=0.19, fn=0.056		True
	24	0.4181		0.7142		0.4666		0.1922		0.8711	0.7475		tp=0.51, tn=0.14, fp=0.17, fn=0.18		False
	25	0.4427		0.6692		0.4403		0.1349		0.8631	0.7488		tp=0.53, tn=0.11, fp=0.19, fn=0.17		False
	26	0.4176		0.6975		0.4784		0.164		0.8739	0.8174		tp=0.66, tn=0.049, fp=0.25, fn=0.042		False
	27	0.4059		0.6185		0.4921		0.112		0.8769	0.7928		tp=0.61, tn=0.069, fp=0.21, fn=0.11		False
	28	0.4061		0.6815		0.5175		0.1074		0.8812	0.7854		tp=0.6, tn=0.07, fp=0.22, fn=0.1		False
	29	0.4006		0.6987		0.5259		0.1463		0.8854	0.7463		tp=0.52, tn=0.12, fp=0.18, fn=0.17		False
	30	0.3986		0.6712		0.4942		0.1584		0.8754	0.7525		tp=0.53, tn=0.12, fp=0.19, fn=0.16		False
	31	0.394		0.7001		0.4967		0.09869		0.8786	0.7476		tp=0.54, tn=0.098, fp=0.2, fn=0.17		False
	32	0.3909		0.6397		0.5214		0.2034		0.8822	0.8091		tp=0.62, tn=0.084, fp=0.21, fn=0.084		False
	33	0.3963		0.7658		0.5107		0.07972		0.8807	0.7946		tp=0.62, tn=0.056, fp=0.22, fn=0.098		False
	34	0.4001		0.6872		0.5257		0.1654		0.8814	0.7751		tp=0.57, tn=0.1, fp=0.17, fn=0.15		False
	35	0.3939		0.689		0.5102		0.1796		0.8793	0.7475		tp=0.52, tn=0.13, fp=0.18, fn=0.17		False
	36	0.391		0.6624		0.5462		0.22		0.8892	0.7905		tp=0.58, tn=0.11, fp=0.19, fn=0.12		False
	37	0.3913		0.7625		0.5294		0.1541		0.8846	0.8305		tp=0.69, tn=0.035, fp=0.25, fn=0.028		False
	38	0.387		0.683		0.5193		0.1153		0.8836	0.7909		tp=0.61, tn=0.07, fp=0.22, fn=0.1		False
	39	0.3721		0.6482		0.5817		0.1936		0.8957	0.8161		tp=0.64, tn=0.077, fp=0.2, fn=0.084		False
	40	0.3801		0.6821		0.5526		0.161		0.8863	0.7907		tp=0.59, tn=0.091, fp=0.18, fn=0.13		False
	41	0.3773		0.7051		0.5535		0.1356		0.8874	0.7964		tp=0.62, tn=0.07, fp=0.22, fn=0.091		False
	42	0.3845		0.6632		0.5275		0.1883		0.8832	0.8037		tp=0.62, tn=0.084, fp=0.21, fn=0.091		False
	43	0.3771		0.7121		0.5316		0.1635		0.8828	0.7964		tp=0.61, tn=0.076, fp=0.23, fn=0.083		False
	44	0.3681		0.7071		0.5875		0.1448		0.8954	0.7714		tp=0.57, tn=0.098, fp=0.2, fn=0.14		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		12
learning rate		0.000127657897768
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_18-lr0.00013-h_size12-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6362		0.6327		-0.001576		0		0.8175	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6185		0.6377		0		0		0.8185	0.8074		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.6167		0.6323		0		0		0.8182	0.8102		tp=0.68, tn=0, fp=0.32, fn=0		False
	4	0.6149		0.6261		0		0		0.8183	0.8147		tp=0.69, tn=0, fp=0.31, fn=0		False
	5	0.6133		0.6337		0		0		0.8183	0.8074		tp=0.68, tn=0, fp=0.32, fn=0		False
	6	0.6115		0.6236		0		0		0.8183	0.8168		tp=0.69, tn=0, fp=0.31, fn=0		False
	7	0.6102		0.6328		0		0		0.818	0.8064		tp=0.68, tn=0, fp=0.32, fn=0		False
	8	0.6082		0.6282		0		0		0.8183	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	9	0.606		0.6236		0		0		0.8186	0.8137		tp=0.69, tn=0, fp=0.31, fn=0		False
	10	0.6047		0.6289		0		0		0.8179	0.8074		tp=0.68, tn=0, fp=0.32, fn=0		False
	11	0.6028		0.629		0		0		0.8181	0.8074		tp=0.68, tn=0, fp=0.32, fn=0		False
	12	0.6005		0.6273		0.02034		0.0556		0.8183	0.8074		tp=0.68, tn=0.0015, fp=0.32, fn=0		True
	13	0.5981		0.6245		0.03171		0		0.8186	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	14	0.5965		0.6214		0.05359		0.02123		0.8189	0.8102		tp=0.68, tn=0.0015, fp=0.32, fn=0.0015		False
	15	0.5943		0.6214		0.0686		0.02104		0.8193	0.8092		tp=0.68, tn=0.0015, fp=0.32, fn=0.0015		False
	16	0.5922		0.6219		0.08333		0.04916		0.8198	0.8081		tp=0.68, tn=0.003, fp=0.32, fn=0.0015		False
	17	0.5902		0.6224		0.09235		0.04993		0.82	0.811		tp=0.68, tn=0.003, fp=0.32, fn=0.0015		False
	18	0.5881		0.6182		0.09934		0.0497		0.8202	0.8102		tp=0.68, tn=0.003, fp=0.32, fn=0.0015		False
	19	0.5857		0.618		0.1106		0.05596		0.821	0.8113		tp=0.68, tn=0.0059, fp=0.31, fn=0.0044		True
	20	0.5837		0.6229		0.1131		0.07031		0.8209	0.8068		tp=0.67, tn=0.0074, fp=0.32, fn=0.0044		True
	21	0.5816		0.6163		0.1275		0.07083		0.8218	0.8082		tp=0.67, tn=0.0074, fp=0.32, fn=0.0044		True
	22	0.5802		0.6177		0.1246		0.06907		0.8214	0.8082		tp=0.67, tn=0.012, fp=0.31, fn=0.01		False
	23	0.578		0.6182		0.1383		0.1102		0.8218	0.8089		tp=0.67, tn=0.013, fp=0.31, fn=0.0059		True
	24	0.5758		0.6165		0.1552		0.08678		0.8229	0.8093		tp=0.67, tn=0.01, fp=0.31, fn=0.0059		False
	25	0.5737		0.615		0.1484		0.06064		0.8227	0.8061		tp=0.67, tn=0.015, fp=0.3, fn=0.016		False
	26	0.5723		0.6121		0.1652		0.1185		0.8233	0.8108		tp=0.67, tn=0.022, fp=0.3, fn=0.015		True
	27	0.5707		0.6135		0.1828		0.05376		0.8241	0.8093		tp=0.67, tn=0.012, fp=0.3, fn=0.013		False
	28	0.5688		0.6175		0.1917		0.07788		0.8248	0.8079		tp=0.67, tn=0.012, fp=0.31, fn=0.0089		False
	29	0.5684		0.6167		0.1904		0.0872		0.8249	0.8015		tp=0.65, tn=0.025, fp=0.3, fn=0.025		False
	30	0.5663		0.6159		0.198		0.08508		0.8249	0.8011		tp=0.65, tn=0.027, fp=0.29, fn=0.028		False
	31	0.5651		0.6115		0.1996		0.06307		0.8246	0.8043		tp=0.66, tn=0.022, fp=0.29, fn=0.028		False
	32	0.5634		0.6157		0.2143		0.08047		0.8262	0.8011		tp=0.65, tn=0.027, fp=0.29, fn=0.03		False
	33	0.5617		0.61		0.2289		0.1061		0.8267	0.8083		tp=0.66, tn=0.024, fp=0.29, fn=0.019		False
	34	0.561		0.608		0.2254		0.1107		0.8265	0.804		tp=0.65, tn=0.034, fp=0.28, fn=0.033		False
	35	0.5601		0.6085		0.2406		0.08397		0.8282	0.8033		tp=0.65, tn=0.031, fp=0.28, fn=0.037		False
	36	0.5582		0.6127		0.2488		0.0958		0.8292	0.7996		tp=0.64, tn=0.033, fp=0.29, fn=0.034		False
	37	0.5578		0.6073		0.2446		0.09142		0.8272	0.7974		tp=0.64, tn=0.037, fp=0.28, fn=0.043		False
	38	0.5564		0.6169		0.2456		0.1003		0.8277	0.8047		tp=0.65, tn=0.028, fp=0.29, fn=0.027		False
	39	0.5556		0.6126		0.246		0.1082		0.8275	0.7959		tp=0.63, tn=0.043, fp=0.28, fn=0.046		False
	40	0.5545		0.6103		0.256		0.1261		0.8283	0.7951		tp=0.62, tn=0.055, fp=0.26, fn=0.059		True
	41	0.5538		0.6047		0.2586		0.1053		0.8279	0.807		tp=0.65, tn=0.034, fp=0.28, fn=0.036		False
	42	0.5531		0.6072		0.2669		0.1103		0.8289	0.8007		tp=0.64, tn=0.041, fp=0.27, fn=0.044		False
	43	0.5513		0.6153		0.2662		0.09803		0.8295	0.8		tp=0.64, tn=0.036, fp=0.28, fn=0.039		False
	44	0.551		0.6198		0.2676		0.09197		0.829	0.7948		tp=0.63, tn=0.039, fp=0.28, fn=0.044		False
	45	0.5494		0.6112		0.2707		0.1263		0.8295	0.7989		tp=0.63, tn=0.046, fp=0.28, fn=0.044		True
	46	0.5495		0.6094		0.2761		0.1273		0.8296	0.8004		tp=0.64, tn=0.047, fp=0.27, fn=0.047		True
	47	0.5479		0.6156		0.2824		0.127		0.8311	0.7955		tp=0.63, tn=0.05, fp=0.27, fn=0.05		False
	48	0.5483		0.6053		0.2833		0.1534		0.8303	0.8019		tp=0.63, tn=0.055, fp=0.26, fn=0.049		True
	49	0.5477		0.6022		0.2826		0.154		0.8298	0.8015		tp=0.63, tn=0.059, fp=0.26, fn=0.056		True
	50	0.5468		0.6171		0.2843		0.123		0.8294	0.7947		tp=0.63, tn=0.052, fp=0.27, fn=0.055		False
	51	0.546		0.6177		0.292		0.1219		0.8305	0.8004		tp=0.64, tn=0.044, fp=0.27, fn=0.044		False
	52	0.5461		0.6129		0.2858		0.1328		0.8294	0.8019		tp=0.64, tn=0.046, fp=0.27, fn=0.043		False
	53	0.5447		0.6143		0.2871		0.128		0.8303	0.7943		tp=0.62, tn=0.053, fp=0.27, fn=0.055		False
	54	0.5448		0.6192		0.2887		0.1222		0.8293	0.8062		tp=0.65, tn=0.037, fp=0.28, fn=0.034		False
	55	0.5445		0.6145		0.2909		0.148		0.8299	0.7943		tp=0.62, tn=0.062, fp=0.26, fn=0.061		False
	56	0.5436		0.6155		0.3039		0.1433		0.8327	0.8008		tp=0.63, tn=0.055, fp=0.26, fn=0.053		False
	57	0.5427		0.6184		0.2969		0.1375		0.8307	0.7977		tp=0.63, tn=0.053, fp=0.27, fn=0.052		False
	58	0.5433		0.615		0.2961		0.1254		0.8303	0.792		tp=0.62, tn=0.058, fp=0.26, fn=0.064		False
	59	0.5422		0.6103		0.2992		0.1887		0.8312	0.8008		tp=0.62, tn=0.073, fp=0.25, fn=0.061		True
	60	0.5421		0.6115		0.2955		0.1715		0.8294	0.7981		tp=0.62, tn=0.07, fp=0.25, fn=0.064		False
	61	0.5411		0.6191		0.3022		0.1526		0.8317	0.7958		tp=0.62, tn=0.061, fp=0.26, fn=0.056		False
	62	0.5408		0.6089		0.3034		0.167		0.8305	0.8053		tp=0.63, tn=0.059, fp=0.25, fn=0.052		False
	63	0.541		0.6148		0.2982		0.1686		0.8303	0.7977		tp=0.62, tn=0.068, fp=0.25, fn=0.062		False
	64	0.5392		0.6083		0.3049		0.1751		0.8312	0.809		tp=0.64, tn=0.058, fp=0.25, fn=0.047		False
	65	0.5394		0.6071		0.3088		0.1761		0.833	0.8034		tp=0.63, tn=0.067, fp=0.25, fn=0.059		False
	66	0.5395		0.6153		0.3056		0.1741		0.8312	0.7965		tp=0.61, tn=0.071, fp=0.25, fn=0.064		False
	67	0.5389		0.6196		0.3058		0.1567		0.8305	0.8022		tp=0.63, tn=0.055, fp=0.26, fn=0.047		False
	68	0.5385		0.6166		0.3019		0.1616		0.8301	0.7939		tp=0.61, tn=0.068, fp=0.25, fn=0.064		False
	69	0.5379		0.6153		0.308		0.1738		0.8317	0.7946		tp=0.61, tn=0.074, fp=0.25, fn=0.068		False
	70	0.5377		0.6148		0.3022		0.1838		0.8301	0.7988		tp=0.61, tn=0.076, fp=0.24, fn=0.068		False
	71	0.5382		0.6208		0.3135		0.1745		0.8312	0.8041		tp=0.63, tn=0.059, fp=0.26, fn=0.047		False
	72	0.5374		0.6113		0.3087		0.1531		0.8309	0.7985		tp=0.62, tn=0.064, fp=0.25, fn=0.064		False
	73	0.5374		0.6139		0.3104		0.1756		0.8306	0.8008		tp=0.62, tn=0.065, fp=0.26, fn=0.055		False
	74	0.5373		0.6195		0.3095		0.1793		0.8306	0.7938		tp=0.61, tn=0.077, fp=0.25, fn=0.07		False
	75	0.5365		0.6059		0.3143		0.1632		0.8314	0.8049		tp=0.63, tn=0.062, fp=0.25, fn=0.059		False
	76	0.5369		0.62		0.3161		0.1718		0.8308	0.8026		tp=0.63, tn=0.061, fp=0.26, fn=0.05		False
	77	0.5371		0.6078		0.309		0.189		0.8303	0.8012		tp=0.62, tn=0.077, fp=0.24, fn=0.07		True
	78	0.5361		0.6142		0.3176		0.1528		0.831	0.8023		tp=0.63, tn=0.058, fp=0.26, fn=0.055		False
	79	0.5358		0.6121		0.3193		0.187		0.8324	0.7977		tp=0.61, tn=0.08, fp=0.24, fn=0.074		False
	80	0.5358		0.6175		0.3162		0.1438		0.8308	0.7992		tp=0.63, tn=0.058, fp=0.26, fn=0.058		False
	81	0.5354		0.6138		0.3174		0.1874		0.8316	0.7969		tp=0.61, tn=0.077, fp=0.25, fn=0.066		False
	82	0.5356		0.6118		0.3184		0.1962		0.8315	0.7977		tp=0.61, tn=0.086, fp=0.23, fn=0.08		True
	83	0.5352		0.6142		0.3295		0.1652		0.8331	0.7965		tp=0.61, tn=0.071, fp=0.24, fn=0.07		False
	84	0.5355		0.6108		0.317		0.1765		0.8313	0.7985		tp=0.62, tn=0.074, fp=0.24, fn=0.07		False
	85	0.5344		0.611		0.3265		0.1818		0.8326	0.8008		tp=0.62, tn=0.073, fp=0.24, fn=0.065		False
	86	0.5347		0.6146		0.3228		0.1653		0.8322	0.8023		tp=0.63, tn=0.062, fp=0.25, fn=0.056		False
	87	0.5343		0.621		0.3194		0.1625		0.8318	0.7911		tp=0.61, tn=0.071, fp=0.25, fn=0.067		False
	88	0.5339		0.6081		0.331		0.1777		0.8335	0.7992		tp=0.62, tn=0.07, fp=0.25, fn=0.061		False
	89	0.5334		0.6097		0.3236		0.1791		0.8324	0.7954		tp=0.61, tn=0.077, fp=0.24, fn=0.071		False
	90	0.5337		0.6097		0.3291		0.1835		0.8324	0.8038		tp=0.63, tn=0.07, fp=0.24, fn=0.061		False
	91	0.5331		0.6133		0.3249		0.162		0.8324	0.7981		tp=0.62, tn=0.067, fp=0.25, fn=0.064		False
	92	0.5328		0.6153		0.3355		0.2044		0.8348	0.7921		tp=0.6, tn=0.092, fp=0.23, fn=0.08		True
	93	0.5333		0.6127		0.3283		0.1652		0.8327	0.7965		tp=0.61, tn=0.071, fp=0.24, fn=0.07		False
	94	0.5327		0.6061		0.3219		0.1891		0.8319	0.7973		tp=0.61, tn=0.083, fp=0.23, fn=0.078		False
	95	0.5337		0.6217		0.3303		0.1494		0.8328	0.7996		tp=0.63, tn=0.058, fp=0.26, fn=0.055		False
	96	0.5327		0.6084		0.3268		0.1665		0.8329	0.8015		tp=0.63, tn=0.065, fp=0.25, fn=0.061		False
	97	0.5324		0.6193		0.3312		0.1767		0.8329	0.8034		tp=0.63, tn=0.064, fp=0.25, fn=0.053		False
	98	0.5322		0.6131		0.3294		0.1582		0.8337	0.7946		tp=0.61, tn=0.07, fp=0.25, fn=0.07		False
	99	0.5326		0.6049		0.3304		0.1722		0.8328	0.7985		tp=0.62, tn=0.073, fp=0.24, fn=0.07		False
	100	0.5323		0.61		0.3325		0.1891		0.8334	0.7949		tp=0.6, tn=0.086, fp=0.23, fn=0.083		False
	101	0.5315		0.619		0.3349		0.1535		0.8346	0.7989		tp=0.62, tn=0.062, fp=0.25, fn=0.061		False
	102	0.5319		0.6088		0.3341		0.1817		0.8335	0.7965		tp=0.61, tn=0.08, fp=0.23, fn=0.077		False
	103	0.5312		0.6122		0.3297		0.1516		0.8333	0.7969		tp=0.62, tn=0.067, fp=0.25, fn=0.07		False
	104	0.5314		0.6215		0.3345		0.1715		0.8337	0.7977		tp=0.62, tn=0.067, fp=0.26, fn=0.058		False
	105	0.5314		0.6203		0.3337		0.1527		0.8338	0.7884		tp=0.6, tn=0.071, fp=0.25, fn=0.071		False
	106	0.5312		0.61		0.3305		0.1895		0.8335	0.7929		tp=0.6, tn=0.089, fp=0.23, fn=0.087		False
	107	0.5306		0.6168		0.3316		0.1719		0.8323	0.793		tp=0.61, tn=0.076, fp=0.25, fn=0.071		False
	108	0.5299		0.6145		0.3388		0.1806		0.8352	0.7918		tp=0.6, tn=0.084, fp=0.23, fn=0.083		False
	109	0.5312		0.6152		0.3335		0.1717		0.8332	0.7965		tp=0.61, tn=0.072, fp=0.25, fn=0.068		False
	110	0.5308		0.6186		0.331		0.1789		0.8329	0.8019		tp=0.62, tn=0.068, fp=0.25, fn=0.059		False
	111	0.5313		0.613		0.3366		0.1774		0.8341	0.8008		tp=0.62, tn=0.073, fp=0.24, fn=0.068		False
	112	0.5313		0.6164		0.3352		0.1701		0.8332	0.7934		tp=0.61, tn=0.074, fp=0.25, fn=0.07		False
	113	0.5301		0.6144		0.3408		0.1736		0.8353	0.7996		tp=0.62, tn=0.068, fp=0.25, fn=0.061		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		152
learning rate		0.00404795824618
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_190-lr0.004-h_size152-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6101		0.6058		0.06208		0.1424		0.812	0.8129		tp=0.67, tn=0.022, fp=0.3, fn=0.01		True
	2	0.6036		0.607		0.08772		0.1497		0.813	0.8063		tp=0.65, tn=0.041, fp=0.28, fn=0.031		True
	3	0.5945		0.6085		0.1354		0.1277		0.8138	0.8051		tp=0.65, tn=0.033, fp=0.29, fn=0.025		False
	4	0.5849		0.6001		0.1833		0.144		0.8176	0.8135		tp=0.66, tn=0.036, fp=0.28, fn=0.027		False
	5	0.5847		0.6059		0.1517		0.1092		0.8132	0.7996		tp=0.64, tn=0.041, fp=0.28, fn=0.044		False
	6	0.5799		0.6026		0.1793		0.1425		0.814	0.8019		tp=0.63, tn=0.052, fp=0.26, fn=0.049		False
	7	0.5766		0.6021		0.2053		0.1205		0.8157	0.7974		tp=0.63, tn=0.05, fp=0.27, fn=0.055		False
	8	0.5691		0.6221		0.2004		0.1117		0.816	0.7978		tp=0.64, tn=0.033, fp=0.3, fn=0.028		False
	9	0.5595		0.6323		0.2443		0.03914		0.8213	0.8018		tp=0.66, tn=0.016, fp=0.3, fn=0.024		False
	10	0.5616		0.6248		0.2085		0.1322		0.8135	0.7853		tp=0.6, tn=0.07, fp=0.25, fn=0.08		False
	11	0.5516		0.6475		0.276		0.07435		0.8245	0.8018		tp=0.65, tn=0.024, fp=0.3, fn=0.027		False
	12	0.5556		0.6265		0.2544		0.1681		0.8202	0.7686		tp=0.56, tn=0.11, fp=0.22, fn=0.12		True
	13	0.5392		0.6361		0.2849		0.1431		0.8261	0.7996		tp=0.63, tn=0.052, fp=0.27, fn=0.047		False
	14	0.5318		0.6297		0.3174		0.1694		0.8311	0.7838		tp=0.59, tn=0.087, fp=0.23, fn=0.09		True
	15	0.5411		0.6356		0.2997		0.15		0.8254	0.777		tp=0.58, tn=0.086, fp=0.24, fn=0.096		False
	16	0.5252		0.6518		0.3286		0.1137		0.8311	0.7936		tp=0.62, tn=0.052, fp=0.27, fn=0.059		False
	17	0.5177		0.6309		0.3578		0.1133		0.8368	0.7901		tp=0.62, tn=0.056, fp=0.26, fn=0.067		False
	18	0.5096		0.6366		0.3605		0.1222		0.8376	0.7701		tp=0.57, tn=0.084, fp=0.23, fn=0.11		False
	19	0.5058		0.6573		0.3845		0.1661		0.8408	0.7992		tp=0.62, tn=0.065, fp=0.25, fn=0.059		False
	20	0.496		0.6475		0.3977		0.146		0.8426	0.79		tp=0.61, tn=0.07, fp=0.25, fn=0.074		False
	21	0.493		0.666		0.3904		0.09586		0.841	0.754		tp=0.55, tn=0.086, fp=0.24, fn=0.12		False
	22	0.4764		0.6507		0.4319		0.1429		0.8488	0.7807		tp=0.59, tn=0.081, fp=0.23, fn=0.096		False
	23	0.4677		0.7039		0.4464		0.1042		0.8533	0.6871		tp=0.45, tn=0.14, fp=0.17, fn=0.23		False
	24	0.4578		0.6907		0.4684		0.1135		0.8573	0.7482		tp=0.54, tn=0.098, fp=0.23, fn=0.13		False
	25	0.4505		0.6909		0.4888		0.1673		0.8614	0.7851		tp=0.59, tn=0.083, fp=0.24, fn=0.083		False
	26	0.4427		0.6914		0.4917		0.1463		0.8616	0.7907		tp=0.61, tn=0.072, fp=0.24, fn=0.081		False
	27	0.4301		0.7084		0.5149		0.09322		0.8673	0.7209		tp=0.5, tn=0.11, fp=0.21, fn=0.18		False
	28	0.4187		0.7059		0.5214		0.08645		0.8687	0.7469		tp=0.54, tn=0.09, fp=0.23, fn=0.14		False
	29	0.4102		0.7206		0.5426		0.1275		0.873	0.7706		tp=0.57, tn=0.083, fp=0.24, fn=0.1		False
	30	0.4015		0.7279		0.558		0.1276		0.8768	0.7277		tp=0.5, tn=0.12, fp=0.2, fn=0.17		False
	31	0.3916		0.7571		0.5865		0.1		0.8835	0.6736		tp=0.43, tn=0.15, fp=0.17, fn=0.25		False
	32	0.3734		0.7543		0.6205		0.1148		0.8928	0.7778		tp=0.59, tn=0.071, fp=0.25, fn=0.09		False
	33	0.3719		0.7643		0.6104		0.1396		0.89	0.7181		tp=0.48, tn=0.14, fp=0.18, fn=0.2		False
	34	0.3613		0.7636		0.6187		0.1414		0.8913	0.7915		tp=0.61, tn=0.068, fp=0.25, fn=0.076		False
	35	0.3488		0.7676		0.6447		0.1198		0.8992	0.7216		tp=0.49, tn=0.13, fp=0.19, fn=0.19		False


data			/scratch/asw462/data/levin
input size		300
hidden size		132
learning rate		5.32060871842e&05
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_191-lr5.3e&05-h_size132-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6009		0.567		-0.003828		0		0.84	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	2	0.5771		0.601		0		0		0.8393	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.556		0.5729		0		0		0.8436	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	4	0.5463		0.5692		0.04312		0		0.842	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	5	0.535		0.5448		0.1609		0.1324		0.8479	0.8361		tp=0.71, tn=0.007, fp=0.28, fn=0		True
	6	0.5273		0.5737		0.1906		0.1172		0.8469	0.8017		tp=0.65, tn=0.028, fp=0.3, fn=0.021		False
	7	0.5202		0.5622		0.2382		0.1254		0.8505	0.812		tp=0.66, tn=0.028, fp=0.29, fn=0.021		False
	8	0.5134		0.5319		0.2359		0.2292		0.8486	0.8487		tp=0.71, tn=0.042, fp=0.23, fn=0.021		True
	9	0.5029		0.5456		0.3002		0.1925		0.8575	0.8276		tp=0.67, tn=0.049, fp=0.24, fn=0.035		False
	10	0.4933		0.521		0.3338		0.3302		0.8624	0.8485		tp=0.69, tn=0.07, fp=0.22, fn=0.021		True
	11	0.4871		0.5422		0.3421		0.236		0.8629	0.8128		tp=0.62, tn=0.091, fp=0.21, fn=0.077		False
	12	0.4859		0.5348		0.3848		0.3028		0.8665	0.8356		tp=0.66, tn=0.084, fp=0.22, fn=0.042		False
	13	0.4769		0.536		0.3786		0.2443		0.8668	0.8128		tp=0.62, tn=0.091, fp=0.22, fn=0.07		False
	14	0.4676		0.5416		0.4078		0.2357		0.8712	0.8198		tp=0.64, tn=0.084, fp=0.21, fn=0.07		False
	15	0.4619		0.5358		0.4295		0.2019		0.8762	0.8108		tp=0.63, tn=0.077, fp=0.22, fn=0.07		False
	16	0.4528		0.5091		0.4402		0.3239		0.8771	0.8444		tp=0.66, tn=0.091, fp=0.2, fn=0.049		False
	17	0.4495		0.5242		0.4637		0.2357		0.8807	0.8198		tp=0.64, tn=0.084, fp=0.21, fn=0.07		False
	18	0.4436		0.5167		0.4782		0.2696		0.8816	0.8288		tp=0.64, tn=0.091, fp=0.2, fn=0.07		False
	19	0.437		0.5295		0.4907		0.2192		0.8855	0.8161		tp=0.64, tn=0.077, fp=0.22, fn=0.063		False
	20	0.4329		0.5607		0.4961		0.2803		0.8839	0.8198		tp=0.64, tn=0.084, fp=0.24, fn=0.042		False
	21	0.4289		0.551		0.4944		0.1718		0.8845	0.7964		tp=0.61, tn=0.076, fp=0.24, fn=0.076		False
	22	0.4189		0.515		0.5051		0.253		0.8876	0.8251		tp=0.64, tn=0.084, fp=0.21, fn=0.063		False
	23	0.4148		0.5511		0.5105		0.2277		0.8874	0.8073		tp=0.62, tn=0.091, fp=0.22, fn=0.077		False
	24	0.4069		0.5343		0.534		0.2682		0.8914	0.8165		tp=0.62, tn=0.098, fp=0.21, fn=0.07		False
	25	0.4043		0.5237		0.5377		0.2532		0.8918	0.8235		tp=0.64, tn=0.091, fp=0.2, fn=0.077		False
	26	0.3972		0.4694		0.5428		0.3382		0.8925	0.8468		tp=0.66, tn=0.1, fp=0.17, fn=0.07		True
	27	0.3942		0.5439		0.5168		0.1926		0.8873	0.8125		tp=0.64, tn=0.07, fp=0.23, fn=0.063		False
	28	0.3855		0.5444		0.5608		0.2516		0.8978	0.8056		tp=0.61, tn=0.098, fp=0.22, fn=0.07		False
	29	0.3783		0.5409		0.5748		0.2276		0.8997	0.8145		tp=0.63, tn=0.084, fp=0.22, fn=0.07		False
	30	0.3758		0.5187		0.5747		0.3404		0.8987	0.8295		tp=0.63, tn=0.11, fp=0.2, fn=0.056		True
	31	0.3724		0.5482		0.5832		0.2276		0.9004	0.8145		tp=0.63, tn=0.084, fp=0.22, fn=0.07		False
	32	0.3641		0.4471		0.5979		0.3756		0.9038	0.8622		tp=0.68, tn=0.1, fp=0.15, fn=0.063		True
	33	0.3606		0.5165		0.6181		0.3404		0.907	0.8295		tp=0.63, tn=0.11, fp=0.2, fn=0.056		False
	34	0.3536		0.4818		0.6108		0.3549		0.9061	0.8349		tp=0.63, tn=0.12, fp=0.19, fn=0.062		False
	35	0.3499		0.5135		0.6237		0.3176		0.9088	0.8311		tp=0.64, tn=0.1, fp=0.2, fn=0.063		False
	36	0.3434		0.505		0.6362		0.3117		0.9111	0.8378		tp=0.65, tn=0.098, fp=0.19, fn=0.063		False
	37	0.3391		0.5009		0.6373		0.3842		0.9115	0.8411		tp=0.63, tn=0.13, fp=0.16, fn=0.077		True
	38	0.3304		0.5159		0.6603		0.3365		0.9165	0.8279		tp=0.62, tn=0.12, fp=0.19, fn=0.07		False
	39	0.3295		0.5317		0.6731		0.3794		0.9198	0.8269		tp=0.6, tn=0.15, fp=0.17, fn=0.084		False
	40	0.3238		0.5409		0.6713		0.3725		0.9188	0.8119		tp=0.57, tn=0.16, fp=0.17, fn=0.091		False
	41	0.3189		0.5283		0.6962		0.2856		0.9241	0.8273		tp=0.64, tn=0.098, fp=0.2, fn=0.07		False
	42	0.312		0.5181		0.6952		0.3267		0.9243	0.8364		tp=0.64, tn=0.1, fp=0.19, fn=0.063		False
	43	0.3067		0.4999		0.7099		0.3982		0.9277	0.8451		tp=0.63, tn=0.14, fp=0.14, fn=0.091		True
	44	0.3045		0.5501		0.7074		0.3181		0.9263	0.8134		tp=0.59, tn=0.13, fp=0.17, fn=0.098		False
	45	0.2989		0.5177		0.7074		0.4003		0.9258	0.8465		tp=0.64, tn=0.13, fp=0.16, fn=0.07		True
	46	0.2933		0.5132		0.7307		0.3525		0.931	0.8455		tp=0.65, tn=0.11, fp=0.17, fn=0.07		False
	47	0.2866		0.5271		0.7264		0.3949		0.9311	0.8325		tp=0.61, tn=0.15, fp=0.17, fn=0.077		False
	48	0.2846		0.5101		0.7475		0.3972		0.9352	0.8381		tp=0.62, tn=0.15, fp=0.15, fn=0.091		False
	49	0.2789		0.4697		0.7446		0.4283		0.9349	0.8558		tp=0.64, tn=0.14, fp=0.14, fn=0.077		True
	50	0.2746		0.4532		0.7626		0.4633		0.9394	0.8531		tp=0.62, tn=0.16, fp=0.15, fn=0.069		True
	51	0.2716		0.4762		0.7544		0.4438		0.9363	0.8545		tp=0.63, tn=0.15, fp=0.12, fn=0.09		False
	52	0.2668		0.4984		0.775		0.4109		0.9418	0.8381		tp=0.62, tn=0.15, fp=0.17, fn=0.07		False
	53	0.2626		0.5233		0.7601		0.426		0.9389	0.8421		tp=0.62, tn=0.15, fp=0.15, fn=0.077		False
	54	0.2554		0.4837		0.778		0.3978		0.9433	0.8426		tp=0.63, tn=0.13, fp=0.17, fn=0.062		False
	55	0.2526		0.5263		0.7977		0.4107		0.9472	0.8365		tp=0.61, tn=0.15, fp=0.15, fn=0.084		False
	56	0.2489		0.4702		0.7888		0.4846		0.9457	0.8664		tp=0.65, tn=0.15, fp=0.15, fn=0.049		True
	57	0.2456		0.4795		0.8001		0.4955		0.9481	0.8599		tp=0.62, tn=0.17, fp=0.12, fn=0.084		True
	58	0.2434		0.5192		0.8114		0.4278		0.951	0.8505		tp=0.64, tn=0.14, fp=0.16, fn=0.063		False
	59	0.2376		0.4734		0.8053		0.4485		0.9498	0.8531		tp=0.63, tn=0.15, fp=0.14, fn=0.077		False
	60	0.2371		0.4944		0.8152		0.4379		0.9516	0.8688		tp=0.67, tn=0.13, fp=0.14, fn=0.063		False
	61	0.2311		0.5083		0.8094		0.4551		0.9504	0.8545		tp=0.64, tn=0.15, fp=0.16, fn=0.056		False
	62	0.2224		0.4259		0.8271		0.5019		0.9552	0.8704		tp=0.66, tn=0.15, fp=0.15, fn=0.042		True
	63	0.2242		0.5106		0.8192		0.4219		0.9534	0.8505		tp=0.64, tn=0.14, fp=0.15, fn=0.07		False
	64	0.2199		0.4801		0.8229		0.485		0.9542	0.8626		tp=0.64, tn=0.16, fp=0.13, fn=0.07		False
	65	0.2179		0.4797		0.8232		0.478		0.9541	0.8558		tp=0.62, tn=0.17, fp=0.13, fn=0.077		False
	66	0.2134		0.4968		0.8379		0.4914		0.9571	0.8651		tp=0.65, tn=0.15, fp=0.16, fn=0.042		False
	67	0.2091		0.4543		0.8441		0.485		0.9592	0.8626		tp=0.64, tn=0.16, fp=0.13, fn=0.07		False
	68	0.2043		0.5114		0.845		0.4672		0.9591	0.8517		tp=0.62, tn=0.16, fp=0.15, fn=0.063		False
	69	0.2005		0.4919		0.86		0.5124		0.9633	0.8679		tp=0.64, tn=0.16, fp=0.15, fn=0.049		True
	70	0.1999		0.4466		0.8485		0.4633		0.9607	0.8531		tp=0.62, tn=0.16, fp=0.15, fn=0.069		False
	71	0.1947		0.4764		0.8606		0.5063		0.9633	0.8732		tp=0.65, tn=0.16, fp=0.11, fn=0.077		False
	72	0.1953		0.5488		0.8589		0.4833		0.9627	0.8598		tp=0.64, tn=0.15, fp=0.16, fn=0.049		False
	73	0.1876		0.4811		0.8655		0.5212		0.9647	0.8756		tp=0.66, tn=0.15, fp=0.15, fn=0.035		True
	74	0.1853		0.529		0.8637		0.4396		0.9643	0.8462		tp=0.62, tn=0.16, fp=0.13, fn=0.091		False
	75	0.186		0.4887		0.8736		0.4692		0.9664	0.8585		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	76	0.1813		0.5277		0.8687		0.4485		0.9657	0.839		tp=0.6, tn=0.17, fp=0.16, fn=0.07		False
	77	0.1784		0.4889		0.8797		0.5062		0.9684	0.8679		tp=0.64, tn=0.16, fp=0.14, fn=0.056		False
	78	0.1719		0.5076		0.8946		0.4556		0.9721	0.8611		tp=0.65, tn=0.14, fp=0.15, fn=0.056		False
	79	0.1738		0.4972		0.8797		0.4943		0.9676	0.8704		tp=0.66, tn=0.15, fp=0.15, fn=0.049		False
	80	0.1682		0.5216		0.9017		0.4629		0.974	0.8502		tp=0.62, tn=0.17, fp=0.13, fn=0.084		False
	81	0.1676		0.526		0.8877		0.486		0.9702	0.8473		tp=0.6, tn=0.18, fp=0.15, fn=0.07		False
	82	0.1651		0.483		0.8888		0.4624		0.9708	0.8651		tp=0.65, tn=0.15, fp=0.13, fn=0.077		False
	83	0.1621		0.467		0.9044		0.5416		0.9742	0.8785		tp=0.66, tn=0.16, fp=0.14, fn=0.042		True
	84	0.1604		0.4584		0.8961		0.4759		0.9718	0.8638		tp=0.64, tn=0.15, fp=0.13, fn=0.07		False
	85	0.1574		0.5268		0.9114		0.5097		0.9761	0.8612		tp=0.63, tn=0.17, fp=0.15, fn=0.049		False
	86	0.1553		0.4852		0.9098		0.5381		0.9757	0.8848		tp=0.67, tn=0.15, fp=0.13, fn=0.049		False
	87	0.1515		0.4884		0.9143		0.4692		0.9772	0.8585		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	88	0.149		0.4622		0.9146		0.449		0.9772	0.8664		tp=0.66, tn=0.14, fp=0.12, fn=0.084		False
	89	0.1474		0.5529		0.9344		0.4003		0.9823	0.8465		tp=0.64, tn=0.13, fp=0.16, fn=0.07		False
	90	0.1448		0.5289		0.9218		0.5045		0.9791	0.8626		tp=0.63, tn=0.17, fp=0.15, fn=0.056		False
	91	0.1426		0.458		0.9235		0.5234		0.9795	0.8858		tp=0.68, tn=0.15, fp=0.12, fn=0.056		False
	92	0.1406		0.5469		0.9263		0.4752		0.9798	0.8585		tp=0.64, tn=0.15, fp=0.15, fn=0.056		False
	93	0.1392		0.5193		0.9149		0.4499		0.9771	0.8558		tp=0.64, tn=0.15, fp=0.15, fn=0.062		False
	94	0.136		0.5189		0.9293		0.4661		0.9809	0.8651		tp=0.65, tn=0.15, fp=0.13, fn=0.07		False
	95	0.1325		0.5046		0.9288		0.4994		0.981	0.8612		tp=0.62, tn=0.17, fp=0.12, fn=0.076		False
	96	0.1294		0.5345		0.9398		0.4643		0.9838	0.8447		tp=0.6, tn=0.17, fp=0.15, fn=0.076		False
	97	0.1283		0.413		0.9455		0.5127		0.9851	0.8796		tp=0.66, tn=0.15, fp=0.11, fn=0.07		False
	98	0.1269		0.4948		0.9397		0.5055		0.9837	0.8756		tp=0.66, tn=0.15, fp=0.14, fn=0.049		False
	99	0.1245		0.4784		0.9417		0.5329		0.9842	0.8732		tp=0.65, tn=0.17, fp=0.14, fn=0.049		False
	100	0.1212		0.5177		0.9392		0.4973		0.9838	0.8692		tp=0.65, tn=0.15, fp=0.14, fn=0.056		False
	101	0.1206		0.52		0.9488		0.5301		0.9861	0.8744		tp=0.66, tn=0.15, fp=0.15, fn=0.035		False
	102	0.1174		0.549		0.9489		0.5015		0.9861	0.8599		tp=0.62, tn=0.17, fp=0.13, fn=0.07		False
	103	0.1172		0.5485		0.949		0.4596		0.9861	0.8598		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	104	0.1131		0.5129		0.9539		0.4782		0.9876	0.8571		tp=0.63, tn=0.16, fp=0.15, fn=0.063		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		126
learning rate		0.00069101490616
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_192-lr0.00069-h_size126-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6996		0.6787		0.01801		0.1794		0.535	0.5714		tp=0.28, tn=0.31, fp=0.16, fn=0.25		True
	2	0.679		0.6762		0.1481		0.1652		0.5882	0.5296		tp=0.24, tn=0.33, fp=0.14, fn=0.29		False
	3	0.6709		0.6694		0.1733		0.1747		0.5983	0.619		tp=0.33, tn=0.26, fp=0.21, fn=0.2		False
	4	0.6574		0.6814		0.2173		0.1547		0.6208	0.672		tp=0.43, tn=0.15, fp=0.33, fn=0.095		False
	5	0.6522		0.667		0.2232		0.1785		0.6286	0.6507		tp=0.38, tn=0.21, fp=0.27, fn=0.14		False
	6	0.6454		0.6707		0.2383		0.2043		0.6293	0.6548		tp=0.38, tn=0.23, fp=0.25, fn=0.14		True
	7	0.6424		0.6848		0.2653		0.1413		0.6492	0.5493		tp=0.26, tn=0.3, fp=0.18, fn=0.26		False
	8	0.6302		0.7415		0.2931		0.05902		0.6533	0.3275		tp=0.12, tn=0.39, fp=0.084, fn=0.41		False
	9	0.6317		0.6869		0.302		0.1659		0.6646	0.5455		tp=0.25, tn=0.32, fp=0.16, fn=0.27		False
	10	0.6352		0.682		0.2693		0.1924		0.638	0.6441		tp=0.36, tn=0.23, fp=0.25, fn=0.16		False
	11	0.6286		0.7336		0.2877		0.1041		0.6528	0.6802		tp=0.47, tn=0.085, fp=0.39, fn=0.056		False
	12	0.622		0.7008		0.302		0.09189		0.6615	0.6534		tp=0.42, tn=0.13, fp=0.34, fn=0.11		False
	13	0.6307		0.6929		0.2778		0.1257		0.655	0.5376		tp=0.26, tn=0.3, fp=0.17, fn=0.27		False
	14	0.6173		0.7207		0.3168		0.06827		0.6672	0.4561		tp=0.2, tn=0.32, fp=0.15, fn=0.33		False
	15	0.6241		0.6954		0.2937		0.1222		0.6529	0.5757		tp=0.3, tn=0.26, fp=0.22, fn=0.22		False
	16	0.611		0.7042		0.3215		0.1833		0.6674	0.6581		tp=0.39, tn=0.19, fp=0.29, fn=0.12		False
	17	0.611		0.7025		0.322		0.1435		0.6707	0.6555		tp=0.4, tn=0.17, fp=0.3, fn=0.13		False
	18	0.6141		0.7041		0.315		0.1238		0.6661	0.5671		tp=0.29, tn=0.27, fp=0.21, fn=0.23		False
	19	0.6066		0.7016		0.338		0.1684		0.6776	0.6179		tp=0.33, tn=0.25, fp=0.22, fn=0.2		False
	20	0.6038		0.7029		0.3393		0.115		0.6737	0.6256		tp=0.36, tn=0.2, fp=0.27, fn=0.17		False
	21	0.6015		0.7071		0.364		0.1351		0.6901	0.6019		tp=0.33, tn=0.24, fp=0.24, fn=0.19		False
	22	0.6082		0.7037		0.3362		0.1111		0.6763	0.6261		tp=0.37, tn=0.19, fp=0.28, fn=0.16		False
	23	0.6046		0.7109		0.3382		0.08756		0.6769	0.6434		tp=0.4, tn=0.15, fp=0.32, fn=0.13		False
	24	0.6007		0.7127		0.3441		0.156		0.6816	0.6058		tp=0.32, tn=0.26, fp=0.22, fn=0.2		False
	25	0.602		0.695		0.3499		0.1662		0.6843	0.5766		tp=0.28, tn=0.3, fp=0.19, fn=0.23		False
	26	0.599		0.7084		0.3445		0.0924		0.6809	0.5201		tp=0.25, tn=0.29, fp=0.18, fn=0.28		False
	27	0.5931		0.7105		0.3731		0.1481		0.6884	0.5891		tp=0.31, tn=0.27, fp=0.2, fn=0.22		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		42
learning rate		0.000613824272977
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_193-lr0.00061-h_size42-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.612		0.613		0.01324		0.05634		0.8168	0.8113		tp=0.68, tn=0.0015, fp=0.32, fn=0		True
	2	0.5886		0.6107		0.09207		0.1339		0.8187	0.8108		tp=0.67, tn=0.024, fp=0.3, fn=0.013		True
	3	0.5732		0.623		0.1878		0.1123		0.8224	0.8086		tp=0.67, tn=0.018, fp=0.31, fn=0.01		False
	4	0.5589		0.6269		0.2536		0.1594		0.8261	0.8123		tp=0.66, tn=0.03, fp=0.29, fn=0.015		True
	5	0.5555		0.6136		0.2686		0.203		0.8248	0.8027		tp=0.62, tn=0.074, fp=0.25, fn=0.056		True
	6	0.5403		0.62		0.3192		0.1902		0.8339	0.8053		tp=0.63, tn=0.07, fp=0.25, fn=0.058		False
	7	0.53		0.616		0.3483		0.188		0.8365	0.7885		tp=0.59, tn=0.092, fp=0.23, fn=0.09		False
	8	0.5274		0.6298		0.3355		0.2007		0.8326	0.7738		tp=0.56, tn=0.12, fp=0.21, fn=0.12		False
	9	0.523		0.626		0.3545		0.1633		0.8347	0.7954		tp=0.62, tn=0.068, fp=0.25, fn=0.064		False
	10	0.5169		0.6221		0.3622		0.1881		0.8365	0.7832		tp=0.58, tn=0.099, fp=0.22, fn=0.1		False
	11	0.5145		0.6362		0.3764		0.1641		0.838	0.7575		tp=0.54, tn=0.12, fp=0.2, fn=0.14		False
	12	0.5076		0.6727		0.3989		0.1624		0.8434	0.8052		tp=0.64, tn=0.046, fp=0.28, fn=0.033		False
	13	0.5114		0.6383		0.3939		0.1783		0.8426	0.7653		tp=0.55, tn=0.12, fp=0.2, fn=0.14		False
	14	0.5054		0.6309		0.3941		0.2025		0.8427	0.8046		tp=0.62, tn=0.08, fp=0.23, fn=0.07		False
	15	0.5005		0.6347		0.4035		0.2076		0.843	0.7917		tp=0.59, tn=0.093, fp=0.23, fn=0.08		True
	16	0.4968		0.6528		0.3968		0.164		0.8424	0.7497		tp=0.53, tn=0.12, fp=0.2, fn=0.16		False
	17	0.5007		0.6287		0.4085		0.1951		0.8444	0.776		tp=0.56, tn=0.11, fp=0.21, fn=0.12		False
	18	0.4987		0.6532		0.3981		0.1926		0.8421	0.8019		tp=0.62, tn=0.073, fp=0.25, fn=0.059		False
	19	0.49		0.6364		0.4144		0.1778		0.8459	0.7829		tp=0.58, tn=0.095, fp=0.22, fn=0.1		False
	20	0.489		0.6683		0.4275		0.1619		0.847	0.8099		tp=0.65, tn=0.041, fp=0.28, fn=0.028		False
	21	0.486		0.6553		0.4243		0.1718		0.8483	0.7518		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	22	0.4819		0.6495		0.4356		0.2162		0.8503	0.7708		tp=0.55, tn=0.13, fp=0.2, fn=0.12		True
	23	0.479		0.6465		0.4464		0.1884		0.8518	0.7823		tp=0.58, tn=0.1, fp=0.22, fn=0.11		False
	24	0.4834		0.6661		0.4268		0.1869		0.8454	0.8086		tp=0.64, tn=0.05, fp=0.27, fn=0.031		False
	25	0.4762		0.6522		0.4339		0.139		0.8496	0.7708		tp=0.57, tn=0.09, fp=0.23, fn=0.11		False
	26	0.4706		0.648		0.4565		0.2083		0.8541	0.7859		tp=0.58, tn=0.11, fp=0.21, fn=0.1		False
	27	0.4659		0.6495		0.4568		0.1666		0.8538	0.7699		tp=0.56, tn=0.11, fp=0.21, fn=0.13		False
	28	0.4617		0.647		0.4738		0.1785		0.8588	0.7787		tp=0.57, tn=0.1, fp=0.21, fn=0.11		False
	29	0.4611		0.6587		0.4819		0.2129		0.86	0.7708		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	30	0.4561		0.6528		0.4771		0.1882		0.8585	0.7532		tp=0.52, tn=0.13, fp=0.18, fn=0.16		False
	31	0.4579		0.6795		0.4757		0.1707		0.8585	0.7992		tp=0.62, tn=0.07, fp=0.25, fn=0.065		False
	32	0.4517		0.6905		0.4811		0.1924		0.8592	0.8057		tp=0.63, tn=0.062, fp=0.26, fn=0.044		False
	33	0.4435		0.658		0.5031		0.2151		0.8648	0.7726		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	34	0.4376		0.66		0.5167		0.1818		0.8684	0.7857		tp=0.59, tn=0.095, fp=0.22, fn=0.1		False
	35	0.4341		0.6577		0.5151		0.2089		0.8674	0.7735		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	36	0.4298		0.6585		0.5216		0.1909		0.8687	0.7922		tp=0.6, tn=0.087, fp=0.23, fn=0.081		False
	37	0.4213		0.6751		0.5431		0.2074		0.8741	0.7588		tp=0.53, tn=0.13, fp=0.19, fn=0.14		False
	38	0.4227		0.677		0.5305		0.2088		0.871	0.7705		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	39	0.4138		0.6781		0.5407		0.1962		0.8747	0.7694		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	40	0.4069		0.6635		0.5666		0.2103		0.8796	0.7804		tp=0.57, tn=0.12, fp=0.2, fn=0.12		False
	41	0.405		0.6962		0.5507		0.1837		0.8757	0.7949		tp=0.61, tn=0.081, fp=0.24, fn=0.077		False
	42	0.3962		0.6801		0.5791		0.2042		0.8824	0.7876		tp=0.59, tn=0.099, fp=0.22, fn=0.092		False
	43	0.388		0.6808		0.5834		0.218		0.8843	0.7892		tp=0.58, tn=0.11, fp=0.21, fn=0.099		True
	44	0.3821		0.6775		0.5907		0.2331		0.8854	0.792		tp=0.58, tn=0.11, fp=0.21, fn=0.095		True
	45	0.3767		0.691		0.5985		0.2098		0.8878	0.7838		tp=0.57, tn=0.11, fp=0.21, fn=0.1		False
	46	0.3688		0.6917		0.6179		0.2306		0.8921	0.7823		tp=0.56, tn=0.12, fp=0.19, fn=0.12		False
	47	0.3638		0.7141		0.6271		0.2393		0.8947	0.802		tp=0.6, tn=0.099, fp=0.22, fn=0.079		True
	48	0.3603		0.6882		0.6317		0.2521		0.896	0.7939		tp=0.58, tn=0.12, fp=0.2, fn=0.11		True
	49	0.3495		0.709		0.6516		0.2421		0.901	0.789		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	50	0.3437		0.7442		0.6521		0.1994		0.901	0.7973		tp=0.61, tn=0.086, fp=0.23, fn=0.077		False
	51	0.3347		0.7311		0.6711		0.2166		0.9058	0.7543		tp=0.52, tn=0.14, fp=0.17, fn=0.17		False
	52	0.3286		0.7528		0.6854		0.2262		0.9097	0.8004		tp=0.6, tn=0.096, fp=0.22, fn=0.081		False
	53	0.3206		0.7344		0.6864		0.2449		0.9101	0.7865		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	54	0.3137		0.742		0.6991		0.222		0.9132	0.7824		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	55	0.3066		0.7302		0.7069		0.2272		0.915	0.7732		tp=0.55, tn=0.13, fp=0.18, fn=0.14		False
	56	0.3006		0.7458		0.7264		0.2321		0.9209	0.75		tp=0.51, tn=0.16, fp=0.16, fn=0.18		False
	57	0.294		0.7488		0.7385		0.2626		0.924	0.7972		tp=0.58, tn=0.12, fp=0.2, fn=0.093		True
	58	0.2832		0.7634		0.7589		0.2606		0.9296	0.7533		tp=0.5, tn=0.17, fp=0.15, fn=0.17		False
	59	0.2844		0.7671		0.7466		0.2375		0.9261	0.7976		tp=0.59, tn=0.11, fp=0.21, fn=0.092		False
	60	0.2673		0.7656		0.7763		0.23		0.9343	0.7683		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	61	0.2625		0.7884		0.7833		0.2594		0.9363	0.7539		tp=0.5, tn=0.17, fp=0.15, fn=0.18		False
	62	0.2554		0.7829		0.7898		0.2638		0.9384	0.7939		tp=0.58, tn=0.12, fp=0.2, fn=0.1		True
	63	0.2485		0.781		0.8012		0.2651		0.9414	0.8056		tp=0.6, tn=0.11, fp=0.21, fn=0.083		True
	64	0.2413		0.8101		0.8075		0.2579		0.9428	0.7955		tp=0.58, tn=0.12, fp=0.2, fn=0.096		False
	65	0.2346		0.8194		0.8204		0.2331		0.947	0.7696		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	66	0.228		0.8044		0.8297		0.2341		0.9492	0.7508		tp=0.51, tn=0.16, fp=0.16, fn=0.18		False
	67	0.219		0.8677		0.8375		0.2347		0.9516	0.7948		tp=0.59, tn=0.1, fp=0.22, fn=0.083		False
	68	0.2188		0.7767		0.8388		0.2655		0.952	0.7766		tp=0.54, tn=0.15, fp=0.17, fn=0.14		True
	69	0.2084		0.8274		0.8505		0.2432		0.9553	0.7792		tp=0.55, tn=0.13, fp=0.19, fn=0.12		False
	70	0.1995		0.8261		0.8686		0.262		0.9606	0.7914		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	71	0.1971		0.8545		0.8584		0.2479		0.9577	0.7791		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	72	0.1902		0.8661		0.8818		0.2393		0.9644	0.802		tp=0.6, tn=0.11, fp=0.2, fn=0.093		False
	73	0.1795		0.9197		0.9004		0.2343		0.9699	0.7915		tp=0.58, tn=0.11, fp=0.21, fn=0.1		False
	74	0.1811		0.8791		0.8828		0.2579		0.9647	0.7926		tp=0.57, tn=0.12, fp=0.19, fn=0.11		False
	75	0.1693		0.883		0.9035		0.24		0.9708	0.7813		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	76	0.1627		0.8997		0.9051		0.2778		0.9714	0.8008		tp=0.58, tn=0.12, fp=0.19, fn=0.097		True
	77	0.1571		0.8702		0.9152		0.262		0.9744	0.7837		tp=0.56, tn=0.14, fp=0.18, fn=0.13		False
	78	0.1535		0.9168		0.9117		0.257		0.9733	0.7709		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	79	0.1477		0.9227		0.9296		0.2512		0.9787	0.7705		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	80	0.1413		0.9239		0.9344		0.2441		0.9801	0.7804		tp=0.56, tn=0.13, fp=0.19, fn=0.13		False
	81	0.1353		0.9154		0.9388		0.2633		0.9814	0.7712		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	82	0.1321		0.9476		0.9402		0.2704		0.9818	0.7734		tp=0.53, tn=0.15, fp=0.17, fn=0.15		False
	83	0.1289		0.9817		0.9459		0.2588		0.9835	0.7935		tp=0.58, tn=0.12, fp=0.2, fn=0.099		False
	84	0.1246		0.9656		0.9436		0.2641		0.9828	0.7753		tp=0.54, tn=0.15, fp=0.17, fn=0.14		False
	85	0.1173		0.9978		0.9532		0.2643		0.9857	0.7988		tp=0.59, tn=0.12, fp=0.2, fn=0.099		False
	86	0.1141		1.009		0.9558		0.2617		0.9865	0.788		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	87	0.1086		1.025		0.9628		0.2584		0.9886	0.7833		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	88	0.1044		1.029		0.9636		0.252		0.9889	0.7786		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	89	0.1021		1.097		0.9663		0.2577		0.9897	0.7935		tp=0.58, tn=0.12, fp=0.2, fn=0.1		False
	90	0.09625		1.046		0.9693		0.2637		0.9906	0.7918		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	91	0.09556		1.052		0.9723		0.2458		0.9915	0.78		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	92	0.09067		1.073		0.9745		0.2445		0.9922	0.7881		tp=0.57, tn=0.12, fp=0.19, fn=0.11		False
	93	0.08871		1.079		0.9745		0.2364		0.9922	0.7775		tp=0.55, tn=0.13, fp=0.19, fn=0.12		False
	94	0.08343		1.113		0.9797		0.2587		0.9938	0.7968		tp=0.58, tn=0.12, fp=0.2, fn=0.098		False
	95	0.08256		1.104		0.978		0.2508		0.9932	0.7889		tp=0.57, tn=0.12, fp=0.2, fn=0.11		False
	96	0.08065		1.098		0.9753		0.252		0.9924	0.7821		tp=0.56, tn=0.13, fp=0.18, fn=0.13		False
	97	0.07575		1.169		0.9827		0.2661		0.9947	0.7992		tp=0.59, tn=0.12, fp=0.2, fn=0.093		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		60
learning rate		0.00275869468029
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_194-lr0.0028-h_size60-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6084		0.6158		0.05572		0.1001		0.8132	0.8097		tp=0.67, tn=0.013, fp=0.31, fn=0.0074		True
	2	0.5975		0.6046		0.1185		0.1121		0.8173	0.8128		tp=0.68, tn=0.013, fp=0.31, fn=0.0059		True
	3	0.5929		0.6057		0.1391		0.1473		0.8172	0.8178		tp=0.68, tn=0.016, fp=0.3, fn=0.0044		True
	4	0.5883		0.5993		0.148		0.149		0.8171	0.8041		tp=0.64, tn=0.05, fp=0.27, fn=0.044		True
	5	0.5844		0.6154		0.1773		0.1254		0.818	0.8126		tp=0.67, tn=0.021, fp=0.3, fn=0.012		False
	6	0.5784		0.603		0.185		0.1381		0.8194	0.807		tp=0.65, tn=0.036, fp=0.29, fn=0.027		False
	7	0.5737		0.598		0.1919		0.1403		0.8166	0.8119		tp=0.66, tn=0.03, fp=0.29, fn=0.019		False
	8	0.5742		0.6137		0.2019		0.1986		0.8166	0.7827		tp=0.58, tn=0.1, fp=0.22, fn=0.1		True
	9	0.5712		0.6085		0.2074		0.1437		0.8205	0.7852		tp=0.6, tn=0.074, fp=0.25, fn=0.081		False
	10	0.5669		0.6042		0.2049		0.1277		0.8167	0.8004		tp=0.64, tn=0.046, fp=0.27, fn=0.044		False
	11	0.565		0.6453		0.224		0.0822		0.8199	0.8107		tp=0.67, tn=0.013, fp=0.3, fn=0.01		False
	12	0.5632		0.6158		0.2282		0.1252		0.8201	0.8094		tp=0.66, tn=0.028, fp=0.29, fn=0.021		False
	13	0.5556		0.6096		0.2405		0.1296		0.8216	0.8044		tp=0.64, tn=0.044, fp=0.27, fn=0.043		False
	14	0.5552		0.6068		0.2615		0.1745		0.8242	0.7934		tp=0.61, tn=0.074, fp=0.25, fn=0.067		False
	15	0.5548		0.6093		0.2546		0.1425		0.8241	0.8022		tp=0.63, tn=0.053, fp=0.26, fn=0.052		False
	16	0.5502		0.6255		0.2604		0.08685		0.8229	0.7667		tp=0.58, tn=0.068, fp=0.26, fn=0.095		False
	17	0.5446		0.614		0.2717		0.1542		0.8247	0.7935		tp=0.61, tn=0.065, fp=0.26, fn=0.062		False
	18	0.5448		0.6051		0.2763		0.1896		0.8261	0.7937		tp=0.6, tn=0.087, fp=0.23, fn=0.084		False
	19	0.5357		0.6263		0.294		0.1321		0.8269	0.7709		tp=0.57, tn=0.086, fp=0.23, fn=0.11		False
	20	0.5354		0.6179		0.2908		0.1616		0.8259	0.8056		tp=0.64, tn=0.053, fp=0.26, fn=0.044		False
	21	0.5316		0.6302		0.3009		0.1678		0.8282	0.7992		tp=0.63, tn=0.061, fp=0.26, fn=0.05		False
	22	0.5246		0.6602		0.3383		0.1301		0.8338	0.7103		tp=0.47, tn=0.14, fp=0.18, fn=0.21		False
	23	0.5228		0.6335		0.3322		0.1265		0.8321	0.7624		tp=0.56, tn=0.093, fp=0.22, fn=0.12		False
	24	0.5176		0.6592		0.3562		0.1001		0.8377	0.7993		tp=0.64, tn=0.037, fp=0.28, fn=0.04		False
	25	0.5132		0.6287		0.3502		0.1421		0.8359	0.78		tp=0.59, tn=0.08, fp=0.24, fn=0.092		False
	26	0.5073		0.6357		0.359		0.154		0.8367	0.795		tp=0.61, tn=0.068, fp=0.25, fn=0.07		False
	27	0.5008		0.6408		0.3699		0.1202		0.8389	0.7785		tp=0.59, tn=0.073, fp=0.25, fn=0.09		False
	28	0.5042		0.6786		0.3804		0.114		0.8404	0.6959		tp=0.46, tn=0.14, fp=0.18, fn=0.22		False
	29	0.4933		0.6456		0.3889		0.1274		0.8409	0.7528		tp=0.54, tn=0.1, fp=0.22, fn=0.14		False


data			/scratch/asw462/data/levin
input size		300
hidden size		25
learning rate		0.000814524509517
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_195-lr0.00081-h_size25-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5916		0.6095		0		0		0.8399	0.8033		tp=0.67, tn=0, fp=0.33, fn=0		False
	2	0.5588		0.5722		0.09605		0		0.8419	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	3	0.535		0.5644		0.1841		0		0.8479	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	4	0.5116		0.5423		0.2844		0.1699		0.8555	0.8333		tp=0.7, tn=0.021, fp=0.27, fn=0.007		True
	5	0.49		0.5131		0.3231		0.2609		0.8584	0.8536		tp=0.71, tn=0.042, fp=0.23, fn=0.014		True
	6	0.4706		0.5301		0.3832		0.2595		0.867	0.823		tp=0.65, tn=0.07, fp=0.24, fn=0.035		False
	7	0.4466		0.5185		0.4758		0.3727		0.8793	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.063		True
	8	0.4242		0.5361		0.5166		0.3371		0.8877	0.8311		tp=0.64, tn=0.1, fp=0.21, fn=0.049		False
	9	0.3947		0.5104		0.5571		0.3596		0.8966	0.8455		tp=0.65, tn=0.11, fp=0.17, fn=0.063		False
	10	0.3834		0.5021		0.5901		0.3405		0.9005	0.8509		tp=0.68, tn=0.084, fp=0.2, fn=0.035		False
	11	0.3694		0.5102		0.5767		0.386		0.8964	0.8325		tp=0.61, tn=0.15, fp=0.15, fn=0.091		True
	12	0.3415		0.4996		0.6439		0.3239		0.9133	0.8341		tp=0.65, tn=0.097, fp=0.21, fn=0.049		False
	13	0.3182		0.5167		0.6837		0.3738		0.9197	0.8357		tp=0.62, tn=0.13, fp=0.17, fn=0.077		False
	14	0.3124		0.55		0.685		0.3246		0.9202	0.8407		tp=0.66, tn=0.084, fp=0.22, fn=0.035		False
	15	0.3005		0.5296		0.6875		0.4151		0.9199	0.8365		tp=0.61, tn=0.15, fp=0.16, fn=0.077		True
	16	0.2797		0.5415		0.7316		0.3682		0.9317	0.8372		tp=0.63, tn=0.13, fp=0.17, fn=0.07		False
	17	0.2759		0.5698		0.735		0.4148		0.9314	0.8182		tp=0.57, tn=0.18, fp=0.098, fn=0.15		False
	18	0.2638		0.56		0.735		0.4463		0.9315	0.8462		tp=0.62, tn=0.16, fp=0.15, fn=0.077		True
	19	0.2685		0.4724		0.7098		0.5082		0.925	0.8654		tp=0.63, tn=0.17, fp=0.11, fn=0.084		True
	20	0.2344		0.5176		0.7912		0.4602		0.9456	0.8585		tp=0.64, tn=0.15, fp=0.13, fn=0.077		False
	21	0.2377		0.5785		0.7729		0.438		0.9412	0.8491		tp=0.63, tn=0.15, fp=0.16, fn=0.063		False
	22	0.2164		0.5977		0.8161		0.4151		0.952	0.8365		tp=0.61, tn=0.15, fp=0.16, fn=0.077		False
	23	0.2052		0.5605		0.841		0.4329		0.9579	0.8558		tp=0.64, tn=0.14, fp=0.15, fn=0.07		False
	24	0.1986		0.5881		0.8452		0.4532		0.9593	0.861		tp=0.67, tn=0.11, fp=0.2, fn=0.021		False
	25	0.1929		0.604		0.8523		0.4813		0.9605	0.8789		tp=0.69, tn=0.13, fp=0.15, fn=0.042		False
	26	0.1843		0.6076		0.8516		0.4451		0.9608	0.8447		tp=0.61, tn=0.17, fp=0.12, fn=0.1		False
	27	0.1741		0.6592		0.8601		0.4066		0.963	0.8465		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	28	0.1689		0.7058		0.8887		0.4112		0.9698	0.8479		tp=0.64, tn=0.13, fp=0.18, fn=0.049		False
	29	0.1645		0.7659		0.8677		0.3397		0.965	0.843		tp=0.66, tn=0.098, fp=0.2, fn=0.049		False
	30	0.1497		0.6267		0.9042		0.4943		0.9742	0.8704		tp=0.66, tn=0.15, fp=0.15, fn=0.049		False
	31	0.1607		0.7051		0.8776		0.3958		0.9671	0.8309		tp=0.6, tn=0.15, fp=0.15, fn=0.091		False
	32	0.1407		0.6614		0.9164		0.4733		0.9776	0.8571		tp=0.63, tn=0.16, fp=0.14, fn=0.07		False
	33	0.1374		0.7753		0.9114		0.44		0.9761	0.8584		tp=0.66, tn=0.13, fp=0.17, fn=0.042		False
	34	0.1356		0.6086		0.9099		0.4497		0.9755	0.8676		tp=0.66, tn=0.13, fp=0.14, fn=0.063		False
	35	0.1228		0.7393		0.9345		0.4387		0.9823	0.8545		tp=0.64, tn=0.15, fp=0.14, fn=0.077		False
	36	0.1172		0.7381		0.9269		0.4249		0.9804	0.8333		tp=0.59, tn=0.17, fp=0.15, fn=0.091		False
	37	0.1192		0.8389		0.9254		0.5015		0.9799	0.8664		tp=0.65, tn=0.15, fp=0.17, fn=0.035		False
	38	0.1118		0.7642		0.9451		0.445		0.9852	0.8558		tp=0.64, tn=0.14, fp=0.16, fn=0.056		False
	39	0.1064		0.7877		0.9421		0.4335		0.9841	0.8505		tp=0.63, tn=0.15, fp=0.15, fn=0.069		False
	40	0.1044		0.7673		0.9471		0.5132		0.9856	0.8789		tp=0.69, tn=0.13, fp=0.17, fn=0.021		True
	41	0.1001		0.8259		0.9561		0.4163		0.988	0.8436		tp=0.62, tn=0.15, fp=0.15, fn=0.077		False
	42	0.09488		0.8789		0.9612		0.503		0.9894	0.8767		tp=0.67, tn=0.14, fp=0.15, fn=0.042		False
	43	0.1096		0.8251		0.9151		0.4477		0.977	0.8374		tp=0.59, tn=0.17, fp=0.15, fn=0.084		False
	44	0.09518		0.8631		0.9311		0.4917		0.9813	0.8676		tp=0.66, tn=0.13, fp=0.17, fn=0.028		False
	45	0.09399		0.8306		0.9471		0.4329		0.9856	0.8558		tp=0.64, tn=0.14, fp=0.15, fn=0.07		False
	46	0.09333		0.857		0.9468		0.5005		0.9857	0.8638		tp=0.64, tn=0.15, fp=0.16, fn=0.042		False
	47	0.08075		0.8823		0.958		0.4487		0.9884	0.8545		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	48	0.08665		0.9873		0.9437		0.3886		0.9846	0.8479		tp=0.64, tn=0.13, fp=0.16, fn=0.07		False
	49	0.09096		1.091		0.9406		0.4033		0.9836	0.8584		tp=0.68, tn=0.098, fp=0.2, fn=0.028		False
	50	0.07669		0.9188		0.9649		0.4694		0.9904	0.8571		tp=0.63, tn=0.16, fp=0.13, fn=0.077		False
	51	0.07852		1.172		0.9632		0.4304		0.9899	0.8532		tp=0.65, tn=0.13, fp=0.18, fn=0.042		False
	52	0.06964		1.07		0.9629		0.4485		0.9899	0.8649		tp=0.67, tn=0.12, fp=0.17, fn=0.035		False
	53	0.06191		0.9577		0.9806		0.5011		0.9947	0.8679		tp=0.64, tn=0.16, fp=0.13, fn=0.063		False
	54	0.06225		0.947		0.9755		0.4642		0.9932	0.8585		tp=0.64, tn=0.15, fp=0.14, fn=0.07		False
	55	0.06078		1.087		0.9717		0.4109		0.9923	0.8519		tp=0.64, tn=0.13, fp=0.15, fn=0.07		False
	56	0.05716		0.9793		0.9841		0.4159		0.9957	0.8584		tp=0.66, tn=0.13, fp=0.15, fn=0.063		False
	57	0.05929		1.023		0.9718		0.3974		0.9923	0.8597		tp=0.66, tn=0.12, fp=0.15, fn=0.07		False
	58	0.05686		1.029		0.9807		0.4811		0.9947	0.8598		tp=0.64, tn=0.15, fp=0.17, fn=0.042		False
	59	0.05118		1.093		0.9859		0.4163		0.9962	0.8436		tp=0.62, tn=0.15, fp=0.15, fn=0.077		False
	60	0.05848		1.099		0.9807		0.4922		0.9947	0.8716		tp=0.66, tn=0.14, fp=0.15, fn=0.042		False
	61	0.051		1.076		0.9808		0.4275		0.9947	0.8436		tp=0.62, tn=0.15, fp=0.17, fn=0.063		False


data			/scratch/asw462/data/levin
input size		300
hidden size		16
learning rate		0.00286276496442
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_196-lr0.0029-h_size16-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.59		0.6074		0		0		0.8418	0.8197		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.5722		0.6018		0.06924		0.1662		0.8402	0.8285		tp=0.69, tn=0.021, fp=0.28, fn=0.007		True
	3	0.5646		0.5418		0.1892		0.186		0.8464	0.8525		tp=0.73, tn=0.021, fp=0.24, fn=0.007		True
	4	0.5503		0.5633		0.2161		0.1911		0.8498	0.8443		tp=0.72, tn=0.014, fp=0.27, fn=0		True
	5	0.5451		0.5897		0.1598		0.1206		0.8421	0.8186		tp=0.68, tn=0.021, fp=0.29, fn=0.014		False
	6	0.5326		0.5688		0.2785		0.149		0.8523	0.8255		tp=0.68, tn=0.035, fp=0.26, fn=0.028		False
	7	0.5221		0.5825		0.2457		0.2521		0.8495	0.8297		tp=0.66, tn=0.069, fp=0.23, fn=0.042		True
	8	0.5152		0.5699		0.2775		0.1867		0.852	0.8261		tp=0.66, tn=0.056, fp=0.23, fn=0.049		False
	9	0.5058		0.578		0.3133		0.2074		0.8555	0.8312		tp=0.67, tn=0.056, fp=0.23, fn=0.042		False
	10	0.4941		0.5713		0.327		0.2043		0.8542	0.8297		tp=0.66, tn=0.063, fp=0.22, fn=0.056		False
	11	0.4917		0.5718		0.3302		0.2625		0.8548	0.8319		tp=0.65, tn=0.083, fp=0.2, fn=0.062		True
	12	0.4744		0.6082		0.3456		0.1964		0.8596	0.7963		tp=0.6, tn=0.091, fp=0.22, fn=0.091		False
	13	0.4751		0.6404		0.3819		0.2103		0.8619	0.8142		tp=0.64, tn=0.063, fp=0.25, fn=0.042		False
	14	0.4629		0.5905		0.3805		0.2667		0.8595	0.8075		tp=0.6, tn=0.11, fp=0.2, fn=0.091		True
	15	0.4516		0.6343		0.3723		0.2516		0.861	0.8111		tp=0.62, tn=0.098, fp=0.21, fn=0.077		False
	16	0.4452		0.6162		0.4066		0.1617		0.866	0.8276		tp=0.67, tn=0.049, fp=0.23, fn=0.049		False
	17	0.4436		0.634		0.4182		0.2009		0.8669	0.8261		tp=0.66, tn=0.056, fp=0.24, fn=0.042		False
	18	0.4372		0.5945		0.4586		0.176		0.8725	0.7907		tp=0.59, tn=0.091, fp=0.21, fn=0.1		False
	19	0.4338		0.6464		0.4571		0.196		0.8718	0.8142		tp=0.64, tn=0.063, fp=0.24, fn=0.049		False
	20	0.4321		0.6286		0.4415		0.2043		0.8715	0.7847		tp=0.57, tn=0.11, fp=0.18, fn=0.13		False
	21	0.4232		0.5793		0.467		0.2376		0.8728	0.7962		tp=0.59, tn=0.11, fp=0.2, fn=0.1		False
	22	0.4168		0.6402		0.483		0.1204		0.8771	0.7834		tp=0.59, tn=0.077, fp=0.22, fn=0.11		False
	23	0.4114		0.6056		0.5227		0.2026		0.8842	0.8194		tp=0.65, tn=0.063, fp=0.24, fn=0.049		False
	24	0.4123		0.6382		0.4896		0.1582		0.8764	0.8072		tp=0.63, tn=0.07, fp=0.22, fn=0.084		False
	25	0.4149		0.6126		0.5063		0.1507		0.8818	0.7926		tp=0.6, tn=0.084, fp=0.2, fn=0.12		False
	26	0.3985		0.5751		0.5159		0.1544		0.8831	0.7773		tp=0.57, tn=0.098, fp=0.19, fn=0.14		False
	27	0.4016		0.6553		0.4983		0.2303		0.8775	0.823		tp=0.65, tn=0.07, fp=0.23, fn=0.049		False
	28	0.3876		0.6793		0.5456		0.1719		0.8911	0.8142		tp=0.64, tn=0.063, fp=0.23, fn=0.063		False
	29	0.3864		0.7006		0.5261		0.1362		0.8863	0.8174		tp=0.66, tn=0.049, fp=0.24, fn=0.056		False
	30	0.4034		0.755		0.486		0.09039		0.8725	0.822		tp=0.68, tn=0.028, fp=0.26, fn=0.035		False
	31	0.3955		0.6874		0.5119		0.1942		0.8822	0.7788		tp=0.57, tn=0.11, fp=0.19, fn=0.13		False
	32	0.3842		0.6522		0.5653		0.1952		0.8929	0.8037		tp=0.62, tn=0.084, fp=0.22, fn=0.084		False
	33	0.3795		0.6582		0.5484		0.1737		0.8879	0.8158		tp=0.65, tn=0.056, fp=0.24, fn=0.049		False
	34	0.38		0.6586		0.537		0.229		0.8883	0.8161		tp=0.63, tn=0.083, fp=0.22, fn=0.069		False
	35	0.368		0.6521		0.5674		0.179		0.8944	0.8072		tp=0.62, tn=0.076, fp=0.22, fn=0.083		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		14
learning rate		0.00016030723885
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_197-lr0.00016-h_size14-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6903		0.6811		0.05753		0.192		0.5771	0.6271		tp=0.34, tn=0.26, fp=0.22, fn=0.18		True
	2	0.6827		0.679		0.1172		0.199		0.6166	0.6406		tp=0.36, tn=0.24, fp=0.24, fn=0.16		True
	3	0.6807		0.6772		0.137		0.2029		0.6149	0.6593		tp=0.38, tn=0.22, fp=0.25, fn=0.15		True
	4	0.6805		0.6721		0.1275		0.1699		0.6145	0.6462		tp=0.38, tn=0.21, fp=0.27, fn=0.14		False
	5	0.68		0.6745		0.1347		0.1798		0.6123	0.6504		tp=0.38, tn=0.22, fp=0.24, fn=0.16		False
	6	0.6804		0.6737		0.1272		0.1881		0.6137	0.6359		tp=0.35, tn=0.24, fp=0.24, fn=0.17		False
	7	0.6802		0.6759		0.1268		0.1916		0.6111	0.6391		tp=0.36, tn=0.24, fp=0.23, fn=0.17		False
	8	0.6804		0.6733		0.1326		0.2081		0.6115	0.6562		tp=0.37, tn=0.24, fp=0.23, fn=0.16		True
	9	0.6798		0.6738		0.1337		0.2016		0.6228	0.6548		tp=0.38, tn=0.23, fp=0.25, fn=0.14		False
	10	0.6796		0.6742		0.1363		0.1559		0.6103	0.6495		tp=0.39, tn=0.2, fp=0.27, fn=0.15		False
	11	0.6793		0.6745		0.1378		0.163		0.616	0.6447		tp=0.38, tn=0.21, fp=0.27, fn=0.15		False
	12	0.68		0.6758		0.1365		0.1521		0.6258	0.6466		tp=0.38, tn=0.2, fp=0.28, fn=0.14		False
	13	0.679		0.6758		0.142		0.188		0.6224	0.6407		tp=0.36, tn=0.24, fp=0.23, fn=0.17		False
	14	0.6795		0.6746		0.1373		0.2027		0.6201	0.637		tp=0.35, tn=0.26, fp=0.22, fn=0.18		False
	15	0.6799		0.6719		0.1372		0.211		0.6171	0.6592		tp=0.38, tn=0.23, fp=0.24, fn=0.15		True
	16	0.6792		0.6755		0.1397		0.1935		0.6223	0.6472		tp=0.37, tn=0.23, fp=0.25, fn=0.15		False
	17	0.679		0.6771		0.1328		0.1554		0.6153	0.6435		tp=0.38, tn=0.2, fp=0.28, fn=0.14		False
	18	0.6791		0.6804		0.138		0.165		0.6242	0.6267		tp=0.35, tn=0.24, fp=0.24, fn=0.18		False
	19	0.6788		0.6769		0.1418		0.1598		0.6208	0.6494		tp=0.38, tn=0.2, fp=0.27, fn=0.14		False
	20	0.679		0.6713		0.1437		0.2148		0.6242	0.6622		tp=0.38, tn=0.23, fp=0.25, fn=0.14		True
	21	0.6789		0.6792		0.1346		0.1763		0.6182	0.6226		tp=0.34, tn=0.25, fp=0.23, fn=0.18		False
	22	0.6793		0.6774		0.1369		0.1669		0.6187	0.6477		tp=0.38, tn=0.21, fp=0.27, fn=0.15		False
	23	0.6783		0.6755		0.1377		0.1919		0.6228	0.6518		tp=0.37, tn=0.23, fp=0.24, fn=0.16		False
	24	0.6789		0.6787		0.1385		0.1525		0.616	0.6466		tp=0.38, tn=0.19, fp=0.28, fn=0.14		False
	25	0.6782		0.6797		0.1324		0.1843		0.6275	0.6425		tp=0.36, tn=0.23, fp=0.25, fn=0.16		False
	26	0.6792		0.6731		0.1368		0.2177		0.6191	0.6681		tp=0.39, tn=0.23, fp=0.24, fn=0.15		True
	27	0.6793		0.6781		0.1353		0.1858		0.6206	0.6457		tp=0.37, tn=0.23, fp=0.25, fn=0.16		False
	28	0.6789		0.6684		0.1412		0.2189		0.6277	0.6667		tp=0.39, tn=0.23, fp=0.25, fn=0.14		True
	29	0.6784		0.6742		0.1355		0.1845		0.6144	0.6565		tp=0.39, tn=0.21, fp=0.26, fn=0.14		False
	30	0.6782		0.6781		0.1438		0.1834		0.6289	0.6505		tp=0.38, tn=0.22, fp=0.26, fn=0.15		False
	31	0.678		0.6751		0.1351		0.157		0.6077	0.6511		tp=0.39, tn=0.19, fp=0.29, fn=0.13		False
	32	0.6785		0.6753		0.1377		0.1556		0.6248	0.6466		tp=0.38, tn=0.2, fp=0.28, fn=0.14		False
	33	0.6786		0.674		0.1368		0.2016		0.625	0.6548		tp=0.38, tn=0.23, fp=0.25, fn=0.15		False
	34	0.6785		0.6745		0.1371		0.2007		0.6149	0.6608		tp=0.39, tn=0.22, fp=0.26, fn=0.14		False
	35	0.6783		0.6792		0.1394		0.1726		0.6286	0.6396		tp=0.36, tn=0.23, fp=0.25, fn=0.16		False
	36	0.678		0.6753		0.1365		0.1969		0.6188	0.6579		tp=0.38, tn=0.22, fp=0.26, fn=0.14		False
	37	0.6783		0.6708		0.1409		0.1988		0.6208	0.6549		tp=0.38, tn=0.22, fp=0.27, fn=0.14		False
	38	0.6777		0.6738		0.1441		0.2041		0.6309	0.6652		tp=0.39, tn=0.22, fp=0.25, fn=0.15		False
	39	0.678		0.6733		0.1356		0.1833		0.6168	0.6652		tp=0.4, tn=0.2, fp=0.26, fn=0.14		False
	40	0.6781		0.6736		0.131		0.1844		0.619	0.652		tp=0.38, tn=0.22, fp=0.26, fn=0.15		False
	41	0.678		0.6759		0.1348		0.1701		0.6212	0.6523		tp=0.39, tn=0.2, fp=0.27, fn=0.14		False
	42	0.6775		0.6813		0.1411		0.1577		0.6298	0.637		tp=0.37, tn=0.22, fp=0.26, fn=0.16		False
	43	0.678		0.6855		0.1372		0.1691		0.6263	0.623		tp=0.34, tn=0.25, fp=0.23, fn=0.18		False
	44	0.6781		0.6744		0.1352		0.1787		0.6146	0.6535		tp=0.38, tn=0.21, fp=0.25, fn=0.15		False
	45	0.6778		0.6755		0.1425		0.1777		0.6203	0.6477		tp=0.38, tn=0.21, fp=0.27, fn=0.14		False
	46	0.6779		0.6787		0.1306		0.1737		0.6236	0.646		tp=0.37, tn=0.22, fp=0.26, fn=0.15		False
	47	0.6777		0.6774		0.1445		0.1588		0.621	0.6538		tp=0.39, tn=0.2, fp=0.26, fn=0.15		False
	48	0.6781		0.6721		0.1245		0.1909		0.6084	0.6681		tp=0.4, tn=0.2, fp=0.27, fn=0.13		False
	49	0.6776		0.6747		0.1402		0.1722		0.6287	0.6491		tp=0.38, tn=0.21, fp=0.26, fn=0.15		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		150
learning rate		0.00349926318573
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_198-lr0.0035-h_size150-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.8346		0.8257		0.02061		0		0.5045	0		tp=0, tn=0.44, fp=0, fn=0.56		False
	2	0.6802		0.7232		0.06736		0.1881		0.51	0.2		tp=0.063, tn=0.43, fp=0.007, fn=0.5		True
	3	0.5538		0.6345		0.4367		0.2917		0.6991	0.6875		tp=0.38, tn=0.27, fp=0.19, fn=0.16		True
	4	0.452		0.6877		0.5775		0.3507		0.7778	0.7294		tp=0.43, tn=0.24, fp=0.22, fn=0.1		True
	5	0.3477		0.8193		0.73		0.1618		0.8614	0.5547		tp=0.27, tn=0.31, fp=0.15, fn=0.27		False
	6	0.2453		0.7905		0.83		0.3649		0.9113	0.7337		tp=0.43, tn=0.25, fp=0.21, fn=0.1		True
	7	0.1596		0.9792		0.9178		0.2605		0.9577	0.6443		tp=0.34, tn=0.29, fp=0.16, fn=0.21		False
	8	0.09392		1.001		0.959		0.3198		0.9787	0.6621		tp=0.34, tn=0.32, fp=0.14, fn=0.2		False
	9	0.06944		1.02		0.9795		0.4094		0.9894	0.7273		tp=0.39, tn=0.31, fp=0.14, fn=0.15		True
	10	0.05517		1.224		0.9677		0.2951		0.9834	0.6795		tp=0.37, tn=0.28, fp=0.17, fn=0.18		False
	11	0.03642		1.479		0.9941		0.238		0.997	0.5821		tp=0.27, tn=0.34, fp=0.13, fn=0.27		False
	12	0.05258		1.349		0.9648		0.39		0.9818	0.7362		tp=0.42, tn=0.28, fp=0.17, fn=0.13		False
	13	0.0479		1.47		0.9765		0.3687		0.988	0.717		tp=0.4, tn=0.29, fp=0.17, fn=0.15		False
	14	0.0517		1.779		0.9736		0.1925		0.9865	0.5588		tp=0.27, tn=0.31, fp=0.13, fn=0.29		False
	15	0.07887		1.819		0.9417		0.2714		0.9694	0.7174		tp=0.46, tn=0.18, fp=0.28, fn=0.083		False
	16	0.2481		1.568		0.7688		0.256		0.883	0.5085		tp=0.21, tn=0.38, fp=0.07, fn=0.34		False
	17	0.08539		1.371		0.9473		0.3531		0.9726	0.7013		tp=0.38, tn=0.3, fp=0.17, fn=0.15		False
	18	0.02344		1.606		0.9971		0.2887		0.9985	0.6533		tp=0.34, tn=0.3, fp=0.13, fn=0.23		False
	19	0.01102		1.633		1		0.2842		1	0.6486		tp=0.34, tn=0.3, fp=0.13, fn=0.23		False
	20	0.008338		1.733		1		0.3255		1	0.6621		tp=0.34, tn=0.32, fp=0.13, fn=0.22		False
	21	0.007002		1.631		1		0.2767		1	0.6389		tp=0.32, tn=0.31, fp=0.15, fn=0.21		False
	22	0.006031		1.697		1		0.2894		1	0.671		tp=0.36, tn=0.28, fp=0.14, fn=0.22		False
	23	0.005796		1.809		1		0.2848		1	0.671		tp=0.36, tn=0.28, fp=0.15, fn=0.2		False
	24	0.00552		1.847		1		0.2974		1	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.22		False
	25	0.005611		1.764		1		0.2863		1	0.6667		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	26	0.005057		1.763		1		0.3031		1	0.6667		tp=0.35, tn=0.3, fp=0.15, fn=0.2		False
	27	0.005133		1.807		1		0.313		1	0.6839		tp=0.37, tn=0.29, fp=0.15, fn=0.2		False
	28	0.004521		1.887		1		0.2876		1	0.6623		tp=0.35, tn=0.29, fp=0.15, fn=0.2		False
	29	0.00432		1.952		1		0.2968		1	0.6753		tp=0.36, tn=0.29, fp=0.17, fn=0.18		False
	30	0.004156		1.939		1		0.3141		1	0.6755		tp=0.36, tn=0.3, fp=0.15, fn=0.19		False


data			/scratch/asw462/data/levin
input size		300
hidden size		148
learning rate		0.00216648005394
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_199-lr0.0022-h_size148-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.603		0.5954		0.02937		0		0.8368	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.5544		0.567		0.1329		0.2696		0.843	0.8376		tp=0.69, tn=0.049, fp=0.25, fn=0.014		True
	3	0.5268		0.5508		0.2811		0.3305		0.8542	0.8173		tp=0.59, tn=0.14, fp=0.14, fn=0.13		True
	4	0.4911		0.6579		0.3246		0.1708		0.8549	0.7254		tp=0.49, tn=0.14, fp=0.13, fn=0.24		False
	5	0.4811		0.6069		0.3631		0.1593		0.8556	0.8354		tp=0.69, tn=0.035, fp=0.24, fn=0.028		False
	6	0.442		0.6347		0.4683		0.1543		0.8767	0.8106		tp=0.64, tn=0.056, fp=0.24, fn=0.056		False
	7	0.4168		0.6552		0.5407		0.2487		0.889	0.7761		tp=0.55, tn=0.14, fp=0.14, fn=0.17		False
	8	0.4027		0.6893		0.5218		0.2026		0.8839	0.8194		tp=0.65, tn=0.063, fp=0.24, fn=0.049		False
	9	0.4069		0.76		0.503		0.1068		0.8791	0.8382		tp=0.71, tn=0.021, fp=0.25, fn=0.021		False
	10	0.3901		0.6547		0.5388		0.2782		0.8837	0.7539		tp=0.5, tn=0.17, fp=0.12, fn=0.2		False
	11	0.3789		0.6772		0.5474		0.2975		0.8904	0.8152		tp=0.6, tn=0.13, fp=0.15, fn=0.12		False
	12	0.3584		0.7951		0.6108		0.1683		0.9012	0.7586		tp=0.54, tn=0.12, fp=0.17, fn=0.17		False
	13	0.3762		0.68		0.5632		0.342		0.8905	0.8263		tp=0.62, tn=0.13, fp=0.18, fn=0.077		True
	14	0.3816		0.7648		0.5399		0.3469		0.8862	0.8378		tp=0.65, tn=0.1, fp=0.2, fn=0.049		True
	15	0.3294		0.8129		0.6533		0.313		0.9119	0.8393		tp=0.65, tn=0.097, fp=0.19, fn=0.062		False
	16	0.3118		0.7808		0.6769		0.3209		0.9164	0.843		tp=0.66, tn=0.098, fp=0.18, fn=0.063		False
	17	0.3717		0.8958		0.5721		0.3484		0.8904	0.8472		tp=0.68, tn=0.077, fp=0.22, fn=0.021		True
	18	0.3218		0.7539		0.6549		0.3326		0.9099	0.8496		tp=0.67, tn=0.091, fp=0.19, fn=0.049		False
	19	0.2961		0.8145		0.6839		0.2632		0.9195	0.7629		tp=0.52, tn=0.16, fp=0.15, fn=0.17		False
	20	0.2896		0.9027		0.6874		0.3027		0.9185	0.8152		tp=0.6, tn=0.13, fp=0.17, fn=0.1		False
	21	0.2942		0.8746		0.7098		0.3673		0.9239	0.8195		tp=0.59, tn=0.15, fp=0.15, fn=0.1		True
	22	0.2925		0.9902		0.6834		0.2757		0.9175	0.8038		tp=0.59, tn=0.13, fp=0.17, fn=0.12		False
	23	0.2919		1.025		0.7058		0.2639		0.9221	0.8235		tp=0.63, tn=0.097, fp=0.19, fn=0.083		False
	24	0.2918		0.9552		0.6866		0.2015		0.9202	0.8		tp=0.6, tn=0.098, fp=0.18, fn=0.12		False
	25	0.2568		0.8883		0.7402		0.424		0.9311	0.8519		tp=0.64, tn=0.13, fp=0.17, fn=0.056		True
	26	0.2537		0.9642		0.7436		0.314		0.933	0.8224		tp=0.62, tn=0.12, fp=0.18, fn=0.084		False
	27	0.258		0.9939		0.7317		0.3538		0.9287	0.8468		tp=0.66, tn=0.1, fp=0.18, fn=0.056		False
	28	0.2581		0.971		0.7434		0.3243		0.9323	0.8263		tp=0.62, tn=0.13, fp=0.15, fn=0.1		False
	29	0.2376		1.057		0.7547		0.3165		0.935	0.8039		tp=0.57, tn=0.15, fp=0.15, fn=0.13		False
	30	0.2359		1.113		0.7633		0.2341		0.9374	0.7368		tp=0.49, tn=0.16, fp=0.12, fn=0.23		False
	31	0.268		1.011		0.6778		0.3498		0.916	0.8155		tp=0.59, tn=0.15, fp=0.17, fn=0.098		False
	32	0.2259		1.152		0.8025		0.3356		0.9478	0.8444		tp=0.66, tn=0.091, fp=0.2, fn=0.042		False
	33	0.2432		1.011		0.7484		0.3166		0.9329	0.8295		tp=0.63, tn=0.11, fp=0.18, fn=0.077		False
	34	0.2236		1.11		0.7601		0.3397		0.9364	0.843		tp=0.66, tn=0.098, fp=0.2, fn=0.049		False
	35	0.2522		0.9427		0.7079		0.2325		0.9226	0.8304		tp=0.65, tn=0.084, fp=0.17, fn=0.091		False
	36	0.1997		1.158		0.8101		0.2766		0.9498	0.7961		tp=0.57, tn=0.13, fp=0.17, fn=0.12		False
	37	0.1736		0.9511		0.8402		0.3686		0.9571	0.8286		tp=0.6, tn=0.15, fp=0.14, fn=0.11		False
	38	0.2066		1.026		0.7861		0.3109		0.9428	0.8077		tp=0.58, tn=0.14, fp=0.16, fn=0.12		False
	39	0.1759		1.188		0.8355		0.307		0.9564	0.8095		tp=0.59, tn=0.13, fp=0.2, fn=0.084		False
	40	0.1551		1.135		0.8658		0.285		0.9643	0.8169		tp=0.61, tn=0.12, fp=0.15, fn=0.12		False
	41	0.1592		1.135		0.8451		0.2669		0.9585	0.8131		tp=0.61, tn=0.11, fp=0.17, fn=0.1		False
	42	0.1359		1.238		0.8965		0.3241		0.9724	0.8208		tp=0.6, tn=0.13, fp=0.15, fn=0.11		False
	43	0.1474		1.322		0.8822		0.2516		0.9677	0.8111		tp=0.62, tn=0.098, fp=0.21, fn=0.077		False
	44	0.1346		1.419		0.886		0.2516		0.9696	0.8111		tp=0.62, tn=0.098, fp=0.21, fn=0.077		False
	45	0.1383		1.179		0.8836		0.3243		0.9684	0.8263		tp=0.62, tn=0.13, fp=0.15, fn=0.1		False
	46	0.1141		1.391		0.9163		0.3327		0.9776	0.8098		tp=0.58, tn=0.15, fp=0.16, fn=0.11		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		139
learning rate		0.000109769175199
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_19-lr0.00011-h_size139-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6923		0.6911		0.0468		0.07532		0.4841	0.5442		tp=0.28, tn=0.26, fp=0.19, fn=0.27		True
	2	0.685		0.6878		0.2065		0.07106		0.6367	0.5442		tp=0.28, tn=0.25, fp=0.19, fn=0.28		False
	3	0.6788		0.6888		0.2218		0.1098		0.5663	0.4844		tp=0.22, tn=0.32, fp=0.13, fn=0.33		True
	4	0.6738		0.6876		0.2339		0.1192		0.5451	0.5324		tp=0.26, tn=0.29, fp=0.15, fn=0.31		True
	5	0.6693		0.6896		0.2334		0.06476		0.5966	0.5442		tp=0.28, tn=0.25, fp=0.21, fn=0.26		False
	6	0.6653		0.6909		0.2332		0.1514		0.5915	0.5333		tp=0.25, tn=0.31, fp=0.13, fn=0.31		True
	7	0.6623		0.6922		0.2433		0.1058		0.5714	0.5324		tp=0.26, tn=0.29, fp=0.17, fn=0.29		False
	8	0.6593		0.6866		0.248		0.1393		0.5924	0.5263		tp=0.24, tn=0.31, fp=0.15, fn=0.29		False
	9	0.6566		0.6905		0.2343		0.1166		0.5672	0.4961		tp=0.22, tn=0.32, fp=0.14, fn=0.31		False
	10	0.655		0.695		0.2402		0.07458		0.5705	0.5379		tp=0.27, tn=0.26, fp=0.18, fn=0.29		False
	11	0.6519		0.6898		0.2688		0.09507		0.6016	0.5517		tp=0.28, tn=0.27, fp=0.2, fn=0.26		False
	12	0.6499		0.688		0.2686		0.1287		0.6115	0.5191		tp=0.24, tn=0.32, fp=0.16, fn=0.28		False
	13	0.6479		0.6965		0.2579		0.1056		0.5832	0.5037		tp=0.24, tn=0.29, fp=0.13, fn=0.34		False
	14	0.6464		0.6822		0.2688		0.1534		0.6029	0.5441		tp=0.26, tn=0.31, fp=0.15, fn=0.29		True
	15	0.6445		0.6968		0.2569		0.09051		0.599	0.4724		tp=0.21, tn=0.32, fp=0.14, fn=0.33		False
	16	0.6434		0.696		0.272		0.06876		0.6	0.4848		tp=0.22, tn=0.3, fp=0.16, fn=0.31		False
	17	0.6411		0.6969		0.2702		0.09961		0.5871	0.4806		tp=0.22, tn=0.31, fp=0.13, fn=0.34		False
	18	0.6391		0.6828		0.2753		0.128		0.5984	0.5532		tp=0.27, tn=0.29, fp=0.17, fn=0.27		False
	19	0.6374		0.693		0.2774		0.1226		0.6156	0.5493		tp=0.27, tn=0.28, fp=0.16, fn=0.29		False
	20	0.6362		0.6912		0.2839		0.1155		0.6065	0.5113		tp=0.24, tn=0.31, fp=0.15, fn=0.31		False
	21	0.6344		0.6928		0.2863		0.1134		0.6197	0.5255		tp=0.25, tn=0.29, fp=0.15, fn=0.3		False
	22	0.6322		0.6942		0.2863		0.1098		0.6185	0.5324		tp=0.26, tn=0.29, fp=0.16, fn=0.29		False
	23	0.6308		0.6859		0.2953		0.1544		0.619	0.5507		tp=0.27, tn=0.3, fp=0.15, fn=0.29		True
	24	0.629		0.6827		0.2953		0.1637		0.619	0.5441		tp=0.26, tn=0.31, fp=0.13, fn=0.3		True
	25	0.6277		0.6942		0.2956		0.09078		0.6154	0.4923		tp=0.22, tn=0.31, fp=0.16, fn=0.3		False
	26	0.6263		0.6913		0.2953		0.1354		0.6341	0.5811		tp=0.3, tn=0.27, fp=0.19, fn=0.24		False
	27	0.6249		0.6927		0.2895		0.1264		0.6134	0.5152		tp=0.24, tn=0.31, fp=0.15, fn=0.3		False
	28	0.6223		0.685		0.3129		0.1672		0.6309	0.6		tp=0.31, tn=0.27, fp=0.19, fn=0.23		True
	29	0.6212		0.682		0.3247		0.1963		0.6494	0.5797		tp=0.28, tn=0.31, fp=0.16, fn=0.24		True
	30	0.6187		0.6884		0.3334		0.169		0.6513	0.5775		tp=0.29, tn=0.29, fp=0.17, fn=0.25		False
	31	0.6174		0.683		0.3335		0.1637		0.6448	0.5441		tp=0.26, tn=0.31, fp=0.13, fn=0.3		False
	32	0.6178		0.679		0.3277		0.2405		0.6514	0.6494		tp=0.35, tn=0.27, fp=0.18, fn=0.2		True
	33	0.6155		0.6848		0.3368		0.1474		0.6401	0.5191		tp=0.24, tn=0.33, fp=0.14, fn=0.3		False
	34	0.6116		0.6817		0.3425		0.169		0.6467	0.5833		tp=0.29, tn=0.29, fp=0.17, fn=0.25		False
	35	0.6115		0.6748		0.3137		0.2083		0.6507	0.6456		tp=0.36, tn=0.25, fp=0.19, fn=0.2		False
	36	0.6097		0.6811		0.3393		0.1959		0.6522	0.5874		tp=0.29, tn=0.29, fp=0.14, fn=0.27		False
	37	0.6071		0.683		0.3363		0.184		0.6512	0.5986		tp=0.31, tn=0.28, fp=0.16, fn=0.25		False
	38	0.6064		0.6833		0.36		0.1489		0.6583	0.585		tp=0.3, tn=0.27, fp=0.19, fn=0.24		False
	39	0.6047		0.6775		0.3393		0.1879		0.6544	0.5874		tp=0.29, tn=0.29, fp=0.15, fn=0.26		False
	40	0.6027		0.6823		0.3363		0.1899		0.6523	0.5986		tp=0.31, tn=0.28, fp=0.16, fn=0.25		False
	41	0.6011		0.6799		0.3337		0.242		0.6566	0.6447		tp=0.34, tn=0.28, fp=0.18, fn=0.2		True
	42	0.5998		0.6862		0.3334		0.1792		0.6502	0.589		tp=0.3, tn=0.28, fp=0.15, fn=0.27		False
	43	0.5987		0.6773		0.3718		0.2168		0.6758	0.6216		tp=0.32, tn=0.29, fp=0.18, fn=0.21		False
	44	0.5956		0.6666		0.3569		0.2535		0.6615	0.6197		tp=0.31, tn=0.31, fp=0.15, fn=0.23		True
	45	0.5952		0.67		0.3658		0.2581		0.6697	0.6536		tp=0.35, tn=0.28, fp=0.16, fn=0.21		True
	46	0.5942		0.6991		0.3872		0.1618		0.6667	0.5547		tp=0.27, tn=0.31, fp=0.15, fn=0.27		False
	47	0.5902		0.6528		0.3717		0.2832		0.6667	0.671		tp=0.36, tn=0.28, fp=0.16, fn=0.2		True
	48	0.59		0.6714		0.3614		0.2855		0.6794	0.6577		tp=0.34, tn=0.3, fp=0.18, fn=0.17		True
	49	0.5872		0.6731		0.3628		0.2527		0.6656	0.6099		tp=0.3, tn=0.31, fp=0.13, fn=0.26		False
	50	0.5869		0.6602		0.3806		0.2483		0.6708	0.6301		tp=0.32, tn=0.3, fp=0.16, fn=0.22		False
	51	0.5846		0.6715		0.3776		0.285		0.6778	0.6623		tp=0.35, tn=0.29, fp=0.17, fn=0.19		False
	52	0.583		0.6668		0.3864		0.2838		0.675	0.6667		tp=0.36, tn=0.29, fp=0.17, fn=0.19		False
	53	0.5812		0.6786		0.3808		0.2728		0.6817	0.6486		tp=0.34, tn=0.3, fp=0.17, fn=0.2		False
	54	0.58		0.684		0.4012		0.2451		0.6822	0.64		tp=0.34, tn=0.29, fp=0.17, fn=0.21		False
	55	0.5788		0.6677		0.4012		0.3013		0.6909	0.6667		tp=0.35, tn=0.3, fp=0.15, fn=0.2		True
	56	0.5766		0.686		0.4275		0.2469		0.6986	0.64		tp=0.34, tn=0.29, fp=0.16, fn=0.22		False
	57	0.5754		0.6627		0.4131		0.323		0.6865	0.6755		tp=0.35, tn=0.31, fp=0.14, fn=0.2		True
	58	0.5736		0.6716		0.3956		0.3		0.6907	0.6667		tp=0.35, tn=0.3, fp=0.16, fn=0.19		False
	59	0.5717		0.6771		0.4245		0.2897		0.6994	0.6483		tp=0.33, tn=0.31, fp=0.15, fn=0.2		False
	60	0.5711		0.6793		0.41		0.2938		0.695	0.6531		tp=0.34, tn=0.31, fp=0.14, fn=0.22		False
	61	0.5686		0.6811		0.4392		0.2656		0.7075	0.625		tp=0.31, tn=0.31, fp=0.13, fn=0.24		False
	62	0.5683		0.6587		0.4099		0.3021		0.6884	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	63	0.5658		0.6583		0.4277		0.3002		0.6958	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	64	0.5658		0.6798		0.4159		0.2612		0.6989	0.6395		tp=0.33, tn=0.3, fp=0.16, fn=0.21		False
	65	0.5626		0.6853		0.4246		0.2605		0.7012	0.6443		tp=0.34, tn=0.29, fp=0.16, fn=0.21		False
	66	0.5621		0.6757		0.4103		0.3043		0.6987	0.6711		tp=0.36, tn=0.29, fp=0.14, fn=0.21		False
	67	0.562		0.6734		0.431		0.2781		0.694	0.6486		tp=0.34, tn=0.3, fp=0.15, fn=0.22		False
	68	0.559		0.6647		0.4275		0.2848		0.7032	0.6667		tp=0.36, tn=0.29, fp=0.16, fn=0.2		False
	69	0.5577		0.6768		0.4305		0.2535		0.7052	0.6197		tp=0.31, tn=0.31, fp=0.15, fn=0.23		False
	70	0.5559		0.6717		0.4336		0.299		0.7089	0.6795		tp=0.37, tn=0.28, fp=0.15, fn=0.2		False
	71	0.5555		0.6757		0.4454		0.3146		0.7051	0.6479		tp=0.32, tn=0.33, fp=0.13, fn=0.22		False
	72	0.5525		0.6551		0.4452		0.2932		0.7123	0.6835		tp=0.38, tn=0.27, fp=0.18, fn=0.17		False
	73	0.5523		0.6692		0.4451		0.2758		0.7106	0.6486		tp=0.34, tn=0.3, fp=0.15, fn=0.21		False
	74	0.5502		0.6787		0.4543		0.3129		0.7207	0.6797		tp=0.36, tn=0.29, fp=0.15, fn=0.19		False
	75	0.5483		0.6802		0.4569		0.2817		0.7193	0.6389		tp=0.32, tn=0.31, fp=0.14, fn=0.22		False
	76	0.5472		0.6863		0.4572		0.2679		0.7114	0.6443		tp=0.34, tn=0.29, fp=0.14, fn=0.23		False
	77	0.5457		0.6747		0.4598		0.2988		0.7169	0.6753		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	78	0.5447		0.6718		0.4599		0.3002		0.7204	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		23
learning rate		5.27857942488e&05
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_1-lr5.3e&05-h_size23-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6321		0.6322		0		0		0.818	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6188		0.6329		0		0		0.8182	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.6167		0.6348		0		0		0.8186	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	4	0.6158		0.6311		0		0		0.818	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	5	0.6139		0.6333		0		0		0.8185	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	6	0.613		0.6351		0		0		0.8182	0.8064		tp=0.68, tn=0, fp=0.32, fn=0		False
	7	0.6118		0.6254		0		0		0.8182	0.814		tp=0.69, tn=0, fp=0.31, fn=0		False
	8	0.6104		0.627		0		0		0.8186	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	9	0.609		0.6282		0		0		0.8186	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	10	0.6081		0.6269		0		0		0.8183	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	11	0.6066		0.6266		0		0		0.8186	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	12	0.6053		0.6289		0		0		0.8186	0.8074		tp=0.68, tn=0, fp=0.32, fn=0		False
	13	0.6042		0.63		0		0		0.8187	0.8074		tp=0.68, tn=0, fp=0.32, fn=0		False
	14	0.6037		0.6286		0		0		0.8182	0.8078		tp=0.68, tn=0, fp=0.32, fn=0		False
	15	0.6022		0.6261		0		0		0.8187	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	16	0.601		0.6227		0		0		0.8186	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	17	0.6004		0.6222		0		0		0.818	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	18	0.5988		0.6243		0.02036		0		0.8185	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	19	0.5978		0.6294		0.02034		0		0.8183	0.8032		tp=0.67, tn=0, fp=0.33, fn=0		False
	20	0.5965		0.6203		0.03527		0		0.8187	0.813		tp=0.68, tn=0, fp=0.32, fn=0		False
	21	0.5956		0.6205		0.02877		0		0.8183	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		186
learning rate		0.00390257113686
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_20-lr0.0039-h_size186-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6924		0.6775		0.09553		0.076		0.5752	0.5714		tp=0.31, tn=0.23, fp=0.25, fn=0.21		True
	2	0.6766		0.6778		0.1802		0.103		0.6105	0.5217		tp=0.25, tn=0.3, fp=0.18, fn=0.27		True
	3	0.6675		0.6957		0.1862		0.136		0.6153	0.5315		tp=0.25, tn=0.31, fp=0.16, fn=0.28		True
	4	0.661		0.7173		0.2155		0.1781		0.6231	0.4698		tp=0.19, tn=0.38, fp=0.097, fn=0.33		True
	5	0.6608		0.6907		0.202		0.1713		0.6121	0.6582		tp=0.4, tn=0.18, fp=0.3, fn=0.12		False
	6	0.6585		0.6839		0.2167		0.0974		0.6252	0.5728		tp=0.3, tn=0.25, fp=0.22, fn=0.23		False
	7	0.6457		0.6733		0.2517		0.1598		0.642	0.6538		tp=0.39, tn=0.19, fp=0.28, fn=0.14		False
	8	0.6414		0.7033		0.2724		0.1721		0.6528	0.6947		tp=0.47, tn=0.12, fp=0.34, fn=0.069		False
	9	0.6449		0.6963		0.2518		0.0775		0.6438	0.6452		tp=0.41, tn=0.14, fp=0.33, fn=0.12		False
	10	0.6361		0.7131		0.2706		0.1267		0.6514	0.5813		tp=0.3, tn=0.26, fp=0.22, fn=0.22		False
	11	0.637		0.6804		0.2665		0.1162		0.6416	0.6051		tp=0.34, tn=0.23, fp=0.25, fn=0.19		False
	12	0.6226		0.7138		0.2907		0.1397		0.655	0.6497		tp=0.39, tn=0.18, fp=0.28, fn=0.14		False
	13	0.6242		0.7138		0.2872		0.09884		0.6578	0.5902		tp=0.32, tn=0.23, fp=0.24, fn=0.2		False
	14	0.6105		0.7148		0.3318		0.1444		0.6801	0.5556		tp=0.27, tn=0.3, fp=0.18, fn=0.25		False
	15	0.6085		0.7267		0.3274		0.1542		0.6747	0.488		tp=0.21, tn=0.36, fp=0.12, fn=0.31		False
	16	0.6029		0.7254		0.3564		0.1292		0.6855	0.6667		tp=0.42, tn=0.15, fp=0.31, fn=0.12		False
	17	0.5978		0.7304		0.3568		0.1704		0.6928	0.4893		tp=0.21, tn=0.37, fp=0.11, fn=0.32		False
	18	0.6038		0.6863		0.3389		0.1437		0.6737	0.5995		tp=0.32, tn=0.25, fp=0.23, fn=0.19		False
	19	0.5935		0.7314		0.356		0.1392		0.6916	0.6693		tp=0.44, tn=0.13, fp=0.35, fn=0.084		False
	20	0.5897		0.7381		0.3577		0.1362		0.6856	0.6731		tp=0.45, tn=0.12, fp=0.36, fn=0.072		False
	21	0.5826		0.7286		0.389		0.116		0.7063	0.5179		tp=0.24, tn=0.31, fp=0.16, fn=0.29		False
	22	0.5722		0.7432		0.3865		0.09384		0.7005	0.5608		tp=0.29, tn=0.26, fp=0.22, fn=0.23		False
	23	0.5722		0.7142		0.3883		0.1279		0.7013	0.6316		tp=0.37, tn=0.2, fp=0.27, fn=0.16		False
	24	0.5582		0.7444		0.4252		0.1804		0.7213	0.551		tp=0.26, tn=0.33, fp=0.14, fn=0.27		True
	25	0.5572		0.7352		0.3995		0.1907		0.7082	0.6722		tp=0.41, tn=0.18, fp=0.29, fn=0.11		True
	26	0.5522		0.7672		0.4133		0.1628		0.7123	0.668		tp=0.42, tn=0.16, fp=0.33, fn=0.095		False
	27	0.5439		0.7445		0.4232		0.08123		0.7186	0.4916		tp=0.23, tn=0.31, fp=0.16, fn=0.3		False
	28	0.5243		0.7333		0.4581		0.2062		0.7364	0.6484		tp=0.36, tn=0.24, fp=0.23, fn=0.16		True
	29	0.5205		0.7737		0.4687		0.1893		0.7386	0.6839		tp=0.44, tn=0.15, fp=0.33, fn=0.082		False
	30	0.5096		0.7738		0.4889		0.1343		0.7514	0.6454		tp=0.39, tn=0.18, fp=0.29, fn=0.14		False
	31	0.5039		0.7735		0.5078		0.08915		0.7611	0.5714		tp=0.3, tn=0.24, fp=0.23, fn=0.23		False
	32	0.4899		0.7518		0.529		0.1995		0.771	0.6119		tp=0.32, tn=0.28, fp=0.19, fn=0.21		False
	33	0.4904		0.7645		0.5209		0.168		0.7643	0.5766		tp=0.28, tn=0.3, fp=0.18, fn=0.24		False
	34	0.4711		0.7694		0.5615		0.1695		0.7852	0.6049		tp=0.32, tn=0.27, fp=0.2, fn=0.21		False
	35	0.4657		0.7779		0.5563		0.1862		0.7844	0.6035		tp=0.31, tn=0.28, fp=0.2, fn=0.21		False
	36	0.45		0.8604		0.5733		0.1257		0.7899	0.4745		tp=0.2, tn=0.35, fp=0.13, fn=0.32		False
	37	0.4466		0.7844		0.5869		0.1752		0.7982	0.6005		tp=0.31, tn=0.28, fp=0.19, fn=0.23		False
	38	0.4432		0.8312		0.5816		0.1345		0.7941	0.6362		tp=0.37, tn=0.2, fp=0.28, fn=0.15		False
	39	0.4339		0.8037		0.5914		0.1972		0.8015	0.6303		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	40	0.4124		0.8369		0.6307		0.1505		0.8193	0.5808		tp=0.29, tn=0.28, fp=0.19, fn=0.23		False
	41	0.3966		0.8718		0.6586		0.1423		0.8342	0.5877		tp=0.31, tn=0.27, fp=0.21, fn=0.22		False
	42	0.3954		0.8383		0.6669		0.1593		0.8383	0.592		tp=0.31, tn=0.27, fp=0.19, fn=0.23		False
	43	0.3912		0.8684		0.662		0.1659		0.8345	0.5455		tp=0.25, tn=0.32, fp=0.16, fn=0.27		False
	44	0.371		0.8756		0.6833		0.1107		0.8444	0.5891		tp=0.32, tn=0.24, fp=0.24, fn=0.21		False
	45	0.3578		0.8996		0.7057		0.1301		0.8555	0.5193		tp=0.24, tn=0.31, fp=0.15, fn=0.3		False
	46	0.3562		0.8804		0.7107		0.1682		0.8592	0.581		tp=0.29, tn=0.29, fp=0.18, fn=0.24		False
	47	0.3381		0.9126		0.7311		0.1638		0.8682	0.6233		tp=0.34, tn=0.24, fp=0.22, fn=0.19		False
	48	0.3334		0.9428		0.7288		0.1939		0.8662	0.6271		tp=0.34, tn=0.26, fp=0.23, fn=0.17		False
	49	0.3209		0.9059		0.7455		0.1853		0.8757	0.6093		tp=0.32, tn=0.28, fp=0.2, fn=0.2		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		53
learning rate		0.00022391064063
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_21-lr0.00022-h_size53-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6902		0.6894		0.03357		0.216		0.4946	0.1818		tp=0.056, tn=0.44, fp=0, fn=0.5		True
	2	0.6537		0.6524		0.2931		0.2728		0.6398	0.5625		tp=0.25, tn=0.36, fp=0.084, fn=0.31		True
	3	0.6269		0.6117		0.364		0.3463		0.6506	0.7262		tp=0.43, tn=0.25, fp=0.2, fn=0.12		True
	4	0.6065		0.6102		0.4222		0.285		0.7055	0.6338		tp=0.31, tn=0.32, fp=0.13, fn=0.23		False
	5	0.5884		0.6051		0.4315		0.3464		0.713	0.6316		tp=0.29, tn=0.36, fp=0.091, fn=0.25		True
	6	0.5717		0.606		0.4877		0.404		0.7486	0.6167		tp=0.26, tn=0.42, fp=0.056, fn=0.27		True
	7	0.5597		0.5859		0.4748		0.3421		0.7308	0.6757		tp=0.35, tn=0.32, fp=0.12, fn=0.21		False
	8	0.5412		0.5798		0.4951		0.3587		0.7378	0.7239		tp=0.41, tn=0.27, fp=0.17, fn=0.15		False
	9	0.522		0.6121		0.5347		0.3842		0.7714	0.6142		tp=0.27, tn=0.39, fp=0.056, fn=0.28		False
	10	0.5175		0.591		0.5343		0.4619		0.7651	0.6917		tp=0.32, tn=0.39, fp=0.063, fn=0.22		True
	11	0.4958		0.5733		0.5812		0.4582		0.7888	0.7101		tp=0.34, tn=0.38, fp=0.084, fn=0.2		False
	12	0.4852		0.5501		0.5861		0.437		0.7854	0.7436		tp=0.41, tn=0.31, fp=0.13, fn=0.15		False
	13	0.4777		0.5659		0.6367		0.447		0.816	0.7297		tp=0.38, tn=0.34, fp=0.1, fn=0.17		False
	14	0.4537		0.5536		0.6366		0.433		0.8075	0.759		tp=0.44, tn=0.28, fp=0.17, fn=0.1		False
	15	0.4429		0.5537		0.6538		0.4629		0.819	0.7595		tp=0.42, tn=0.31, fp=0.13, fn=0.14		True
	16	0.4385		0.5586		0.6488		0.4511		0.823	0.7516		tp=0.41, tn=0.31, fp=0.12, fn=0.15		False
	17	0.4161		0.5575		0.6923		0.4749		0.844	0.7702		tp=0.43, tn=0.31, fp=0.12, fn=0.14		True
	18	0.4007		0.5217		0.7041		0.5512		0.8499	0.7724		tp=0.39, tn=0.38, fp=0.07, fn=0.16		True
	19	0.3894		0.6602		0.7037		0.3677		0.8486	0.5439		tp=0.22, tn=0.42, fp=0.035, fn=0.33		False
	20	0.3875		0.5793		0.7185		0.4665		0.8567	0.7101		tp=0.34, tn=0.38, fp=0.076, fn=0.2		False
	21	0.3711		0.5914		0.7417		0.5354		0.8667	0.7368		tp=0.34, tn=0.41, fp=0.056, fn=0.19		False
	22	0.3594		0.5872		0.7505		0.4578		0.8714	0.6772		tp=0.3, tn=0.41, fp=0.063, fn=0.22		False
	23	0.3432		0.5604		0.7388		0.5126		0.8658	0.7682		tp=0.41, tn=0.35, fp=0.098, fn=0.15		False
	24	0.3302		0.5786		0.7769		0.5191		0.8852	0.7619		tp=0.39, tn=0.36, fp=0.084, fn=0.16		False
	25	0.321		0.6208		0.8092		0.4666		0.9017	0.6822		tp=0.31, tn=0.41, fp=0.056, fn=0.23		False
	26	0.3155		0.5744		0.8038		0.5194		0.8971	0.7518		tp=0.37, tn=0.38, fp=0.084, fn=0.16		False
	27	0.3046		0.5849		0.8004		0.5421		0.8976	0.7724		tp=0.39, tn=0.38, fp=0.091, fn=0.14		False
	28	0.2921		0.5997		0.8299		0.5126		0.9116	0.7682		tp=0.41, tn=0.35, fp=0.098, fn=0.15		False
	29	0.2802		0.6008		0.8504		0.5006		0.9226	0.7568		tp=0.39, tn=0.36, fp=0.098, fn=0.15		False
	30	0.2746		0.5806		0.8503		0.5045		0.9228	0.7826		tp=0.44, tn=0.31, fp=0.14, fn=0.1		False
	31	0.2693		0.5479		0.8536		0.5281		0.9256	0.7733		tp=0.41, tn=0.36, fp=0.091, fn=0.15		False
	32	0.2602		0.6245		0.8565		0.5517		0.925	0.7571		tp=0.37, tn=0.4, fp=0.056, fn=0.18		True
	33	0.2484		0.6232		0.877		0.4871		0.9358	0.7361		tp=0.37, tn=0.36, fp=0.077, fn=0.19		False
	34	0.2388		0.6344		0.8889		0.495		0.9417	0.7692		tp=0.42, tn=0.33, fp=0.1, fn=0.15		False
	35	0.2334		0.6287		0.8826		0.4699		0.9394	0.7467		tp=0.39, tn=0.34, fp=0.11, fn=0.15		False
	36	0.2227		0.6242		0.9122		0.5369		0.9543	0.7843		tp=0.42, tn=0.35, fp=0.1, fn=0.13		False
	37	0.2203		0.6238		0.9032		0.5009		0.9502	0.7662		tp=0.41, tn=0.34, fp=0.091, fn=0.16		False
	38	0.2149		0.6719		0.8973		0.5272		0.947	0.7518		tp=0.37, tn=0.38, fp=0.07, fn=0.17		False
	39	0.2033		0.6716		0.9179		0.5269		0.9574	0.7482		tp=0.36, tn=0.39, fp=0.07, fn=0.17		False
	40	0.1969		0.6317		0.9208		0.5219		0.959	0.7848		tp=0.43, tn=0.33, fp=0.14, fn=0.098		False
	41	0.1894		0.502		0.9354		0.5353		0.9668	0.7871		tp=0.43, tn=0.34, fp=0.11, fn=0.12		False
	42	0.1848		0.7097		0.9385		0.4791		0.9681	0.7111		tp=0.34, tn=0.39, fp=0.07, fn=0.2		False
	43	0.181		0.6418		0.9237		0.4807		0.9606	0.7613		tp=0.41, tn=0.33, fp=0.11, fn=0.15		False
	44	0.1717		0.6666		0.9501		0.4948		0.9743	0.7632		tp=0.41, tn=0.34, fp=0.12, fn=0.13		False
	45	0.1699		0.6625		0.9384		0.4799		0.9682	0.7907		tp=0.48, tn=0.27, fp=0.15, fn=0.098		False
	46	0.1639		0.6742		0.9355		0.4962		0.967	0.7568		tp=0.39, tn=0.36, fp=0.12, fn=0.13		False
	47	0.1551		0.6892		0.953		0.4875		0.9759	0.7517		tp=0.39, tn=0.35, fp=0.098, fn=0.16		False
	48	0.1513		0.6732		0.9619		0.4883		0.9805	0.7448		tp=0.38, tn=0.36, fp=0.098, fn=0.16		False
	49	0.1496		0.6702		0.9531		0.5274		0.9758	0.7763		tp=0.41, tn=0.35, fp=0.091, fn=0.15		False
	50	0.144		0.6807		0.9589		0.5392		0.979	0.7639		tp=0.38, tn=0.38, fp=0.07, fn=0.17		False
	51	0.139		0.666		0.956		0.5164		0.9773	0.7586		tp=0.38, tn=0.37, fp=0.091, fn=0.15		False
	52	0.1349		0.7421		0.9707		0.4082		0.9849	0.75		tp=0.44, tn=0.27, fp=0.2, fn=0.098		False
	53	0.1307		0.7045		0.9765		0.5168		0.988	0.7927		tp=0.45, tn=0.31, fp=0.14, fn=0.098		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		143
learning rate		0.000691419625336
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_22-lr0.00069-h_size143-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6109		0.6106		0.0821		0.101		0.8138	0.8117		tp=0.68, tn=0.0089, fp=0.31, fn=0.003		True
	2	0.6092		0.611		0.06822		0.09955		0.8164	0.8085		tp=0.67, tn=0.0089, fp=0.32, fn=0.003		False
	3	0.6082		0.61		0.09297		0.09011		0.8177	0.8148		tp=0.68, tn=0.0059, fp=0.31, fn=0.0015		False
	4	0.6062		0.6119		0.07896		0.08567		0.8169	0.8089		tp=0.67, tn=0.0074, fp=0.32, fn=0.003		False
	5	0.6057		0.6007		0.1025		0.1038		0.8196	0.818		tp=0.69, tn=0.0089, fp=0.3, fn=0.003		True
	6	0.6051		0.6066		0.09169		0.1011		0.8185	0.8132		tp=0.68, tn=0.012, fp=0.31, fn=0.0059		False
	7	0.6061		0.6138		0.07419		0.08775		0.8165	0.8082		tp=0.67, tn=0.0059, fp=0.32, fn=0.0015		False
	8	0.6054		0.6097		0.08142		0.07077		0.8171	0.8113		tp=0.68, tn=0.0059, fp=0.31, fn=0.003		False
	9	0.6041		0.6178		0.1044		0.05018		0.8197	0.8043		tp=0.67, tn=0.0044, fp=0.32, fn=0.003		False
	10	0.6047		0.6035		0.09407		0.08827		0.8197	0.8152		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	11	0.6052		0.6117		0.08343		0.04938		0.8173	0.8088		tp=0.68, tn=0.003, fp=0.32, fn=0.0015		False
	12	0.6049		0.61		0.08372		0.1345		0.8182	0.8115		tp=0.67, tn=0.024, fp=0.3, fn=0.013		True
	13	0.6053		0.6093		0.09354		0.1337		0.8185	0.8119		tp=0.67, tn=0.022, fp=0.3, fn=0.012		False
	14	0.6049		0.6061		0.09743		0.09943		0.8192	0.81		tp=0.67, tn=0.012, fp=0.31, fn=0.0059		False
	15	0.6046		0.6087		0.09034		0.05328		0.8193	0.8141		tp=0.68, tn=0.0044, fp=0.31, fn=0.003		False
	16	0.6046		0.6166		0.1013		0.06961		0.8174	0.8082		tp=0.67, tn=0.0059, fp=0.32, fn=0.003		False
	17	0.6053		0.6068		0.1017		0.1006		0.8189	0.8124		tp=0.68, tn=0.012, fp=0.31, fn=0.0059		False
	18	0.6049		0.6089		0.09329		0.08929		0.8182	0.8111		tp=0.67, tn=0.012, fp=0.31, fn=0.0074		False
	19	0.6042		0.6109		0.08417		0.0866		0.818	0.8113		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	20	0.6042		0.6097		0.0916		0.1019		0.8191	0.8128		tp=0.68, tn=0.013, fp=0.3, fn=0.0074		False
	21	0.6041		0.6137		0.09295		0.1751		0.8181	0.8088		tp=0.65, tn=0.041, fp=0.28, fn=0.024		True
	22	0.6029		0.6137		0.0982		0.07045		0.818	0.8106		tp=0.68, tn=0.0059, fp=0.31, fn=0.003		False
	23	0.6037		0.6172		0.1073		0.05118		0.8197	0.8075		tp=0.67, tn=0.0044, fp=0.32, fn=0.003		False
	24	0.6041		0.6114		0.1118		0.1242		0.8203	0.8089		tp=0.67, tn=0.0074, fp=0.32, fn=0		False
	25	0.6043		0.6095		0.1178		0.1714		0.8205	0.8128		tp=0.66, tn=0.038, fp=0.28, fn=0.022		False
	26	0.6041		0.6081		0.1023		0.1256		0.8181	0.8121		tp=0.68, tn=0.012, fp=0.31, fn=0.003		False
	27	0.6046		0.6001		0.1102		0.1388		0.8191	0.8217		tp=0.68, tn=0.019, fp=0.29, fn=0.0089		False
	28	0.6032		0.6098		0.09784		0.1343		0.8191	0.8147		tp=0.67, tn=0.019, fp=0.3, fn=0.0089		False
	29	0.6034		0.6128		0.115		0.05185		0.8189	0.8096		tp=0.68, tn=0.0044, fp=0.32, fn=0.003		False
	30	0.6041		0.6122		0.1024		0.1423		0.819	0.8118		tp=0.67, tn=0.018, fp=0.31, fn=0.0059		False
	31	0.6024		0.6103		0.1131		0.07123		0.8202	0.8127		tp=0.68, tn=0.0059, fp=0.31, fn=0.003		False
	32	0.6028		0.6133		0.1041		0.1337		0.82	0.8114		tp=0.67, tn=0.015, fp=0.31, fn=0.0044		False
	33	0.6034		0.6052		0.09003		0.1561		0.8179	0.8189		tp=0.68, tn=0.019, fp=0.29, fn=0.0059		False
	34	0.6036		0.6082		0.1072		0.1431		0.8201	0.8143		tp=0.67, tn=0.021, fp=0.3, fn=0.0089		False
	35	0.6028		0.6076		0.1041		0.1142		0.8196	0.8128		tp=0.68, tn=0.01, fp=0.31, fn=0.003		False
	36	0.6034		0.6064		0.108		0.1156		0.819	0.8156		tp=0.68, tn=0.01, fp=0.31, fn=0.003		False
	37	0.6025		0.6041		0.0952		0.1543		0.8189	0.8175		tp=0.68, tn=0.021, fp=0.29, fn=0.0074		False
	38	0.6026		0.6088		0.1009		0.1571		0.8189	0.8182		tp=0.68, tn=0.018, fp=0.3, fn=0.0044		False
	39	0.6044		0.6172		0.1094		0.07151		0.8175	0.8117		tp=0.68, tn=0.0044, fp=0.31, fn=0.0015		False
	40	0.6037		0.612		0.1146		0.1369		0.8195	0.8128		tp=0.68, tn=0.013, fp=0.31, fn=0.003		False
	41	0.6024		0.6124		0.1108		0.1546		0.8204	0.8168		tp=0.68, tn=0.019, fp=0.3, fn=0.0059		False
	42	0.6035		0.6153		0.1202		0.02951		0.8198	0.8078		tp=0.68, tn=0.003, fp=0.32, fn=0.003		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		175
learning rate		0.00100900542564
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_23-lr0.001-h_size175-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7132		0.6745		0.05096		0.1524		0.548	0.4386		tp=0.17, tn=0.38, fp=0.091, fn=0.36		True
	2	0.6424		0.6951		0.2747		0.2004		0.5797	0.3434		tp=0.12, tn=0.43, fp=0.035, fn=0.42		True
	3	0.6129		0.6521		0.3013		0.2404		0.621	0.6259		tp=0.32, tn=0.29, fp=0.15, fn=0.24		True
	4	0.5613		0.6333		0.4366		0.2425		0.7108	0.6494		tp=0.35, tn=0.27, fp=0.17, fn=0.21		True
	5	0.5113		0.6239		0.5343		0.324		0.7496	0.7108		tp=0.41, tn=0.26, fp=0.2, fn=0.13		True
	6	0.4849		0.7265		0.5156		0.2488		0.7489	0.4444		tp=0.17, tn=0.41, fp=0.049, fn=0.37		False
	7	0.4229		0.6493		0.6243		0.327		0.8049	0.6842		tp=0.36, tn=0.3, fp=0.15, fn=0.18		True
	8	0.3838		0.7256		0.6596		0.3413		0.8253	0.6212		tp=0.29, tn=0.36, fp=0.084, fn=0.27		True
	9	0.3401		0.8397		0.7095		0.2557		0.8493	0.5366		tp=0.23, tn=0.37, fp=0.084, fn=0.31		False
	10	0.2978		0.7588		0.7714		0.3251		0.8804	0.6667		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	11	0.2538		0.8345		0.8185		0.3027		0.908	0.6232		tp=0.3, tn=0.34, fp=0.1, fn=0.26		False
	12	0.2307		0.7631		0.8538		0.3533		0.9231	0.6803		tp=0.35, tn=0.32, fp=0.12, fn=0.21		True
	13	0.2066		0.8228		0.8826		0.3893		0.9399	0.6714		tp=0.33, tn=0.35, fp=0.084, fn=0.24		True
	14	0.1772		0.8635		0.9297		0.3974		0.9635	0.719		tp=0.38, tn=0.31, fp=0.13, fn=0.17		True
	15	0.1544		0.9145		0.9181		0.3594		0.9583	0.6933		tp=0.36, tn=0.31, fp=0.13, fn=0.19		False
	16	0.1308		1.022		0.9473		0.3606		0.9726	0.6849		tp=0.35, tn=0.33, fp=0.13, fn=0.19		False
	17	0.1574		1.331		0.8916		0.2707		0.9447	0.5692		tp=0.26, tn=0.35, fp=0.09, fn=0.3		False
	18	0.1569		1.088		0.8712		0.3963		0.9327	0.719		tp=0.38, tn=0.31, fp=0.14, fn=0.16		False
	19	0.1617		1.149		0.868		0.2973		0.9325	0.6483		tp=0.33, tn=0.31, fp=0.13, fn=0.22		False
	20	0.1076		1.149		0.9355		0.3625		0.9667	0.6892		tp=0.36, tn=0.32, fp=0.13, fn=0.2		False
	21	0.08183		1.1		0.9677		0.4217		0.9835	0.7389		tp=0.41, tn=0.31, fp=0.13, fn=0.15		True
	22	0.06604		1.288		0.9853		0.363		0.9925	0.6849		tp=0.35, tn=0.33, fp=0.13, fn=0.2		False
	23	0.05776		1.348		0.9795		0.3495		0.9895	0.6846		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	24	0.07313		1.383		0.9707		0.4346		0.9849	0.7468		tp=0.41, tn=0.31, fp=0.13, fn=0.15		True
	25	0.07279		1.385		0.9648		0.3976		0.9819	0.7114		tp=0.37, tn=0.33, fp=0.15, fn=0.15		False
	26	0.05045		1.443		0.9912		0.3882		0.9955	0.7027		tp=0.36, tn=0.33, fp=0.13, fn=0.18		False
	27	0.03999		1.483		0.9941		0.3695		0.997	0.6849		tp=0.35, tn=0.33, fp=0.11, fn=0.21		False
	28	0.04381		1.73		0.9853		0.2561		0.9925	0.5909		tp=0.27, tn=0.35, fp=0.13, fn=0.24		False
	29	0.0349		1.447		1		0.4519		1	0.7451		tp=0.4, tn=0.33, fp=0.13, fn=0.14		True
	30	0.03296		1.651		1		0.4032		1	0.7407		tp=0.42, tn=0.29, fp=0.13, fn=0.16		False
	31	0.02957		1.692		1		0.3533		1	0.6803		tp=0.35, tn=0.32, fp=0.12, fn=0.21		False
	32	0.02866		1.775		1		0.4031		1	0.7114		tp=0.37, tn=0.33, fp=0.12, fn=0.18		False
	33	0.0241		1.824		1		0.3281		1	0.68		tp=0.36, tn=0.31, fp=0.15, fn=0.18		False
	34	0.02161		1.545		1		0.4343		1	0.7468		tp=0.41, tn=0.31, fp=0.14, fn=0.14		False
	35	0.0217		1.703		1		0.3984		1	0.7152		tp=0.38, tn=0.32, fp=0.13, fn=0.17		False
	36	0.01973		1.951		1		0.3479		1	0.6928		tp=0.37, tn=0.31, fp=0.14, fn=0.19		False
	37	0.01955		1.905		1		0.4217		1	0.7389		tp=0.41, tn=0.31, fp=0.13, fn=0.15		False
	38	0.0204		1.981		1		0.3438		1	0.6803		tp=0.35, tn=0.32, fp=0.15, fn=0.18		False
	39	0.02031		1.817		1		0.4273		1	0.7248		tp=0.38, tn=0.34, fp=0.13, fn=0.16		False
	40	0.01688		2.078		1		0.3583		1	0.7013		tp=0.38, tn=0.31, fp=0.15, fn=0.17		False
	41	0.01833		1.979		1		0.3937		1	0.7027		tp=0.36, tn=0.33, fp=0.11, fn=0.2		False
	42	0.01695		1.976		1		0.4217		1	0.7389		tp=0.41, tn=0.31, fp=0.13, fn=0.15		False
	43	0.01368		2.108		1		0.3505		1	0.6759		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	44	0.0131		1.925		1		0.3741		1	0.702		tp=0.37, tn=0.31, fp=0.13, fn=0.19		False
	45	0.01205		2.144		1		0.4063		1	0.7342		tp=0.41, tn=0.3, fp=0.14, fn=0.15		False
	46	0.01171		2.254		1		0.3373		1	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.21		False
	47	0.01375		2.239		1		0.3736		1	0.7284		tp=0.41, tn=0.28, fp=0.15, fn=0.15		False
	48	0.01256		2.175		1		0.3505		1	0.6759		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	49	0.01492		2.239		1		0.3194		1	0.6667		tp=0.34, tn=0.31, fp=0.14, fn=0.2		False
	50	0.01166		2.306		1		0.408		1	0.7308		tp=0.4, tn=0.31, fp=0.15, fn=0.14		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		74
learning rate		0.00028881472422
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_24-lr0.00029-h_size74-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5807		0.5668		0.2054		0.248		0.8226	0.8202		tp=0.65, tn=0.067, fp=0.25, fn=0.034		True
	2	0.561		0.566		0.2646		0.2938		0.8275	0.8201		tp=0.63, tn=0.098, fp=0.22, fn=0.055		True
	3	0.5545		0.5648		0.2784		0.2832		0.8298	0.8229		tp=0.64, tn=0.087, fp=0.23, fn=0.047		False
	4	0.5474		0.5746		0.2963		0.2594		0.8302	0.8178		tp=0.64, tn=0.073, fp=0.25, fn=0.036		False
	5	0.5402		0.5701		0.3135		0.3225		0.8336	0.8179		tp=0.61, tn=0.12, fp=0.2, fn=0.07		True
	6	0.5365		0.5769		0.3298		0.2918		0.8361	0.817		tp=0.63, tn=0.095, fp=0.23, fn=0.049		False
	7	0.5285		0.5731		0.3444		0.2886		0.8375	0.8164		tp=0.62, tn=0.1, fp=0.22, fn=0.062		False
	8	0.5216		0.5839		0.367		0.2726		0.8424	0.8028		tp=0.59, tn=0.11, fp=0.21, fn=0.081		False
	9	0.5165		0.5852		0.3753		0.2602		0.8437	0.8193		tp=0.64, tn=0.076, fp=0.24, fn=0.04		False
	10	0.5122		0.5832		0.3908		0.2537		0.8459	0.8082		tp=0.61, tn=0.095, fp=0.23, fn=0.065		False
	11	0.5064		0.5826		0.3941		0.2649		0.8445	0.8004		tp=0.59, tn=0.12, fp=0.21, fn=0.089		False
	12	0.5051		0.5864		0.4079		0.3095		0.8484	0.7975		tp=0.57, tn=0.15, fp=0.17, fn=0.12		False
	13	0.5015		0.5849		0.397		0.2417		0.8449	0.8104		tp=0.62, tn=0.089, fp=0.23, fn=0.065		False
	14	0.4979		0.5929		0.4094		0.3012		0.8481	0.8021		tp=0.58, tn=0.13, fp=0.19, fn=0.099		False
	15	0.4898		0.605		0.4216		0.2311		0.8497	0.8058		tp=0.62, tn=0.086, fp=0.24, fn=0.062		False
	16	0.4879		0.5987		0.4276		0.2611		0.8511	0.8071		tp=0.61, tn=0.1, fp=0.21, fn=0.075		False
	17	0.4867		0.613		0.4323		0.2423		0.851	0.8171		tp=0.64, tn=0.076, fp=0.24, fn=0.047		False
	18	0.4866		0.6074		0.4421		0.2403		0.8536	0.7988		tp=0.6, tn=0.1, fp=0.22, fn=0.08		False
	19	0.4822		0.6077		0.4343		0.2368		0.8517	0.7972		tp=0.59, tn=0.1, fp=0.22, fn=0.084		False
	20	0.481		0.5992		0.4464		0.2745		0.8548	0.8072		tp=0.6, tn=0.11, fp=0.2, fn=0.083		False
	21	0.4779		0.6042		0.4408		0.3089		0.8527	0.7992		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	22	0.4763		0.6236		0.4556		0.2619		0.8559	0.778		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	23	0.4775		0.6127		0.4468		0.2474		0.853	0.7843		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	24	0.4726		0.6285		0.449		0.2833		0.8544	0.7781		tp=0.54, tn=0.16, fp=0.17, fn=0.14		False
	25	0.4742		0.622		0.4566		0.2505		0.8559	0.7919		tp=0.58, tn=0.12, fp=0.2, fn=0.1		False
	26	0.4734		0.6514		0.47		0.1878		0.8587	0.8023		tp=0.63, tn=0.067, fp=0.26, fn=0.052		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		10
learning rate		0.000432798283957
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_25-lr0.00043-h_size10-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.687		0.6734		0.0828		0.2371		0.511	0.5538		tp=0.25, tn=0.34, fp=0.098, fn=0.31		True
	2	0.6616		0.6547		0.3009		0.1846		0.5719	0.5874		tp=0.29, tn=0.29, fp=0.16, fn=0.25		False
	3	0.6415		0.6439		0.3635		0.3194		0.6539	0.547		tp=0.22, tn=0.41, fp=0.062, fn=0.31		True
	4	0.6259		0.6292		0.3955		0.3495		0.6898	0.6569		tp=0.31, tn=0.36, fp=0.13, fn=0.2		True
	5	0.6113		0.6477		0.4349		0.2351		0.7166	0.4444		tp=0.17, tn=0.41, fp=0.056, fn=0.36		False
	6	0.6008		0.6089		0.4426		0.3352		0.7022	0.662		tp=0.33, tn=0.34, fp=0.13, fn=0.2		False
	7	0.5845		0.6063		0.4777		0.3344		0.7236	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.2		False
	8	0.5716		0.6095		0.5023		0.4097		0.75	0.6565		tp=0.3, tn=0.38, fp=0.07, fn=0.24		True
	9	0.5609		0.6296		0.5092		0.342		0.7558	0.5667		tp=0.24, tn=0.4, fp=0.056, fn=0.31		False
	10	0.5548		0.5781		0.4488		0.378		0.7035	0.7317		tp=0.42, tn=0.27, fp=0.19, fn=0.12		False
	11	0.5367		0.5751		0.5539		0.435		0.7669	0.7172		tp=0.36, tn=0.35, fp=0.1, fn=0.18		True
	12	0.5323		0.5739		0.5274		0.4013		0.7549	0.75		tp=0.44, tn=0.27, fp=0.18, fn=0.11		False
	13	0.5152		0.5994		0.5634		0.4245		0.7845	0.6857		tp=0.34, tn=0.36, fp=0.07, fn=0.24		False
	14	0.5017		0.5901		0.6306		0.4267		0.8125	0.6767		tp=0.31, tn=0.38, fp=0.077, fn=0.22		False
	15	0.4889		0.5778		0.6429		0.4631		0.8201	0.7101		tp=0.34, tn=0.38, fp=0.077, fn=0.2		True
	16	0.4801		0.5699		0.6662		0.4798		0.8314	0.7153		tp=0.34, tn=0.38, fp=0.07, fn=0.2		True
	17	0.4679		0.5389		0.6625		0.4979		0.8244	0.76		tp=0.4, tn=0.35, fp=0.1, fn=0.15		True
	18	0.4543		0.553		0.6802		0.4834		0.8361	0.7517		tp=0.39, tn=0.35, fp=0.11, fn=0.15		False
	19	0.4491		0.532		0.6802		0.4743		0.8361	0.7702		tp=0.43, tn=0.31, fp=0.13, fn=0.13		False
	20	0.4376		0.5313		0.6923		0.5058		0.844	0.7771		tp=0.43, tn=0.33, fp=0.12, fn=0.13		True
	21	0.4198		0.5611		0.7069		0.5231		0.8512	0.7552		tp=0.38, tn=0.38, fp=0.077, fn=0.17		True
	22	0.4128		0.5972		0.7038		0.4173		0.849	0.6565		tp=0.3, tn=0.38, fp=0.063, fn=0.25		False
	23	0.4076		0.5639		0.7242		0.511		0.8589	0.7465		tp=0.37, tn=0.38, fp=0.077, fn=0.17		False
	24	0.3881		0.5672		0.7307		0.5108		0.8639	0.7534		tp=0.38, tn=0.36, fp=0.077, fn=0.17		False
	25	0.3805		0.5548		0.7566		0.5392		0.8759	0.7606		tp=0.38, tn=0.38, fp=0.07, fn=0.17		True
	26	0.3777		0.5701		0.7329		0.511		0.8619	0.7465		tp=0.37, tn=0.38, fp=0.077, fn=0.17		False
	27	0.3637		0.5677		0.7599		0.539		0.8783	0.7571		tp=0.37, tn=0.39, fp=0.07, fn=0.17		False
	28	0.3526		0.611		0.7653		0.4477		0.8799	0.6767		tp=0.31, tn=0.38, fp=0.056, fn=0.24		False
	29	0.3478		0.5601		0.777		0.539		0.8845	0.7671		tp=0.39, tn=0.37, fp=0.07, fn=0.17		False
	30	0.3324		0.5341		0.7975		0.4923		0.8959	0.7692		tp=0.42, tn=0.33, fp=0.13, fn=0.13		False
	31	0.3212		0.5667		0.8239		0.5038		0.9094	0.75		tp=0.38, tn=0.37, fp=0.091, fn=0.16		False
	32	0.3148		0.5258		0.8182		0.5251		0.9072	0.7703		tp=0.4, tn=0.36, fp=0.1, fn=0.13		False
	33	0.3035		0.5558		0.8269		0.515		0.9113	0.7682		tp=0.41, tn=0.35, fp=0.091, fn=0.15		False
	34	0.2944		0.5368		0.8327		0.5414		0.9138	0.7785		tp=0.41, tn=0.36, fp=0.091, fn=0.14		True
	35	0.287		0.5519		0.8504		0.5069		0.9224	0.7568		tp=0.39, tn=0.36, fp=0.09, fn=0.16		False
	36	0.2796		0.54		0.8621		0.5552		0.9287	0.7755		tp=0.4, tn=0.37, fp=0.063, fn=0.17		True
	37	0.2697		0.5367		0.8826		0.5658		0.9396	0.7947		tp=0.42, tn=0.36, fp=0.098, fn=0.12		True
	38	0.2669		0.5758		0.8797		0.4948		0.938	0.7376		tp=0.36, tn=0.38, fp=0.084, fn=0.17		False
	39	0.2586		0.5525		0.8797		0.5117		0.9378	0.7712		tp=0.41, tn=0.34, fp=0.098, fn=0.15		False
	40	0.2489		0.5742		0.8886		0.5		0.9422	0.76		tp=0.4, tn=0.35, fp=0.098, fn=0.15		False
	41	0.2427		0.5702		0.9061		0.5117		0.9515	0.7712		tp=0.41, tn=0.34, fp=0.098, fn=0.15		False
	42	0.2352		0.5613		0.9092		0.5044		0.9528	0.7799		tp=0.43, tn=0.32, fp=0.13, fn=0.12		False
	43	0.2328		0.5429		0.9091		0.4878		0.953	0.7778		tp=0.44, tn=0.31, fp=0.13, fn=0.12		False
	44	0.227		0.5855		0.9208		0.4845		0.9594	0.755		tp=0.4, tn=0.34, fp=0.1, fn=0.15		False
	45	0.2204		0.6091		0.9123		0.4889		0.9541	0.7582		tp=0.41, tn=0.34, fp=0.091, fn=0.17		False
	46	0.2103		0.5592		0.9296		0.5089		0.9636	0.7742		tp=0.42, tn=0.34, fp=0.1, fn=0.14		False
	47	0.2056		0.5986		0.9296		0.4705		0.9639	0.7432		tp=0.38, tn=0.35, fp=0.11, fn=0.15		False
	48	0.1968		0.5727		0.9268		0.481		0.9619	0.755		tp=0.4, tn=0.34, fp=0.13, fn=0.13		False
	49	0.1992		0.5419		0.9354		0.5456		0.9668	0.8072		tp=0.47, tn=0.31, fp=0.14, fn=0.084		False
	50	0.1931		0.5425		0.9354		0.5219		0.9668	0.7792		tp=0.42, tn=0.34, fp=0.11, fn=0.13		False
	51	0.1825		0.5978		0.9502		0.5164		0.9745	0.7586		tp=0.38, tn=0.37, fp=0.091, fn=0.15		False
	52	0.1779		0.6133		0.9531		0.4957		0.976	0.7722		tp=0.43, tn=0.32, fp=0.098, fn=0.15		False
	53	0.1719		0.6188		0.956		0.5436		0.9775	0.7571		tp=0.37, tn=0.39, fp=0.063, fn=0.17		False
	54	0.1711		0.5963		0.9472		0.5038		0.9729	0.75		tp=0.38, tn=0.37, fp=0.091, fn=0.16		False
	55	0.1717		0.6071		0.9356		0.4926		0.9666	0.7692		tp=0.42, tn=0.33, fp=0.12, fn=0.13		False
	56	0.1723		0.6243		0.9385		0.4566		0.968	0.7738		tp=0.45, tn=0.28, fp=0.16, fn=0.1		False
	57	0.1622		0.6396		0.9531		0.4921		0.9758	0.7722		tp=0.43, tn=0.32, fp=0.14, fn=0.11		False
	58	0.1579		0.6167		0.9619		0.5115		0.9805	0.7651		tp=0.4, tn=0.36, fp=0.1, fn=0.14		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		41
learning rate		0.000365596228536
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_26-lr0.00037-h_size41-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6967		0.6869		0.03322		0.1361		0.5597	0.4882		tp=0.21, tn=0.34, fp=0.13, fn=0.32		True
	2	0.687		0.6886		0.07911		0.1207		0.5688	0.257		tp=0.082, tn=0.44, fp=0.038, fn=0.44		False
	3	0.6802		0.6752		0.1201		0.2224		0.5778	0.6219		tp=0.32, tn=0.29, fp=0.18, fn=0.2		True
	4	0.6744		0.6745		0.1491		0.1971		0.5968	0.6593		tp=0.38, tn=0.22, fp=0.24, fn=0.16		False
	5	0.6684		0.6757		0.1789		0.2001		0.6044	0.5652		tp=0.27, tn=0.32, fp=0.14, fn=0.27		False
	6	0.6622		0.6731		0.2121		0.1623		0.6223	0.6402		tp=0.37, tn=0.21, fp=0.27, fn=0.14		False
	7	0.6542		0.6731		0.2445		0.1596		0.6346	0.6435		tp=0.38, tn=0.2, fp=0.29, fn=0.13		False
	8	0.6506		0.6698		0.2316		0.1882		0.633	0.6441		tp=0.37, tn=0.23, fp=0.25, fn=0.15		False
	9	0.6441		0.7072		0.2649		0.1132		0.6521	0.3285		tp=0.12, tn=0.41, fp=0.064, fn=0.41		False
	10	0.6393		0.669		0.2517		0.1901		0.6356	0.6271		tp=0.34, tn=0.26, fp=0.21, fn=0.19		False
	11	0.6362		0.6794		0.2725		0.1771		0.6429	0.5781		tp=0.28, tn=0.3, fp=0.17, fn=0.24		False
	12	0.6358		0.7049		0.2611		0.1166		0.642	0.4		tp=0.15, tn=0.38, fp=0.092, fn=0.37		False
	13	0.6286		0.6899		0.2884		0.1225		0.6524	0.6302		tp=0.37, tn=0.2, fp=0.27, fn=0.16		False
	14	0.6244		0.6891		0.3064		0.1396		0.6551	0.5779		tp=0.29, tn=0.27, fp=0.2, fn=0.23		False
	15	0.6232		0.6926		0.302		0.135		0.6617	0.5764		tp=0.29, tn=0.27, fp=0.19, fn=0.24		False
	16	0.621		0.7336		0.2921		0.1501		0.6503	0.6767		tp=0.46, tn=0.1, fp=0.38, fn=0.054		False
	17	0.6224		0.6959		0.2996		0.1518		0.6592	0.5966		tp=0.31, tn=0.26, fp=0.21, fn=0.21		False
	18	0.6148		0.6951		0.3197		0.1654		0.6692	0.6524		tp=0.39, tn=0.19, fp=0.28, fn=0.13		False
	19	0.6145		0.6868		0.3203		0.1877		0.6726	0.634		tp=0.35, tn=0.25, fp=0.22, fn=0.19		False
	20	0.6139		0.6953		0.3215		0.1947		0.6682	0.6455		tp=0.36, tn=0.24, fp=0.23, fn=0.17		False
	21	0.6112		0.7053		0.324		0.1446		0.6661	0.6029		tp=0.32, tn=0.25, fp=0.22, fn=0.21		False
	22	0.6129		0.7001		0.3219		0.1226		0.6781	0.5112		tp=0.23, tn=0.32, fp=0.15, fn=0.29		False
	23	0.6116		0.7024		0.3285		0.1292		0.673	0.5813		tp=0.3, tn=0.26, fp=0.22, fn=0.22		False
	24	0.6075		0.6972		0.3299		0.17		0.6686	0.6398		tp=0.37, tn=0.22, fp=0.25, fn=0.16		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		119
learning rate		0.000250534591243
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_27-lr0.00025-h_size119-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6835		0.6778		0.1371		0.1851		0.6048	0.6409		tp=0.36, tn=0.24, fp=0.24, fn=0.17		True
	2	0.6802		0.6766		0.1314		0.1553		0.6053	0.645		tp=0.38, tn=0.2, fp=0.27, fn=0.15		False
	3	0.6809		0.6768		0.1247		0.1865		0.6086	0.6359		tp=0.35, tn=0.24, fp=0.23, fn=0.17		True
	4	0.6812		0.6758		0.1366		0.16		0.6126	0.645		tp=0.38, tn=0.2, fp=0.29, fn=0.13		False
	5	0.681		0.6809		0.1203		0.1502		0.6154	0.6389		tp=0.37, tn=0.2, fp=0.28, fn=0.14		False
	6	0.6802		0.674		0.1358		0.174		0.6079	0.6596		tp=0.4, tn=0.19, fp=0.28, fn=0.13		False
	7	0.6794		0.676		0.1332		0.1885		0.6244	0.6489		tp=0.37, tn=0.22, fp=0.26, fn=0.15		True
	8	0.6798		0.6723		0.1535		0.1725		0.6314	0.6523		tp=0.39, tn=0.2, fp=0.28, fn=0.13		False
	9	0.6804		0.6768		0.1253		0.2061		0.6165	0.6577		tp=0.38, tn=0.23, fp=0.24, fn=0.16		True
	10	0.6794		0.6821		0.1374		0.1484		0.6197	0.6121		tp=0.34, tn=0.24, fp=0.25, fn=0.18		False
	11	0.6809		0.6764		0.1154		0.1883		0.6136	0.6519		tp=0.38, tn=0.22, fp=0.25, fn=0.15		False
	12	0.6792		0.6737		0.1299		0.1845		0.6147	0.6535		tp=0.38, tn=0.21, fp=0.26, fn=0.14		False
	13	0.6795		0.6767		0.1389		0.1616		0.6243	0.6524		tp=0.39, tn=0.19, fp=0.28, fn=0.14		False
	14	0.6787		0.6784		0.1391		0.1516		0.6192	0.6653		tp=0.42, tn=0.15, fp=0.33, fn=0.095		False
	15	0.6784		0.6817		0.1421		0.1543		0.6284	0.5654		tp=0.28, tn=0.3, fp=0.18, fn=0.25		False
	16	0.6804		0.6781		0.1298		0.1493		0.6225	0.6513		tp=0.4, tn=0.18, fp=0.31, fn=0.12		False
	17	0.6782		0.6754		0.1466		0.1584		0.6193	0.6539		tp=0.39, tn=0.19, fp=0.29, fn=0.13		False
	18	0.6786		0.6751		0.1385		0.2042		0.6259	0.6562		tp=0.38, tn=0.23, fp=0.25, fn=0.15		False
	19	0.6804		0.6798		0.1112		0.1464		0.5939	0.664		tp=0.43, tn=0.13, fp=0.36, fn=0.077		False
	20	0.6784		0.6737		0.1272		0.1449		0.6133	0.6584		tp=0.41, tn=0.17, fp=0.3, fn=0.12		False
	21	0.679		0.678		0.1356		0.2002		0.6287	0.6453		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	22	0.6789		0.6768		0.1371		0.1874		0.6163	0.6519		tp=0.38, tn=0.22, fp=0.25, fn=0.16		False
	23	0.6797		0.6778		0.1346		0.1971		0.6224	0.6321		tp=0.34, tn=0.26, fp=0.23, fn=0.17		False
	24	0.6793		0.6814		0.124		0.1726		0.6143	0.6139		tp=0.33, tn=0.26, fp=0.23, fn=0.18		False
	25	0.6789		0.678		0.137		0.1482		0.6246	0.6453		tp=0.39, tn=0.19, fp=0.29, fn=0.14		False
	26	0.6785		0.677		0.1422		0.1976		0.6233	0.6518		tp=0.37, tn=0.23, fp=0.26, fn=0.14		False
	27	0.6781		0.6773		0.1374		0.2079		0.6278	0.6515		tp=0.37, tn=0.24, fp=0.23, fn=0.16		True
	28	0.6786		0.6789		0.1215		0.184		0.6173	0.6488		tp=0.37, tn=0.23, fp=0.24, fn=0.16		False
	29	0.6778		0.6736		0.1321		0.2043		0.6129	0.6501		tp=0.37, tn=0.24, fp=0.24, fn=0.16		False
	30	0.6778		0.676		0.1416		0.2117		0.6234	0.6531		tp=0.37, tn=0.24, fp=0.24, fn=0.15		True
	31	0.6771		0.6786		0.1424		0.2153		0.6297	0.6481		tp=0.36, tn=0.25, fp=0.22, fn=0.17		True
	32	0.6769		0.6763		0.1328		0.1933		0.6175	0.6424		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	33	0.6775		0.6706		0.1306		0.2156		0.6136	0.6608		tp=0.38, tn=0.23, fp=0.26, fn=0.13		True
	34	0.6766		0.6833		0.1369		0.1421		0.6279	0.5897		tp=0.31, tn=0.26, fp=0.21, fn=0.22		False
	35	0.6777		0.6797		0.1302		0.1671		0.6129	0.6462		tp=0.38, tn=0.21, fp=0.26, fn=0.15		False
	36	0.6777		0.6757		0.1299		0.1454		0.6098	0.664		tp=0.42, tn=0.16, fp=0.31, fn=0.11		False
	37	0.678		0.6824		0.1354		0.1703		0.6257	0.6413		tp=0.37, tn=0.22, fp=0.25, fn=0.16		False
	38	0.6775		0.6784		0.1299		0.1898		0.6153	0.6579		tp=0.38, tn=0.22, fp=0.25, fn=0.15		False
	39	0.677		0.681		0.1439		0.1292		0.6116	0.664		tp=0.43, tn=0.13, fp=0.36, fn=0.082		False
	40	0.6796		0.6851		0.1258		0.1416		0.6226	0.5917		tp=0.31, tn=0.26, fp=0.22, fn=0.21		False
	41	0.6775		0.6745		0.1313		0.1883		0.6195	0.6549		tp=0.38, tn=0.22, fp=0.26, fn=0.14		False
	42	0.6765		0.6906		0.1394		0.1031		0.6203	0.4943		tp=0.22, tn=0.32, fp=0.15, fn=0.3		False
	43	0.6772		0.6806		0.1452		0.1051		0.6097	0.6493		tp=0.42, tn=0.14, fp=0.35, fn=0.097		False
	44	0.6768		0.6834		0.1382		0.1566		0.6246	0.6323		tp=0.36, tn=0.22, fp=0.26, fn=0.16		False
	45	0.6753		0.6871		0.159		0.1193		0.6287	0.6627		tp=0.43, tn=0.13, fp=0.36, fn=0.085		False
	46	0.6776		0.6818		0.143		0.1854		0.6211	0.6425		tp=0.36, tn=0.23, fp=0.25, fn=0.16		False
	47	0.6759		0.6777		0.1422		0.1724		0.6183	0.661		tp=0.4, tn=0.2, fp=0.27, fn=0.14		False
	48	0.6775		0.6837		0.1393		0.1659		0.6241	0.6416		tp=0.37, tn=0.21, fp=0.27, fn=0.15		False
	49	0.6775		0.675		0.134		0.1951		0.6179	0.6563		tp=0.38, tn=0.22, fp=0.24, fn=0.15		False
	50	0.676		0.6771		0.1452		0.2167		0.6267	0.6652		tp=0.39, tn=0.22, fp=0.27, fn=0.13		True
	51	0.6763		0.6825		0.1406		0.1358		0.6188	0.6513		tp=0.4, tn=0.18, fp=0.29, fn=0.13		False
	52	0.677		0.6798		0.1303		0.1969		0.6151	0.6422		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	53	0.6761		0.6828		0.1328		0.1322		0.6139	0.6559		tp=0.42, tn=0.14, fp=0.35, fn=0.092		False
	54	0.6769		0.6762		0.1236		0.1815		0.6146	0.652		tp=0.38, tn=0.22, fp=0.26, fn=0.15		False
	55	0.6752		0.6792		0.1334		0.2146		0.6126	0.6449		tp=0.35, tn=0.26, fp=0.21, fn=0.18		False
	56	0.6751		0.6753		0.1427		0.2002		0.606	0.6548		tp=0.38, tn=0.23, fp=0.25, fn=0.15		False
	57	0.6755		0.6799		0.1532		0.1964		0.6258	0.6286		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	58	0.6759		0.6769		0.1324		0.152		0.6125	0.6612		tp=0.41, tn=0.16, fp=0.32, fn=0.11		False
	59	0.6765		0.6793		0.1402		0.12		0.624	0.6573		tp=0.42, tn=0.14, fp=0.34, fn=0.1		False
	60	0.6761		0.6765		0.1405		0.17		0.6104	0.6398		tp=0.37, tn=0.22, fp=0.25, fn=0.16		False
	61	0.6763		0.6788		0.1517		0.1459		0.6278	0.6758		tp=0.44, tn=0.13, fp=0.34, fn=0.082		False
	62	0.6756		0.6834		0.1489		0.1526		0.6259	0.6481		tp=0.39, tn=0.19, fp=0.28, fn=0.14		False
	63	0.6745		0.6815		0.1429		0.1291		0.614	0.6653		tp=0.43, tn=0.14, fp=0.34, fn=0.092		False
	64	0.6752		0.6718		0.1319		0.2025		0.6172	0.6652		tp=0.4, tn=0.2, fp=0.28, fn=0.12		False
	65	0.6768		0.6805		0.1338		0.1472		0.6136	0.6482		tp=0.39, tn=0.19, fp=0.29, fn=0.13		False
	66	0.6748		0.6814		0.1307		0.1052		0.6034	0.6392		tp=0.4, tn=0.15, fp=0.34, fn=0.11		False
	67	0.6748		0.6785		0.1249		0.1854		0.6169	0.6667		tp=0.4, tn=0.19, fp=0.27, fn=0.13		False
	68	0.6755		0.6857		0.1566		0.1135		0.6245	0.6417		tp=0.39, tn=0.16, fp=0.32, fn=0.12		False
	69	0.6755		0.6895		0.1382		0.1706		0.6145	0.6139		tp=0.33, tn=0.26, fp=0.2, fn=0.21		False
	70	0.6749		0.688		0.1541		0.02478		0.6232	0.3088		tp=0.11, tn=0.38, fp=0.092, fn=0.41		False
	71	0.6745		0.6789		0.1409		0.198		0.6046	0.6549		tp=0.38, tn=0.22, fp=0.26, fn=0.14		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		10
learning rate		0.00312275618669
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_28-lr0.0031-h_size10-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7015		0.6875		0.07181		0.138		0.4578	0.32		tp=0.11, tn=0.41, fp=0.049, fn=0.43		True
	2	0.6714		0.7056		0.12		0.1294		0.584	0.2128		tp=0.07, tn=0.41, fp=0.021, fn=0.5		False
	3	0.6308		0.6583		0.3025		0.1926		0.6098	0.5161		tp=0.22, tn=0.36, fp=0.11, fn=0.31		True
	4	0.5997		0.6252		0.4089		0.2686		0.6731	0.6623		tp=0.36, tn=0.28, fp=0.19, fn=0.17		True
	5	0.5648		0.6698		0.4305		0.2736		0.7052	0.4912		tp=0.19, tn=0.4, fp=0.056, fn=0.35		True
	6	0.5245		0.6636		0.5075		0.2682		0.7367	0.521		tp=0.22, tn=0.38, fp=0.07, fn=0.33		False
	7	0.4815		0.6212		0.598		0.3345		0.794	0.6212		tp=0.29, tn=0.36, fp=0.091, fn=0.26		True
	8	0.4512		0.5733		0.6126		0.3961		0.7982	0.7226		tp=0.39, tn=0.31, fp=0.13, fn=0.17		True
	9	0.3912		0.6692		0.7108		0.3296		0.8451	0.6107		tp=0.28, tn=0.36, fp=0.084, fn=0.27		False
	10	0.378		0.6287		0.6903		0.4132		0.8339	0.7657		tp=0.47, tn=0.24, fp=0.2, fn=0.091		True
	11	0.3457		0.6612		0.7155		0.3785		0.855	0.6761		tp=0.34, tn=0.34, fp=0.098, fn=0.22		False
	12	0.2924		0.641		0.7946		0.3544		0.8936	0.6974		tp=0.37, tn=0.31, fp=0.17, fn=0.15		False
	13	0.2925		0.666		0.7638		0.3982		0.8814	0.7114		tp=0.37, tn=0.33, fp=0.14, fn=0.16		False
	14	0.3235		0.7049		0.7388		0.3529		0.8645	0.7444		tp=0.47, tn=0.21, fp=0.24, fn=0.077		False
	15	0.2378		0.7179		0.8624		0.3798		0.928	0.7179		tp=0.39, tn=0.3, fp=0.15, fn=0.16		False
	16	0.1958		0.7435		0.9064		0.3887		0.9511	0.6986		tp=0.36, tn=0.34, fp=0.13, fn=0.18		False
	17	0.179		0.788		0.9149		0.3863		0.9563	0.7027		tp=0.36, tn=0.33, fp=0.13, fn=0.17		False
	18	0.1632		0.7902		0.9149		0.3734		0.9561	0.6939		tp=0.36, tn=0.33, fp=0.13, fn=0.18		False
	19	0.1665		0.8704		0.912		0.3501		0.9547	0.6803		tp=0.35, tn=0.32, fp=0.13, fn=0.2		False
	20	0.1288		0.9119		0.9619		0.3393		0.9804	0.6757		tp=0.35, tn=0.32, fp=0.13, fn=0.2		False
	21	0.114		0.9393		0.9648		0.3697		0.982	0.6761		tp=0.34, tn=0.34, fp=0.11, fn=0.21		False
	22	0.1083		1.016		0.9765		0.3344		0.9879	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.2		False
	23	0.1045		0.9855		0.9677		0.3806		0.9834	0.7179		tp=0.39, tn=0.3, fp=0.14, fn=0.17		False
	24	0.09139		0.9408		0.9707		0.3858		0.9849	0.6897		tp=0.35, tn=0.34, fp=0.1, fn=0.21		False
	25	0.08024		1.043		0.9853		0.3644		0.9925	0.717		tp=0.4, tn=0.29, fp=0.14, fn=0.17		False
	26	0.07904		1.119		0.9795		0.3459		0.9894	0.6713		tp=0.34, tn=0.34, fp=0.14, fn=0.19		False
	27	0.06859		1.051		0.9853		0.3984		0.9925	0.7152		tp=0.38, tn=0.32, fp=0.13, fn=0.17		False
	28	0.0626		1.137		0.9853		0.3863		0.9925	0.7027		tp=0.36, tn=0.33, fp=0.13, fn=0.17		False
	29	0.05729		1.103		0.9941		0.4015		0.997	0.7075		tp=0.36, tn=0.34, fp=0.13, fn=0.17		False
	30	0.05183		1.057		1		0.4577		1	0.7451		tp=0.4, tn=0.33, fp=0.1, fn=0.17		True
	31	0.05032		1.233		0.9912		0.3937		0.9955	0.7027		tp=0.36, tn=0.33, fp=0.11, fn=0.2		False
	32	0.05488		1.203		0.9912		0.3756		0.9955	0.6939		tp=0.36, tn=0.33, fp=0.13, fn=0.19		False
	33	0.04406		1.192		1		0.3929		1	0.7261		tp=0.4, tn=0.3, fp=0.15, fn=0.15		False
	34	0.04236		1.155		1		0.4438		1	0.7333		tp=0.38, tn=0.34, fp=0.11, fn=0.17		False
	35	0.03557		1.281		1		0.4037		1	0.7075		tp=0.36, tn=0.34, fp=0.12, fn=0.18		False
	36	0.0336		1.331		1		0.3812		1	0.7143		tp=0.38, tn=0.31, fp=0.15, fn=0.16		False
	37	0.03343		1.328		1		0.3944		1	0.7226		tp=0.39, tn=0.31, fp=0.15, fn=0.15		False
	38	0.03106		1.402		1		0.3976		1	0.7114		tp=0.37, tn=0.33, fp=0.15, fn=0.15		False
	39	0.02929		1.362		1		0.4114		1	0.7237		tp=0.38, tn=0.32, fp=0.13, fn=0.16		False
	40	0.02803		1.428		1		0.3937		1	0.7027		tp=0.36, tn=0.33, fp=0.11, fn=0.2		False
	41	0.02706		1.42		1		0.4195		1	0.7083		tp=0.36, tn=0.35, fp=0.11, fn=0.18		False
	42	0.03033		1.461		1		0.3455		1	0.662		tp=0.33, tn=0.34, fp=0.11, fn=0.22		False
	43	0.0289		1.644		0.9971		0.2968		0.9985	0.6232		tp=0.3, tn=0.34, fp=0.12, fn=0.24		False
	44	0.03194		1.524		0.9912		0.3576		0.9955	0.6713		tp=0.34, tn=0.34, fp=0.11, fn=0.22		False
	45	0.02358		1.547		1		0.4088		1	0.7308		tp=0.4, tn=0.31, fp=0.13, fn=0.16		False
	46	0.02094		1.6		1		0.3916		1	0.7296		tp=0.41, tn=0.29, fp=0.14, fn=0.16		False
	47	0.02014		1.394		1		0.4505		1	0.726		tp=0.37, tn=0.35, fp=0.098, fn=0.18		False
	48	0.0186		1.619		1		0.3438		1	0.6887		tp=0.36, tn=0.31, fp=0.14, fn=0.19		False
	49	0.01859		1.65		1		0.3611		1	0.7205		tp=0.41, tn=0.28, fp=0.15, fn=0.17		False
	50	0.01562		1.569		1		0.3756		1	0.6939		tp=0.36, tn=0.33, fp=0.13, fn=0.19		False
	51	0.01605		1.588		1		0.3701		1	0.698		tp=0.36, tn=0.32, fp=0.15, fn=0.17		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		65
learning rate		0.00391347796826
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_29-lr0.0039-h_size65-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6998		0.6772		0.07896		0.1123		0.4943	0.4923		tp=0.22, tn=0.31, fp=0.13, fn=0.33		True
	2	0.6234		0.6784		0.3512		0.1282		0.6646	0.5594		tp=0.28, tn=0.28, fp=0.17, fn=0.27		True
	3	0.5729		0.6766		0.3865		0.1469		0.6739	0.5694		tp=0.28, tn=0.28, fp=0.17, fn=0.26		True
	4	0.5025		0.7085		0.5069		0.1117		0.7407	0.5987		tp=0.33, tn=0.23, fp=0.2, fn=0.24		False
	5	0.4623		0.7924		0.5453		0.2156		0.7597	0.5899		tp=0.29, tn=0.31, fp=0.15, fn=0.25		True
	6	0.3916		0.9225		0.6685		0.1443		0.827	0.5263		tp=0.24, tn=0.31, fp=0.14, fn=0.3		False
	7	0.4487		1.075		0.5658		0.165		0.7778	0.4878		tp=0.21, tn=0.35, fp=0.1, fn=0.34		False
	8	0.3349		0.9691		0.7195		0.09282		0.85	0.5578		tp=0.29, tn=0.26, fp=0.2, fn=0.25		False
	9	0.294		0.9969		0.7596		0.2491		0.8742	0.64		tp=0.34, tn=0.29, fp=0.15, fn=0.22		True
	10	0.2767		1.213		0.7831		0.1715		0.8896	0.5612		tp=0.27, tn=0.3, fp=0.14, fn=0.29		False
	11	0.3065		1.412		0.7535		0.1493		0.8731	0.5039		tp=0.22, tn=0.34, fp=0.13, fn=0.31		False
	12	0.2977		1.354		0.7418		0.1736		0.8675	0.5588		tp=0.27, tn=0.31, fp=0.15, fn=0.27		False
	13	0.2116		1.29		0.8503		0.2244		0.9228	0.6014		tp=0.3, tn=0.3, fp=0.13, fn=0.27		False
	14	0.2024		1.553		0.8738		0.1832		0.9353	0.5693		tp=0.27, tn=0.31, fp=0.16, fn=0.25		False
	15	0.1818		1.669		0.8651		0.2201		0.9301	0.5672		tp=0.27, tn=0.33, fp=0.12, fn=0.29		False
	16	0.1897		1.759		0.8562		0.2106		0.9261	0.5735		tp=0.27, tn=0.32, fp=0.13, fn=0.27		False
	17	0.2032		1.744		0.8621		0.2233		0.9291	0.6584		tp=0.37, tn=0.24, fp=0.22, fn=0.16		False
	18	0.2278		1.653		0.7916		0.255		0.8929	0.6581		tp=0.36, tn=0.27, fp=0.17, fn=0.2		True
	19	0.1539		1.829		0.8681		0.2254		0.9315	0.6111		tp=0.31, tn=0.3, fp=0.15, fn=0.24		False
	20	0.1214		2.153		0.9297		0.2476		0.9642	0.5758		tp=0.27, tn=0.34, fp=0.11, fn=0.28		False
	21	0.134		2.19		0.918		0.2989		0.9582	0.6711		tp=0.36, tn=0.29, fp=0.16, fn=0.19		True
	22	0.168		2.304		0.868		0.2557		0.9323	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	23	0.1812		2.545		0.8562		0.2045		0.9261	0.5082		tp=0.22, tn=0.36, fp=0.098, fn=0.32		False
	24	0.1381		2.498		0.8885		0.2523		0.9429	0.6043		tp=0.29, tn=0.32, fp=0.13, fn=0.26		False
	25	0.09334		2.658		0.9589		0.2652		0.979	0.5909		tp=0.27, tn=0.35, fp=0.12, fn=0.26		False
	26	0.08707		2.653		0.9561		0.1984		0.9772	0.5735		tp=0.27, tn=0.32, fp=0.15, fn=0.25		False
	27	0.09537		2.849		0.9413		0.241		0.9699	0.6154		tp=0.31, tn=0.31, fp=0.15, fn=0.24		False
	28	0.09635		2.923		0.9326		0.2199		0.9651	0.5957		tp=0.29, tn=0.31, fp=0.14, fn=0.26		False
	29	0.1211		3.259		0.909		0.2186		0.9532	0.5606		tp=0.26, tn=0.34, fp=0.12, fn=0.29		False
	30	0.2359		2.91		0.7682		0.2267		0.8808	0.5778		tp=0.27, tn=0.33, fp=0.13, fn=0.26		False
	31	0.2185		2.665		0.8479		0.2401		0.9228	0.5942		tp=0.29, tn=0.32, fp=0.13, fn=0.27		False
	32	0.2028		2.552		0.8213		0.2808		0.9066	0.6187		tp=0.3, tn=0.33, fp=0.12, fn=0.25		False
	33	0.2421		2.164		0.8037		0.2184		0.9001	0.6584		tp=0.37, tn=0.24, fp=0.2, fn=0.19		False
	34	0.1222		2.431		0.8944		0.2764		0.9455	0.6438		tp=0.33, tn=0.31, fp=0.15, fn=0.21		False
	35	0.08043		2.653		0.9589		0.255		0.9789	0.6029		tp=0.29, tn=0.34, fp=0.14, fn=0.24		False
	36	0.05193		2.813		0.9796		0.2354		0.9894	0.5942		tp=0.29, tn=0.32, fp=0.13, fn=0.26		False
	37	0.05558		3.058		0.9825		0.2354		0.991	0.5942		tp=0.29, tn=0.32, fp=0.13, fn=0.26		False
	38	0.04678		3.051		0.9883		0.2556		0.994	0.5926		tp=0.28, tn=0.34, fp=0.12, fn=0.27		False
	39	0.04023		3.249		0.9883		0.2516		0.994	0.5985		tp=0.29, tn=0.33, fp=0.13, fn=0.26		False
	40	0.0352		3.211		0.9883		0.1969		0.994	0.5816		tp=0.28, tn=0.31, fp=0.15, fn=0.26		False
	41	0.0391		2.947		0.9853		0.2762		0.9925	0.6187		tp=0.3, tn=0.33, fp=0.13, fn=0.24		False
	42	0.03968		3.153		0.9883		0.2559		0.994	0.6087		tp=0.29, tn=0.33, fp=0.14, fn=0.24		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		170
learning rate		0.00201989228698
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_2-lr0.002-h_size170-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.8127		0.6289		0.02641		0.2922		0.4369	0.7024		tp=0.41, tn=0.24, fp=0.21, fn=0.14		True
	2	0.6447		0.596		0.2649		0.2887		0.6431	0.6988		tp=0.41, tn=0.24, fp=0.21, fn=0.14		False
	3	0.6101		0.5648		0.3204		0.4277		0.6588	0.776		tp=0.5, tn=0.22, fp=0.23, fn=0.056		True
	4	0.5754		0.5395		0.3637		0.3668		0.6877	0.7097		tp=0.38, tn=0.3, fp=0.15, fn=0.17		False
	5	0.5005		0.5571		0.5127		0.4586		0.7454	0.7417		tp=0.39, tn=0.34, fp=0.1, fn=0.17		True
	6	0.4432		0.5579		0.6098		0.505		0.8006	0.7799		tp=0.43, tn=0.32, fp=0.13, fn=0.11		True
	7	0.4347		0.5934		0.5874		0.4945		0.778	0.7483		tp=0.38, tn=0.36, fp=0.084, fn=0.17		False
	8	0.3266		0.6417		0.7549		0.5014		0.8768	0.7218		tp=0.34, tn=0.41, fp=0.07, fn=0.19		False
	9	0.2731		0.6473		0.7806		0.5076		0.8841	0.7771		tp=0.43, tn=0.33, fp=0.14, fn=0.1		True
	10	0.2338		0.6206		0.8153		0.6		0.9038	0.8054		tp=0.42, tn=0.38, fp=0.07, fn=0.13		True
	11	0.2243		0.7395		0.8327		0.5363		0.9143	0.7843		tp=0.42, tn=0.35, fp=0.11, fn=0.12		False
	12	0.1432		0.7741		0.9268		0.5146		0.9619	0.7952		tp=0.46, tn=0.3, fp=0.14, fn=0.098		False
	13	0.1235		0.9499		0.9237		0.458		0.9607	0.7133		tp=0.36, tn=0.36, fp=0.07, fn=0.22		False
	14	0.1076		0.9318		0.9502		0.5174		0.9742	0.7132		tp=0.32, tn=0.42, fp=0.049, fn=0.21		False
	15	0.1055		1.206		0.9355		0.4141		0.967	0.5812		tp=0.24, tn=0.42, fp=0.028, fn=0.31		False
	16	0.1363		0.9627		0.8826		0.5526		0.9398	0.7867		tp=0.41, tn=0.36, fp=0.098, fn=0.13		False
	17	0.07589		1.288		0.9589		0.3784		0.9789	0.5812		tp=0.24, tn=0.42, fp=0.049, fn=0.29		False
	18	0.07709		1.075		0.9589		0.5488		0.9789	0.8		tp=0.45, tn=0.33, fp=0.13, fn=0.091		False
	19	0.05872		1.044		0.9853		0.4936		0.9925	0.7722		tp=0.43, tn=0.32, fp=0.15, fn=0.1		False
	20	0.08893		1.135		0.9413		0.4841		0.9699	0.7273		tp=0.36, tn=0.37, fp=0.069, fn=0.2		False
	21	0.132		1.139		0.8944		0.4612		0.9458	0.7625		tp=0.43, tn=0.31, fp=0.13, fn=0.14		False
	22	0.04053		1.299		0.9883		0.474		0.994	0.7811		tp=0.46, tn=0.28, fp=0.17, fn=0.091		False
	23	0.03927		1.284		0.9853		0.476		0.9925	0.7702		tp=0.43, tn=0.31, fp=0.15, fn=0.11		False
	24	0.02425		1.252		0.9912		0.4607		0.9955	0.687		tp=0.31, tn=0.4, fp=0.063, fn=0.22		False
	25	0.02212		1.387		0.9971		0.4712		0.9985	0.7836		tp=0.47, tn=0.27, fp=0.17, fn=0.091		False
	26	0.02076		1.396		0.9971		0.4525		0.9985	0.7484		tp=0.41, tn=0.32, fp=0.12, fn=0.15		False
	27	0.01928		1.404		0.9971		0.4815		0.9985	0.755		tp=0.4, tn=0.34, fp=0.12, fn=0.14		False
	28	0.01679		1.177		0.9971		0.4992		0.9985	0.7632		tp=0.41, tn=0.34, fp=0.098, fn=0.15		False
	29	0.01532		1.368		0.9971		0.5299		0.9985	0.7975		tp=0.45, tn=0.31, fp=0.13, fn=0.1		False
	30	0.01211		1.471		1		0.4732		1	0.75		tp=0.4, tn=0.34, fp=0.11, fn=0.15		False
	31	0.01265		1.413		0.9971		0.5744		0.9985	0.8125		tp=0.45, tn=0.34, fp=0.1, fn=0.1		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		19
learning rate		0.00141075837572
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_30-lr0.0014-h_size19-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6946		0.6785		0.03888		0.167		0.5606	0.6653		tp=0.41, tn=0.18, fp=0.28, fn=0.13		True
	2	0.6857		0.6757		0.1053		0.2016		0.5763	0.6623		tp=0.39, tn=0.21, fp=0.28, fn=0.12		True
	3	0.6724		0.6633		0.1534		0.2151		0.5962	0.6607		tp=0.38, tn=0.24, fp=0.23, fn=0.16		True
	4	0.6672		0.6805		0.176		0.08572		0.5976	0.6704		tp=0.46, tn=0.09, fp=0.38, fn=0.067		False
	5	0.6556		0.67		0.2227		0.1359		0.6265	0.561		tp=0.28, tn=0.29, fp=0.19, fn=0.24		False
	6	0.6494		0.6763		0.2291		0.1358		0.6281	0.6612		tp=0.42, tn=0.16, fp=0.31, fn=0.12		False
	7	0.6463		0.6826		0.2417		0.1167		0.6364	0.5553		tp=0.28, tn=0.28, fp=0.19, fn=0.25		False
	8	0.6382		0.6786		0.2731		0.2031		0.6424	0.6268		tp=0.33, tn=0.27, fp=0.22, fn=0.18		False
	9	0.6313		0.685		0.2838		0.138		0.6543	0.521		tp=0.24, tn=0.32, fp=0.15, fn=0.29		False
	10	0.6211		0.6875		0.2984		0.1579		0.657	0.5941		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	11	0.6196		0.6833		0.2898		0.1712		0.6481	0.599		tp=0.31, tn=0.28, fp=0.19, fn=0.22		False
	12	0.6122		0.6877		0.3161		0.1661		0.6665	0.6333		tp=0.36, tn=0.23, fp=0.23, fn=0.18		False
	13	0.6122		0.689		0.3233		0.1334		0.6709	0.5743		tp=0.29, tn=0.27, fp=0.21, fn=0.23		False
	14	0.6041		0.7105		0.3445		0.1013		0.6803	0.4578		tp=0.19, tn=0.34, fp=0.13, fn=0.33		False
	15	0.6075		0.718		0.3368		0.1169		0.677	0.5111		tp=0.24, tn=0.31, fp=0.15, fn=0.3		False
	16	0.5979		0.6935		0.3429		0.1642		0.6794	0.5894		tp=0.3, tn=0.28, fp=0.2, fn=0.22		False
	17	0.5963		0.738		0.3523		0.1002		0.6812	0.4565		tp=0.19, tn=0.34, fp=0.13, fn=0.34		False
	18	0.6026		0.7457		0.3452		0.08715		0.6785	0.3686		tp=0.14, tn=0.39, fp=0.092, fn=0.38		False
	19	0.5929		0.7091		0.3588		0.1276		0.6911	0.4956		tp=0.22, tn=0.34, fp=0.15, fn=0.29		False
	20	0.5783		0.7354		0.386		0.1015		0.6979	0.4795		tp=0.21, tn=0.33, fp=0.15, fn=0.31		False
	21	0.5716		0.7055		0.3967		0.184		0.7021	0.6131		tp=0.32, tn=0.27, fp=0.18, fn=0.22		False
	22	0.5668		0.7121		0.3965		0.1548		0.706	0.5946		tp=0.31, tn=0.27, fp=0.22, fn=0.2		False
	23	0.5655		0.7497		0.4108		0.1009		0.7131	0.4431		tp=0.18, tn=0.35, fp=0.12, fn=0.34		False
	24	0.557		0.7689		0.4167		0.1164		0.7128	0.4639		tp=0.2, tn=0.35, fp=0.13, fn=0.33		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		26
learning rate		0.000187187989345
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_31-lr0.00019-h_size26-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6653		0.6346		0.2426		0.3384		0.6704	0.7238		tp=0.43, tn=0.24, fp=0.23, fn=0.1		True
	2	0.6421		0.6313		0.2947		0.3706		0.6885	0.6948		tp=0.36, tn=0.33, fp=0.14, fn=0.18		True
	3	0.6369		0.6154		0.2885		0.3885		0.676	0.7226		tp=0.4, tn=0.3, fp=0.18, fn=0.12		True
	4	0.6314		0.6077		0.3128		0.3785		0.6888	0.7244		tp=0.41, tn=0.28, fp=0.19, fn=0.12		False
	5	0.6285		0.6118		0.323		0.3614		0.6942	0.7232		tp=0.41, tn=0.27, fp=0.2, fn=0.12		False
	6	0.6256		0.6147		0.3266		0.3307		0.6954	0.7152		tp=0.42, tn=0.25, fp=0.21, fn=0.12		False
	7	0.6222		0.622		0.343		0.3179		0.6998	0.697		tp=0.39, tn=0.27, fp=0.22, fn=0.13		False
	8	0.6189		0.61		0.344		0.3574		0.7034	0.7045		tp=0.38, tn=0.3, fp=0.17, fn=0.15		False
	9	0.6146		0.623		0.3529		0.3478		0.7065	0.6864		tp=0.36, tn=0.32, fp=0.17, fn=0.16		False
	10	0.6115		0.6205		0.3567		0.3468		0.7068	0.691		tp=0.36, tn=0.31, fp=0.16, fn=0.16		False
	11	0.6074		0.6218		0.3636		0.3208		0.7103	0.6842		tp=0.37, tn=0.29, fp=0.18, fn=0.15		False
	12	0.6051		0.6145		0.3573		0.3402		0.7073	0.7023		tp=0.39, tn=0.28, fp=0.19, fn=0.14		False
	13	0.6005		0.6069		0.3628		0.3504		0.708	0.7133		tp=0.41, tn=0.27, fp=0.21, fn=0.11		False
	14	0.5968		0.623		0.3775		0.3614		0.7195	0.6613		tp=0.32, tn=0.36, fp=0.11, fn=0.21		False
	15	0.5919		0.6266		0.3801		0.297		0.7149	0.6584		tp=0.34, tn=0.31, fp=0.17, fn=0.18		False
	16	0.5904		0.6214		0.3836		0.3161		0.7176	0.6826		tp=0.37, tn=0.29, fp=0.19, fn=0.15		False
	17	0.5855		0.6146		0.3991		0.3137		0.7244	0.6925		tp=0.39, tn=0.27, fp=0.23, fn=0.12		False
	18	0.5839		0.6372		0.4056		0.3349		0.727	0.6232		tp=0.28, tn=0.38, fp=0.11, fn=0.24		False
	19	0.585		0.6165		0.4008		0.3409		0.7227	0.6632		tp=0.33, tn=0.34, fp=0.13, fn=0.2		False
	20	0.5795		0.6166		0.4136		0.3273		0.7245	0.6765		tp=0.35, tn=0.31, fp=0.16, fn=0.17		False
	21	0.5733		0.6255		0.4273		0.321		0.7367	0.6563		tp=0.33, tn=0.33, fp=0.15, fn=0.19		False
	22	0.5704		0.6193		0.4197		0.3005		0.731	0.6715		tp=0.36, tn=0.29, fp=0.18, fn=0.16		False
	23	0.5686		0.616		0.4305		0.2849		0.7353	0.6906		tp=0.39, tn=0.25, fp=0.21, fn=0.15		False
	24	0.5635		0.6285		0.4393		0.2725		0.7393	0.6414		tp=0.33, tn=0.31, fp=0.17, fn=0.19		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		41
learning rate		0.000184028535185
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_32-lr0.00018-h_size41-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6926		0.6866		-0.004968		0.09747		0.5967	0.6912		tp=0.51, tn=0.044, fp=0.43, fn=0.023		True
	2	0.6871		0.6838		0.1165		0.1116		0.6252	0.6753		tp=0.47, tn=0.085, fp=0.4, fn=0.051		True
	3	0.6827		0.6792		0.1554		0.189		0.6434	0.6638		tp=0.4, tn=0.2, fp=0.27, fn=0.13		True
	4	0.6773		0.6782		0.1905		0.2095		0.6433	0.6592		tp=0.38, tn=0.23, fp=0.25, fn=0.15		True
	5	0.6721		0.6775		0.2207		0.1795		0.6427	0.6276		tp=0.34, tn=0.25, fp=0.23, fn=0.18		False
	6	0.667		0.6881		0.2275		0.1547		0.6512	0.4068		tp=0.15, tn=0.4, fp=0.077, fn=0.37		False
	7	0.6618		0.6712		0.2612		0.1932		0.6481	0.5798		tp=0.28, tn=0.32, fp=0.17, fn=0.23		False
	8	0.6553		0.6752		0.2582		0.2197		0.6505	0.5753		tp=0.27, tn=0.33, fp=0.14, fn=0.26		True
	9	0.6492		0.6681		0.2772		0.2017		0.6452	0.65		tp=0.37, tn=0.24, fp=0.23, fn=0.17		False
	10	0.6444		0.6721		0.3015		0.1652		0.6722	0.5838		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	11	0.6389		0.6732		0.2969		0.1867		0.6667	0.596		tp=0.3, tn=0.29, fp=0.18, fn=0.23		False
	12	0.6335		0.6757		0.3304		0.1476		0.6717	0.6327		tp=0.37, tn=0.21, fp=0.27, fn=0.15		False
	13	0.629		0.6679		0.3188		0.2121		0.6751	0.6111		tp=0.31, tn=0.29, fp=0.18, fn=0.22		False
	14	0.6251		0.6901		0.3435		0.1686		0.685	0.472		tp=0.19, tn=0.37, fp=0.1, fn=0.34		False
	15	0.6214		0.6675		0.3357		0.1785		0.6734	0.6276		tp=0.34, tn=0.25, fp=0.22, fn=0.19		False
	16	0.6163		0.677		0.3445		0.1524		0.6816	0.645		tp=0.38, tn=0.2, fp=0.28, fn=0.14		False
	17	0.6137		0.6746		0.3558		0.1331		0.6893	0.6019		tp=0.33, tn=0.24, fp=0.23, fn=0.21		False
	18	0.6106		0.6834		0.3635		0.1391		0.6934	0.5882		tp=0.31, tn=0.26, fp=0.21, fn=0.22		False
	19	0.607		0.6741		0.3676		0.1431		0.6925	0.6178		tp=0.35, tn=0.23, fp=0.26, fn=0.17		False
	20	0.6036		0.6763		0.3606		0.1715		0.6912	0.597		tp=0.31, tn=0.28, fp=0.19, fn=0.22		False
	21	0.6		0.6806		0.3706		0.1919		0.6944	0.5691		tp=0.27, tn=0.32, fp=0.16, fn=0.25		False
	22	0.5977		0.6803		0.3847		0.1353		0.6994	0.5786		tp=0.3, tn=0.27, fp=0.21, fn=0.23		False
	23	0.5958		0.6876		0.383		0.1467		0.7022	0.614		tp=0.34, tn=0.24, fp=0.24, fn=0.18		False
	24	0.5928		0.6902		0.3871		0.1421		0.703	0.567		tp=0.28, tn=0.29, fp=0.19, fn=0.24		False
	25	0.5922		0.6822		0.3924		0.1549		0.7039	0.5926		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	26	0.5911		0.6807		0.3984		0.1368		0.7095	0.6161		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	27	0.5879		0.702		0.3954		0.09005		0.7059	0.5436		tp=0.27, tn=0.27, fp=0.2, fn=0.25		False
	28	0.5866		0.6954		0.3854		0.1809		0.703	0.551		tp=0.26, tn=0.33, fp=0.15, fn=0.27		False
	29	0.5866		0.692		0.3942		0.127		0.7045	0.5488		tp=0.27, tn=0.29, fp=0.19, fn=0.25		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		32
learning rate		0.001880256459
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_33-lr0.0019-h_size32-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6799		0.6713		0.1256		0.09517		0.579	0.5707		tp=0.3, tn=0.25, fp=0.22, fn=0.23		True
	2	0.6706		0.6694		0.2007		0.1577		0.6204	0.6256		tp=0.35, tn=0.23, fp=0.25, fn=0.17		True
	3	0.662		0.6749		0.2079		0.1652		0.6251	0.6197		tp=0.34, tn=0.25, fp=0.23, fn=0.18		True
	4	0.6589		0.6743		0.2102		0.1263		0.6209	0.6185		tp=0.35, tn=0.22, fp=0.26, fn=0.17		False
	5	0.6541		0.6822		0.2096		0.09157		0.6237	0.5849		tp=0.32, tn=0.23, fp=0.24, fn=0.21		False
	6	0.6468		0.6792		0.2487		0.09031		0.6409	0.5776		tp=0.31, tn=0.24, fp=0.24, fn=0.22		False
	7	0.6465		0.689		0.2419		0.1337		0.6415	0.6484		tp=0.39, tn=0.18, fp=0.29, fn=0.14		False
	8	0.6411		0.6882		0.2594		0.1343		0.6433	0.6454		tp=0.39, tn=0.18, fp=0.29, fn=0.14		False
	9	0.6429		0.6857		0.2518		0.1311		0.6462	0.5986		tp=0.32, tn=0.24, fp=0.24, fn=0.19		False
	10	0.6373		0.6895		0.2584		0.1535		0.6491	0.5885		tp=0.3, tn=0.27, fp=0.2, fn=0.22		False
	11	0.6381		0.6928		0.2629		0.1321		0.6476	0.5827		tp=0.3, tn=0.26, fp=0.22, fn=0.22		False
	12	0.6313		0.6984		0.279		0.1353		0.6563	0.6		tp=0.32, tn=0.25, fp=0.24, fn=0.19		False
	13	0.6287		0.7017		0.2848		0.1293		0.6519	0.6061		tp=0.33, tn=0.23, fp=0.25, fn=0.18		False
	14	0.6289		0.699		0.2997		0.08927		0.6636	0.5982		tp=0.34, tn=0.21, fp=0.26, fn=0.19		False
	15	0.6243		0.7017		0.2779		0.1291		0.6575	0.5275		tp=0.25, tn=0.31, fp=0.17, fn=0.27		False
	16	0.627		0.7026		0.2978		0.1708		0.6566	0.5766		tp=0.28, tn=0.3, fp=0.18, fn=0.24		True
	17	0.62		0.7018		0.2896		0.1421		0.6593	0.5995		tp=0.32, tn=0.25, fp=0.22, fn=0.21		False
	18	0.618		0.7287		0.3066		0.1143		0.6648	0.6448		tp=0.4, tn=0.15, fp=0.33, fn=0.11		False
	19	0.6249		0.7062		0.2842		0.1475		0.6501	0.5751		tp=0.29, tn=0.28, fp=0.18, fn=0.24		False
	20	0.6221		0.6983		0.2966		0.1531		0.658	0.6449		tp=0.38, tn=0.2, fp=0.27, fn=0.15		False
	21	0.618		0.7037		0.3087		0.1121		0.6628	0.5948		tp=0.32, tn=0.23, fp=0.25, fn=0.19		False
	22	0.6131		0.7166		0.3298		0.1215		0.6756	0.66		tp=0.42, tn=0.15, fp=0.33, fn=0.11		False
	23	0.6111		0.7147		0.3234		0.118		0.6744	0.6222		tp=0.36, tn=0.21, fp=0.27, fn=0.17		False
	24	0.6098		0.7138		0.3222		0.1515		0.6763	0.5145		tp=0.23, tn=0.34, fp=0.14, fn=0.29		False
	25	0.6062		0.7231		0.341		0.1031		0.6802	0.6449		tp=0.41, tn=0.15, fp=0.33, fn=0.11		False
	26	0.6063		0.7211		0.331		0.1034		0.6784	0.5935		tp=0.33, tn=0.23, fp=0.25, fn=0.19		False
	27	0.5992		0.7007		0.3469		0.1752		0.6829	0.5903		tp=0.3, tn=0.29, fp=0.19, fn=0.22		True
	28	0.6028		0.7195		0.3364		0.1183		0.6798	0.5678		tp=0.29, tn=0.27, fp=0.21, fn=0.23		False
	29	0.6076		0.7127		0.3327		0.142		0.676	0.6033		tp=0.32, tn=0.25, fp=0.23, fn=0.2		False
	30	0.6013		0.7157		0.3304		0.155		0.6723	0.5307		tp=0.24, tn=0.33, fp=0.15, fn=0.28		False
	31	0.603		0.7099		0.328		0.1636		0.6711	0.5816		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	32	0.5934		0.7136		0.3554		0.1319		0.69	0.625		tp=0.36, tn=0.21, fp=0.26, fn=0.17		False
	33	0.5898		0.7207		0.3564		0.07861		0.6879	0.5687		tp=0.3, tn=0.24, fp=0.24, fn=0.22		False
	34	0.591		0.7593		0.35		0.11		0.6834	0.6575		tp=0.43, tn=0.13, fp=0.36, fn=0.087		False
	35	0.5918		0.7175		0.3622		0.123		0.6891	0.6065		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	36	0.5864		0.7102		0.3457		0.1132		0.6825	0.577		tp=0.3, tn=0.26, fp=0.22, fn=0.22		False
	37	0.5846		0.7127		0.3812		0.1303		0.6989	0.5535		tp=0.27, tn=0.29, fp=0.19, fn=0.24		False
	38	0.5812		0.7308		0.3807		0.128		0.7024	0.6115		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	39	0.5809		0.7131		0.3712		0.07849		0.6912	0.5707		tp=0.31, tn=0.24, fp=0.24, fn=0.22		False
	40	0.5759		0.7272		0.3848		0.1017		0.698	0.6282		tp=0.38, tn=0.18, fp=0.31, fn=0.14		False
	41	0.5749		0.7517		0.3918		0.1474		0.7057	0.6653		tp=0.42, tn=0.16, fp=0.32, fn=0.11		False
	42	0.5796		0.7086		0.3747		0.1523		0.6942	0.6388		tp=0.37, tn=0.21, fp=0.27, fn=0.15		False
	43	0.5659		0.7307		0.4039		0.1585		0.7088	0.6253		tp=0.35, tn=0.23, fp=0.24, fn=0.17		False
	44	0.5684		0.7375		0.3944		0.118		0.7089	0.6222		tp=0.36, tn=0.21, fp=0.27, fn=0.17		False
	45	0.5653		0.7172		0.4043		0.1317		0.7095	0.6129		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	46	0.5637		0.7103		0.3907		0.1517		0.7058	0.6062		tp=0.32, tn=0.25, fp=0.21, fn=0.21		False
	47	0.5583		0.7496		0.4249		0.1313		0.7197	0.6453		tp=0.39, tn=0.19, fp=0.27, fn=0.15		False
	48	0.5558		0.728		0.4303		0.1551		0.7236	0.5865		tp=0.3, tn=0.28, fp=0.19, fn=0.23		False


data			/scratch/asw462/data/levin
input size		300
hidden size		64
learning rate		0.00129631544191
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_34-lr0.0013-h_size64-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5873		0.6039		0.01686		0		0.8395	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5484		0.538		0.04353		0		0.8422	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	3	0.5151		0.546		0.2112		0.1999		0.8479	0.8255		tp=0.68, tn=0.035, fp=0.27, fn=0.014		True
	4	0.4717		0.5014		0.3624		0.3896		0.8652	0.8584		tp=0.68, tn=0.098, fp=0.19, fn=0.035		True
	5	0.4481		0.499		0.4422		0.4355		0.8723	0.8584		tp=0.65, tn=0.13, fp=0.16, fn=0.056		True
	6	0.4158		0.5532		0.4595		0.3505		0.8747	0.8356		tp=0.66, tn=0.084, fp=0.24, fn=0.021		False
	7	0.3929		0.5129		0.5277		0.5037		0.8851	0.8692		tp=0.65, tn=0.15, fp=0.15, fn=0.049		True
	8	0.3874		0.5182		0.5537		0.4057		0.8897	0.861		tp=0.67, tn=0.11, fp=0.17, fn=0.049		False
	9	0.3548		0.5454		0.5988		0.3472		0.9	0.806		tp=0.57, tn=0.16, fp=0.13, fn=0.14		False
	10	0.3471		0.5545		0.6122		0.3235		0.9022	0.8295		tp=0.63, tn=0.11, fp=0.19, fn=0.07		False
	11	0.3425		0.5129		0.6204		0.4113		0.9044	0.8673		tp=0.69, tn=0.1, fp=0.17, fn=0.042		False
	12	0.3403		0.5657		0.6309		0.3725		0.9076	0.8426		tp=0.64, tn=0.13, fp=0.16, fn=0.077		False
	13	0.3232		0.575		0.6528		0.4008		0.9111	0.8396		tp=0.62, tn=0.14, fp=0.17, fn=0.07		False
	14	0.3163		0.5508		0.6652		0.3992		0.9136	0.8532		tp=0.65, tn=0.13, fp=0.15, fn=0.07		False
	15	0.308		0.5555		0.6753		0.3465		0.9176	0.8455		tp=0.65, tn=0.11, fp=0.16, fn=0.077		False
	16	0.2991		0.5732		0.6964		0.2883		0.921	0.8472		tp=0.68, tn=0.077, fp=0.2, fn=0.049		False
	17	0.3096		0.6025		0.6627		0.3536		0.9127	0.8333		tp=0.63, tn=0.12, fp=0.19, fn=0.063		False
	18	0.2926		0.6011		0.6876		0.386		0.9195	0.8325		tp=0.61, tn=0.15, fp=0.15, fn=0.091		False
	19	0.2746		0.6092		0.7282		0.3473		0.9296	0.8302		tp=0.62, tn=0.13, fp=0.15, fn=0.1		False
	20	0.2855		0.5783		0.6954		0.3724		0.9202	0.8341		tp=0.62, tn=0.14, fp=0.15, fn=0.098		False
	21	0.2747		0.6885		0.7207		0.2997		0.9268	0.8152		tp=0.6, tn=0.13, fp=0.16, fn=0.11		False
	22	0.2725		0.6913		0.7244		0.3464		0.9276	0.8155		tp=0.59, tn=0.15, fp=0.16, fn=0.1		False
	23	0.2665		0.6744		0.7296		0.3688		0.9294	0.8269		tp=0.6, tn=0.15, fp=0.15, fn=0.1		False
	24	0.2734		0.7138		0.7088		0.3381		0.9234	0.8079		tp=0.57, tn=0.15, fp=0.14, fn=0.13		False
	25	0.2645		0.6355		0.7266		0.3588		0.9296	0.8357		tp=0.62, tn=0.13, fp=0.14, fn=0.1		False
	26	0.2552		0.6441		0.7427		0.3795		0.9331	0.8411		tp=0.63, tn=0.13, fp=0.15, fn=0.084		False
	27	0.2551		0.6866		0.7522		0.3612		0.9355	0.8357		tp=0.62, tn=0.13, fp=0.15, fn=0.098		False
	28	0.2523		0.7317		0.7233		0.3472		0.9262	0.806		tp=0.57, tn=0.16, fp=0.13, fn=0.14		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		39
learning rate		0.000171070996994
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_35-lr0.00017-h_size39-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6994		0.6956		-0.04276		0.03563		0.429	0.04938		tp=0.014, tn=0.45, fp=0.007, fn=0.53		True
	2	0.6876		0.6827		0.03936		0.277		0.5964	0.6946		tp=0.41, tn=0.24, fp=0.22, fn=0.13		True
	3	0.6782		0.6826		0.1697		0.1417		0.3163	0.2947		tp=0.098, tn=0.43, fp=0.042, fn=0.43		False
	4	0.6677		0.6753		0.3304		0.2409		0.646	0.6099		tp=0.3, tn=0.31, fp=0.15, fn=0.24		False
	5	0.6609		0.6708		0.3325		0.2227		0.5882	0.6056		tp=0.3, tn=0.31, fp=0.16, fn=0.23		False
	6	0.6542		0.6662		0.3281		0.2371		0.601	0.5564		tp=0.26, tn=0.33, fp=0.091, fn=0.32		False
	7	0.6452		0.6675		0.3713		0.2106		0.688	0.5735		tp=0.27, tn=0.32, fp=0.13, fn=0.27		False
	8	0.6365		0.6627		0.397		0.2218		0.6438	0.6216		tp=0.32, tn=0.29, fp=0.16, fn=0.23		False
	9	0.628		0.6647		0.3989		0.1613		0.6741	0.4793		tp=0.2, tn=0.36, fp=0.1, fn=0.34		False
	10	0.6196		0.6484		0.3905		0.2929		0.6416	0.6286		tp=0.31, tn=0.33, fp=0.12, fn=0.24		True
	11	0.612		0.6501		0.4426		0.28		0.7156	0.6533		tp=0.34, tn=0.29, fp=0.14, fn=0.22		False
	12	0.6036		0.6539		0.431		0.2378		0.6798	0.5323		tp=0.23, tn=0.36, fp=0.091, fn=0.31		False
	13	0.5979		0.6526		0.4159		0.2371		0.6905	0.5538		tp=0.25, tn=0.34, fp=0.098, fn=0.31		False
	14	0.5893		0.6456		0.4373		0.207		0.6952	0.5797		tp=0.28, tn=0.31, fp=0.14, fn=0.27		False
	15	0.5811		0.6295		0.4587		0.2781		0.703	0.6232		tp=0.3, tn=0.34, fp=0.15, fn=0.22		False
	16	0.5745		0.6352		0.4924		0.3667		0.7398	0.626		tp=0.29, tn=0.37, fp=0.07, fn=0.27		True
	17	0.567		0.6416		0.4897		0.2934		0.7067	0.5954		tp=0.27, tn=0.36, fp=0.098, fn=0.27		False
	18	0.5587		0.6307		0.498		0.3345		0.7373	0.6212		tp=0.29, tn=0.36, fp=0.091, fn=0.26		False
	19	0.5514		0.6422		0.5144		0.3175		0.7357	0.6165		tp=0.29, tn=0.36, fp=0.098, fn=0.26		False
	20	0.5435		0.623		0.5321		0.3312		0.7452	0.6528		tp=0.33, tn=0.33, fp=0.1, fn=0.24		False
	21	0.5379		0.6437		0.5309		0.3306		0.7619	0.5827		tp=0.26, tn=0.37, fp=0.063, fn=0.31		False
	22	0.5337		0.6342		0.5218		0.2708		0.7346	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.2		False
	23	0.5212		0.6343		0.5773		0.3336		0.7805	0.626		tp=0.29, tn=0.37, fp=0.1, fn=0.24		False
	24	0.5147		0.6203		0.5718		0.3175		0.7633	0.6429		tp=0.31, tn=0.34, fp=0.12, fn=0.22		False
	25	0.5075		0.6257		0.5628		0.2885		0.7704	0.6438		tp=0.33, tn=0.31, fp=0.13, fn=0.24		False
	26	0.5005		0.6138		0.5787		0.305		0.7729	0.6483		tp=0.33, tn=0.31, fp=0.12, fn=0.24		False
	27	0.4949		0.639		0.5837		0.3217		0.7887	0.5873		tp=0.26, tn=0.38, fp=0.077, fn=0.29		False
	28	0.4986		0.6143		0.5556		0.2939		0.7587	0.6835		tp=0.38, tn=0.27, fp=0.16, fn=0.19		False
	29	0.4795		0.6317		0.6091		0.2596		0.7866	0.6087		tp=0.29, tn=0.33, fp=0.13, fn=0.24		False
	30	0.4738		0.6209		0.6275		0.3097		0.8043	0.6383		tp=0.31, tn=0.33, fp=0.11, fn=0.24		False
	31	0.4692		0.6264		0.617		0.2968		0.7937	0.6232		tp=0.3, tn=0.34, fp=0.12, fn=0.24		False
	32	0.461		0.6379		0.6214		0.2334		0.8042	0.5839		tp=0.28, tn=0.32, fp=0.12, fn=0.28		False
	33	0.4554		0.6253		0.6555		0.2974		0.8139	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.22		False
	34	0.4465		0.6148		0.649		0.3005		0.8119	0.6331		tp=0.31, tn=0.34, fp=0.13, fn=0.23		False
	35	0.4402		0.6189		0.6639		0.3187		0.8195	0.6711		tp=0.35, tn=0.31, fp=0.14, fn=0.2		False
	36	0.4361		0.6333		0.6832		0.2764		0.8344	0.597		tp=0.28, tn=0.35, fp=0.11, fn=0.26		False
	37	0.4256		0.6267		0.6857		0.3687		0.8286	0.702		tp=0.37, tn=0.31, fp=0.16, fn=0.15		True
	38	0.4246		0.6467		0.6685		0.3208		0.827	0.6377		tp=0.31, tn=0.34, fp=0.11, fn=0.24		False
	39	0.4162		0.6331		0.6772		0.3387		0.8338	0.6165		tp=0.29, tn=0.36, fp=0.077, fn=0.28		False
	40	0.4135		0.6236		0.6632		0.2886		0.8212	0.6577		tp=0.34, tn=0.3, fp=0.15, fn=0.2		False
	41	0.4075		0.6006		0.7143		0.358		0.8406	0.7305		tp=0.43, tn=0.26, fp=0.19, fn=0.13		False
	42	0.4085		0.6336		0.6716		0.3336		0.8328	0.626		tp=0.29, tn=0.37, fp=0.1, fn=0.24		False
	43	0.3926		0.6538		0.7067		0.2981		0.8466	0.6338		tp=0.31, tn=0.32, fp=0.11, fn=0.25		False
	44	0.3863		0.6284		0.7201		0.3039		0.8491	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	45	0.3812		0.65		0.7184		0.3647		0.8563	0.6418		tp=0.3, tn=0.36, fp=0.084, fn=0.25		False
	46	0.3814		0.6229		0.7134		0.2939		0.8474	0.6577		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	47	0.37		0.631		0.7429		0.3281		0.8629	0.6423		tp=0.31, tn=0.35, fp=0.12, fn=0.22		False
	48	0.366		0.6233		0.726		0.3695		0.8522	0.6714		tp=0.33, tn=0.35, fp=0.11, fn=0.21		True
	49	0.3591		0.6587		0.745		0.3476		0.8703	0.637		tp=0.3, tn=0.36, fp=0.091, fn=0.25		False
	50	0.3549		0.5988		0.7694		0.3552		0.8722	0.7013		tp=0.38, tn=0.3, fp=0.14, fn=0.18		False
	51	0.3518		0.6301		0.7567		0.3425		0.8725	0.6423		tp=0.31, tn=0.35, fp=0.098, fn=0.24		False
	52	0.3438		0.5743		0.7747		0.3846		0.881	0.7105		tp=0.38, tn=0.31, fp=0.13, fn=0.17		True
	53	0.3418		0.6555		0.7747		0.2913		0.881	0.6531		tp=0.34, tn=0.31, fp=0.15, fn=0.21		False
	54	0.3401		0.6325		0.7571		0.2969		0.8717	0.6531		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	55	0.3329		0.643		0.7917		0.3926		0.8932	0.6667		tp=0.32, tn=0.36, fp=0.083, fn=0.24		True
	56	0.3283		0.6412		0.7828		0.3867		0.8879	0.6519		tp=0.31, tn=0.37, fp=0.076, fn=0.25		False
	57	0.3235		0.6683		0.7891		0.3608		0.8892	0.6569		tp=0.31, tn=0.36, fp=0.1, fn=0.22		False
	58	0.3171		0.6733		0.799		0.3256		0.8924	0.6573		tp=0.33, tn=0.33, fp=0.13, fn=0.22		False
	59	0.3115		0.5902		0.8036		0.3907		0.8974	0.7027		tp=0.36, tn=0.33, fp=0.12, fn=0.19		False
	60	0.3082		0.6544		0.8018		0.3289		0.8941	0.6757		tp=0.35, tn=0.31, fp=0.15, fn=0.18		False
	61	0.3086		0.6765		0.8269		0.3565		0.9115	0.6569		tp=0.31, tn=0.36, fp=0.11, fn=0.22		False
	62	0.3023		0.6571		0.8298		0.3884		0.9124	0.6667		tp=0.31, tn=0.37, fp=0.098, fn=0.22		False
	63	0.2955		0.6687		0.8241		0.3545		0.9083	0.6667		tp=0.33, tn=0.33, fp=0.1, fn=0.23		False
	64	0.2915		0.6366		0.8563		0.3407		0.9254	0.6522		tp=0.31, tn=0.35, fp=0.12, fn=0.22		False
	65	0.2845		0.6753		0.8445		0.3255		0.9198	0.6621		tp=0.34, tn=0.32, fp=0.13, fn=0.22		False
	66	0.2819		0.6724		0.8475		0.3662		0.9207	0.6761		tp=0.34, tn=0.34, fp=0.12, fn=0.2		False
	67	0.2782		0.6699		0.8475		0.3498		0.9207	0.6571		tp=0.32, tn=0.34, fp=0.1, fn=0.23		False
	68	0.2724		0.669		0.8591		0.3288		0.9275	0.6475		tp=0.31, tn=0.34, fp=0.12, fn=0.22		False
	69	0.2726		0.6558		0.8327		0.3336		0.914	0.68		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	70	0.2638		0.6647		0.8712		0.3937		0.9327	0.7027		tp=0.36, tn=0.33, fp=0.11, fn=0.2		True
	71	0.2621		0.7009		0.8623		0.3382		0.9282	0.6621		tp=0.34, tn=0.32, fp=0.1, fn=0.24		False
	72	0.2561		0.6844		0.8832		0.3475		0.9385	0.6803		tp=0.35, tn=0.32, fp=0.13, fn=0.2		False
	73	0.2532		0.7006		0.8856		0.366		0.9408	0.6714		tp=0.33, tn=0.35, fp=0.12, fn=0.2		False
	74	0.2493		0.6597		0.8888		0.3655		0.9419	0.6892		tp=0.36, tn=0.32, fp=0.12, fn=0.2		False
	75	0.2456		0.6311		0.8837		0.4065		0.9381	0.7075		tp=0.36, tn=0.34, fp=0.11, fn=0.19		True
	76	0.2448		0.749		0.8973		0.3334		0.9474	0.6525		tp=0.32, tn=0.34, fp=0.11, fn=0.23		False
	77	0.241		0.6968		0.8947		0.3415		0.945	0.662		tp=0.33, tn=0.34, fp=0.12, fn=0.22		False
	78	0.239		0.678		0.8917		0.375		0.9435	0.698		tp=0.36, tn=0.32, fp=0.13, fn=0.19		False
	79	0.2354		0.7067		0.8831		0.3454		0.9387	0.6803		tp=0.35, tn=0.32, fp=0.14, fn=0.19		False
	80	0.2343		0.7297		0.8857		0.3663		0.9417	0.6619		tp=0.32, tn=0.35, fp=0.098, fn=0.23		False
	81	0.2288		0.7396		0.8973		0.3046		0.9474	0.6531		tp=0.34, tn=0.31, fp=0.12, fn=0.24		False
	82	0.2235		0.7069		0.9178		0.3164		0.9577	0.6377		tp=0.31, tn=0.34, fp=0.12, fn=0.23		False
	83	0.2215		0.7306		0.9183		0.3245		0.9571	0.6423		tp=0.31, tn=0.35, fp=0.13, fn=0.22		False
	84	0.2176		0.7508		0.9034		0.2938		0.9496	0.6331		tp=0.31, tn=0.34, fp=0.14, fn=0.22		False
	85	0.2132		0.7495		0.9178		0.2974		0.9577	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.22		False
	86	0.2096		0.7434		0.9179		0.3199		0.9576	0.6573		tp=0.33, tn=0.33, fp=0.14, fn=0.2		False
	87	0.2079		0.688		0.9179		0.4248		0.958	0.7285		tp=0.38, tn=0.33, fp=0.14, fn=0.15		True
	88	0.2035		0.6841		0.924		0.404		0.9602	0.7034		tp=0.36, tn=0.34, fp=0.12, fn=0.18		False
	89	0.2032		0.8091		0.9325		0.2645		0.9653	0.6143		tp=0.3, tn=0.32, fp=0.13, fn=0.25		False
	90	0.2067		0.8307		0.909		0.2915		0.9532	0.6176		tp=0.29, tn=0.34, fp=0.12, fn=0.24		False
	91	0.1989		0.7855		0.9354		0.3054		0.9669	0.6667		tp=0.35, tn=0.3, fp=0.14, fn=0.21		False
	92	0.1921		0.7479		0.9296		0.3412		0.9636	0.6712		tp=0.34, tn=0.32, fp=0.12, fn=0.22		False
	93	0.1905		0.7696		0.9415		0.3505		0.9695	0.6759		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	94	0.1858		0.7847		0.9472		0.3251		0.9727	0.6667		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	95	0.1838		0.7817		0.9501		0.3328		0.9743	0.662		tp=0.33, tn=0.34, fp=0.14, fn=0.2		False
	96	0.181		0.7463		0.9414		0.389		0.9697	0.7105		tp=0.38, tn=0.31, fp=0.12, fn=0.19		False
	97	0.1788		0.7996		0.9531		0.3225		0.9758	0.6573		tp=0.33, tn=0.33, fp=0.13, fn=0.21		False
	98	0.176		0.7866		0.9501		0.3251		0.9743	0.6667		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	99	0.1733		0.7805		0.9561		0.4001		0.9772	0.7152		tp=0.38, tn=0.32, fp=0.13, fn=0.17		False
	100	0.1717		0.807		0.9443		0.3552		0.9712	0.7013		tp=0.38, tn=0.3, fp=0.14, fn=0.18		False
	101	0.1686		0.7434		0.9472		0.348		0.9728	0.6713		tp=0.34, tn=0.34, fp=0.13, fn=0.2		False
	102	0.1676		0.7565		0.9532		0.3783		0.9757	0.6939		tp=0.36, tn=0.33, fp=0.12, fn=0.2		False
	103	0.1644		0.8035		0.956		0.3712		0.9773	0.698		tp=0.36, tn=0.32, fp=0.14, fn=0.17		False
	104	0.163		0.743		0.9413		0.4114		0.9698	0.7237		tp=0.38, tn=0.32, fp=0.13, fn=0.16		False
	105	0.1603		0.7764		0.9472		0.4001		0.9729	0.7152		tp=0.38, tn=0.32, fp=0.13, fn=0.17		False
	106	0.1557		0.8219		0.9619		0.3505		0.9804	0.6759		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	107	0.1558		0.8413		0.9619		0.3468		0.9803	0.6846		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	108	0.1543		0.8196		0.953		0.3787		0.9759	0.6897		tp=0.35, tn=0.34, fp=0.12, fn=0.2		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		153
learning rate		0.000704219454181
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_36-lr0.0007-h_size153-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6115		0.6102		0.06032		0.09005		0.8134	0.8145		tp=0.68, tn=0.0059, fp=0.31, fn=0.0015		True
	2	0.6062		0.6026		0.07778		0.1698		0.8163	0.8173		tp=0.67, tn=0.027, fp=0.29, fn=0.01		True
	3	0.6073		0.6047		0.09402		0.115		0.8184	0.8129		tp=0.67, tn=0.018, fp=0.3, fn=0.01		False
	4	0.6077		0.6129		0.07758		0.08857		0.8165	0.8106		tp=0.68, tn=0.0059, fp=0.32, fn=0.0015		False
	5	0.6067		0.6101		0.07795		0.1108		0.8165	0.8079		tp=0.67, tn=0.016, fp=0.31, fn=0.0089		False
	6	0.6058		0.6079		0.07786		0.0861		0.8178	0.8099		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	7	0.605		0.607		0.08647		0.08674		0.8185	0.812		tp=0.68, tn=0.0074, fp=0.31, fn=0.0029		False
	8	0.6062		0.6113		0.09476		0.07006		0.8188	0.8096		tp=0.68, tn=0.0059, fp=0.32, fn=0.003		False
	9	0.6046		0.6005		0.0909		0.1073		0.8183	0.8197		tp=0.69, tn=0.0074, fp=0.3, fn=0.0015		False
	10	0.606		0.6045		0.1001		0.0879		0.8188	0.8145		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	11	0.6055		0.6124		0.08486		0.08895		0.8179	0.8117		tp=0.68, tn=0.0059, fp=0.31, fn=0.0015		False
	12	0.6049		0.6159		0.08695		0.07084		0.8175	0.8096		tp=0.68, tn=0.0044, fp=0.32, fn=0.0015		False
	13	0.6056		0.6091		0.08695		0.0861		0.8175	0.8099		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	14	0.6054		0.6146		0.09554		0.06923		0.8185	0.8071		tp=0.67, tn=0.0059, fp=0.32, fn=0.003		False
	15	0.6042		0.6099		0.09607		0.08653		0.8195	0.811		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	16	0.6048		0.6104		0.08128		0.08966		0.8176	0.8134		tp=0.68, tn=0.0059, fp=0.31, fn=0.0015		False
	17	0.605		0.6071		0.09973		0.123		0.8193	0.8125		tp=0.67, tn=0.015, fp=0.31, fn=0.0059		False
	18	0.6042		0.6023		0.09727		0.08878		0.8181	0.8166		tp=0.68, tn=0.0074, fp=0.3, fn=0.003		False
	19	0.604		0.6063		0.09338		0.1193		0.8191	0.8159		tp=0.68, tn=0.0089, fp=0.31, fn=0.0015		False
	20	0.6048		0.6126		0.09779		0.1114		0.8195	0.8111		tp=0.67, tn=0.013, fp=0.31, fn=0.0059		False
	21	0.604		0.6115		0.1042		0.1006		0.819	0.8113		tp=0.68, tn=0.0089, fp=0.31, fn=0.003		False
	22	0.6035		0.6168		0.09833		0.02923		0.819	0.8067		tp=0.67, tn=0.003, fp=0.32, fn=0.003		False
	23	0.6043		0.6108		0.0954		0.08567		0.8195	0.8089		tp=0.67, tn=0.0074, fp=0.32, fn=0.003		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		48
learning rate		0.000330866724727
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_37-lr0.00033-h_size48-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6928		0.6906		0.0395		0.00162		0.5246	0.1136		tp=0.035, tn=0.42, fp=0.028, fn=0.52		True
	2	0.6689		0.6654		0.2307		0.3299		0.4962	0.7374		tp=0.46, tn=0.21, fp=0.24, fn=0.091		True
	3	0.6529		0.6716		0.2754		0.2549		0.5971	0.4957		tp=0.2, tn=0.38, fp=0.063, fn=0.35		False
	4	0.6356		0.6681		0.3513		0.2659		0.6657	0.487		tp=0.19, tn=0.4, fp=0.056, fn=0.35		False
	5	0.6183		0.6457		0.3896		0.2268		0.6441	0.6452		tp=0.35, tn=0.27, fp=0.17, fn=0.21		False
	6	0.6036		0.662		0.408		0.3149		0.6773	0.5217		tp=0.21, tn=0.41, fp=0.049, fn=0.34		False
	7	0.5883		0.6488		0.4488		0.2255		0.7035	0.5714		tp=0.27, tn=0.34, fp=0.13, fn=0.27		False
	8	0.5723		0.631		0.472		0.2877		0.7188	0.6531		tp=0.34, tn=0.31, fp=0.16, fn=0.2		False
	9	0.5549		0.6334		0.4951		0.3652		0.7354	0.619		tp=0.27, tn=0.39, fp=0.077, fn=0.26		True
	10	0.5384		0.6312		0.5395		0.3046		0.7558	0.6331		tp=0.31, tn=0.34, fp=0.12, fn=0.24		False
	11	0.5247		0.6189		0.5392		0.3571		0.7632	0.6803		tp=0.35, tn=0.32, fp=0.11, fn=0.22		False
	12	0.5142		0.6129		0.5509		0.3476		0.7685	0.637		tp=0.3, tn=0.36, fp=0.091, fn=0.25		False
	13	0.4997		0.6222		0.5363		0.3412		0.7569	0.6887		tp=0.36, tn=0.31, fp=0.15, fn=0.17		False
	14	0.484		0.6184		0.5927		0.3907		0.7832	0.7027		tp=0.36, tn=0.33, fp=0.12, fn=0.19		True
	15	0.4649		0.5966		0.6439		0.3435		0.8006	0.7195		tp=0.41, tn=0.27, fp=0.17, fn=0.15		False
	16	0.4549		0.5982		0.6098		0.3783		0.7957	0.6939		tp=0.36, tn=0.33, fp=0.12, fn=0.2		False
	17	0.4375		0.6198		0.6685		0.3697		0.8264	0.6761		tp=0.34, tn=0.34, fp=0.11, fn=0.21		False
	18	0.431		0.5949		0.6362		0.3006		0.8098	0.6753		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	19	0.4137		0.6567		0.6864		0.3376		0.8346	0.6377		tp=0.31, tn=0.34, fp=0.091, fn=0.26		False
	20	0.4023		0.6404		0.7134		0.3498		0.8474	0.6571		tp=0.32, tn=0.34, fp=0.1, fn=0.23		False
	21	0.3862		0.6258		0.7108		0.3944		0.8451	0.7296		tp=0.41, tn=0.29, fp=0.17, fn=0.13		True
	22	0.3836		0.6332		0.683		0.313		0.8364	0.6839		tp=0.37, tn=0.29, fp=0.15, fn=0.2		False
	23	0.3653		0.6351		0.7448		0.3505		0.8672	0.6759		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	24	0.353		0.5936		0.7547		0.4193		0.8692	0.7123		tp=0.36, tn=0.34, fp=0.11, fn=0.18		True
	25	0.3431		0.6553		0.7605		0.3199		0.8723	0.6573		tp=0.33, tn=0.33, fp=0.14, fn=0.2		False
	26	0.3297		0.6318		0.7919		0.3902		0.8913	0.6809		tp=0.34, tn=0.35, fp=0.098, fn=0.22		False
	27	0.3215		0.6524		0.7975		0.3515		0.8953	0.7051		tp=0.38, tn=0.29, fp=0.17, fn=0.15		False
	28	0.31		0.6406		0.8015		0.3558		0.8944	0.7305		tp=0.43, tn=0.26, fp=0.18, fn=0.13		False
	29	0.3166		0.611		0.7594		0.3934		0.8765	0.7261		tp=0.4, tn=0.3, fp=0.16, fn=0.14		False
	30	0.2926		0.6902		0.8155		0.3256		0.9032	0.6573		tp=0.33, tn=0.33, fp=0.13, fn=0.22		False
	31	0.2923		0.668		0.8004		0.3528		0.8976	0.7013		tp=0.38, tn=0.3, fp=0.16, fn=0.16		False
	32	0.2826		0.6783		0.83		0.3942		0.9113	0.6857		tp=0.34, tn=0.36, fp=0.11, fn=0.2		False
	33	0.2656		0.7048		0.8535		0.3609		0.9235	0.662		tp=0.33, tn=0.34, fp=0.091, fn=0.24		False
	34	0.2655		0.7024		0.8305		0.3194		0.9105	0.6667		tp=0.34, tn=0.31, fp=0.14, fn=0.2		False
	35	0.2527		0.7565		0.8592		0.3052		0.9281	0.6434		tp=0.32, tn=0.32, fp=0.12, fn=0.24		False
	36	0.2473		0.6748		0.8861		0.376		0.9401	0.6897		tp=0.35, tn=0.34, fp=0.13, fn=0.19		False
	37	0.2349		0.7046		0.8944		0.3344		0.9455	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.2		False
	38	0.2263		0.6614		0.915		0.3783		0.956	0.6939		tp=0.36, tn=0.33, fp=0.12, fn=0.2		False
	39	0.2202		0.7604		0.909		0.3292		0.9532	0.6525		tp=0.32, tn=0.34, fp=0.12, fn=0.22		False
	40	0.215		0.7348		0.9149		0.3415		0.9561	0.662		tp=0.33, tn=0.34, fp=0.12, fn=0.22		False
	41	0.2079		0.7176		0.918		0.376		0.9573	0.6897		tp=0.35, tn=0.34, fp=0.13, fn=0.19		False
	42	0.202		0.7605		0.9326		0.3734		0.9655	0.6939		tp=0.36, tn=0.33, fp=0.13, fn=0.18		False
	43	0.2004		0.7593		0.9121		0.3865		0.9551	0.7105		tp=0.38, tn=0.31, fp=0.13, fn=0.18		False
	44	0.1922		0.8221		0.9237		0.3217		0.9608	0.6575		tp=0.33, tn=0.32, fp=0.12, fn=0.23		False
	45	0.1975		0.8972		0.8739		0.2964		0.9346	0.6176		tp=0.29, tn=0.34, fp=0.11, fn=0.25		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		63
learning rate		0.00101277985313
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_38-lr0.001-h_size63-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6918		0.7034		0.0777		0.1129		0.5687	0.2222		tp=0.069, tn=0.45, fp=0.031, fn=0.45		True
	2	0.635		0.6689		0.2869		0.1773		0.6451	0.547		tp=0.25, tn=0.33, fp=0.14, fn=0.28		True
	3	0.5938		0.6987		0.3667		0.1169		0.6847	0.6573		tp=0.42, tn=0.14, fp=0.33, fn=0.1		False
	4	0.5448		0.7736		0.4474		0.1295		0.7284	0.6718		tp=0.45, tn=0.11, fp=0.37, fn=0.066		False
	5	0.5166		0.6953		0.4923		0.1956		0.7511	0.6372		tp=0.35, tn=0.25, fp=0.22, fn=0.18		True
	6	0.4797		0.7482		0.5573		0.2188		0.7838	0.5926		tp=0.29, tn=0.32, fp=0.15, fn=0.24		True
	7	0.4281		0.8301		0.6094		0.1792		0.8076	0.5341		tp=0.24, tn=0.34, fp=0.13, fn=0.29		False
	8	0.4098		0.7722		0.6407		0.2084		0.8223	0.5995		tp=0.3, tn=0.31, fp=0.18, fn=0.21		False
	9	0.3815		0.8888		0.6714		0.1808		0.8385	0.5622		tp=0.27, tn=0.32, fp=0.15, fn=0.26		False
	10	0.3452		1.027		0.7111		0.1585		0.8589	0.415		tp=0.16, tn=0.4, fp=0.082, fn=0.36		False
	11	0.3468		0.8919		0.7122		0.2189		0.8582	0.6067		tp=0.3, tn=0.31, fp=0.17, fn=0.22		True
	12	0.3128		0.9774		0.7441		0.1868		0.8742	0.5954		tp=0.3, tn=0.29, fp=0.18, fn=0.23		False
	13	0.2955		0.9936		0.7707		0.1885		0.8877	0.6374		tp=0.35, tn=0.24, fp=0.23, fn=0.17		False
	14	0.2802		0.9863		0.7808		0.2207		0.8917	0.6181		tp=0.32, tn=0.29, fp=0.18, fn=0.21		True
	15	0.2514		1.093		0.7991		0.1984		0.901	0.6578		tp=0.38, tn=0.23, fp=0.24, fn=0.16		False
	16	0.2401		1.105		0.8127		0.1682		0.9083	0.599		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	17	0.2047		1.23		0.8547		0.1601		0.9288	0.5116		tp=0.23, tn=0.34, fp=0.13, fn=0.3		False
	18	0.2077		1.277		0.8564		0.1961		0.929	0.6338		tp=0.35, tn=0.26, fp=0.21, fn=0.19		False
	19	0.184		1.288		0.876		0.2498		0.9393	0.6422		tp=0.34, tn=0.29, fp=0.19, fn=0.18		True
	20	0.165		1.359		0.8972		0.206		0.9494	0.6115		tp=0.31, tn=0.29, fp=0.18, fn=0.22		False
	21	0.1631		1.444		0.9019		0.2204		0.9518	0.6514		tp=0.36, tn=0.25, fp=0.24, fn=0.15		False
	22	0.169		1.376		0.8854		0.2303		0.9438	0.6305		tp=0.33, tn=0.29, fp=0.18, fn=0.21		False
	23	0.1524		1.457		0.9001		0.238		0.9509	0.6057		tp=0.3, tn=0.32, fp=0.15, fn=0.23		False
	24	0.1234		1.515		0.9338		0.2138		0.9675	0.6091		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	25	0.106		1.552		0.9575		0.1839		0.9791	0.5855		tp=0.29, tn=0.3, fp=0.17, fn=0.24		False
	26	0.1016		1.657		0.9557		0.1815		0.9781	0.6376		tp=0.36, tn=0.24, fp=0.23, fn=0.18		False
	27	0.09328		1.652		0.9581		0.2463		0.9794	0.6423		tp=0.34, tn=0.29, fp=0.18, fn=0.19		False
	28	0.08468		1.689		0.9681		0.2251		0.9843	0.6062		tp=0.3, tn=0.31, fp=0.16, fn=0.23		False
	29	0.07987		1.849		0.9687		0.2086		0.9846	0.6036		tp=0.3, tn=0.3, fp=0.17, fn=0.23		False
	30	0.07404		1.71		0.9728		0.2716		0.9866	0.6553		tp=0.35, tn=0.29, fp=0.18, fn=0.18		True
	31	0.1189		1.523		0.9137		0.2261		0.9576	0.6308		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	32	0.1064		1.827		0.9351		0.2265		0.9681	0.592		tp=0.28, tn=0.32, fp=0.15, fn=0.25		False
	33	0.07995		2.02		0.964		0.1974		0.9823	0.548		tp=0.25, tn=0.34, fp=0.13, fn=0.28		False
	34	0.07022		1.876		0.9669		0.1908		0.9837	0.6357		tp=0.35, tn=0.25, fp=0.23, fn=0.17		False
	35	0.06107		1.874		0.9776		0.2043		0.989	0.6318		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	36	0.06012		2.001		0.974		0.2046		0.9872	0.602		tp=0.3, tn=0.3, fp=0.18, fn=0.22		False
	37	0.06322		1.941		0.9758		0.2386		0.9881	0.611		tp=0.3, tn=0.32, fp=0.17, fn=0.22		False
	38	0.0617		1.853		0.9788		0.2417		0.9896	0.6525		tp=0.35, tn=0.27, fp=0.2, fn=0.17		False
	39	0.05173		1.989		0.9835		0.2452		0.9918	0.6105		tp=0.3, tn=0.32, fp=0.16, fn=0.22		False
	40	0.04939		2.011		0.9829		0.2387		0.9916	0.6459		tp=0.35, tn=0.27, fp=0.21, fn=0.17		False
	41	0.05031		2.085		0.9829		0.2121		0.9916	0.6169		tp=0.32, tn=0.29, fp=0.17, fn=0.22		False
	42	0.04789		2.044		0.9858		0.2314		0.993	0.625		tp=0.32, tn=0.29, fp=0.18, fn=0.21		False
	43	0.04166		2.099		0.9911		0.2195		0.9956	0.6415		tp=0.35, tn=0.26, fp=0.22, fn=0.17		False
	44	0.04361		2.129		0.9864		0.2257		0.9933	0.6326		tp=0.33, tn=0.28, fp=0.2, fn=0.19		False
	45	0.0596		2.045		0.9758		0.234		0.9881	0.6134		tp=0.31, tn=0.31, fp=0.17, fn=0.22		False
	46	0.04205		2.126		0.9858		0.1933		0.993	0.6161		tp=0.32, tn=0.27, fp=0.19, fn=0.21		False
	47	0.04228		2.139		0.9876		0.2158		0.9939	0.6146		tp=0.31, tn=0.29, fp=0.18, fn=0.21		False
	48	0.05359		2.102		0.9793		0.2003		0.9898	0.5943		tp=0.29, tn=0.3, fp=0.17, fn=0.23		False
	49	0.04967		2.286		0.9787		0.202		0.9895	0.5683		tp=0.27, tn=0.33, fp=0.15, fn=0.26		False
	50	0.0596		2.09		0.9716		0.2405		0.986	0.6266		tp=0.32, tn=0.3, fp=0.17, fn=0.21		False
	51	0.05029		2.222		0.9799		0.2287		0.9901	0.6377		tp=0.34, tn=0.28, fp=0.21, fn=0.18		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		46
learning rate		0.000132324774355
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_39-lr0.00013-h_size46-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6909		0.6877		0.03282		0.1599		0.5596	0.2439		tp=0.077, tn=0.45, fp=0.023, fn=0.45		True
	2	0.6737		0.6645		0.1678		0.2047		0.5919	0.6452		tp=0.36, tn=0.25, fp=0.22, fn=0.18		True
	3	0.6595		0.6663		0.249		0.224		0.6276	0.6326		tp=0.33, tn=0.28, fp=0.18, fn=0.21		True
	4	0.6402		0.6585		0.3424		0.2357		0.6857	0.6266		tp=0.32, tn=0.3, fp=0.18, fn=0.2		True
	5	0.6242		0.6534		0.3749		0.219		0.6999	0.6275		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	6	0.6046		0.6492		0.389		0.2528		0.6975	0.649		tp=0.34, tn=0.28, fp=0.2, fn=0.18		True
	7	0.5886		0.6735		0.4104		0.2375		0.7092	0.5215		tp=0.22, tn=0.38, fp=0.092, fn=0.31		False
	8	0.5689		0.6625		0.4682		0.2057		0.7375	0.6779		tp=0.41, tn=0.19, fp=0.27, fn=0.12		False
	9	0.5536		0.6645		0.4728		0.1751		0.7419	0.5781		tp=0.28, tn=0.3, fp=0.17, fn=0.24		False
	10	0.5341		0.6629		0.515		0.1876		0.759	0.6471		tp=0.37, tn=0.23, fp=0.22, fn=0.18		False
	11	0.5208		0.6488		0.5378		0.239		0.7735	0.639		tp=0.34, tn=0.28, fp=0.19, fn=0.19		False
	12	0.5042		0.6601		0.5458		0.258		0.7738	0.6787		tp=0.39, tn=0.25, fp=0.22, fn=0.15		True
	13	0.4982		0.6942		0.5331		0.2104		0.7725	0.6623		tp=0.39, tn=0.22, fp=0.26, fn=0.13		False
	14	0.4778		0.7114		0.5792		0.1642		0.7931	0.506		tp=0.22, tn=0.36, fp=0.13, fn=0.29		False
	15	0.4644		0.7023		0.597		0.2076		0.8017	0.6623		tp=0.39, tn=0.22, fp=0.26, fn=0.13		False
	16	0.4543		0.6874		0.62		0.2203		0.8124	0.6219		tp=0.32, tn=0.29, fp=0.18, fn=0.21		False
	17	0.44		0.7		0.6326		0.2299		0.8199	0.6287		tp=0.33, tn=0.29, fp=0.19, fn=0.2		False
	18	0.4316		0.7299		0.6436		0.1927		0.8246	0.6471		tp=0.37, tn=0.23, fp=0.24, fn=0.16		False
	19	0.4186		0.7427		0.649		0.1891		0.8272	0.5699		tp=0.27, tn=0.32, fp=0.16, fn=0.25		False
	20	0.4057		0.7175		0.6732		0.2241		0.8404	0.6122		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	21	0.4006		0.7436		0.6856		0.2406		0.8447	0.6318		tp=0.33, tn=0.29, fp=0.18, fn=0.2		False
	22	0.3918		0.7386		0.6785		0.2202		0.8414	0.6465		tp=0.36, tn=0.26, fp=0.23, fn=0.16		False
	23	0.3773		0.7384		0.7027		0.2195		0.8542	0.6256		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	24	0.3711		0.7574		0.7169		0.2445		0.8611	0.6557		tp=0.36, tn=0.26, fp=0.22, fn=0.16		False
	25	0.3652		0.8085		0.714		0.184		0.8595	0.6565		tp=0.38, tn=0.21, fp=0.25, fn=0.15		False
	26	0.3576		0.8014		0.7353		0.2217		0.8692	0.6447		tp=0.35, tn=0.26, fp=0.22, fn=0.17		False
	27	0.3488		0.8146		0.7265		0.1962		0.8658	0.6104		tp=0.31, tn=0.28, fp=0.2, fn=0.2		False
	28	0.3409		0.7957		0.7329		0.1911		0.8679	0.622		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	29	0.3326		0.8223		0.7536		0.2367		0.8792	0.6755		tp=0.39, tn=0.23, fp=0.23, fn=0.15		False
	30	0.325		0.8044		0.7631		0.2017		0.884	0.6139		tp=0.32, tn=0.28, fp=0.19, fn=0.21		False
	31	0.3225		0.836		0.7577		0.185		0.8808	0.6238		tp=0.34, tn=0.26, fp=0.21, fn=0.2		False
	32	0.3154		0.8811		0.7708		0.2327		0.8878	0.6606		tp=0.37, tn=0.25, fp=0.23, fn=0.15		False
	33	0.31		0.86		0.7684		0.2084		0.8866	0.6192		tp=0.32, tn=0.28, fp=0.19, fn=0.21		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		137
learning rate		0.000197770975922
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_3-lr0.0002-h_size137-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.615		0.6392		0.01434		0		0.818	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5866		0.6206		0.1021		0.02331		0.8196	0.806		tp=0.67, tn=0.0044, fp=0.32, fn=0.0059		True
	3	0.5606		0.6187		0.213		0.1014		0.8256	0.7955		tp=0.63, tn=0.046, fp=0.27, fn=0.055		True
	4	0.532		0.663		0.3152		0.05596		0.8368	0.8113		tp=0.68, tn=0.0059, fp=0.31, fn=0.0044		False
	5	0.5092		0.6369		0.358		0.13		0.8405	0.7865		tp=0.6, tn=0.07, fp=0.24, fn=0.083		True
	6	0.4862		0.6463		0.4374		0.1191		0.8535	0.7715		tp=0.58, tn=0.08, fp=0.24, fn=0.1		False
	7	0.4612		0.6636		0.4689		0.1474		0.8591	0.765		tp=0.56, tn=0.1, fp=0.21, fn=0.13		True
	8	0.442		0.6935		0.5		0.1312		0.8644	0.7743		tp=0.58, tn=0.083, fp=0.23, fn=0.1		False
	9	0.428		0.707		0.5317		0.1557		0.8714	0.7382		tp=0.51, tn=0.13, fp=0.2, fn=0.17		True
	10	0.4064		0.7328		0.5717		0.1353		0.8814	0.7556		tp=0.55, tn=0.1, fp=0.22, fn=0.13		False
	11	0.3963		0.7622		0.5816		0.1228		0.8827	0.766		tp=0.57, tn=0.086, fp=0.24, fn=0.11		False
	12	0.3847		0.804		0.5931		0.1157		0.8846	0.7733		tp=0.58, tn=0.075, fp=0.25, fn=0.096		False
	13	0.3772		0.8385		0.5987		0.1271		0.8856	0.7834		tp=0.6, tn=0.068, fp=0.25, fn=0.079		False
	14	0.364		0.8185		0.6156		0.1552		0.8903	0.7588		tp=0.54, tn=0.11, fp=0.21, fn=0.13		False
	15	0.3522		0.8182		0.6378		0.1855		0.8965	0.7519		tp=0.52, tn=0.13, fp=0.18, fn=0.16		True
	16	0.3411		0.9063		0.6525		0.1443		0.8993	0.772		tp=0.57, tn=0.09, fp=0.23, fn=0.11		False
	17	0.3378		0.903		0.6544		0.1605		0.9003	0.7595		tp=0.54, tn=0.11, fp=0.21, fn=0.13		False
	18	0.3288		0.9024		0.663		0.1802		0.9022	0.7352		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	19	0.3269		0.9336		0.6673		0.1633		0.9031	0.7608		tp=0.55, tn=0.11, fp=0.21, fn=0.13		False
	20	0.3128		0.9886		0.6857		0.1504		0.9082	0.7706		tp=0.57, tn=0.095, fp=0.23, fn=0.11		False
	21	0.3116		0.9508		0.6866		0.1663		0.9086	0.7398		tp=0.51, tn=0.13, fp=0.18, fn=0.18		False
	22	0.3025		1.01		0.7087		0.1468		0.9147	0.7391		tp=0.51, tn=0.12, fp=0.19, fn=0.17		False
	23	0.2953		1.053		0.7177		0.1835		0.9172	0.7568		tp=0.53, tn=0.13, fp=0.2, fn=0.15		False
	24	0.297		1.071		0.7142		0.1665		0.9158	0.7098		tp=0.46, tn=0.16, fp=0.16, fn=0.22		False
	25	0.2931		1.077		0.7193		0.1928		0.9177	0.7337		tp=0.49, tn=0.15, fp=0.17, fn=0.19		True
	26	0.2815		1.119		0.7373		0.1635		0.9225	0.7531		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	27	0.2786		1.132		0.7371		0.1781		0.9227	0.7143		tp=0.47, tn=0.16, fp=0.17, fn=0.21		False
	28	0.2728		1.156		0.7394		0.2049		0.9226	0.7859		tp=0.58, tn=0.11, fp=0.21, fn=0.11		True
	29	0.27		1.191		0.7501		0.1701		0.9259	0.7133		tp=0.47, tn=0.16, fp=0.16, fn=0.22		False
	30	0.2677		1.215		0.7366		0.1771		0.9216	0.7191		tp=0.47, tn=0.16, fp=0.17, fn=0.2		False
	31	0.2562		1.187		0.7661		0.1803		0.9304	0.7352		tp=0.5, tn=0.14, fp=0.17, fn=0.18		False
	32	0.2628		1.189		0.7553		0.2046		0.927	0.7569		tp=0.53, tn=0.14, fp=0.18, fn=0.16		False
	33	0.2655		1.289		0.7531		0.1384		0.9263	0.7661		tp=0.56, tn=0.095, fp=0.22, fn=0.12		False
	34	0.2563		1.288		0.7566		0.1872		0.9275	0.7254		tp=0.48, tn=0.16, fp=0.17, fn=0.2		False
	35	0.2516		1.331		0.7653		0.1963		0.9304	0.7105		tp=0.46, tn=0.17, fp=0.15, fn=0.22		False
	36	0.2377		1.347		0.7899		0.1992		0.9372	0.7188		tp=0.47, tn=0.17, fp=0.15, fn=0.22		False
	37	0.2416		1.35		0.7841		0.1967		0.9354	0.723		tp=0.47, tn=0.16, fp=0.16, fn=0.21		False
	38	0.2393		1.377		0.7757		0.1947		0.9329	0.7516		tp=0.52, tn=0.14, fp=0.18, fn=0.16		False
	39	0.2374		1.381		0.7789		0.1843		0.9336	0.7157		tp=0.47, tn=0.16, fp=0.15, fn=0.22		False
	40	0.2359		1.423		0.7914		0.185		0.9374	0.7199		tp=0.47, tn=0.16, fp=0.16, fn=0.21		False
	41	0.2366		1.437		0.7848		0.1855		0.9355	0.7228		tp=0.48, tn=0.16, fp=0.17, fn=0.2		False
	42	0.2226		1.485		0.8062		0.1797		0.942	0.7043		tp=0.45, tn=0.17, fp=0.15, fn=0.23		False
	43	0.2209		1.463		0.8017		0.197		0.9407	0.7062		tp=0.45, tn=0.17, fp=0.15, fn=0.23		False
	44	0.2176		1.477		0.8121		0.1904		0.9436	0.7413		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	45	0.2265		1.518		0.7952		0.1799		0.9384	0.717		tp=0.47, tn=0.16, fp=0.16, fn=0.22		False
	46	0.2233		1.537		0.7958		0.1773		0.9388	0.6917		tp=0.44, tn=0.17, fp=0.14, fn=0.24		False
	47	0.2078		1.622		0.8171		0.1512		0.9449	0.6659		tp=0.41, tn=0.18, fp=0.14, fn=0.27		False
	48	0.206		1.609		0.8278		0.1731		0.948	0.7311		tp=0.49, tn=0.14, fp=0.18, fn=0.19		False
	49	0.2019		1.65		0.8192		0.1928		0.9456	0.7357		tp=0.49, tn=0.15, fp=0.17, fn=0.18		False


data			/scratch/asw462/data/levin
input size		300
hidden size		195
learning rate		5.39860296862e&05
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_40-lr5.4e&05-h_size195-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6085		0.5913		0.02606		0		0.8356	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5769		0.6058		0		0		0.8426	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.5755		0.6036		0		0		0.8399	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	4	0.5662		0.5732		0		0		0.843	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	5	0.5605		0.6026		0		0		0.844	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	6	0.5565		0.5803		0		0		0.8416	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	7	0.5513		0.5965		0		0		0.8421	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	8	0.5482		0.5651		0.04297		0		0.841	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	9	0.5439		0.5668		0.07436		0		0.8414	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	10	0.538		0.5629		0.08634		0		0.843	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	11	0.527		0.5645		0.1385		0		0.8483	0.8197		tp=0.69, tn=0, fp=0.31, fn=0		False
	12	0.5271		0.5554		0.1438		0		0.846	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	13	0.5208		0.5453		0.1681		0.05394		0.8473	0.8264		tp=0.7, tn=0.007, fp=0.29, fn=0.007		True
	14	0.5205		0.5693		0.2058		0.04753		0.8473	0.8117		tp=0.68, tn=0.007, fp=0.31, fn=0.007		False
	15	0.5134		0.5606		0.1953		0.1206		0.8474	0.8186		tp=0.68, tn=0.021, fp=0.29, fn=0.014		True
	16	0.508		0.554		0.2158		0.1168		0.8499	0.825		tp=0.69, tn=0.014, fp=0.29, fn=0.007		False
	17	0.5016		0.5559		0.2387		0.265		0.8509	0.8291		tp=0.68, tn=0.042, fp=0.27, fn=0.007		True
	18	0.4965		0.5321		0.2669		0.3049		0.8548	0.8426		tp=0.69, tn=0.049, fp=0.25, fn=0.007		True
	19	0.4894		0.5329		0.2982		0.05845		0.8593	0.8361		tp=0.71, tn=0.007, fp=0.27, fn=0.007		False
	20	0.4881		0.5315		0.3036		0.2986		0.8575	0.8412		tp=0.69, tn=0.056, fp=0.24, fn=0.014		False
	21	0.4791		0.5246		0.3384		0.2594		0.8626	0.8398		tp=0.68, tn=0.063, fp=0.22, fn=0.035		False
	22	0.4758		0.5282		0.353		0.2803		0.8645	0.8384		tp=0.67, tn=0.07, fp=0.22, fn=0.035		False
	23	0.4702		0.5131		0.4		0.2446		0.8695	0.8376		tp=0.69, tn=0.049, fp=0.24, fn=0.021		False
	24	0.4654		0.5201		0.3766		0.1873		0.8675	0.8403		tp=0.7, tn=0.035, fp=0.24, fn=0.021		False
	25	0.4563		0.5415		0.3988		0.2392		0.8713	0.8246		tp=0.66, tn=0.063, fp=0.24, fn=0.035		False
	26	0.4534		0.5317		0.4103		0.2701		0.8723	0.8348		tp=0.67, tn=0.063, fp=0.24, fn=0.028		False
	27	0.4481		0.5001		0.4315		0.2141		0.8749	0.8362		tp=0.68, tn=0.056, fp=0.22, fn=0.042		False
	28	0.4434		0.5151		0.4504		0.2701		0.8776	0.8348		tp=0.67, tn=0.063, fp=0.24, fn=0.028		False
	29	0.4399		0.5055		0.4419		0.2985		0.8765	0.8407		tp=0.66, tn=0.084, fp=0.2, fn=0.049		False
	30	0.4319		0.5369		0.5014		0.2902		0.8874	0.8333		tp=0.66, tn=0.07, fp=0.24, fn=0.028		False
	31	0.4283		0.5037		0.4692		0.2525		0.8806	0.8384		tp=0.67, tn=0.07, fp=0.21, fn=0.049		False
	32	0.4225		0.523		0.5052		0.2701		0.8866	0.8267		tp=0.65, tn=0.077, fp=0.23, fn=0.042		False
	33	0.4208		0.5469		0.5287		0.1612		0.8912	0.8053		tp=0.64, tn=0.056, fp=0.26, fn=0.049		False
	34	0.4143		0.5132		0.531		0.3115		0.892	0.8485		tp=0.69, tn=0.07, fp=0.22, fn=0.028		True
	35	0.4156		0.4854		0.5021		0.3271		0.8854	0.8509		tp=0.68, tn=0.084, fp=0.2, fn=0.042		True
	36	0.4067		0.4974		0.5427		0.3578		0.894	0.8584		tp=0.68, tn=0.098, fp=0.17, fn=0.056		True
	37	0.4025		0.495		0.5528		0.3896		0.8952	0.8584		tp=0.68, tn=0.098, fp=0.19, fn=0.035		True
	38	0.3981		0.4989		0.5647		0.3864		0.8972	0.8507		tp=0.66, tn=0.11, fp=0.18, fn=0.049		False
	39	0.3914		0.5181		0.5835		0.4083		0.9014	0.8507		tp=0.66, tn=0.11, fp=0.2, fn=0.035		True
	40	0.3904		0.4877		0.5864		0.3831		0.9022	0.852		tp=0.66, tn=0.1, fp=0.19, fn=0.042		False
	41	0.387		0.5201		0.5914		0.4041		0.902	0.8411		tp=0.63, tn=0.13, fp=0.18, fn=0.056		False
	42	0.3835		0.5022		0.5983		0.3741		0.9044	0.8596		tp=0.69, tn=0.091, fp=0.19, fn=0.035		False
	43	0.373		0.5348		0.607		0.3484		0.9059	0.8341		tp=0.65, tn=0.091, fp=0.23, fn=0.028		False
	44	0.374		0.4877		0.6139		0.3776		0.9068	0.8584		tp=0.68, tn=0.098, fp=0.18, fn=0.042		False
	45	0.3657		0.5219		0.6294		0.2655		0.9107	0.8384		tp=0.67, tn=0.07, fp=0.22, fn=0.042		False
	46	0.3655		0.5403		0.6246		0.3097		0.9091	0.8203		tp=0.62, tn=0.1, fp=0.22, fn=0.056		False
	47	0.3601		0.502		0.63		0.3742		0.9106	0.8468		tp=0.66, tn=0.1, fp=0.2, fn=0.042		False
	48	0.3577		0.4983		0.6349		0.3597		0.9109	0.8482		tp=0.66, tn=0.098, fp=0.2, fn=0.042		False
	49	0.3539		0.4976		0.6371		0.3951		0.9115	0.8479		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	50	0.3522		0.4851		0.6283		0.3639		0.9095	0.852		tp=0.66, tn=0.11, fp=0.16, fn=0.069		False
	51	0.346		0.4821		0.6623		0.4112		0.9164	0.8479		tp=0.64, tn=0.13, fp=0.18, fn=0.049		True
	52	0.3404		0.5116		0.6461		0.4214		0.9131	0.8507		tp=0.66, tn=0.11, fp=0.2, fn=0.028		True
	53	0.341		0.5216		0.6547		0.385		0.9154	0.8426		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	54	0.3336		0.5208		0.6628		0.3797		0.9172	0.8357		tp=0.62, tn=0.13, fp=0.17, fn=0.07		False
	55	0.3305		0.5303		0.6662		0.3636		0.9184	0.8559		tp=0.69, tn=0.084, fp=0.2, fn=0.028		False
	56	0.3285		0.5225		0.6654		0.3773		0.9176	0.8507		tp=0.66, tn=0.11, fp=0.17, fn=0.056		False
	57	0.3235		0.4937		0.6766		0.404		0.9202	0.8571		tp=0.67, tn=0.1, fp=0.19, fn=0.035		False
	58	0.3208		0.4826		0.6913		0.3753		0.9229	0.8482		tp=0.66, tn=0.1, fp=0.19, fn=0.042		False
	59	0.3196		0.5253		0.6714		0.3616		0.9189	0.8263		tp=0.61, tn=0.13, fp=0.19, fn=0.069		False
	60	0.3155		0.4838		0.69		0.4421		0.9224	0.8571		tp=0.65, tn=0.13, fp=0.17, fn=0.049		True
	61	0.3149		0.4873		0.6839		0.4596		0.9214	0.8598		tp=0.64, tn=0.15, fp=0.15, fn=0.063		True
	62	0.3114		0.5182		0.7087		0.4017		0.9259	0.8426		tp=0.64, tn=0.13, fp=0.19, fn=0.049		False
	63	0.3056		0.5171		0.7055		0.4276		0.9259	0.8571		tp=0.65, tn=0.13, fp=0.15, fn=0.063		False
	64	0.301		0.5226		0.7103		0.4527		0.9275	0.8558		tp=0.64, tn=0.14, fp=0.17, fn=0.049		False
	65	0.3		0.4967		0.7046		0.4187		0.9262	0.8597		tp=0.66, tn=0.12, fp=0.17, fn=0.049		False
	66	0.2956		0.5021		0.7138		0.4347		0.9281	0.8505		tp=0.64, tn=0.14, fp=0.17, fn=0.056		False
	67	0.2946		0.5118		0.7258		0.3951		0.931	0.8479		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	68	0.2894		0.5116		0.7331		0.414		0.9322	0.8465		tp=0.64, tn=0.13, fp=0.17, fn=0.056		False
	69	0.2922		0.5454		0.7152		0.2951		0.9277	0.8485		tp=0.69, tn=0.07, fp=0.21, fn=0.035		False
	70	0.2896		0.4822		0.7297		0.4214		0.9309	0.8436		tp=0.62, tn=0.15, fp=0.16, fn=0.07		False
	71	0.2803		0.5177		0.7368		0.365		0.9329	0.8318		tp=0.62, tn=0.13, fp=0.17, fn=0.076		False
	72	0.2779		0.5365		0.7478		0.3028		0.9358	0.8326		tp=0.64, tn=0.098, fp=0.2, fn=0.063		False
	73	0.2759		0.5049		0.7328		0.5028		0.9324	0.8612		tp=0.62, tn=0.17, fp=0.13, fn=0.069		True
	74	0.2732		0.539		0.741		0.3621		0.9349	0.8333		tp=0.63, tn=0.12, fp=0.2, fn=0.056		False
	75	0.2716		0.5283		0.751		0.3658		0.9359	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.07		False
	76	0.2693		0.5252		0.7571		0.3827		0.9378	0.8493		tp=0.65, tn=0.12, fp=0.17, fn=0.063		False
	77	0.2665		0.5183		0.7628		0.4219		0.9391	0.8571		tp=0.65, tn=0.13, fp=0.15, fn=0.07		False
	78	0.2648		0.4554		0.7586		0.441		0.9381	0.8636		tp=0.66, tn=0.13, fp=0.16, fn=0.049		False
	79	0.2597		0.4911		0.7767		0.3727		0.9421	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.063		False
	80	0.2581		0.4967		0.7693		0.4343		0.9404	0.8571		tp=0.65, tn=0.13, fp=0.16, fn=0.056		False
	81	0.255		0.5247		0.7869		0.382		0.9452	0.8455		tp=0.65, tn=0.12, fp=0.18, fn=0.056		False
	82	0.2518		0.5004		0.7837		0.5097		0.9447	0.8612		tp=0.63, tn=0.17, fp=0.15, fn=0.049		True
	83	0.2516		0.5449		0.7957		0.3408		0.9466	0.8224		tp=0.61, tn=0.12, fp=0.19, fn=0.069		False
	84	0.2475		0.5553		0.7916		0.4275		0.9464	0.8436		tp=0.62, tn=0.15, fp=0.17, fn=0.063		False
	85	0.2477		0.5101		0.7717		0.3627		0.9413	0.8507		tp=0.66, tn=0.11, fp=0.16, fn=0.07		False
	86	0.2401		0.5643		0.7998		0.4072		0.9481	0.8396		tp=0.62, tn=0.14, fp=0.17, fn=0.063		False
	87	0.2425		0.5393		0.7968		0.4072		0.9471	0.8396		tp=0.62, tn=0.14, fp=0.17, fn=0.063		False
	88	0.2395		0.558		0.8085		0.4333		0.9496	0.8532		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False
	89	0.2379		0.5397		0.7995		0.4642		0.9479	0.8585		tp=0.64, tn=0.15, fp=0.14, fn=0.07		False
	90	0.2358		0.5306		0.7893		0.4511		0.9452	0.8447		tp=0.61, tn=0.17, fp=0.14, fn=0.084		False
	91	0.2323		0.552		0.8176		0.485		0.9527	0.8626		tp=0.64, tn=0.16, fp=0.13, fn=0.07		False
	92	0.2307		0.5601		0.8211		0.4633		0.9529	0.8531		tp=0.62, tn=0.16, fp=0.15, fn=0.069		False
	93	0.2294		0.5434		0.8141		0.4005		0.951	0.8545		tp=0.65, tn=0.12, fp=0.15, fn=0.069		False
	94	0.2252		0.5923		0.8258		0.3371		0.9543	0.8311		tp=0.64, tn=0.1, fp=0.21, fn=0.049		False
	95	0.2226		0.5419		0.8241		0.3948		0.9539	0.8533		tp=0.67, tn=0.098, fp=0.2, fn=0.028		False
	96	0.2241		0.5638		0.8289		0.4278		0.9553	0.8505		tp=0.64, tn=0.14, fp=0.16, fn=0.063		False
	97	0.2222		0.578		0.8173		0.4109		0.9528	0.8381		tp=0.62, tn=0.15, fp=0.17, fn=0.07		False
	98	0.2175		0.5504		0.8323		0.4126		0.9554	0.8532		tp=0.65, tn=0.13, fp=0.17, fn=0.056		False
	99	0.2136		0.598		0.8306		0.4648		0.9559	0.8447		tp=0.61, tn=0.17, fp=0.16, fn=0.063		False
	100	0.2128		0.533		0.8373		0.461		0.9571	0.8624		tp=0.66, tn=0.13, fp=0.17, fn=0.042		False
	101	0.2117		0.5389		0.8397		0.5011		0.9575	0.8679		tp=0.64, tn=0.16, fp=0.13, fn=0.063		False
	102	0.208		0.5688		0.8333		0.4582		0.9562	0.8531		tp=0.63, tn=0.15, fp=0.15, fn=0.063		False
	103	0.2088		0.537		0.8187		0.5206		0.9526	0.8667		tp=0.64, tn=0.17, fp=0.15, fn=0.049		True
	104	0.2028		0.5938		0.8495		0.3725		0.9603	0.852		tp=0.66, tn=0.1, fp=0.18, fn=0.049		False
	105	0.2009		0.5316		0.8594		0.4861		0.9626	0.8638		tp=0.64, tn=0.15, fp=0.15, fn=0.056		False
	106	0.1998		0.5495		0.8464		0.4494		0.96	0.8611		tp=0.65, tn=0.14, fp=0.15, fn=0.063		False
	107	0.1971		0.6164		0.8591		0.4418		0.9626	0.8476		tp=0.62, tn=0.15, fp=0.15, fn=0.07		False
	108	0.1995		0.6054		0.8537		0.3727		0.9611	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.063		False
	109	0.1958		0.6068		0.854		0.3727		0.9613	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.063		False
	110	0.1948		0.6466		0.8653		0.2609		0.9637	0.837		tp=0.66, tn=0.077, fp=0.2, fn=0.056		False
	111	0.1926		0.6316		0.8528		0.4284		0.9612	0.8333		tp=0.59, tn=0.17, fp=0.15, fn=0.084		False
	112	0.1913		0.543		0.8597		0.4676		0.9626	0.8585		tp=0.63, tn=0.16, fp=0.12, fn=0.083		False
	113	0.1887		0.5931		0.8647		0.3967		0.9639	0.8507		tp=0.66, tn=0.11, fp=0.19, fn=0.042		False
	114	0.1859		0.6163		0.873		0.4767		0.9664	0.8651		tp=0.65, tn=0.15, fp=0.15, fn=0.056		False
	115	0.1871		0.58		0.8706		0.4556		0.9651	0.8611		tp=0.65, tn=0.14, fp=0.15, fn=0.056		False
	116	0.1821		0.5621		0.871		0.5048		0.9661	0.8704		tp=0.65, tn=0.15, fp=0.15, fn=0.049		False
	117	0.1809		0.6285		0.8819		0.4441		0.9686	0.8688		tp=0.67, tn=0.13, fp=0.15, fn=0.056		False
	118	0.1802		0.6341		0.887		0.3951		0.9702	0.8479		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	119	0.1759		0.6487		0.89		0.4304		0.9704	0.8532		tp=0.65, tn=0.13, fp=0.18, fn=0.042		False
	120	0.1754		0.6418		0.8879		0.4055		0.97	0.8381		tp=0.62, tn=0.15, fp=0.16, fn=0.077		False
	121	0.1712		0.6253		0.8853		0.4447		0.9696	0.8491		tp=0.63, tn=0.15, fp=0.17, fn=0.056		False
	122	0.1724		0.573		0.8895		0.4371		0.9706	0.8476		tp=0.62, tn=0.15, fp=0.15, fn=0.077		False
	123	0.1787		0.6028		0.8683		0.4187		0.9647	0.8597		tp=0.66, tn=0.12, fp=0.17, fn=0.049		False
	124	0.1693		0.5703		0.879		0.44		0.9676	0.8611		tp=0.65, tn=0.14, fp=0.13, fn=0.077		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		189
learning rate		0.000169149601303
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_41-lr0.00017-h_size189-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6867		0.6783		0.1045		0.1508		0.6008	0.6511		tp=0.39, tn=0.19, fp=0.29, fn=0.13		True
	2	0.6769		0.6781		0.1627		0.09193		0.6182	0.5714		tp=0.3, tn=0.25, fp=0.22, fn=0.23		False
	3	0.6733		0.6766		0.1622		0.09289		0.5998	0.5672		tp=0.3, tn=0.25, fp=0.22, fn=0.23		False
	4	0.67		0.674		0.1974		0.1181		0.6196	0.5938		tp=0.32, tn=0.24, fp=0.23, fn=0.21		False
	5	0.6669		0.6713		0.1884		0.1227		0.6142	0.6286		tp=0.37, tn=0.2, fp=0.27, fn=0.16		False
	6	0.6634		0.6723		0.2083		0.1277		0.6323	0.6005		tp=0.33, tn=0.24, fp=0.23, fn=0.21		False
	7	0.6611		0.6786		0.2125		0.1015		0.6214	0.6237		tp=0.37, tn=0.18, fp=0.3, fn=0.14		False
	8	0.6578		0.6781		0.2209		0.1169		0.6327	0.5743		tp=0.3, tn=0.26, fp=0.23, fn=0.22		False
	9	0.6552		0.6727		0.2162		0.1395		0.6273	0.633		tp=0.37, tn=0.21, fp=0.27, fn=0.16		False
	10	0.6535		0.6762		0.2319		0.09474		0.6389	0.5958		tp=0.33, tn=0.22, fp=0.25, fn=0.2		False
	11	0.6523		0.6774		0.2263		0.1206		0.6322	0.586		tp=0.31, tn=0.25, fp=0.23, fn=0.21		False
	12	0.6502		0.6738		0.234		0.1646		0.6353	0.6447		tp=0.38, tn=0.21, fp=0.27, fn=0.14		True
	13	0.6473		0.6792		0.2419		0.1211		0.6431	0.5819		tp=0.31, tn=0.26, fp=0.22, fn=0.22		False
	14	0.646		0.68		0.2474		0.1505		0.6465	0.5425		tp=0.25, tn=0.32, fp=0.17, fn=0.26		False
	15	0.6457		0.6772		0.2517		0.1462		0.6416	0.5772		tp=0.29, tn=0.28, fp=0.19, fn=0.24		False
	16	0.6425		0.6768		0.2524		0.1383		0.6436	0.6178		tp=0.35, tn=0.23, fp=0.25, fn=0.17		False
	17	0.6406		0.6804		0.2737		0.1141		0.6537	0.6122		tp=0.35, tn=0.22, fp=0.26, fn=0.18		False
	18	0.6388		0.6823		0.2643		0.1295		0.6552	0.5792		tp=0.3, tn=0.27, fp=0.21, fn=0.22		False
	19	0.6376		0.6788		0.2725		0.1313		0.6514	0.6075		tp=0.33, tn=0.24, fp=0.23, fn=0.2		False
	20	0.6365		0.69		0.2833		0.1034		0.6611	0.5857		tp=0.32, tn=0.24, fp=0.24, fn=0.21		False
	21	0.6337		0.6829		0.2921		0.1309		0.6627	0.6061		tp=0.33, tn=0.23, fp=0.25, fn=0.18		False
	22	0.6333		0.6853		0.2797		0.1138		0.6577	0.6208		tp=0.36, tn=0.2, fp=0.27, fn=0.17		False
	23	0.6312		0.6934		0.2895		0.08969		0.6583	0.6204		tp=0.37, tn=0.18, fp=0.29, fn=0.16		False
	24	0.6307		0.6866		0.2774		0.09651		0.6571	0.5882		tp=0.32, tn=0.23, fp=0.24, fn=0.21		False
	25	0.6331		0.6955		0.2802		0.1057		0.6555	0.5915		tp=0.32, tn=0.23, fp=0.25, fn=0.2		False
	26	0.6289		0.6882		0.2902		0.1048		0.6618	0.6323		tp=0.38, tn=0.18, fp=0.28, fn=0.16		False
	27	0.6295		0.6907		0.2896		0.1381		0.6589	0.6213		tp=0.35, tn=0.22, fp=0.26, fn=0.17		False
	28	0.6258		0.694		0.3019		0.1416		0.6693	0.5995		tp=0.32, tn=0.25, fp=0.24, fn=0.19		False
	29	0.6255		0.6945		0.2949		0.1315		0.6604	0.6042		tp=0.33, tn=0.24, fp=0.24, fn=0.19		False
	30	0.6241		0.7021		0.2961		0.1045		0.6608	0.6327		tp=0.38, tn=0.18, fp=0.29, fn=0.15		False
	31	0.6248		0.6943		0.292		0.1121		0.6616	0.5831		tp=0.31, tn=0.25, fp=0.23, fn=0.21		False
	32	0.6228		0.6997		0.3061		0.1408		0.6665	0.6313		tp=0.37, tn=0.21, fp=0.28, fn=0.15		False
	33	0.6241		0.7046		0.3027		0.1372		0.6722	0.5633		tp=0.28, tn=0.29, fp=0.19, fn=0.25		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		50
learning rate		7.79593764008e&05
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_42-lr7.8e&05-h_size50-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6218		0.636		0.005437		0		0.8175	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6064		0.6297		0		0		0.8183	0.8085		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.5963		0.628		0		0		0.8182	0.8074		tp=0.68, tn=0, fp=0.32, fn=0		False
	4	0.5846		0.6355		0.05362		0		0.8191	0.8088		tp=0.68, tn=0, fp=0.32, fn=0		False
	5	0.5771		0.6249		0.1149		-0.02642		0.8205	0.8085		tp=0.68, tn=0, fp=0.32, fn=0.0015		False
	6	0.5648		0.6278		0.1588		-0.01182		0.823	0.806		tp=0.67, tn=0.0015, fp=0.32, fn=0.0044		False
	7	0.5543		0.6183		0.1949		0.1135		0.8263	0.8084		tp=0.66, tn=0.028, fp=0.29, fn=0.024		True
	8	0.5462		0.6241		0.232		0.04848		0.8291	0.8082		tp=0.67, tn=0.01, fp=0.31, fn=0.012		False
	9	0.5339		0.6232		0.2944		0.03539		0.8365	0.7967		tp=0.65, tn=0.019, fp=0.3, fn=0.03		False
	10	0.5251		0.6276		0.3406		0.05775		0.8423	0.8025		tp=0.66, tn=0.021, fp=0.3, fn=0.027		False
	11	0.5166		0.6331		0.3441		0.1232		0.8428	0.8004		tp=0.64, tn=0.039, fp=0.29, fn=0.034		True
	12	0.5057		0.6194		0.3695		0.1715		0.8458	0.7981		tp=0.62, tn=0.07, fp=0.25, fn=0.064		True
	13	0.4949		0.6323		0.3951		0.192		0.8496	0.8019		tp=0.62, tn=0.068, fp=0.26, fn=0.052		True
	14	0.4866		0.6334		0.4269		0.1415		0.8553	0.8011		tp=0.63, tn=0.052, fp=0.27, fn=0.049		False
	15	0.4781		0.6338		0.4476		0.1896		0.8589	0.8061		tp=0.63, tn=0.067, fp=0.25, fn=0.053		False
	16	0.4705		0.6371		0.4561		0.1806		0.8599	0.7558		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	17	0.4635		0.6416		0.4811		0.1453		0.8648	0.7812		tp=0.59, tn=0.08, fp=0.24, fn=0.09		False
	18	0.4547		0.6443		0.4931		0.1373		0.8667	0.7691		tp=0.57, tn=0.092, fp=0.22, fn=0.12		False
	19	0.4477		0.6631		0.5133		0.1404		0.8707	0.7977		tp=0.63, tn=0.053, fp=0.27, fn=0.05		False
	20	0.4393		0.6583		0.519		0.1253		0.8722	0.7916		tp=0.62, tn=0.059, fp=0.26, fn=0.067		False
	21	0.432		0.6772		0.5444		0.1083		0.8769	0.7878		tp=0.61, tn=0.056, fp=0.26, fn=0.068		False
	22	0.4279		0.6562		0.544		0.1457		0.8769	0.7674		tp=0.56, tn=0.096, fp=0.22, fn=0.12		False
	23	0.4221		0.6655		0.5446		0.1481		0.8768	0.7534		tp=0.54, tn=0.11, fp=0.2, fn=0.15		False
	24	0.413		0.6731		0.5657		0.1472		0.8814	0.7593		tp=0.55, tn=0.11, fp=0.21, fn=0.14		False
	25	0.4106		0.6797		0.5713		0.1388		0.8826	0.7505		tp=0.53, tn=0.11, fp=0.21, fn=0.14		False
	26	0.4007		0.686		0.59		0.1487		0.8869	0.7672		tp=0.56, tn=0.098, fp=0.22, fn=0.12		False
	27	0.398		0.6983		0.5879		0.1434		0.8857	0.7476		tp=0.53, tn=0.11, fp=0.21, fn=0.15		False
	28	0.3902		0.7044		0.6021		0.1347		0.8894	0.7609		tp=0.55, tn=0.098, fp=0.22, fn=0.13		False
	29	0.3846		0.7268		0.605		0.1374		0.8899	0.7709		tp=0.57, tn=0.086, fp=0.24, fn=0.1		False
	30	0.3793		0.7095		0.6177		0.1799		0.8934	0.7571		tp=0.53, tn=0.12, fp=0.19, fn=0.15		False
	31	0.3772		0.7183		0.6205		0.1689		0.8938	0.7534		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	32	0.3727		0.7278		0.6304		0.1616		0.8961	0.7608		tp=0.55, tn=0.11, fp=0.21, fn=0.13		False
	33	0.366		0.7244		0.6354		0.1922		0.8973	0.7628		tp=0.54, tn=0.12, fp=0.19, fn=0.14		True
	34	0.3622		0.7369		0.6449		0.1447		0.8996	0.7562		tp=0.54, tn=0.11, fp=0.21, fn=0.14		False
	35	0.3582		0.7379		0.6467		0.1636		0.9	0.7575		tp=0.54, tn=0.12, fp=0.2, fn=0.14		False
	36	0.354		0.7432		0.6416		0.1613		0.8981	0.7521		tp=0.53, tn=0.12, fp=0.19, fn=0.16		False
	37	0.3498		0.7598		0.6487		0.1525		0.9001	0.7557		tp=0.54, tn=0.11, fp=0.21, fn=0.14		False
	38	0.3481		0.7762		0.6525		0.1341		0.9012	0.7776		tp=0.58, tn=0.083, fp=0.23, fn=0.1		False
	39	0.3409		0.7934		0.6631		0.1449		0.9039	0.7513		tp=0.53, tn=0.11, fp=0.21, fn=0.15		False
	40	0.3383		0.8052		0.661		0.1489		0.9035	0.7664		tp=0.56, tn=0.099, fp=0.22, fn=0.12		False
	41	0.3352		0.8238		0.6659		0.217		0.9043	0.7195		tp=0.46, tn=0.17, fp=0.15, fn=0.21		True
	42	0.3351		0.8194		0.6602		0.1586		0.9024	0.7332		tp=0.5, tn=0.13, fp=0.19, fn=0.18		False
	43	0.3338		0.826		0.667		0.1461		0.904	0.7526		tp=0.54, tn=0.11, fp=0.21, fn=0.14		False
	44	0.3247		0.8219		0.6906		0.1506		0.9108	0.767		tp=0.56, tn=0.1, fp=0.2, fn=0.13		False
	45	0.3232		0.8381		0.6759		0.126		0.9066	0.7629		tp=0.56, tn=0.093, fp=0.22, fn=0.13		False
	46	0.3195		0.8528		0.6922		0.1743		0.9115	0.7265		tp=0.49, tn=0.15, fp=0.17, fn=0.19		False
	47	0.3164		0.8466		0.691		0.1799		0.9108	0.7471		tp=0.52, tn=0.13, fp=0.19, fn=0.16		False
	48	0.3171		0.8661		0.6873		0.1655		0.9099	0.734		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	49	0.3094		0.8657		0.7054		0.1904		0.9141	0.7556		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	50	0.3048		0.8899		0.7123		0.1567		0.9165	0.7714		tp=0.57, tn=0.098, fp=0.22, fn=0.12		False
	51	0.3056		0.9147		0.7113		0.1509		0.916	0.7655		tp=0.56, tn=0.099, fp=0.23, fn=0.12		False
	52	0.3045		0.8879		0.7062		0.1801		0.9149	0.7558		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	53	0.2978		0.8697		0.7169		0.173		0.9174	0.7433		tp=0.51, tn=0.13, fp=0.18, fn=0.17		False
	54	0.2955		0.9214		0.7251		0.1727		0.9199	0.7395		tp=0.51, tn=0.14, fp=0.19, fn=0.17		False
	55	0.2922		0.9014		0.7245		0.1974		0.9195	0.7535		tp=0.52, tn=0.14, fp=0.18, fn=0.16		False
	56	0.2898		0.9445		0.7306		0.1571		0.921	0.7666		tp=0.56, tn=0.1, fp=0.21, fn=0.13		False
	57	0.287		0.934		0.7342		0.1907		0.9225	0.7329		tp=0.49, tn=0.15, fp=0.17, fn=0.19		False
	58	0.2864		0.9443		0.7381		0.1816		0.9233	0.7511		tp=0.52, tn=0.13, fp=0.19, fn=0.16		False
	59	0.284		0.9573		0.7383		0.1635		0.9232	0.7484		tp=0.52, tn=0.12, fp=0.19, fn=0.16		False
	60	0.2801		0.9802		0.7444		0.1884		0.925	0.7309		tp=0.49, tn=0.15, fp=0.17, fn=0.19		False
	61	0.2784		0.9751		0.7398		0.1876		0.9238	0.736		tp=0.5, tn=0.15, fp=0.17, fn=0.19		False
	62	0.2761		1.002		0.7505		0.1778		0.9265	0.7338		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False


data			/scratch/asw462/data/levin
input size		300
hidden size		137
learning rate		6.309196503e&05
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_43-lr6.3e&05-h_size137-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6734		0.6435		0.0427		0		0.7116	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.6083		0.603		0		0		0.8412	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5895		0.589		0		0		0.8407	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	4	0.5826		0.603		0		0		0.8418	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	5	0.5788		0.5944		0		0		0.8422	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	6	0.576		0.5994		0		0		0.8435	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	7	0.5802		0.6038		0		0		0.8394	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	8	0.5786		0.5731		0		0		0.8398	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	9	0.5771		0.5923		0		0		0.8399	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	10	0.5731		0.5999		0		0		0.8418	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	11	0.5707		0.5803		0		0		0.8422	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	12	0.569		0.6077		0		0		0.8426	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	13	0.5682		0.5813		0		0		0.843	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	14	0.5674		0.5961		0		0		0.8412	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	15	0.5655		0.5766		0		0		0.844	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	16	0.5651		0.5951		0		0		0.843	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	17	0.5668		0.5858		0		0		0.8407	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	18	0.5629		0.6016		0		0		0.8426	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	19	0.5645		0.5459		0.04283		0		0.8402	0.8514		tp=0.74, tn=0, fp=0.26, fn=0		False
	20	0.5633		0.579		0.0608		0		0.8415	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	21	0.5637		0.5966		0.08559		0		0.8408	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False


data			/scratch/asw462/data/levin
input size		300
hidden size		83
learning rate		6.44739393549e&05
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_44-lr6.4e&05-h_size83-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6245		0.6118		-0.01626		0		0.8407	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.5883		0.592		0		0		0.8402	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	3	0.5853		0.6102		0		0		0.8412	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	4	0.5843		0.599		0		0		0.8416	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	5	0.5821		0.6184		0		0		0.8427	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	6	0.5845		0.6204		0		0		0.8412	0.8148		tp=0.69, tn=0, fp=0.31, fn=0		False
	7	0.5833		0.6281		0		0		0.8418	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	8	0.5828		0.6079		0		0		0.8421	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	9	0.585		0.5994		0		0		0.8402	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	10	0.582		0.6155		0		0		0.8422	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	11	0.5852		0.6081		0		0		0.8407	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	12	0.5839		0.604		0		0		0.8416	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	13	0.5842		0.6222		0		0		0.8407	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	14	0.5814		0.6011		0		0		0.8427	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	15	0.5837		0.5871		0		0		0.8404	0.834		tp=0.72, tn=0, fp=0.28, fn=0		False
	16	0.5833		0.6075		0		0		0.8416	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	17	0.5846		0.6006		0		0		0.8402	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	18	0.5797		0.6153		0		0		0.844	0.8148		tp=0.69, tn=0, fp=0.31, fn=0		False
	19	0.5847		0.6064		0		0		0.8402	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	20	0.5828		0.5985		0		0		0.8413	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	21	0.581		0.5865		0		0		0.8421	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		72
learning rate		0.000595719656935
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_45-lr0.0006-h_size72-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6127		0.6124		0.05858		0.0899		0.8185	0.8086		tp=0.67, tn=0.013, fp=0.31, fn=0.0089		True
	2	0.6003		0.6075		0.09511		0.07257		0.817	0.8151		tp=0.68, tn=0.0044, fp=0.31, fn=0.0015		False
	3	0.5946		0.605		0.1065		0.1315		0.8181	0.808		tp=0.66, tn=0.03, fp=0.29, fn=0.021		True
	4	0.589		0.5988		0.1447		0.1478		0.8202	0.8137		tp=0.67, tn=0.03, fp=0.29, fn=0.018		True
	5	0.5854		0.6044		0.1307		0.1662		0.8175	0.8124		tp=0.66, tn=0.039, fp=0.28, fn=0.024		True
	6	0.5828		0.603		0.1593		0.1464		0.8167	0.7992		tp=0.63, tn=0.058, fp=0.26, fn=0.056		False
	7	0.5819		0.6008		0.148		0.1414		0.8161	0.8151		tp=0.67, tn=0.028, fp=0.29, fn=0.018		False
	8	0.5774		0.6037		0.1653		0.1613		0.8165	0.8113		tp=0.66, tn=0.034, fp=0.29, fn=0.019		False
	9	0.5748		0.5973		0.188		0.1753		0.8194	0.8011		tp=0.62, tn=0.068, fp=0.25, fn=0.061		True
	10	0.5732		0.5975		0.1798		0.1417		0.8176	0.7996		tp=0.63, tn=0.056, fp=0.26, fn=0.056		False
	11	0.5728		0.6098		0.1945		0.1847		0.8164	0.7832		tp=0.58, tn=0.099, fp=0.21, fn=0.11		True
	12	0.5692		0.5945		0.1899		0.1687		0.8181	0.8101		tp=0.64, tn=0.055, fp=0.26, fn=0.046		False
	13	0.5685		0.6026		0.1991		0.1781		0.8182	0.8034		tp=0.63, tn=0.058, fp=0.27, fn=0.043		False
	14	0.5667		0.5983		0.2036		0.2028		0.8178	0.7929		tp=0.6, tn=0.093, fp=0.23, fn=0.086		True
	15	0.5667		0.6167		0.2272		0.2098		0.8214	0.778		tp=0.57, tn=0.11, fp=0.22, fn=0.11		True
	16	0.5649		0.6034		0.2227		0.1666		0.8204	0.7942		tp=0.61, tn=0.071, fp=0.25, fn=0.067		False
	17	0.5648		0.603		0.222		0.1457		0.8185	0.8041		tp=0.64, tn=0.046, fp=0.27, fn=0.039		False
	18	0.5661		0.6487		0.2223		0.1525		0.8201	0.8136		tp=0.67, tn=0.019, fp=0.3, fn=0.0059		False
	19	0.5653		0.6147		0.203		0.1438		0.8185	0.8066		tp=0.65, tn=0.04, fp=0.28, fn=0.031		False
	20	0.5628		0.6029		0.2438		0.1331		0.8222	0.8044		tp=0.64, tn=0.044, fp=0.27, fn=0.041		False
	21	0.5622		0.6003		0.2258		0.1466		0.8205	0.795		tp=0.62, tn=0.065, fp=0.25, fn=0.068		False
	22	0.5635		0.6005		0.2284		0.1756		0.82	0.7996		tp=0.62, tn=0.07, fp=0.25, fn=0.062		False
	23	0.5583		0.6061		0.2376		0.18		0.821	0.8097		tp=0.65, tn=0.05, fp=0.27, fn=0.034		False
	24	0.5585		0.6059		0.2426		0.1813		0.8222	0.8093		tp=0.64, tn=0.052, fp=0.27, fn=0.036		False
	25	0.5609		0.6071		0.2368		0.1465		0.8205	0.797		tp=0.62, tn=0.058, fp=0.26, fn=0.055		False
	26	0.5592		0.6084		0.2429		0.1401		0.8223	0.8117		tp=0.66, tn=0.037, fp=0.28, fn=0.03		False
	27	0.5582		0.6059		0.2322		0.1849		0.8198	0.8049		tp=0.64, tn=0.056, fp=0.27, fn=0.039		False
	28	0.558		0.6041		0.2429		0.1442		0.8223	0.795		tp=0.62, tn=0.064, fp=0.25, fn=0.067		False
	29	0.5562		0.6193		0.2464		0.1473		0.823	0.7677		tp=0.56, tn=0.098, fp=0.22, fn=0.12		False
	30	0.557		0.6243		0.2529		0.2056		0.8235	0.7616		tp=0.53, tn=0.13, fp=0.19, fn=0.14		False
	31	0.5615		0.6092		0.2428		0.1658		0.8201	0.7867		tp=0.59, tn=0.083, fp=0.24, fn=0.086		False
	32	0.5538		0.6067		0.2624		0.1462		0.8246	0.8008		tp=0.63, tn=0.055, fp=0.26, fn=0.052		False
	33	0.555		0.6059		0.2557		0.1416		0.8244	0.7824		tp=0.59, tn=0.077, fp=0.24, fn=0.087		False
	34	0.5532		0.6112		0.2607		0.1627		0.8253	0.8037		tp=0.64, tn=0.053, fp=0.27, fn=0.043		False
	35	0.5545		0.6089		0.2462		0.178		0.8217	0.8049		tp=0.64, tn=0.056, fp=0.27, fn=0.041		False
	36	0.5513		0.6105		0.2533		0.164		0.8222	0.803		tp=0.63, tn=0.055, fp=0.27, fn=0.044		False


data			/scratch/asw462/data/levin
input size		300
hidden size		33
learning rate		5.15405185236e&05
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_46-lr5.2e&05-h_size33-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6213		0.5969		0		0		0.8402	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	2	0.59		0.6034		0		0		0.8412	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	3	0.5831		0.6054		0		0		0.8421	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	4	0.5799		0.5881		0		0		0.8435	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	5	0.5809		0.5791		0		0		0.8416	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	6	0.5806		0.627		0		0		0.8407	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	7	0.581		0.6175		0		0		0.8402	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	8	0.5767		0.6103		0		0		0.8426	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	9	0.5769		0.5982		0		0		0.8412	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	10	0.5781		0.6089		0		0		0.8398	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	11	0.575		0.5876		0		0		0.8413	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	12	0.575		0.6102		0		0		0.8412	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	13	0.5733		0.598		0		0		0.8412	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	14	0.5694		0.5998		0		0		0.8435	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	15	0.5722		0.6025		0		0		0.8404	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	16	0.5661		0.6146		0		0		0.844	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	17	0.5697		0.5884		0		0		0.8407	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	18	0.5685		0.5907		0		0		0.8412	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	19	0.5641		0.5781		0		0		0.843	0.834		tp=0.72, tn=0, fp=0.28, fn=0		False
	20	0.566		0.5977		0		0		0.8412	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	21	0.5638		0.6004		0		0		0.8422	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		108
learning rate		7.91516855308e&05
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_47-lr7.9e&05-h_size108-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6883		0.6808		0.08107		0.1869		0.6256	0.6184		tp=0.33, tn=0.27, fp=0.21, fn=0.19		True
	2	0.6813		0.6808		0.1383		0.1851		0.6228	0.5637		tp=0.27, tn=0.32, fp=0.15, fn=0.26		False
	3	0.6811		0.6753		0.1211		0.1777		0.6036	0.6551		tp=0.39, tn=0.21, fp=0.27, fn=0.14		False
	4	0.6806		0.678		0.1339		0.1339		0.6213	0.6379		tp=0.38, tn=0.19, fp=0.29, fn=0.14		False
	5	0.6806		0.6751		0.1269		0.1635		0.6157	0.6552		tp=0.39, tn=0.19, fp=0.27, fn=0.14		False
	6	0.6796		0.6717		0.1455		0.194		0.6132	0.6623		tp=0.39, tn=0.21, fp=0.27, fn=0.13		True
	7	0.6798		0.6762		0.148		0.1979		0.6354	0.6321		tp=0.34, tn=0.26, fp=0.22, fn=0.18		True
	8	0.6799		0.6754		0.1212		0.1707		0.6082	0.6507		tp=0.38, tn=0.21, fp=0.26, fn=0.15		False
	9	0.6799		0.6743		0.1435		0.2016		0.6264	0.6517		tp=0.37, tn=0.23, fp=0.24, fn=0.15		True
	10	0.6798		0.6785		0.1467		0.1365		0.6283	0.6422		tp=0.38, tn=0.19, fp=0.28, fn=0.15		False
	11	0.6799		0.6747		0.1395		0.1621		0.619	0.6386		tp=0.37, tn=0.21, fp=0.27, fn=0.15		False
	12	0.6809		0.676		0.1114		0.1893		0.6146	0.6323		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	13	0.6795		0.6798		0.1335		0.1864		0.6228	0.6343		tp=0.35, tn=0.24, fp=0.24, fn=0.17		False
	14	0.6792		0.6724		0.1317		0.2161		0.6194	0.6607		tp=0.38, tn=0.23, fp=0.25, fn=0.14		True
	15	0.6798		0.6805		0.1282		0.1816		0.6197	0.6311		tp=0.35, tn=0.25, fp=0.23, fn=0.18		False
	16	0.6785		0.6769		0.1281		0.1485		0.6128	0.6467		tp=0.39, tn=0.19, fp=0.28, fn=0.14		False
	17	0.6792		0.6779		0.135		0.1963		0.621	0.6563		tp=0.38, tn=0.22, fp=0.25, fn=0.15		False
	18	0.6787		0.6767		0.1367		0.1802		0.626	0.6427		tp=0.37, tn=0.23, fp=0.25, fn=0.15		False
	19	0.6785		0.671		0.1341		0.1743		0.6144	0.6667		tp=0.41, tn=0.19, fp=0.27, fn=0.13		False
	20	0.6794		0.6771		0.1291		0.1964		0.6228	0.6549		tp=0.38, tn=0.22, fp=0.25, fn=0.15		False
	21	0.6787		0.6765		0.1406		0.1835		0.6308	0.6521		tp=0.38, tn=0.22, fp=0.26, fn=0.15		False
	22	0.6787		0.6725		0.1404		0.1817		0.6224	0.6459		tp=0.37, tn=0.22, fp=0.26, fn=0.15		False
	23	0.6785		0.6735		0.1372		0.1598		0.6205	0.6538		tp=0.39, tn=0.19, fp=0.28, fn=0.14		False
	24	0.6784		0.6718		0.1446		0.1888		0.6281	0.6624		tp=0.39, tn=0.2, fp=0.27, fn=0.13		False
	25	0.678		0.6782		0.1393		0.189		0.6253	0.6472		tp=0.37, tn=0.23, fp=0.24, fn=0.16		False
	26	0.6784		0.6754		0.1391		0.1812		0.6192	0.6596		tp=0.4, tn=0.2, fp=0.28, fn=0.12		False
	27	0.6783		0.6796		0.1289		0.1907		0.6235	0.6391		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	28	0.6784		0.6769		0.1251		0.1923		0.6153	0.6472		tp=0.37, tn=0.23, fp=0.25, fn=0.15		False
	29	0.6787		0.6742		0.1414		0.1922		0.6261	0.6579		tp=0.38, tn=0.22, fp=0.26, fn=0.14		False
	30	0.6786		0.6815		0.1407		0.1453		0.6199	0.6422		tp=0.38, tn=0.19, fp=0.29, fn=0.14		False
	31	0.6777		0.6819		0.1368		0.154		0.6273	0.6356		tp=0.37, tn=0.21, fp=0.26, fn=0.16		False
	32	0.6787		0.6747		0.1331		0.1724		0.6203	0.6567		tp=0.39, tn=0.19, fp=0.28, fn=0.13		False
	33	0.6783		0.6737		0.144		0.1911		0.626	0.6519		tp=0.38, tn=0.22, fp=0.25, fn=0.15		False
	34	0.6779		0.6784		0.1297		0.1645		0.6154	0.6494		tp=0.38, tn=0.2, fp=0.27, fn=0.15		False
	35	0.6779		0.6745		0.1433		0.2069		0.6284	0.6562		tp=0.38, tn=0.23, fp=0.25, fn=0.15		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		32
learning rate		0.00125296348402
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_48-lr0.0013-h_size32-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6905		0.6703		0.07517		0.2223		0.5579	0.5465		tp=0.24, tn=0.36, fp=0.12, fn=0.28		True
	2	0.6562		0.6688		0.2383		0.1616		0.6402	0.6784		tp=0.44, tn=0.14, fp=0.34, fn=0.079		False
	3	0.6281		0.6826		0.3085		0.1487		0.6617	0.5484		tp=0.26, tn=0.31, fp=0.16, fn=0.27		False
	4	0.6108		0.6615		0.3517		0.2453		0.6814	0.6697		tp=0.38, tn=0.25, fp=0.23, fn=0.15		True
	5	0.5994		0.6681		0.3682		0.2605		0.691	0.6011		tp=0.28, tn=0.34, fp=0.14, fn=0.24		True
	6	0.5804		0.7155		0.4037		0.254		0.7096	0.5317		tp=0.23, tn=0.38, fp=0.085, fn=0.31		False
	7	0.5764		0.6773		0.3936		0.2346		0.703	0.6138		tp=0.31, tn=0.31, fp=0.16, fn=0.22		False
	8	0.5574		0.6856		0.4267		0.1832		0.7195	0.6328		tp=0.35, tn=0.24, fp=0.25, fn=0.16		False
	9	0.5474		0.7101		0.4527		0.2119		0.7333	0.5889		tp=0.28, tn=0.32, fp=0.16, fn=0.24		False
	10	0.5501		0.7164		0.4517		0.2031		0.7323	0.5675		tp=0.26, tn=0.33, fp=0.15, fn=0.25		False
	11	0.5342		0.7325		0.4676		0.1612		0.7371	0.6639		tp=0.41, tn=0.17, fp=0.3, fn=0.11		False
	12	0.5346		0.7278		0.4657		0.186		0.7393	0.5796		tp=0.28, tn=0.3, fp=0.16, fn=0.26		False
	13	0.5211		0.7219		0.4871		0.1629		0.7469	0.5975		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	14	0.5108		0.7646		0.5035		0.1935		0.7574	0.5652		tp=0.27, tn=0.32, fp=0.15, fn=0.26		False
	15	0.516		0.8048		0.4953		0.1993		0.7529	0.4858		tp=0.2, tn=0.38, fp=0.095, fn=0.32		False
	16	0.5031		0.724		0.5072		0.1612		0.7564	0.6553		tp=0.39, tn=0.19, fp=0.28, fn=0.14		False
	17	0.4942		0.7632		0.5196		0.1866		0.7624	0.6291		tp=0.34, tn=0.25, fp=0.23, fn=0.17		False
	18	0.4842		0.7745		0.5455		0.1655		0.7773	0.6462		tp=0.38, tn=0.21, fp=0.26, fn=0.15		False
	19	0.4841		0.7352		0.5307		0.1815		0.7703	0.5918		tp=0.3, tn=0.29, fp=0.18, fn=0.23		False
	20	0.4669		0.7575		0.5662		0.1811		0.788	0.602		tp=0.31, tn=0.28, fp=0.2, fn=0.21		False
	21	0.4742		0.7894		0.5556		0.2336		0.7829	0.5914		tp=0.28, tn=0.33, fp=0.14, fn=0.25		False
	22	0.4467		0.8172		0.5905		0.1601		0.7995	0.654		tp=0.4, tn=0.18, fp=0.3, fn=0.12		False
	23	0.453		0.8086		0.5851		0.1963		0.7975	0.5699		tp=0.27, tn=0.32, fp=0.15, fn=0.26		False
	24	0.4281		0.788		0.6117		0.1991		0.8095	0.6608		tp=0.39, tn=0.22, fp=0.26, fn=0.14		False
	25	0.4233		0.7997		0.6105		0.174		0.809	0.6522		tp=0.38, tn=0.21, fp=0.27, fn=0.14		False
	26	0.4119		0.8348		0.6348		0.1843		0.8214	0.6274		tp=0.34, tn=0.25, fp=0.22, fn=0.19		False


data			/scratch/asw462/data/levin
input size		300
hidden size		50
learning rate		5.92902080969e&05
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_49-lr5.9e&05-h_size50-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6073		0.6087		-0.02818		0		0.8398	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.5799		0.5659		0		0		0.8421	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	3	0.5718		0.5748		0		0		0.8408	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	4	0.5645		0.5507		0		0		0.8393	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	5	0.5491		0.5519		0		0		0.843	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	6	0.5432		0.5819		0.1368		0		0.8452	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	7	0.5357		0.5605		0.144		0.1259		0.8463	0.8216		tp=0.69, tn=0.007, fp=0.3, fn=0		True
	8	0.5303		0.5576		0.173		0.04202		0.8472	0.8167		tp=0.68, tn=0.014, fp=0.28, fn=0.021		False
	9	0.5221		0.5583		0.2049		0.04442		0.85	0.8201		tp=0.69, tn=0.014, fp=0.28, fn=0.021		False
	10	0.5184		0.5548		0.2504		0.1682		0.8525	0.822		tp=0.67, tn=0.035, fp=0.27, fn=0.021		True
	11	0.5134		0.5402		0.2472		0.1646		0.8523	0.8403		tp=0.7, tn=0.035, fp=0.24, fn=0.028		False
	12	0.5088		0.5336		0.2687		0.2748		0.8528	0.8412		tp=0.69, tn=0.056, fp=0.24, fn=0.021		True
	13	0.5031		0.563		0.2989		0.1685		0.8568	0.8139		tp=0.66, tn=0.042, fp=0.27, fn=0.028		False
	14	0.494		0.5276		0.3228		0.2234		0.8611	0.8439		tp=0.7, tn=0.042, fp=0.24, fn=0.021		False
	15	0.492		0.5293		0.3505		0.1985		0.8632	0.8326		tp=0.68, tn=0.049, fp=0.24, fn=0.035		False
	16	0.4857		0.5534		0.3611		0.2629		0.8657	0.8214		tp=0.64, tn=0.077, fp=0.24, fn=0.042		False
	17	0.4836		0.5433		0.3667		0.251		0.8645	0.8282		tp=0.66, tn=0.07, fp=0.23, fn=0.042		False
	18	0.4775		0.521		0.3879		0.2741		0.8687	0.8448		tp=0.68, tn=0.069, fp=0.21, fn=0.042		False
	19	0.4712		0.5562		0.4147		0.2949		0.872	0.8214		tp=0.64, tn=0.077, fp=0.25, fn=0.028		True
	20	0.4685		0.5305		0.4168		0.2302		0.8721	0.8297		tp=0.66, tn=0.063, fp=0.23, fn=0.042		False
	21	0.4596		0.5265		0.4331		0.1674		0.8761	0.821		tp=0.66, tn=0.056, fp=0.23, fn=0.056		False
	22	0.4592		0.5233		0.4368		0.2269		0.8752	0.8214		tp=0.64, tn=0.077, fp=0.22, fn=0.063		False
	23	0.4528		0.5439		0.4696		0.2119		0.8813	0.8037		tp=0.62, tn=0.084, fp=0.23, fn=0.07		False
	24	0.451		0.513		0.4563		0.2445		0.8777	0.8182		tp=0.63, tn=0.091, fp=0.2, fn=0.077		False
	25	0.4438		0.5313		0.4778		0.1926		0.8822	0.8125		tp=0.64, tn=0.07, fp=0.23, fn=0.063		False
	26	0.4386		0.5424		0.4882		0.2371		0.885	0.8145		tp=0.63, tn=0.084, fp=0.22, fn=0.063		False
	27	0.4342		0.5282		0.4919		0.211		0.8847	0.8178		tp=0.64, tn=0.076, fp=0.22, fn=0.069		False
	28	0.4325		0.507		0.4974		0.179		0.8852	0.8194		tp=0.65, tn=0.063, fp=0.22, fn=0.063		False
	29	0.4302		0.5415		0.4996		0.2227		0.8849	0.8108		tp=0.63, tn=0.077, fp=0.24, fn=0.056		False
	30	0.4226		0.5241		0.5074		0.2019		0.8873	0.8108		tp=0.63, tn=0.077, fp=0.22, fn=0.07		False
	31	0.4175		0.5021		0.5267		0.2645		0.8905	0.8319		tp=0.66, tn=0.077, fp=0.22, fn=0.049		False
	32	0.4156		0.5329		0.5202		0.2603		0.8892	0.8165		tp=0.62, tn=0.098, fp=0.2, fn=0.077		False
	33	0.4102		0.5448		0.5213		0.2551		0.8912	0.8145		tp=0.62, tn=0.09, fp=0.22, fn=0.062		False
	34	0.4061		0.5147		0.541		0.253		0.8935	0.8251		tp=0.64, tn=0.084, fp=0.21, fn=0.063		False
	35	0.4011		0.521		0.5467		0.2782		0.8944	0.8288		tp=0.64, tn=0.091, fp=0.2, fn=0.063		False
	36	0.3985		0.5189		0.5391		0.2964		0.8926	0.8341		tp=0.65, tn=0.091, fp=0.2, fn=0.056		True
	37	0.3945		0.5214		0.5462		0.2256		0.8935	0.8282		tp=0.66, tn=0.07, fp=0.22, fn=0.056		False
	38	0.3917		0.5327		0.5538		0.2375		0.8947	0.8214		tp=0.64, tn=0.077, fp=0.22, fn=0.056		False
	39	0.3863		0.5394		0.5769		0.2617		0.8987	0.8182		tp=0.63, tn=0.091, fp=0.22, fn=0.063		False
	40	0.3778		0.4999		0.5732		0.241		0.899	0.8384		tp=0.67, tn=0.07, fp=0.2, fn=0.056		False
	41	0.3774		0.5077		0.5686		0.3189		0.898	0.8364		tp=0.64, tn=0.1, fp=0.18, fn=0.07		True
	42	0.3743		0.5209		0.5902		0.244		0.9018	0.8251		tp=0.64, tn=0.084, fp=0.2, fn=0.07		False
	43	0.368		0.4799		0.5977		0.3685		0.9036	0.8533		tp=0.67, tn=0.098, fp=0.19, fn=0.042		True
	44	0.3638		0.5249		0.6018		0.2682		0.9055	0.8165		tp=0.62, tn=0.098, fp=0.21, fn=0.07		False
	45	0.3635		0.5136		0.596		0.3727		0.9034	0.844		tp=0.64, tn=0.12, fp=0.17, fn=0.063		True
	46	0.3574		0.4945		0.5959		0.3202		0.9033	0.8378		tp=0.65, tn=0.1, fp=0.18, fn=0.069		False
	47	0.3525		0.4881		0.6315		0.3263		0.9108	0.8349		tp=0.64, tn=0.11, fp=0.17, fn=0.077		False
	48	0.3508		0.53		0.6442		0.367		0.9132	0.819		tp=0.6, tn=0.13, fp=0.21, fn=0.056		False
	49	0.3453		0.4953		0.6445		0.3534		0.9136	0.8333		tp=0.62, tn=0.12, fp=0.17, fn=0.076		False
	50	0.3429		0.4935		0.6512		0.3807		0.9149	0.844		tp=0.64, tn=0.12, fp=0.18, fn=0.056		True
	51	0.3402		0.4892		0.663		0.3475		0.918	0.8349		tp=0.63, tn=0.12, fp=0.18, fn=0.069		False
	52	0.3341		0.5138		0.6565		0.3004		0.9165	0.8257		tp=0.63, tn=0.1, fp=0.2, fn=0.07		False
	53	0.331		0.4779		0.6699		0.2792		0.9183	0.8458		tp=0.67, tn=0.084, fp=0.17, fn=0.07		False
	54	0.3279		0.508		0.6891		0.2875		0.9227	0.8393		tp=0.66, tn=0.091, fp=0.18, fn=0.07		False
	55	0.3241		0.5212		0.6708		0.2617		0.9183	0.8182		tp=0.63, tn=0.091, fp=0.22, fn=0.063		False
	56	0.3185		0.518		0.7143		0.3356		0.9284	0.8364		tp=0.64, tn=0.1, fp=0.2, fn=0.056		False
	57	0.3198		0.5322		0.6874		0.3224		0.9215	0.8241		tp=0.62, tn=0.11, fp=0.2, fn=0.063		False
	58	0.3118		0.4679		0.7053		0.4109		0.9258	0.8519		tp=0.64, tn=0.13, fp=0.15, fn=0.07		True
	59	0.3063		0.4815		0.7205		0.4066		0.93	0.8545		tp=0.65, tn=0.12, fp=0.16, fn=0.062		False
	60	0.3069		0.5261		0.7021		0.3713		0.9254	0.8318		tp=0.62, tn=0.13, fp=0.18, fn=0.069		False
	61	0.3012		0.5213		0.7229		0.3965		0.9308	0.8411		tp=0.63, tn=0.13, fp=0.17, fn=0.063		False
	62	0.3021		0.5064		0.7235		0.3783		0.9303	0.8426		tp=0.64, tn=0.13, fp=0.17, fn=0.07		False
	63	0.2937		0.5138		0.743		0.3951		0.9349	0.8479		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	64	0.2941		0.5416		0.7299		0.3583		0.9337	0.8318		tp=0.62, tn=0.13, fp=0.18, fn=0.07		False
	65	0.2905		0.5119		0.7341		0.417		0.9328	0.8505		tp=0.64, tn=0.14, fp=0.15, fn=0.077		True
	66	0.2885		0.4994		0.738		0.3886		0.9338	0.8479		tp=0.64, tn=0.13, fp=0.16, fn=0.07		False
	67	0.2826		0.4992		0.761		0.4276		0.9394	0.8571		tp=0.65, tn=0.13, fp=0.15, fn=0.063		True
	68	0.2813		0.4972		0.7503		0.4614		0.9369	0.8558		tp=0.64, tn=0.14, fp=0.17, fn=0.042		True
	69	0.2775		0.5067		0.7519		0.4218		0.9368	0.8421		tp=0.62, tn=0.15, fp=0.15, fn=0.084		False
	70	0.2752		0.5072		0.7766		0.4418		0.9417	0.8476		tp=0.62, tn=0.15, fp=0.15, fn=0.07		False
	71	0.27		0.5051		0.7639		0.3959		0.9398	0.8559		tp=0.66, tn=0.11, fp=0.17, fn=0.049		False
	72	0.2705		0.4668		0.7696		0.4568		0.9407	0.8624		tp=0.65, tn=0.14, fp=0.15, fn=0.056		False
	73	0.2654		0.4808		0.7728		0.4322		0.9416	0.8491		tp=0.63, tn=0.15, fp=0.15, fn=0.07		False
	74	0.2607		0.4902		0.7801		0.4645		0.9432	0.8531		tp=0.63, tn=0.15, fp=0.16, fn=0.056		True
	75	0.2577		0.4813		0.7822		0.4322		0.9443	0.8491		tp=0.63, tn=0.15, fp=0.15, fn=0.07		False
	76	0.2542		0.5228		0.7856		0.4278		0.9444	0.8505		tp=0.64, tn=0.14, fp=0.16, fn=0.063		False
	77	0.2503		0.4913		0.7924		0.4145		0.9467	0.8421		tp=0.62, tn=0.15, fp=0.13, fn=0.1		False
	78	0.2495		0.5157		0.7798		0.4112		0.9442	0.8451		tp=0.63, tn=0.14, fp=0.16, fn=0.07		False
	79	0.2478		0.5128		0.808		0.3805		0.95	0.8325		tp=0.61, tn=0.15, fp=0.14, fn=0.1		False
	80	0.2466		0.496		0.7973		0.4782		0.9473	0.8571		tp=0.63, tn=0.16, fp=0.15, fn=0.063		True
	81	0.244		0.5182		0.804		0.4092		0.9498	0.8493		tp=0.65, tn=0.12, fp=0.19, fn=0.042		False
	82	0.2446		0.4966		0.7845		0.4718		0.9446	0.8531		tp=0.63, tn=0.15, fp=0.17, fn=0.049		False
	83	0.2356		0.5		0.8157		0.4577		0.952	0.8517		tp=0.62, tn=0.16, fp=0.14, fn=0.077		False
	84	0.2333		0.4689		0.8203		0.3972		0.9533	0.861		tp=0.67, tn=0.11, fp=0.16, fn=0.056		False
	85	0.2313		0.5213		0.8162		0.4425		0.9518	0.8462		tp=0.62, tn=0.16, fp=0.14, fn=0.084		False
	86	0.2283		0.497		0.826		0.503		0.9545	0.8767		tp=0.67, tn=0.14, fp=0.15, fn=0.042		True
	87	0.2261		0.4964		0.8124		0.4563		0.9514	0.8558		tp=0.64, tn=0.15, fp=0.16, fn=0.056		False
	88	0.2214		0.439		0.8262		0.5178		0.9553	0.8732		tp=0.65, tn=0.16, fp=0.13, fn=0.056		True
	89	0.2207		0.5028		0.82		0.5124		0.9534	0.8679		tp=0.64, tn=0.16, fp=0.15, fn=0.049		False
	90	0.2179		0.4929		0.8297		0.4621		0.9555	0.8636		tp=0.66, tn=0.13, fp=0.17, fn=0.042		False
	91	0.2173		0.5299		0.8361		0.4163		0.9567	0.8436		tp=0.62, tn=0.15, fp=0.15, fn=0.077		False
	92	0.2147		0.5042		0.8298		0.4517		0.9555	0.8517		tp=0.62, tn=0.16, fp=0.13, fn=0.091		False
	93	0.2111		0.4984		0.8568		0.4645		0.9623	0.8531		tp=0.63, tn=0.15, fp=0.16, fn=0.056		False
	94	0.2067		0.5088		0.8354		0.462		0.9569	0.8517		tp=0.62, tn=0.16, fp=0.15, fn=0.07		False
	95	0.2056		0.4797		0.8496		0.4267		0.9605	0.8636		tp=0.66, tn=0.13, fp=0.15, fn=0.063		False
	96	0.201		0.4984		0.8605		0.4955		0.9632	0.8767		tp=0.67, tn=0.14, fp=0.14, fn=0.049		False
	97	0.1992		0.5146		0.8572		0.4485		0.9623	0.8531		tp=0.63, tn=0.15, fp=0.14, fn=0.077		False
	98	0.1982		0.4844		0.8509		0.4487		0.9604	0.8545		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	99	0.1984		0.4911		0.8558		0.4596		0.9618	0.8598		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	100	0.195		0.4857		0.8714		0.507		0.966	0.8818		tp=0.68, tn=0.14, fp=0.13, fn=0.049		False
	101	0.1955		0.5006		0.8596		0.4752		0.9628	0.8585		tp=0.64, tn=0.15, fp=0.15, fn=0.056		False
	102	0.1905		0.5063		0.8664		0.4818		0.9646	0.8558		tp=0.62, tn=0.17, fp=0.14, fn=0.07		False
	103	0.1904		0.522		0.87		0.4059		0.9655	0.8519		tp=0.64, tn=0.13, fp=0.15, fn=0.077		False
	104	0.1864		0.4591		0.8768		0.5174		0.9674	0.8654		tp=0.63, tn=0.17, fp=0.13, fn=0.063		False
	105	0.1847		0.5202		0.8723		0.4387		0.9659	0.8545		tp=0.64, tn=0.15, fp=0.14, fn=0.077		False
	106	0.1798		0.536		0.8787		0.4735		0.9679	0.8664		tp=0.66, tn=0.14, fp=0.15, fn=0.049		False
	107	0.1818		0.4935		0.8637		0.5159		0.9642	0.8889		tp=0.69, tn=0.13, fp=0.13, fn=0.042		False
	108	0.1757		0.5269		0.8833		0.3906		0.9694	0.8396		tp=0.62, tn=0.14, fp=0.15, fn=0.084		False
	109	0.175		0.5175		0.8897		0.4003		0.9706	0.8465		tp=0.64, tn=0.13, fp=0.16, fn=0.07		False


data			/scratch/asw462/data/levin
input size		300
hidden size		13
learning rate		0.000590239217975
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_4-lr0.00059-h_size13-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6472		0.6066		0.02742		0		0.754	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.5867		0.591		0		0		0.8407	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5851		0.61		0		0		0.8398	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	4	0.5797		0.6138		0		0		0.8412	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	5	0.574		0.5879		0		0		0.8426	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	6	0.5689		0.5825		0		0		0.8421	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	7	0.5655		0.5641		0		0		0.8408	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	8	0.5559		0.5755		0.04312		0		0.842	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	9	0.5452		0.5627		0.1145		0.1301		0.8445	0.8313		tp=0.71, tn=0.007, fp=0.29, fn=0		True
	10	0.5384		0.5642		0.1722		0.1786		0.8452	0.825		tp=0.69, tn=0.014, fp=0.29, fn=0		True
	11	0.5256		0.5495		0.2231		0.1816		0.8506	0.8299		tp=0.7, tn=0.014, fp=0.29, fn=0		True
	12	0.5147		0.5398		0.3093		0.176		0.8588	0.8216		tp=0.69, tn=0.014, fp=0.3, fn=0		False
	13	0.5023		0.5327		0.3329		0.1262		0.8617	0.8395		tp=0.71, tn=0.014, fp=0.27, fn=0.007		False
	14	0.4903		0.5373		0.3292		0.2754		0.8619	0.8426		tp=0.69, tn=0.049, fp=0.24, fn=0.014		True
	15	0.4817		0.5288		0.3835		0.3258		0.8677	0.8448		tp=0.69, tn=0.063, fp=0.24, fn=0.014		True
	16	0.4704		0.5327		0.3976		0.3258		0.8708	0.8448		tp=0.69, tn=0.063, fp=0.24, fn=0.014		False
	17	0.4587		0.5209		0.4253		0.2986		0.8756	0.8412		tp=0.69, tn=0.056, fp=0.24, fn=0.014		False
	18	0.4514		0.52		0.4441		0.3302		0.8765	0.8485		tp=0.69, tn=0.07, fp=0.22, fn=0.021		True
	19	0.4358		0.5087		0.4778		0.3658		0.8831	0.8584		tp=0.7, tn=0.07, fp=0.22, fn=0.014		True
	20	0.4355		0.5189		0.4497		0.3408		0.8743	0.8393		tp=0.66, tn=0.091, fp=0.22, fn=0.035		False
	21	0.4281		0.5068		0.477		0.3808		0.8799	0.8533		tp=0.67, tn=0.098, fp=0.2, fn=0.035		True
	22	0.4205		0.5077		0.4947		0.3742		0.8832	0.8468		tp=0.66, tn=0.1, fp=0.2, fn=0.042		False
	23	0.4145		0.5215		0.4914		0.3951		0.8825	0.8479		tp=0.64, tn=0.13, fp=0.17, fn=0.063		True
	24	0.4065		0.5443		0.5108		0.4035		0.8851	0.8357		tp=0.62, tn=0.13, fp=0.2, fn=0.049		True
	25	0.4015		0.5055		0.5358		0.4088		0.8888	0.8545		tp=0.66, tn=0.12, fp=0.17, fn=0.049		True
	26	0.3918		0.5058		0.543		0.4629		0.8921	0.8676		tp=0.66, tn=0.13, fp=0.15, fn=0.049		True
	27	0.39		0.5141		0.5643		0.4288		0.8963	0.8649		tp=0.67, tn=0.12, fp=0.16, fn=0.049		False
	28	0.3834		0.495		0.562		0.3896		0.8945	0.8584		tp=0.68, tn=0.098, fp=0.19, fn=0.035		False
	29	0.377		0.5053		0.5773		0.4709		0.8989	0.8624		tp=0.66, tn=0.13, fp=0.17, fn=0.035		True
	30	0.3742		0.4879		0.5794		0.4817		0.8994	0.8727		tp=0.67, tn=0.13, fp=0.15, fn=0.042		True
	31	0.3696		0.5306		0.5849		0.3428		0.8982	0.8378		tp=0.65, tn=0.098, fp=0.21, fn=0.042		False
	32	0.3646		0.5169		0.6028		0.4422		0.9022	0.8545		tp=0.65, tn=0.12, fp=0.19, fn=0.035		False
	33	0.3601		0.4891		0.6073		0.4712		0.9036	0.8676		tp=0.66, tn=0.13, fp=0.16, fn=0.042		False
	34	0.3592		0.5278		0.6126		0.4186		0.9041	0.8545		tp=0.66, tn=0.12, fp=0.18, fn=0.042		False
	35	0.3539		0.5227		0.6166		0.378		0.9048	0.8416		tp=0.65, tn=0.1, fp=0.21, fn=0.035		False
	36	0.3516		0.539		0.6204		0.3311		0.9073	0.8378		tp=0.65, tn=0.098, fp=0.2, fn=0.049		False
	37	0.3476		0.4964		0.6248		0.483		0.9057	0.87		tp=0.68, tn=0.12, fp=0.18, fn=0.021		True
	38	0.3455		0.4889		0.6203		0.4844		0.9058	0.8716		tp=0.66, tn=0.14, fp=0.15, fn=0.049		True
	39	0.3376		0.5136		0.6348		0.3723		0.9085	0.8482		tp=0.66, tn=0.098, fp=0.2, fn=0.035		False
	40	0.3359		0.5403		0.6404		0.3208		0.9108	0.8378		tp=0.65, tn=0.098, fp=0.2, fn=0.056		False
	41	0.3328		0.5548		0.6317		0.374		0.9086	0.8318		tp=0.62, tn=0.13, fp=0.2, fn=0.056		False
	42	0.3298		0.5417		0.6547		0.4017		0.9128	0.8426		tp=0.64, tn=0.13, fp=0.19, fn=0.049		False
	43	0.3276		0.5375		0.6596		0.3904		0.9143	0.8493		tp=0.65, tn=0.12, fp=0.17, fn=0.056		False
	44	0.3247		0.499		0.6585		0.3967		0.914	0.8507		tp=0.66, tn=0.11, fp=0.19, fn=0.042		False
	45	0.3254		0.5603		0.6575		0.3028		0.9149	0.8356		tp=0.66, tn=0.084, fp=0.22, fn=0.042		False
	46	0.3182		0.5633		0.6707		0.3771		0.9172	0.8455		tp=0.65, tn=0.11, fp=0.19, fn=0.049		False
	47	0.3189		0.5562		0.6689		0.3268		0.9175	0.8311		tp=0.64, tn=0.1, fp=0.2, fn=0.056		False
	48	0.3134		0.4988		0.6741		0.4253		0.9179	0.87		tp=0.68, tn=0.12, fp=0.14, fn=0.063		False
	49	0.3106		0.5744		0.6767		0.4072		0.9185	0.8396		tp=0.62, tn=0.14, fp=0.17, fn=0.063		False
	50	0.3052		0.5574		0.6962		0.4041		0.9219	0.8411		tp=0.63, tn=0.13, fp=0.18, fn=0.056		False
	51	0.3056		0.5537		0.6791		0.3677		0.9186	0.8455		tp=0.65, tn=0.11, fp=0.18, fn=0.056		False
	52	0.3052		0.5464		0.6838		0.3951		0.9194	0.8479		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	53	0.2985		0.5326		0.6907		0.4088		0.9221	0.8545		tp=0.66, tn=0.12, fp=0.17, fn=0.049		False
	54	0.2965		0.5668		0.7017		0.3833		0.925	0.8372		tp=0.63, tn=0.13, fp=0.19, fn=0.056		False
	55	0.2965		0.5548		0.7145		0.4385		0.9262	0.8558		tp=0.64, tn=0.14, fp=0.15, fn=0.063		False
	56	0.2949		0.5599		0.6993		0.417		0.9242	0.8519		tp=0.64, tn=0.13, fp=0.16, fn=0.063		False
	57	0.2925		0.5845		0.705		0.3868		0.9252	0.8396		tp=0.62, tn=0.14, fp=0.15, fn=0.091		False
	58	0.2924		0.5402		0.7067		0.3904		0.9248	0.8493		tp=0.65, tn=0.12, fp=0.17, fn=0.056		False
	59	0.291		0.5956		0.7187		0.4275		0.9275	0.8436		tp=0.62, tn=0.15, fp=0.17, fn=0.063		False


data			/scratch/asw462/data/levin
input size		300
hidden size		64
learning rate		0.00450289056227
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_50-lr0.0045-h_size64-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6457		0.5708		0.02678		0.06326		0.8309	0.8136		tp=0.67, tn=0.021, fp=0.28, fn=0.028		True
	2	0.5423		0.5676		0.2543		0.3324		0.846	0.8462		tp=0.69, tn=0.056, fp=0.24, fn=0.007		True
	3	0.4919		0.5387		0.3634		0.2292		0.8586	0.8091		tp=0.62, tn=0.09, fp=0.22, fn=0.076		False
	4	0.4438		0.5118		0.4458		0.2618		0.8702	0.8475		tp=0.69, tn=0.056, fp=0.22, fn=0.028		False
	5	0.4009		0.5265		0.5319		0.2876		0.8875	0.8435		tp=0.68, tn=0.07, fp=0.22, fn=0.035		False
	6	0.3358		0.5521		0.6449		0.4159		0.9114	0.8584		tp=0.66, tn=0.13, fp=0.15, fn=0.063		True
	7	0.2727		0.5013		0.7455		0.4254		0.9347	0.8406		tp=0.61, tn=0.16, fp=0.13, fn=0.098		True
	8	0.245		0.4289		0.7698		0.5447		0.9397	0.8987		tp=0.71, tn=0.13, fp=0.13, fn=0.028		True
	9	0.2189		0.556		0.8125		0.4923		0.9511	0.8558		tp=0.62, tn=0.17, fp=0.15, fn=0.056		False
	10	0.1771		0.5758		0.8353		0.4952		0.9564	0.8426		tp=0.58, tn=0.2, fp=0.098, fn=0.12		False
	11	0.1216		0.4663		0.9057		0.496		0.9747	0.8442		tp=0.58, tn=0.2, fp=0.1, fn=0.11		False
	12	0.09566		0.5364		0.9344		0.5505		0.9824	0.8738		tp=0.63, tn=0.19, fp=0.1, fn=0.077		True
	13	0.08173		0.6425		0.9613		0.5011		0.9894	0.8679		tp=0.64, tn=0.16, fp=0.13, fn=0.063		False
	14	0.09079		0.6587		0.9281		0.4845		0.9803	0.8367		tp=0.57, tn=0.2, fp=0.091, fn=0.13		False
	15	0.05844		0.7595		0.9629		0.5005		0.9899	0.8651		tp=0.65, tn=0.15, fp=0.17, fn=0.035		False
	16	0.04495		0.7114		0.9736		0.5272		0.9928	0.8732		tp=0.65, tn=0.17, fp=0.13, fn=0.056		False
	17	0.03956		0.5655		0.9822		0.5981		0.9952	0.891		tp=0.65, tn=0.19, fp=0.1, fn=0.056		True
	18	0.03105		0.7335		0.9877		0.5087		0.9966	0.8571		tp=0.61, tn=0.19, fp=0.11, fn=0.091		False
	19	0.03261		0.7662		0.9859		0.5823		0.9962	0.8804		tp=0.64, tn=0.18, fp=0.14, fn=0.035		False
	20	0.03138		0.8278		0.9877		0.4759		0.9966	0.8638		tp=0.64, tn=0.15, fp=0.13, fn=0.07		False
	21	0.02746		0.7187		0.9841		0.5624		0.9957	0.8725		tp=0.62, tn=0.2, fp=0.12, fn=0.063		False
	22	0.02544		0.7855		0.9842		0.5722		0.9957	0.878		tp=0.63, tn=0.2, fp=0.1, fn=0.07		False
	23	0.02209		0.7964		0.9894		0.4848		0.9971	0.8778		tp=0.68, tn=0.13, fp=0.14, fn=0.049		False
	24	0.02139		0.9146		0.9912		0.5015		0.9976	0.8599		tp=0.62, tn=0.17, fp=0.13, fn=0.07		False
	25	0.01711		0.8555		0.993		0.5379		0.9981	0.8774		tp=0.65, tn=0.17, fp=0.13, fn=0.056		False
	26	0.01801		0.95		0.993		0.5161		0.9981	0.8571		tp=0.61, tn=0.19, fp=0.13, fn=0.07		False
	27	0.02092		0.8801		0.9894		0.5104		0.9971	0.8654		tp=0.63, tn=0.17, fp=0.12, fn=0.077		False
	28	0.01472		0.8822		0.9948		0.5091		0.9986	0.8732		tp=0.65, tn=0.16, fp=0.12, fn=0.07		False
	29	0.01403		0.8436		0.993		0.5884		0.9981	0.892		tp=0.66, tn=0.18, fp=0.097, fn=0.062		False
	30	0.01536		0.9345		0.9947		0.5509		0.9986	0.8762		tp=0.64, tn=0.17, fp=0.13, fn=0.049		False
	31	0.01459		0.8612		0.993		0.5285		0.9981	0.8614		tp=0.61, tn=0.2, fp=0.1, fn=0.091		False
	32	0.01521		1.01		0.9912		0.5095		0.9976	0.8667		tp=0.64, tn=0.17, fp=0.13, fn=0.063		False
	33	0.01395		1.049		0.9948		0.5011		0.9985	0.8679		tp=0.64, tn=0.16, fp=0.13, fn=0.063		False
	34	0.01225		0.962		0.9947		0.5611		0.9986	0.875		tp=0.63, tn=0.19, fp=0.12, fn=0.056		False
	35	0.01347		0.946		0.993		0.5359		0.9981	0.8683		tp=0.62, tn=0.19, fp=0.1, fn=0.084		False
	36	0.01258		1.031		0.9947		0.5367		0.9986	0.8696		tp=0.63, tn=0.18, fp=0.13, fn=0.063		False
	37	0.01298		0.8797		0.9912		0.5586		0.9976	0.8804		tp=0.64, tn=0.18, fp=0.1, fn=0.07		False
	38	0.01483		1.065		0.9913		0.5161		0.9976	0.8571		tp=0.61, tn=0.19, fp=0.13, fn=0.07		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		77
learning rate		0.000216373794433
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_51-lr0.00022-h_size77-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6907		0.6844		0.07501		0.167		0.5852	0.6548		tp=0.38, tn=0.21, fp=0.23, fn=0.17		True
	2	0.6824		0.6861		0.2304		0.1981		0.5774	0.5312		tp=0.24, tn=0.34, fp=0.11, fn=0.31		True
	3	0.6766		0.6788		0.2575		0.3537		0.5636	0.6667		tp=0.33, tn=0.34, fp=0.12, fn=0.21		True
	4	0.6705		0.6764		0.3136		0.3475		0.6226	0.6418		tp=0.3, tn=0.36, fp=0.1, fn=0.23		False
	5	0.6639		0.673		0.2963		0.3668		0.5754	0.6713		tp=0.34, tn=0.34, fp=0.098, fn=0.23		True
	6	0.6569		0.6686		0.3571		0.3212		0.6562	0.6962		tp=0.38, tn=0.28, fp=0.17, fn=0.17		False
	7	0.6508		0.6701		0.3383		0.2827		0.6295	0.6533		tp=0.34, tn=0.3, fp=0.15, fn=0.22		False
	8	0.6417		0.66		0.3988		0.3486		0.6751	0.6887		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	9	0.6334		0.6516		0.413		0.3485		0.71	0.7125		tp=0.4, tn=0.28, fp=0.15, fn=0.17		False
	10	0.6263		0.6559		0.3928		0.3336		0.6719	0.68		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	11	0.616		0.6528		0.4163		0.3352		0.7025	0.6667		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	12	0.6078		0.6415		0.4307		0.3336		0.6809	0.68		tp=0.36, tn=0.31, fp=0.13, fn=0.2		False
	13	0.5975		0.6486		0.4612		0.3052		0.6952	0.6434		tp=0.32, tn=0.32, fp=0.12, fn=0.24		False
	14	0.5888		0.6397		0.4605		0.3099		0.7262	0.6839		tp=0.37, tn=0.29, fp=0.17, fn=0.17		False
	15	0.5792		0.6273		0.4809		0.3821		0.7101	0.6853		tp=0.34, tn=0.34, fp=0.11, fn=0.2		True
	16	0.5686		0.6366		0.5102		0.2711		0.7395	0.6709		tp=0.37, tn=0.27, fp=0.19, fn=0.17		False
	17	0.56		0.6389		0.5309		0.2832		0.7619	0.671		tp=0.36, tn=0.28, fp=0.16, fn=0.2		False
	18	0.5512		0.6362		0.5326		0.3042		0.7356	0.6277		tp=0.3, tn=0.35, fp=0.12, fn=0.23		False
	19	0.5426		0.6392		0.5362		0.2469		0.7577	0.6708		tp=0.38, tn=0.25, fp=0.19, fn=0.18		False
	20	0.5325		0.6388		0.5809		0.2535		0.7769	0.6581		tp=0.36, tn=0.27, fp=0.19, fn=0.18		False
	21	0.5243		0.6324		0.5569		0.2469		0.7729	0.64		tp=0.34, tn=0.29, fp=0.16, fn=0.22		False
	22	0.5148		0.6298		0.5842		0.2479		0.7774	0.6447		tp=0.34, tn=0.28, fp=0.18, fn=0.19		False
	23	0.5075		0.6312		0.6137		0.2451		0.7851	0.64		tp=0.34, tn=0.29, fp=0.17, fn=0.21		False
	24	0.5008		0.6208		0.58		0.2814		0.7913	0.6752		tp=0.37, tn=0.27, fp=0.16, fn=0.2		False
	25	0.4921		0.6265		0.6206		0.259		0.787	0.6443		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	26	0.4831		0.6351		0.6203		0.2566		0.7943	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	27	0.4753		0.618		0.6361		0.2721		0.811	0.6579		tp=0.35, tn=0.29, fp=0.16, fn=0.2		False
	28	0.467		0.6053		0.6502		0.2886		0.8095	0.6577		tp=0.34, tn=0.3, fp=0.15, fn=0.2		False
	29	0.4598		0.6461		0.6391		0.2451		0.8116	0.64		tp=0.34, tn=0.29, fp=0.17, fn=0.21		False
	30	0.454		0.6426		0.6427		0.2701		0.81	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.19		False
	31	0.4449		0.635		0.6631		0.259		0.8217	0.6443		tp=0.34, tn=0.29, fp=0.17, fn=0.2		False
	32	0.439		0.6414		0.6668		0.2552		0.8148	0.6536		tp=0.35, tn=0.28, fp=0.18, fn=0.19		False
	33	0.433		0.6168		0.6743		0.3043		0.8305	0.6711		tp=0.36, tn=0.29, fp=0.14, fn=0.21		False
	34	0.4262		0.6475		0.6921		0.2254		0.8387	0.6452		tp=0.35, tn=0.27, fp=0.2, fn=0.19		False
	35	0.4205		0.6498		0.713		0.2845		0.8483	0.6623		tp=0.35, tn=0.29, fp=0.17, fn=0.18		False
	36	0.4153		0.6333		0.6924		0.2427		0.8307	0.6447		tp=0.34, tn=0.28, fp=0.17, fn=0.2		False


data			/scratch/asw462/data/levin
input size		300
hidden size		113
learning rate		0.000456945502724
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_52-lr0.00046-h_size113-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5811		0.5739		0.06013		0		0.8395	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.5199		0.5339		0.2433		0.1485		0.8502	0.8291		tp=0.68, tn=0.042, fp=0.24, fn=0.042		True
	3	0.4844		0.5408		0.3696		0.2298		0.8645	0.8362		tp=0.68, tn=0.056, fp=0.23, fn=0.035		True
	4	0.462		0.5383		0.4144		0.2617		0.8673	0.8182		tp=0.63, tn=0.091, fp=0.22, fn=0.063		True
	5	0.4363		0.5359		0.4767		0.2965		0.8802	0.8131		tp=0.6, tn=0.12, fp=0.19, fn=0.083		True
	6	0.4012		0.5573		0.5549		0.2525		0.8924	0.8348		tp=0.67, tn=0.063, fp=0.23, fn=0.035		False
	7	0.3625		0.5637		0.5876		0.3558		0.902	0.804		tp=0.56, tn=0.17, fp=0.14, fn=0.13		True
	8	0.3382		0.5184		0.6437		0.3889		0.9117	0.8141		tp=0.57, tn=0.17, fp=0.13, fn=0.13		True
	9	0.3025		0.5333		0.6879		0.259		0.9196	0.8498		tp=0.69, tn=0.063, fp=0.2, fn=0.042		False
	10	0.2729		0.5312		0.7515		0.4174		0.9365	0.8451		tp=0.63, tn=0.14, fp=0.17, fn=0.063		True
	11	0.2484		0.5145		0.7721		0.3764		0.9413	0.8177		tp=0.58, tn=0.16, fp=0.15, fn=0.1		False
	12	0.2291		0.555		0.8073		0.3612		0.9497	0.8286		tp=0.61, tn=0.14, fp=0.15, fn=0.098		False
	13	0.2075		0.5927		0.8404		0.3808		0.9582	0.8533		tp=0.67, tn=0.098, fp=0.2, fn=0.035		False
	14	0.1858		0.4421		0.8527		0.5134		0.9614	0.8654		tp=0.63, tn=0.17, fp=0.13, fn=0.07		True
	15	0.1722		0.5032		0.8519		0.5416		0.9609	0.8785		tp=0.66, tn=0.16, fp=0.14, fn=0.042		True
	16	0.1733		0.5521		0.8637		0.4219		0.964	0.8571		tp=0.65, tn=0.13, fp=0.15, fn=0.07		False
	17	0.1418		0.5723		0.9025		0.5305		0.9737	0.8732		tp=0.65, tn=0.16, fp=0.15, fn=0.042		False
	18	0.1255		0.5649		0.933		0.5124		0.9818	0.8679		tp=0.64, tn=0.16, fp=0.15, fn=0.049		False
	19	0.1301		0.6036		0.9		0.5385		0.9734	0.872		tp=0.64, tn=0.17, fp=0.15, fn=0.042		False
	20	0.1124		0.6007		0.9436		0.4935		0.9846	0.8612		tp=0.63, tn=0.17, fp=0.13, fn=0.07		False
	21	0.1072		0.5064		0.9367		0.5457		0.9827	0.8762		tp=0.64, tn=0.17, fp=0.13, fn=0.056		True
	22	0.102		0.6002		0.9473		0.5492		0.9856	0.8738		tp=0.63, tn=0.19, fp=0.098, fn=0.084		True
	23	0.08426		0.5982		0.9631		0.5784		0.9899	0.8768		tp=0.62, tn=0.2, fp=0.1, fn=0.07		True
	24	0.08995		0.6256		0.9543		0.5187		0.9875	0.8667		tp=0.63, tn=0.17, fp=0.13, fn=0.062		False
	25	0.07143		0.6557		0.9631		0.5236		0.9899	0.8732		tp=0.65, tn=0.16, fp=0.14, fn=0.049		False
	26	0.06519		0.7633		0.9735		0.491		0.9928	0.8664		tp=0.66, tn=0.14, fp=0.17, fn=0.035		False
	27	0.05951		0.7234		0.9736		0.4822		0.9928	0.8585		tp=0.64, tn=0.15, fp=0.16, fn=0.049		False
	28	0.05661		0.7031		0.9806		0.4895		0.9947	0.8626		tp=0.64, tn=0.16, fp=0.14, fn=0.063		False
	29	0.05256		0.6702		0.9789		0.5252		0.9942	0.8785		tp=0.66, tn=0.16, fp=0.12, fn=0.063		False
	30	0.05253		0.7225		0.9843		0.553		0.9957	0.875		tp=0.64, tn=0.18, fp=0.13, fn=0.056		False
	31	0.0482		0.627		0.9825		0.5511		0.9952	0.8815		tp=0.65, tn=0.17, fp=0.1, fn=0.07		False
	32	0.04511		0.7768		0.9842		0.5432		0.9957	0.8774		tp=0.65, tn=0.17, fp=0.13, fn=0.049		False
	33	0.04572		0.9327		0.9825		0.5301		0.9952	0.8744		tp=0.66, tn=0.15, fp=0.15, fn=0.035		False
	34	0.04441		0.7412		0.9807		0.5624		0.9947	0.8725		tp=0.62, tn=0.2, fp=0.12, fn=0.063		False
	35	0.04675		0.86		0.9841		0.5011		0.9957	0.8679		tp=0.64, tn=0.16, fp=0.13, fn=0.063		False
	36	0.04181		0.8972		0.9895		0.5402		0.9971	0.8683		tp=0.62, tn=0.19, fp=0.12, fn=0.07		False
	37	0.04187		0.941		0.9843		0.5457		0.9956	0.875		tp=0.64, tn=0.18, fp=0.11, fn=0.07		False
	38	0.03748		0.8249		0.9842		0.5968		0.9957	0.8824		tp=0.63, tn=0.2, fp=0.11, fn=0.056		True
	39	0.03262		0.937		0.9878		0.5694		0.9966	0.8713		tp=0.61, tn=0.21, fp=0.097, fn=0.083		False
	40	0.03282		0.8676		0.9859		0.5607		0.9962	0.8848		tp=0.67, tn=0.15, fp=0.15, fn=0.028		False
	41	0.0424		0.9837		0.9789		0.5413		0.9942	0.8807		tp=0.67, tn=0.15, fp=0.15, fn=0.028		False
	42	0.03596		0.8239		0.9843		0.6302		0.9957	0.8821		tp=0.6, tn=0.24, fp=0.07, fn=0.091		True
	43	0.03886		0.917		0.9788		0.5669		0.9942	0.8868		tp=0.66, tn=0.17, fp=0.1, fn=0.063		False
	44	0.03136		0.9541		0.9912		0.5903		0.9976	0.891		tp=0.66, tn=0.18, fp=0.1, fn=0.056		False
	45	0.02954		0.8917		0.9877		0.6165		0.9966	0.8942		tp=0.65, tn=0.2, fp=0.098, fn=0.056		False
	46	0.02634		0.9318		0.9877		0.5651		0.9966	0.8804		tp=0.64, tn=0.18, fp=0.12, fn=0.056		False
	47	0.02835		0.9895		0.9859		0.5691		0.9961	0.8837		tp=0.66, tn=0.17, fp=0.14, fn=0.035		False
	48	0.03545		0.7972		0.9859		0.6097		0.9962	0.8867		tp=0.63, tn=0.21, fp=0.084, fn=0.077		False
	49	0.03226		1.008		0.9894		0.5068		0.9971	0.8654		tp=0.63, tn=0.17, fp=0.1, fn=0.091		False
	50	0.033		0.8984		0.9894		0.5896		0.9971	0.8744		tp=0.61, tn=0.22, fp=0.1, fn=0.07		False
	51	0.03001		1.053		0.9877		0.5461		0.9966	0.8826		tp=0.66, tn=0.17, fp=0.11, fn=0.063		False
	52	0.02543		0.949		0.993		0.5614		0.9981	0.8804		tp=0.64, tn=0.18, fp=0.11, fn=0.063		False
	53	0.03632		1.108		0.9824		0.5203		0.9952	0.8708		tp=0.64, tn=0.17, fp=0.091, fn=0.098		False
	54	0.02527		0.9851		0.993		0.5622		0.9981	0.8713		tp=0.62, tn=0.2, fp=0.084, fn=0.098		False
	55	0.03311		0.8359		0.9861		0.6019		0.9961	0.891		tp=0.65, tn=0.19, fp=0.11, fn=0.049		False
	56	0.0304		0.9957		0.9877		0.5777		0.9966	0.8804		tp=0.64, tn=0.19, fp=0.12, fn=0.049		False
	57	0.0304		1.004		0.9877		0.5835		0.9966	0.8835		tp=0.64, tn=0.2, fp=0.084, fn=0.084		False
	58	0.02817		0.9438		0.9913		0.5257		0.9976	0.8708		tp=0.64, tn=0.17, fp=0.12, fn=0.07		False
	59	0.02308		1.078		0.993		0.5206		0.9981	0.8667		tp=0.64, tn=0.17, fp=0.15, fn=0.049		False
	60	0.02062		0.9034		0.9948		0.5469		0.9986	0.867		tp=0.62, tn=0.2, fp=0.12, fn=0.07		False
	61	0.03039		1.51		0.9894		0.4947		0.9971	0.8624		tp=0.66, tn=0.13, fp=0.19, fn=0.021		False
	62	0.03218		1.083		0.9841		0.5909		0.9957	0.8756		tp=0.61, tn=0.22, fp=0.1, fn=0.069		False
	63	0.0232		1.052		0.9912		0.5489		0.9976	0.875		tp=0.64, tn=0.18, fp=0.12, fn=0.063		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		34
learning rate		0.00355545490291
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_53-lr0.0036-h_size34-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6872		0.6935		0.1234		0.1046		0.5115	0.4806		tp=0.22, tn=0.32, fp=0.13, fn=0.33		True
	2	0.6509		0.6939		0.2304		0.119		0.5944	0.4923		tp=0.22, tn=0.31, fp=0.13, fn=0.34		True
	3	0.6367		0.6908		0.2517		0.1332		0.5827	0.6211		tp=0.35, tn=0.22, fp=0.22, fn=0.21		True
	4	0.6221		0.6821		0.31		0.1953		0.6412	0.5755		tp=0.28, tn=0.31, fp=0.14, fn=0.27		True
	5	0.602		0.6956		0.3162		0.2145		0.6486	0.5469		tp=0.24, tn=0.35, fp=0.12, fn=0.29		True
	6	0.5951		0.8023		0.3717		0.1868		0.6728	0.2391		tp=0.077, tn=0.43, fp=0.014, fn=0.48		False
	7	0.6105		0.6812		0.3042		0.242		0.6244	0.6667		tp=0.38, tn=0.25, fp=0.22, fn=0.16		True
	8	0.592		0.6621		0.3573		0.2951		0.683	0.6623		tp=0.35, tn=0.3, fp=0.15, fn=0.21		True
	9	0.5605		0.7075		0.4106		0.1735		0.6815	0.4878		tp=0.21, tn=0.35, fp=0.098, fn=0.34		False
	10	0.5401		0.6818		0.4746		0.2964		0.7242	0.6176		tp=0.29, tn=0.34, fp=0.11, fn=0.25		True
	11	0.5344		0.7013		0.4462		0.2948		0.7208	0.5172		tp=0.21, tn=0.4, fp=0.056, fn=0.34		False
	12	0.5141		0.7092		0.4598		0.2863		0.7187	0.6241		tp=0.31, tn=0.32, fp=0.11, fn=0.26		False
	13	0.5018		0.7116		0.4922		0.2814		0.7383	0.6438		tp=0.33, tn=0.31, fp=0.14, fn=0.22		False
	14	0.4979		0.7311		0.4952		0.2189		0.7346	0.6584		tp=0.37, tn=0.24, fp=0.2, fn=0.18		False
	15	0.4735		0.7225		0.5453		0.2975		0.7597	0.6286		tp=0.31, tn=0.33, fp=0.12, fn=0.24		True
	16	0.4689		0.7279		0.5162		0.1921		0.7418	0.6744		tp=0.41, tn=0.2, fp=0.24, fn=0.15		False
	17	0.4556		0.7716		0.5597		0.1972		0.7727	0.6323		tp=0.34, tn=0.26, fp=0.2, fn=0.2		False
	18	0.4682		0.8497		0.5013		0.2079		0.7455	0.5564		tp=0.26, tn=0.33, fp=0.12, fn=0.29		False
	19	0.4711		0.8316		0.5397		0.2865		0.7551	0.5172		tp=0.21, tn=0.4, fp=0.062, fn=0.33		False
	20	0.4972		1.086		0.5129		0.135		0.7508	0.3		tp=0.1, tn=0.41, fp=0.042, fn=0.45		False
	21	0.4475		0.7943		0.5818		0.1206		0.7741	0.6474		tp=0.39, tn=0.18, fp=0.27, fn=0.16		False
	22	0.424		0.8256		0.6067		0.2559		0.7976	0.6087		tp=0.29, tn=0.33, fp=0.14, fn=0.24		False
	23	0.411		0.7881		0.5861		0.2351		0.7847	0.6259		tp=0.32, tn=0.29, fp=0.16, fn=0.22		False
	24	0.3986		0.8308		0.639		0.25		0.8122	0.6351		tp=0.33, tn=0.29, fp=0.15, fn=0.22		False
	25	0.4006		0.8476		0.6254		0.1893		0.7994	0.6744		tp=0.41, tn=0.2, fp=0.23, fn=0.16		False
	26	0.4027		0.8549		0.6068		0.2149		0.7982	0.6267		tp=0.33, tn=0.28, fp=0.2, fn=0.2		False
	27	0.4008		0.9483		0.6302		0.1427		0.8097	0.6429		tp=0.38, tn=0.2, fp=0.25, fn=0.17		False
	28	0.3896		0.8679		0.6395		0.1863		0.8093	0.6889		tp=0.43, tn=0.18, fp=0.25, fn=0.14		False
	29	0.3818		0.91		0.6595		0.2431		0.8237	0.6309		tp=0.33, tn=0.29, fp=0.14, fn=0.24		False
	30	0.3722		0.8795		0.6511		0.1826		0.8161	0.6587		tp=0.38, tn=0.22, fp=0.22, fn=0.17		False
	31	0.3657		0.9092		0.6596		0.2565		0.8232	0.649		tp=0.34, tn=0.29, fp=0.18, fn=0.19		False
	32	0.4188		0.9301		0.6302		0.1769		0.8085	0.6463		tp=0.37, tn=0.22, fp=0.24, fn=0.17		False
	33	0.4002		0.9328		0.6395		0.1927		0.8093	0.6415		tp=0.36, tn=0.24, fp=0.2, fn=0.2		False
	34	0.3551		0.922		0.683		0.3549		0.8369	0.6571		tp=0.32, tn=0.34, fp=0.098, fn=0.24		True
	35	0.3366		0.8952		0.7217		0.2687		0.8532	0.6395		tp=0.33, tn=0.3, fp=0.14, fn=0.23		False
	36	0.3637		0.9603		0.6568		0.2055		0.8246	0.6069		tp=0.31, tn=0.29, fp=0.17, fn=0.22		False
	37	0.3535		1.025		0.6713		0.2951		0.8308	0.5574		tp=0.24, tn=0.38, fp=0.077, fn=0.3		False
	38	0.3642		0.9976		0.6836		0.3431		0.8328	0.6475		tp=0.31, tn=0.34, fp=0.098, fn=0.24		False
	39	0.3341		1.066		0.7124		0.324		0.852	0.6165		tp=0.29, tn=0.36, fp=0.091, fn=0.27		False
	40	0.3313		1.047		0.6919		0.246		0.8397	0.5926		tp=0.28, tn=0.34, fp=0.13, fn=0.25		False
	41	0.3249		1.042		0.7359		0.3425		0.8632	0.6423		tp=0.31, tn=0.35, fp=0.098, fn=0.24		False
	42	0.3148		1.021		0.7334		0.2906		0.8598	0.6577		tp=0.34, tn=0.3, fp=0.15, fn=0.21		False
	43	0.321		1.071		0.7182		0.3122		0.8545	0.6061		tp=0.28, tn=0.36, fp=0.091, fn=0.27		False
	44	0.3185		1.136		0.6977		0.1303		0.8432	0.6258		tp=0.36, tn=0.22, fp=0.22, fn=0.2		False
	45	0.4063		1.381		0.6186		0.1532		0.8048	0.4		tp=0.15, tn=0.38, fp=0.07, fn=0.39		False
	46	0.3997		1.125		0.6155		0.2515		0.8012	0.56		tp=0.24, tn=0.37, fp=0.11, fn=0.27		False
	47	0.3256		1.082		0.7396		0.2732		0.862	0.6029		tp=0.29, tn=0.34, fp=0.11, fn=0.27		False
	48	0.307		1.094		0.739		0.1769		0.8637	0.6463		tp=0.37, tn=0.22, fp=0.24, fn=0.17		False
	49	0.3501		1.152		0.6654		0.109		0.8267	0.6353		tp=0.38, tn=0.19, fp=0.26, fn=0.17		False
	50	0.3489		1.182		0.6715		0.1731		0.8277	0.6778		tp=0.43, tn=0.17, fp=0.29, fn=0.11		False
	51	0.3184		1.161		0.7156		0.1989		0.851	0.6275		tp=0.34, tn=0.27, fp=0.2, fn=0.2		False
	52	0.296		1.151		0.7594		0.285		0.875	0.6338		tp=0.31, tn=0.32, fp=0.13, fn=0.23		False
	53	0.2756		1.135		0.7594		0.3455		0.8754	0.6667		tp=0.34, tn=0.33, fp=0.11, fn=0.22		False
	54	0.2816		1.197		0.7594		0.2813		0.8754	0.5846		tp=0.27, tn=0.36, fp=0.098, fn=0.28		False
	55	0.2856		1.218		0.7626		0.3325		0.8756	0.6712		tp=0.34, tn=0.32, fp=0.14, fn=0.2		False


data			/scratch/asw462/data/levin
input size		300
hidden size		46
learning rate		0.00213423117049
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_54-lr0.0021-h_size46-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5927		0.608		0.002503		0		0.8367	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5853		0.5993		0		0		0.8421	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5829		0.6243		0		0		0.8426	0.8033		tp=0.67, tn=0, fp=0.33, fn=0		False
	4	0.5829		0.5909		0		-0.0523		0.8416	0.8327		tp=0.71, tn=0, fp=0.28, fn=0.007		False
	5	0.5834		0.638		0.0432		0		0.8426	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	6	0.5861		0.6203		0.04313		0		0.8422	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	7	0.585		0.6008		0.04282		-0.0532		0.8401	0.8279		tp=0.71, tn=0, fp=0.29, fn=0.007		False
	8	0.5836		0.609		0.04305		-0.05456		0.8415	0.8197		tp=0.69, tn=0, fp=0.3, fn=0.0069		False
	9	0.585		0.607		0.04289		-0.05412		0.8398	0.823		tp=0.7, tn=0, fp=0.29, fn=0.007		False
	10	0.5841		0.6324		0.0432		-0.05687		0.8424	0.8083		tp=0.68, tn=0, fp=0.31, fn=0.007		False
	11	0.5792		0.6141		0.04328		-0.05412		0.843	0.823		tp=0.7, tn=0, fp=0.29, fn=0.007		False
	12	0.5834		0.6084		0.04312		-0.05412		0.842	0.823		tp=0.7, tn=0, fp=0.29, fn=0.007		False
	13	0.5824		0.6223		0		-0.05687		0.8407	0.8083		tp=0.68, tn=0, fp=0.31, fn=0.007		False
	14	0.5825		0.6142		0.0432		-0.05595		0.8424	0.8133		tp=0.69, tn=0, fp=0.31, fn=0.007		False
	15	0.5849		0.6556		0.04305		-0.05872		0.8415	0.7983		tp=0.66, tn=0, fp=0.33, fn=0.007		False
	16	0.5806		0.6041		0.04313		-0.05276		0.8421	0.8293		tp=0.71, tn=0, fp=0.28, fn=0.0069		False
	17	0.5845		0.6021		0.06344		-0.0532		0.8419	0.8279		tp=0.71, tn=0, fp=0.29, fn=0.007		False
	18	0.5846		0.6069		0.06069		-0.0532		0.8409	0.8279		tp=0.71, tn=0, fp=0.29, fn=0.007		False
	19	0.5776		0.6384		0.06101		-0.05779		0.8424	0.8033		tp=0.67, tn=0, fp=0.32, fn=0.007		False
	20	0.5811		0.5992		0.01372		-0.0523		0.8359	0.8327		tp=0.71, tn=0, fp=0.28, fn=0.007		False
	21	0.5781		0.6079		0.04327		-0.05412		0.8429	0.823		tp=0.7, tn=0, fp=0.29, fn=0.007		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		70
learning rate		0.000653379597909
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_55-lr0.00065-h_size70-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6507		0.6162		0.2566		0.3654		0.6633	0.7156		tp=0.4, tn=0.28, fp=0.2, fn=0.12		True
	2	0.6397		0.6688		0.2931		0.3307		0.6771	0.4895		tp=0.18, tn=0.45, fp=0.036, fn=0.34		False
	3	0.6244		0.6306		0.3315		0.3114		0.6941	0.6582		tp=0.33, tn=0.32, fp=0.15, fn=0.2		False
	4	0.6113		0.6194		0.3492		0.3001		0.7004	0.7033		tp=0.41, tn=0.24, fp=0.22, fn=0.13		False
	5	0.5982		0.6326		0.3745		0.3154		0.7123	0.7202		tp=0.45, tn=0.2, fp=0.27, fn=0.074		False
	6	0.5996		0.6196		0.3592		0.3272		0.704	0.7277		tp=0.45, tn=0.22, fp=0.25, fn=0.087		False
	7	0.5913		0.6176		0.3671		0.298		0.7025	0.6715		tp=0.36, tn=0.29, fp=0.19, fn=0.16		False
	8	0.5772		0.6173		0.4045		0.2785		0.7233	0.686		tp=0.39, tn=0.25, fp=0.24, fn=0.13		False
	9	0.5687		0.6231		0.42		0.2969		0.7268	0.6935		tp=0.4, tn=0.25, fp=0.23, fn=0.12		False
	10	0.5592		0.6364		0.4053		0.2726		0.7206	0.6502		tp=0.34, tn=0.3, fp=0.18, fn=0.18		False
	11	0.5518		0.6462		0.4359		0.3107		0.7366	0.6324		tp=0.3, tn=0.35, fp=0.13, fn=0.22		False
	12	0.5505		0.6782		0.4501		0.3194		0.7409	0.5732		tp=0.24, tn=0.4, fp=0.079, fn=0.28		False
	13	0.5525		0.6297		0.4269		0.264		0.7304	0.6418		tp=0.33, tn=0.3, fp=0.17, fn=0.2		False
	14	0.5364		0.6386		0.4593		0.2589		0.7446	0.6636		tp=0.36, tn=0.27, fp=0.2, fn=0.16		False
	15	0.5399		0.6455		0.4511		0.2504		0.7423	0.6386		tp=0.33, tn=0.29, fp=0.18, fn=0.19		False
	16	0.5319		0.6619		0.458		0.2553		0.7423	0.6126		tp=0.3, tn=0.33, fp=0.15, fn=0.23		False
	17	0.5238		0.6775		0.4768		0.2712		0.7542	0.615		tp=0.29, tn=0.34, fp=0.14, fn=0.23		False
	18	0.5152		0.6647		0.4822		0.2437		0.7536	0.63		tp=0.32, tn=0.3, fp=0.17, fn=0.2		False
	19	0.5188		0.6432		0.4827		0.2497		0.7539	0.6507		tp=0.35, tn=0.28, fp=0.18, fn=0.19		False
	20	0.5177		0.682		0.4773		0.2539		0.7518	0.6971		tp=0.43, tn=0.2, fp=0.28, fn=0.097		False
	21	0.5193		0.7149		0.4842		0.2463		0.7562	0.5529		tp=0.24, tn=0.37, fp=0.11, fn=0.28		False
	22	0.5073		0.6972		0.5003		0.2799		0.7635	0.6263		tp=0.31, tn=0.33, fp=0.14, fn=0.22		False


data			/scratch/asw462/data/levin
input size		300
hidden size		58
learning rate		0.000870524260335
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_56-lr0.00087-h_size58-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5841		0.5718		0.05034		0.05394		0.8318	0.8264		tp=0.7, tn=0.007, fp=0.29, fn=0.007		True
	2	0.5195		0.5546		0.2947		0.2992		0.8521	0.8376		tp=0.69, tn=0.049, fp=0.26, fn=0.007		True
	3	0.472		0.541		0.3881		0.1902		0.8647	0.8178		tp=0.64, tn=0.07, fp=0.22, fn=0.07		False
	4	0.4355		0.535		0.4779		0.2789		0.878	0.8219		tp=0.62, tn=0.1, fp=0.19, fn=0.083		False
	5	0.4029		0.5424		0.5316		0.2978		0.8884	0.8186		tp=0.62, tn=0.11, fp=0.2, fn=0.077		False
	6	0.367		0.5062		0.5995		0.3028		0.9013	0.8326		tp=0.64, tn=0.098, fp=0.2, fn=0.063		True
	7	0.324		0.5564		0.6795		0.2233		0.9183	0.8178		tp=0.64, tn=0.07, fp=0.24, fn=0.049		False
	8	0.2799		0.4988		0.7289		0.491		0.9306	0.8664		tp=0.66, tn=0.14, fp=0.17, fn=0.035		True
	9	0.2627		0.5243		0.743		0.4475		0.9344	0.8476		tp=0.62, tn=0.15, fp=0.16, fn=0.063		False
	10	0.216		0.5532		0.8057		0.431		0.9492	0.8421		tp=0.62, tn=0.15, fp=0.16, fn=0.07		False
	11	0.2058		0.4897		0.8166		0.5179		0.9518	0.8641		tp=0.62, tn=0.18, fp=0.12, fn=0.077		True
	12	0.1713		0.5308		0.8742		0.5321		0.967	0.8818		tp=0.68, tn=0.14, fp=0.15, fn=0.028		True
	13	0.1754		0.5849		0.8483		0.5151		0.9597	0.841		tp=0.57, tn=0.22, fp=0.076, fn=0.14		False
	14	0.1365		0.5718		0.8956		0.463		0.9718	0.8611		tp=0.65, tn=0.14, fp=0.16, fn=0.049		False
	15	0.1238		0.5446		0.9224		0.549		0.9789	0.8657		tp=0.61, tn=0.2, fp=0.084, fn=0.1		True
	16	0.1152		0.5748		0.9309		0.4887		0.9813	0.8529		tp=0.61, tn=0.18, fp=0.12, fn=0.091		False
	17	0.0955		0.5824		0.9543		0.5005		0.9875	0.8651		tp=0.65, tn=0.15, fp=0.17, fn=0.035		False
	18	0.08757		0.5953		0.9521		0.5382		0.9871	0.8762		tp=0.64, tn=0.17, fp=0.11, fn=0.07		False
	19	0.07774		0.6474		0.9702		0.5107		0.9918	0.8651		tp=0.65, tn=0.15, fp=0.17, fn=0.028		False
	20	0.07141		0.5997		0.9682		0.4805		0.9914	0.8638		tp=0.64, tn=0.15, fp=0.14, fn=0.063		False
	21	0.06236		0.674		0.9683		0.5426		0.9913	0.867		tp=0.62, tn=0.2, fp=0.1, fn=0.084		False
	22	0.06553		0.7616		0.9719		0.4621		0.9923	0.8636		tp=0.66, tn=0.13, fp=0.17, fn=0.042		False
	23	0.05948		0.5326		0.9736		0.5359		0.9928	0.8762		tp=0.64, tn=0.17, fp=0.1, fn=0.077		False
	24	0.04804		0.7017		0.9806		0.5089		0.9947	0.8744		tp=0.66, tn=0.15, fp=0.13, fn=0.056		False
	25	0.04486		0.7613		0.9789		0.5381		0.9942	0.86		tp=0.6, tn=0.2, fp=0.12, fn=0.077		False
	26	0.04629		0.6794		0.9806		0.5728		0.9947	0.8879		tp=0.66, tn=0.17, fp=0.13, fn=0.042		True
	27	0.04896		0.6687		0.9772		0.6806		0.9937	0.9231		tp=0.71, tn=0.17, fp=0.098, fn=0.021		True
	28	0.04816		0.8209		0.9719		0.5332		0.9923	0.8696		tp=0.63, tn=0.18, fp=0.12, fn=0.07		False
	29	0.04319		0.8214		0.9789		0.5226		0.9942	0.8641		tp=0.62, tn=0.19, fp=0.097, fn=0.097		False
	30	0.04501		0.7552		0.9788		0.5903		0.9942	0.891		tp=0.66, tn=0.18, fp=0.1, fn=0.056		False
	31	0.05825		0.9095		0.9719		0.4683		0.9923	0.84		tp=0.59, tn=0.19, fp=0.1, fn=0.12		False
	32	0.05533		0.7653		0.9684		0.6284		0.9913	0.9083		tp=0.69, tn=0.17, fp=0.1, fn=0.035		False
	33	0.03826		0.9363		0.9807		0.5257		0.9947	0.8708		tp=0.64, tn=0.17, fp=0.12, fn=0.07		False
	34	0.04864		0.8069		0.9737		0.5816		0.9928	0.8756		tp=0.62, tn=0.21, fp=0.091, fn=0.084		False
	35	0.03784		1.038		0.9806		0.5531		0.9947	0.8657		tp=0.61, tn=0.2, fp=0.12, fn=0.07		False
	36	0.02854		0.6967		0.9911		0.6035		0.9976	0.8889		tp=0.64, tn=0.2, fp=0.1, fn=0.056		False
	37	0.02981		0.8595		0.9877		0.5942		0.9966	0.89		tp=0.65, tn=0.19, fp=0.098, fn=0.063		False
	38	0.02586		0.8625		0.9876		0.5593		0.9966	0.8959		tp=0.69, tn=0.15, fp=0.12, fn=0.042		False
	39	0.02603		1.085		0.9877		0.5367		0.9966	0.8696		tp=0.63, tn=0.18, fp=0.13, fn=0.063		False
	40	0.02509		1.105		0.9913		0.5117		0.9976	0.8778		tp=0.68, tn=0.13, fp=0.16, fn=0.028		False
	41	0.02752		0.7695		0.9929		0.6106		0.9981	0.8867		tp=0.63, tn=0.21, fp=0.091, fn=0.07		False
	42	0.02413		0.653		0.9878		0.6495		0.9966	0.8955		tp=0.63, tn=0.22, fp=0.084, fn=0.063		False
	43	0.02556		0.8852		0.9842		0.6105		0.9957	0.8972		tp=0.67, tn=0.17, fp=0.12, fn=0.035		False
	44	0.02438		0.9232		0.9913		0.4596		0.9976	0.8598		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	45	0.02489		1.007		0.9877		0.554		0.9966	0.8815		tp=0.65, tn=0.17, fp=0.11, fn=0.063		False
	46	0.02882		1.074		0.9895		0.5637		0.9971	0.8826		tp=0.65, tn=0.17, fp=0.12, fn=0.049		False
	47	0.02462		1.093		0.9912		0.5443		0.9976	0.8785		tp=0.65, tn=0.17, fp=0.13, fn=0.049		False
	48	0.02025		0.8787		0.9913		0.5968		0.9976	0.8824		tp=0.63, tn=0.2, fp=0.11, fn=0.056		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		105
learning rate		5.92142224757e&05
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_57-lr5.9e&05-h_size105-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6063		0.584		0.07832		0.158		0.8185	0.8106		tp=0.66, tn=0.037, fp=0.28, fn=0.024		True
	2	0.5735		0.5728		0.1993		0.2405		0.8234	0.8172		tp=0.64, tn=0.067, fp=0.25, fn=0.036		True
	3	0.5675		0.5642		0.2366		0.2919		0.8245	0.8236		tp=0.64, tn=0.086, fp=0.23, fn=0.041		True
	4	0.5637		0.5651		0.2468		0.2777		0.8252	0.8231		tp=0.64, tn=0.08, fp=0.24, fn=0.04		False
	5	0.5612		0.5727		0.2608		0.2502		0.826	0.8191		tp=0.65, tn=0.067, fp=0.25, fn=0.033		False
	6	0.5584		0.571		0.2631		0.2513		0.8266	0.8184		tp=0.64, tn=0.07, fp=0.25, fn=0.036		False
	7	0.5556		0.5665		0.2749		0.2993		0.83	0.8239		tp=0.63, tn=0.095, fp=0.22, fn=0.05		True
	8	0.5537		0.5698		0.2736		0.25		0.8281	0.821		tp=0.65, tn=0.068, fp=0.25, fn=0.036		False
	9	0.5515		0.5657		0.2789		0.2814		0.8296	0.8232		tp=0.64, tn=0.084, fp=0.23, fn=0.044		False
	10	0.5495		0.5619		0.287		0.286			0.83	0.8226		tp=0.64, tn=0.09, fp=0.22, fn=0.05		False
	11	0.5474		0.5617		0.2908		0.3166		0.8316	0.8233		tp=0.63, tn=0.1, fp=0.22, fn=0.05		True
	12	0.5449		0.5716		0.3013		0.2306		0.8328	0.8168		tp=0.65, tn=0.064, fp=0.25, fn=0.036		False
	13	0.5423		0.5739		0.3127		0.2549		0.8341	0.8184		tp=0.64, tn=0.07, fp=0.25, fn=0.034		False
	14	0.5414		0.5771		0.3144		0.2503		0.8342	0.8212		tp=0.65, tn=0.062, fp=0.26, fn=0.028		False
	15	0.5384		0.5686		0.3145		0.264		0.8355	0.8194		tp=0.64, tn=0.08, fp=0.24, fn=0.044		False
	16	0.536		0.5667		0.336		0.2935		0.8383	0.8234		tp=0.64, tn=0.092, fp=0.22, fn=0.049		False
	17	0.5342		0.5736		0.3211		0.3035		0.8348	0.8184		tp=0.62, tn=0.1, fp=0.22, fn=0.056		False
	18	0.5313		0.5656		0.3391		0.3003		0.8393	0.8236		tp=0.63, tn=0.1, fp=0.21, fn=0.059		False
	19	0.5302		0.5739		0.3458		0.2947		0.8399	0.8108		tp=0.6, tn=0.12, fp=0.21, fn=0.076		False
	20	0.5284		0.5736		0.3456		0.2941		0.8389	0.8186		tp=0.63, tn=0.098, fp=0.22, fn=0.053		False
	21	0.5257		0.5773		0.3492		0.2733		0.8408	0.8172		tp=0.63, tn=0.084, fp=0.24, fn=0.044		False
	22	0.5254		0.5744		0.3537		0.2941		0.8405	0.8186		tp=0.63, tn=0.098, fp=0.22, fn=0.053		False
	23	0.5228		0.5736		0.3534		0.2797		0.8396	0.8274		tp=0.65, tn=0.074, fp=0.24, fn=0.034		False
	24	0.5202		0.5738		0.3571		0.2797		0.8413	0.8125		tp=0.62, tn=0.099, fp=0.23, fn=0.059		False
	25	0.5184		0.5695		0.3615		0.2732		0.8415	0.8221		tp=0.64, tn=0.083, fp=0.23, fn=0.046		False
	26	0.5168		0.5719		0.372		0.288		0.8438	0.8215		tp=0.63, tn=0.092, fp=0.22, fn=0.05		False
	27	0.5137		0.5761		0.373		0.2949		0.8436	0.8183		tp=0.62, tn=0.099, fp=0.22, fn=0.055		False
	28	0.5134		0.5857		0.3737		0.2636		0.8435	0.8232		tp=0.65, tn=0.068, fp=0.25, fn=0.031		False
	29	0.5112		0.5801		0.3872		0.2599		0.8466	0.8164		tp=0.63, tn=0.083, fp=0.24, fn=0.049		False
	30	0.5099		0.5724		0.38		0.2792		0.8451	0.808		tp=0.6, tn=0.11, fp=0.2, fn=0.083		False
	31	0.5083		0.5695		0.3864		0.302		0.8453	0.8196		tp=0.62, tn=0.11, fp=0.21, fn=0.067		False
	32	0.5055		0.5812		0.3906		0.2502		0.8463	0.81		tp=0.62, tn=0.087, fp=0.24, fn=0.056		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		130
learning rate		0.000116390898595
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_58-lr0.00012-h_size130-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6162		0.6227		0.00801		0		0.8184	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6063		0.6142		0.00945		0.01482		0.8183	0.8078		tp=0.68, tn=0.003, fp=0.32, fn=0.0044		True
	3	0.602		0.6115		0.06914		0.09108		0.8187	0.8107		tp=0.67, tn=0.013, fp=0.31, fn=0.0089		True
	4	0.5995		0.6118		0.08371		0.1026		0.8187	0.809		tp=0.67, tn=0.016, fp=0.31, fn=0.01		True
	5	0.5972		0.609		0.08811		0.06951		0.8181	0.8089		tp=0.67, tn=0.012, fp=0.31, fn=0.01		False
	6	0.5939		0.608		0.1108		0.1056		0.8192	0.8108		tp=0.67, tn=0.018, fp=0.3, fn=0.012		True
	7	0.5927		0.6109		0.1187		0.1134		0.8194	0.8044		tp=0.65, tn=0.027, fp=0.3, fn=0.021		True
	8	0.5908		0.6047		0.1232		0.1395		0.8192	0.8087		tp=0.66, tn=0.031, fp=0.29, fn=0.021		True
	9	0.5883		0.6151		0.1388		0.1204		0.8208	0.8086		tp=0.67, tn=0.016, fp=0.31, fn=0.0074		False
	10	0.5874		0.6032		0.1373		0.1537		0.8202	0.8085		tp=0.65, tn=0.043, fp=0.28, fn=0.033		True
	11	0.586		0.5998		0.1365		0.14		0.8186	0.8151		tp=0.67, tn=0.027, fp=0.29, fn=0.016		False
	12	0.5846		0.5997		0.1462		0.1137		0.82	0.8105		tp=0.67, tn=0.024, fp=0.29, fn=0.018		False
	13	0.5825		0.601		0.152		0.1408		0.8205	0.8099		tp=0.66, tn=0.036, fp=0.28, fn=0.027		False
	14	0.5827		0.6003		0.1471		0.146		0.8187	0.8116		tp=0.66, tn=0.03, fp=0.29, fn=0.018		False
	15	0.5807		0.5949		0.1548		0.1795		0.8196	0.8192		tp=0.67, tn=0.033, fp=0.28, fn=0.015		True
	16	0.5788		0.5998		0.1582		0.1457		0.8201	0.8127		tp=0.67, tn=0.028, fp=0.29, fn=0.016		False
	17	0.5788		0.6008		0.1628		0.1408		0.8195	0.8099		tp=0.66, tn=0.036, fp=0.28, fn=0.027		False
	18	0.5777		0.6064		0.1595		0.168		0.8186	0.8052		tp=0.64, tn=0.043, fp=0.29, fn=0.027		False
	19	0.5768		0.5955		0.1662		0.1865		0.8182	0.8126		tp=0.65, tn=0.053, fp=0.26, fn=0.037		True
	20	0.5746		0.601		0.1741		0.1406		0.8207	0.8037		tp=0.65, tn=0.04, fp=0.28, fn=0.031		False
	21	0.5744		0.5987		0.17		0.1651		0.8186	0.8049		tp=0.64, tn=0.056, fp=0.26, fn=0.047		False
	22	0.5744		0.5976		0.1771		0.1722		0.8178	0.8107		tp=0.65, tn=0.046, fp=0.27, fn=0.031		False
	23	0.5734		0.5972		0.1785		0.1845		0.8195	0.809		tp=0.64, tn=0.062, fp=0.25, fn=0.05		False
	24	0.5716		0.6004		0.186		0.166		0.82	0.8089		tp=0.65, tn=0.046, fp=0.27, fn=0.033		False
	25	0.5714		0.6013		0.1972		0.2233		0.8214	0.8106		tp=0.63, tn=0.071, fp=0.25, fn=0.046		True
	26	0.5701		0.6024		0.1934		0.1753		0.8203	0.8096		tp=0.65, tn=0.046, fp=0.28, fn=0.03		False
	27	0.5692		0.5957		0.1849		0.1954		0.8194	0.8046		tp=0.62, tn=0.074, fp=0.24, fn=0.062		False
	28	0.5696		0.5962		0.1976		0.1708		0.8207	0.8071		tp=0.64, tn=0.056, fp=0.26, fn=0.046		False
	29	0.5678		0.5943		0.1946		0.1752		0.82	0.8089		tp=0.64, tn=0.05, fp=0.27, fn=0.036		False
	30	0.5674		0.6011		0.2071		0.1689		0.8217	0.8092		tp=0.65, tn=0.044, fp=0.28, fn=0.03		False
	31	0.5674		0.5975		0.2048		0.1907		0.8214	0.8053		tp=0.63, tn=0.064, fp=0.26, fn=0.047		False
	32	0.5661		0.5928		0.1969		0.195		0.8176	0.8138		tp=0.65, tn=0.056, fp=0.26, fn=0.039		False
	33	0.5661		0.5978		0.2141		0.1386		0.8209	0.812		tp=0.66, tn=0.033, fp=0.28, fn=0.024		False
	34	0.5656		0.5962		0.207		0.1693		0.8214	0.8157		tp=0.66, tn=0.039, fp=0.28, fn=0.024		False
	35	0.5644		0.5893		0.2183		0.2165		0.8221	0.8124		tp=0.64, tn=0.068, fp=0.25, fn=0.046		False
	36	0.5653		0.596		0.2057		0.1768		0.8207	0.8079		tp=0.64, tn=0.058, fp=0.26, fn=0.046		False
	37	0.5643		0.5957		0.2138		0.1843		0.8199	0.8129		tp=0.65, tn=0.047, fp=0.27, fn=0.03		False
	38	0.5629		0.5987		0.2173		0.1693		0.8221	0.8157		tp=0.66, tn=0.039, fp=0.28, fn=0.024		False
	39	0.5647		0.6031		0.207		0.1617		0.8187	0.7943		tp=0.61, tn=0.069, fp=0.25, fn=0.066		False
	40	0.5618		0.6019		0.2127		0.1621		0.8212	0.7962		tp=0.62, tn=0.068, fp=0.25, fn=0.065		False
	41	0.5611		0.5987		0.2321		0.1857		0.8227	0.8094		tp=0.64, tn=0.061, fp=0.25, fn=0.047		False
	42	0.5618		0.5968		0.2254		0.201		0.8221	0.8072		tp=0.63, tn=0.068, fp=0.25, fn=0.05		False
	43	0.5602		0.5996		0.2106		0.1728		0.8201	0.795		tp=0.61, tn=0.077, fp=0.24, fn=0.076		False
	44	0.5602		0.5941		0.2227		0.1721		0.8221	0.809		tp=0.64, tn=0.058, fp=0.25, fn=0.049		False
	45	0.5596		0.598		0.2242		0.1693		0.8216	0.8034		tp=0.63, tn=0.062, fp=0.25, fn=0.055		False
	46	0.5595		0.597		0.2369		0.1774		0.8228	0.8068		tp=0.64, tn=0.059, fp=0.26, fn=0.047		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		191
learning rate		9.69073401195e&05
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_59-lr9.7e&05-h_size191-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6933		0.6901		-0.02507		0.1101		0.4089	0.5075		tp=0.24, tn=0.3, fp=0.14, fn=0.32		True
	2	0.6875		0.6877		0.1757		0.1029		0.513	0.539		tp=0.27, tn=0.28, fp=0.17, fn=0.28		False
	3	0.6829		0.6862		0.2766		0.1234		0.6603	0.6076		tp=0.34, tn=0.23, fp=0.22, fn=0.21		True
	4	0.6784		0.6827		0.3157		0.177		0.6365	0.5986		tp=0.31, tn=0.28, fp=0.18, fn=0.23		True
	5	0.6733		0.6824		0.3284		0.1409		0.6587	0.5694		tp=0.29, tn=0.28, fp=0.17, fn=0.26		False
	6	0.6691		0.6776		0.3066		0.1707		0.5897	0.5547		tp=0.27, tn=0.31, fp=0.14, fn=0.29		False
	7	0.6639		0.6733		0.3364		0.2342		0.6458	0.6625		tp=0.37, tn=0.25, fp=0.2, fn=0.18		True
	8	0.659		0.6715		0.3663		0.2409		0.6766	0.6207		tp=0.31, tn=0.31, fp=0.16, fn=0.22		True
	9	0.6543		0.6718		0.3658		0.227		0.6697	0.6405		tp=0.34, tn=0.27, fp=0.19, fn=0.2		False
	10	0.649		0.6676		0.3855		0.2254		0.658	0.6056		tp=0.3, tn=0.31, fp=0.15, fn=0.24		False
	11	0.6441		0.6699		0.3923		0.2004		0.6791	0.6275		tp=0.34, tn=0.27, fp=0.18, fn=0.22		False
	12	0.6385		0.663		0.4143		0.2741		0.6785	0.6486		tp=0.34, tn=0.3, fp=0.16, fn=0.2		True
	13	0.633		0.6589		0.4319		0.3081		0.6891	0.6879		tp=0.38, tn=0.28, fp=0.17, fn=0.17		True
	14	0.6276		0.6513		0.4334		0.346		0.7044	0.6887		tp=0.36, tn=0.31, fp=0.13, fn=0.2		True
	15	0.6219		0.658		0.4247		0.2701		0.6947	0.6579		tp=0.35, tn=0.29, fp=0.17, fn=0.19		False
	16	0.6166		0.6575		0.4493		0.2568		0.7006	0.625		tp=0.31, tn=0.31, fp=0.14, fn=0.24		False
	17	0.6104		0.654		0.4505		0.2366		0.6958	0.6582		tp=0.36, tn=0.26, fp=0.18, fn=0.2		False
	18	0.6051		0.6481		0.4574		0.2412		0.7096	0.6494		tp=0.35, tn=0.27, fp=0.17, fn=0.2		False
	19	0.599		0.6411		0.4763		0.3151		0.7136	0.6711		tp=0.35, tn=0.31, fp=0.15, fn=0.19		False
	20	0.5928		0.6452		0.4746		0.2686		0.7292	0.6623		tp=0.36, tn=0.28, fp=0.19, fn=0.17		False
	21	0.5868		0.6373		0.4833		0.3002		0.7317	0.6711		tp=0.36, tn=0.29, fp=0.15, fn=0.2		False
	22	0.5817		0.6469		0.4952		0.2715		0.7196	0.6443		tp=0.34, tn=0.29, fp=0.13, fn=0.24		False
	23	0.5756		0.6414		0.4866		0.2451		0.727	0.64		tp=0.34, tn=0.29, fp=0.17, fn=0.21		False
	24	0.57		0.6373		0.5056		0.2758		0.7305	0.6486		tp=0.34, tn=0.3, fp=0.15, fn=0.21		False
	25	0.5634		0.6314		0.5333		0.2845		0.758	0.6623		tp=0.35, tn=0.29, fp=0.17, fn=0.18		False
	26	0.5572		0.6479		0.5284		0.2409		0.7465	0.6207		tp=0.31, tn=0.3, fp=0.15, fn=0.24		False
	27	0.5538		0.6394		0.5543		0.2557		0.7632	0.6536		tp=0.35, tn=0.28, fp=0.17, fn=0.2		False
	28	0.5462		0.6361		0.5643		0.3062		0.7639	0.6622		tp=0.34, tn=0.31, fp=0.14, fn=0.21		False
	29	0.5405		0.6412		0.5659		0.3021		0.7709	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	30	0.5348		0.635		0.5658		0.3194		0.7601	0.6667		tp=0.34, tn=0.31, fp=0.14, fn=0.2		False
	31	0.5288		0.6271		0.5746		0.2727		0.7759	0.6667		tp=0.36, tn=0.28, fp=0.18, fn=0.18		False
	32	0.5242		0.6369		0.5868		0.3021		0.78	0.6622		tp=0.34, tn=0.31, fp=0.15, fn=0.2		False
	33	0.5179		0.6244		0.5924		0.2777		0.7845	0.6792		tp=0.38, tn=0.27, fp=0.17, fn=0.18		False
	34	0.5127		0.6259		0.6082		0.3213		0.7886	0.6711		tp=0.35, tn=0.31, fp=0.13, fn=0.21		False
	35	0.5076		0.6171		0.5988		0.3373		0.7856	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.21		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		157
learning rate		0.000105192261148
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_5-lr0.00011-h_size157-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6913		0.6886		0.0508		0.08435		0.5974	0.5904		tp=0.33, tn=0.21, fp=0.28, fn=0.18		True
	2	0.6876		0.6867		0.08239		0.1201		0.5896	0.4793		tp=0.21, tn=0.34, fp=0.13, fn=0.32		True
	3	0.6844		0.6912		0.1225		0.1168		0.6124	0.2901		tp=0.097, tn=0.43, fp=0.049, fn=0.43		False
	4	0.6788		0.6811		0.1486		0.1388		0.5918	0.6719		tp=0.44, tn=0.13, fp=0.34, fn=0.087		True
	5	0.6763		0.6791		0.1761		0.1612		0.6084	0.5352		tp=0.24, tn=0.33, fp=0.16, fn=0.27		True
	6	0.6724		0.6781		0.1837		0.1618		0.601	0.6553		tp=0.39, tn=0.19, fp=0.28, fn=0.13		True
	7	0.669		0.6749		0.1938		0.1718		0.6224	0.6582		tp=0.4, tn=0.19, fp=0.28, fn=0.13		True
	8	0.6648		0.6746		0.2083		0.1937		0.6253	0.6123		tp=0.32, tn=0.28, fp=0.21, fn=0.2		True
	9	0.6611		0.678		0.2235		0.1437		0.6215	0.6706		tp=0.44, tn=0.13, fp=0.36, fn=0.074		False
	10	0.6578		0.6734		0.2214		0.1733		0.6268	0.6813		tp=0.44, tn=0.15, fp=0.31, fn=0.095		False
	11	0.6552		0.6701		0.2303		0.1799		0.6282	0.6376		tp=0.36, tn=0.24, fp=0.22, fn=0.18		False
	12	0.6501		0.669		0.2383		0.1804		0.6356	0.6359		tp=0.35, tn=0.24, fp=0.22, fn=0.19		False
	13	0.6478		0.6686		0.2548		0.1707		0.6431	0.6158		tp=0.33, tn=0.26, fp=0.22, fn=0.19		False
	14	0.6425		0.6748		0.2742		0.1711		0.6455	0.6158		tp=0.33, tn=0.26, fp=0.22, fn=0.19		False
	15	0.6406		0.6751		0.2608		0.1617		0.6469	0.5859		tp=0.3, tn=0.28, fp=0.2, fn=0.22		False
	16	0.6374		0.6738		0.2753		0.1676		0.6509	0.6368		tp=0.36, tn=0.22, fp=0.25, fn=0.16		False
	17	0.635		0.6671		0.285		0.1977		0.6527	0.642		tp=0.36, tn=0.25, fp=0.22, fn=0.18		True
	18	0.6337		0.6735		0.2671		0.1853		0.6497	0.6093		tp=0.32, tn=0.28, fp=0.2, fn=0.2		False
	19	0.6331		0.6744		0.2783		0.1955		0.648	0.6578		tp=0.38, tn=0.22, fp=0.24, fn=0.16		False
	20	0.6287		0.6722		0.2883		0.178		0.6568	0.6653		tp=0.4, tn=0.19, fp=0.27, fn=0.13		False
	21	0.6263		0.6825		0.2978		0.1472		0.6582	0.5931		tp=0.31, tn=0.26, fp=0.21, fn=0.22		False
	22	0.6277		0.6808		0.2951		0.1443		0.6577	0.5484		tp=0.26, tn=0.31, fp=0.17, fn=0.26		False
	23	0.6223		0.6811		0.3081		0.1803		0.6624	0.6172		tp=0.33, tn=0.26, fp=0.21, fn=0.2		False
	24	0.6207		0.6853		0.3161		0.1378		0.6695	0.5479		tp=0.26, tn=0.3, fp=0.17, fn=0.26		False
	25	0.6188		0.6835		0.3176		0.1793		0.6616	0.6064		tp=0.32, tn=0.27, fp=0.2, fn=0.21		False
	26	0.6157		0.6889		0.3303		0.156		0.6764	0.578		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	27	0.6158		0.6798		0.3162		0.1522		0.6645	0.5946		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	28	0.6136		0.6925		0.3234		0.1616		0.669	0.6337		tp=0.36, tn=0.22, fp=0.26, fn=0.15		False
	29	0.6133		0.6893		0.3227		0.1665		0.6748	0.6072		tp=0.32, tn=0.26, fp=0.24, fn=0.18		False
	30	0.611		0.7006		0.3285		0.1207		0.6739	0.5521		tp=0.27, tn=0.29, fp=0.19, fn=0.25		False
	31	0.6124		0.6817		0.3232		0.2022		0.6701	0.637		tp=0.35, tn=0.26, fp=0.22, fn=0.18		True
	32	0.6097		0.6928		0.3303		0.1729		0.6743	0.6139		tp=0.33, tn=0.26, fp=0.21, fn=0.2		False
	33	0.6109		0.7034		0.3322		0.1503		0.6721	0.6376		tp=0.37, tn=0.2, fp=0.29, fn=0.14		False
	34	0.6094		0.7006		0.3287		0.1414		0.6764	0.5736		tp=0.29, tn=0.28, fp=0.19, fn=0.24		False
	35	0.6069		0.6915		0.341		0.1627		0.6775	0.6091		tp=0.32, tn=0.26, fp=0.21, fn=0.2		False
	36	0.6046		0.6937		0.3469		0.1458		0.6816	0.6066		tp=0.33, tn=0.25, fp=0.22, fn=0.2		False
	37	0.6059		0.7144		0.3303		0.1118		0.6749	0.5707		tp=0.29, tn=0.26, fp=0.22, fn=0.22		False
	38	0.6135		0.6972		0.3221		0.1262		0.6733	0.5627		tp=0.28, tn=0.28, fp=0.2, fn=0.23		False
	39	0.6046		0.7099		0.3362		0.1176		0.6753	0.5728		tp=0.3, tn=0.26, fp=0.2, fn=0.24		False
	40	0.6059		0.7052		0.3364		0.1628		0.6727	0.6147		tp=0.33, tn=0.25, fp=0.23, fn=0.19		False
	41	0.6035		0.704		0.334		0.1529		0.6797	0.5906		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	42	0.6016		0.7066		0.3399		0.1585		0.6756	0.6253		tp=0.35, tn=0.23, fp=0.24, fn=0.17		False
	43	0.6027		0.6975		0.3393		0.1959		0.6824	0.6321		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	44	0.6028		0.7078		0.3463		0.1291		0.6816	0.6233		tp=0.36, tn=0.21, fp=0.26, fn=0.17		False
	45	0.6021		0.6979		0.3416		0.1867		0.6782	0.6274		tp=0.34, tn=0.25, fp=0.23, fn=0.18		False
	46	0.5988		0.7362		0.3588		0.1001		0.6906	0.4692		tp=0.2, tn=0.33, fp=0.14, fn=0.33		False
	47	0.5996		0.7037		0.3646		0.1787		0.6885	0.602		tp=0.31, tn=0.28, fp=0.2, fn=0.21		False
	48	0.5986		0.7131		0.3493		0.09871		0.683	0.5305		tp=0.26, tn=0.29, fp=0.19, fn=0.26		False
	49	0.6		0.7139		0.3505		0.145		0.6828	0.5976		tp=0.32, tn=0.26, fp=0.21, fn=0.21		False
	50	0.6005		0.7193		0.3393		0.1189		0.6809	0.5348		tp=0.26, tn=0.3, fp=0.17, fn=0.27		False
	51	0.5998		0.7073		0.3487		0.1507		0.6813	0.5744		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	52	0.597		0.7086		0.3516		0.1596		0.684	0.598		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		80
learning rate		0.00403438049991
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_60-lr0.004-h_size80-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6922		0.6373		0.1066		0.3061		0.5265	0.703		tp=0.41, tn=0.25, fp=0.21, fn=0.13		True
	2	0.6355		0.6155		0.2853		0.2577		0.6639	0.6829		tp=0.39, tn=0.24, fp=0.2, fn=0.17		False
	3	0.6107		0.6027		0.3266		0.3553		0.6637	0.7638		tp=0.53, tn=0.14, fp=0.3, fn=0.028		True
	4	0.581		0.5926		0.4136		0.3814		0.7024	0.765		tp=0.49, tn=0.21, fp=0.22, fn=0.077		True
	5	0.5964		0.6897		0.3682		0.2444		0.686	0.3043		tp=0.098, tn=0.45, fp=0.014, fn=0.43		False
	6	0.5338		0.572		0.4966		0.3838		0.7478	0.7456		tp=0.44, tn=0.26, fp=0.18, fn=0.12		True
	7	0.5318		0.6068		0.4551		0.3967		0.7257	0.7514		tp=0.48, tn=0.21, fp=0.27, fn=0.049		True
	8	0.4897		0.7883		0.5413		0.2101		0.7715	0.3654		tp=0.13, tn=0.41, fp=0.035, fn=0.43		False
	9	0.4512		0.6365		0.5745		0.4024		0.782	0.7571		tp=0.47, tn=0.23, fp=0.23, fn=0.07		True
	10	0.4484		0.7761		0.5599		0.2		0.7821	0.4324		tp=0.17, tn=0.39, fp=0.063, fn=0.38		False
	11	0.415		0.6685		0.6069		0.4127		0.7994	0.763		tp=0.46, tn=0.25, fp=0.19, fn=0.098		True
	12	0.3982		0.7021		0.6424		0.3178		0.8185	0.6755		tp=0.36, tn=0.3, fp=0.14, fn=0.2		False
	13	0.3614		0.9311		0.7073		0.1929		0.8521	0.3673		tp=0.13, tn=0.44, fp=0.049, fn=0.38		False
	14	0.4203		0.801		0.6049		0.2692		0.8012	0.5736		tp=0.26, tn=0.36, fp=0.098, fn=0.29		False
	15	0.3458		0.7405		0.7156		0.3934		0.851	0.6667		tp=0.31, tn=0.37, fp=0.091, fn=0.22		False
	16	0.3134		0.8618		0.716		0.3055		0.8563	0.6061		tp=0.28, tn=0.36, fp=0.098, fn=0.27		False
	17	0.2969		0.8038		0.7476		0.3397		0.8701	0.662		tp=0.33, tn=0.34, fp=0.13, fn=0.2		False
	18	0.2891		0.8196		0.7535		0.4144		0.8739	0.7162		tp=0.37, tn=0.34, fp=0.13, fn=0.17		True
	19	0.269		1.143		0.7688		0.218		0.883	0.4561		tp=0.18, tn=0.38, fp=0.063, fn=0.37		False
	20	0.2805		0.9304		0.7713		0.3099		0.8807	0.6839		tp=0.37, tn=0.29, fp=0.17, fn=0.17		False
	21	0.2848		1.182		0.7546		0.2086		0.8765	0.4505		tp=0.17, tn=0.4, fp=0.07, fn=0.36		False
	22	0.3988		0.9122		0.6156		0.3034		0.803	0.72		tp=0.44, tn=0.22, fp=0.24, fn=0.1		False
	23	0.4257		0.8944		0.5685		0.2794		0.7756	0.5556		tp=0.24, tn=0.36, fp=0.077, fn=0.31		False
	24	0.289		0.7317		0.7716		0.383		0.8843	0.6897		tp=0.35, tn=0.34, fp=0.12, fn=0.19		False
	25	0.2266		0.972		0.8685		0.3647		0.9333	0.6418		tp=0.3, tn=0.36, fp=0.084, fn=0.25		False
	26	0.2306		0.9605		0.8035		0.3114		0.8977	0.6839		tp=0.37, tn=0.29, fp=0.15, fn=0.19		False
	27	0.2199		1.084		0.8357		0.1847		0.9149	0.6667		tp=0.4, tn=0.2, fp=0.25, fn=0.15		False
	28	0.2327		1.267		0.7889		0.3464		0.8925	0.5854		tp=0.25, tn=0.39, fp=0.063, fn=0.29		False
	29	0.2499		1.097		0.7919		0.2959		0.8942	0.6795		tp=0.37, tn=0.28, fp=0.16, fn=0.19		False
	30	0.2015		1.2		0.8592		0.3673		0.9273	0.6016		tp=0.26, tn=0.4, fp=0.063, fn=0.28		False
	31	0.1907		1.084		0.8738		0.3249		0.9351	0.6883		tp=0.37, tn=0.29, fp=0.16, fn=0.17		False
	32	0.1734		1.158		0.8973		0.3312		0.9475	0.68		tp=0.36, tn=0.31, fp=0.14, fn=0.2		False
	33	0.2132		1.428		0.824		0.3273		0.9102	0.6061		tp=0.28, tn=0.36, fp=0.077, fn=0.29		False
	34	0.2156		1.423		0.8181		0.283		0.9069	0.5909		tp=0.27, tn=0.35, fp=0.098, fn=0.28		False
	35	0.1728		1.286		0.9032		0.3819		0.9499	0.6809		tp=0.34, tn=0.35, fp=0.11, fn=0.2		False
	36	0.1553		1.417		0.8975		0.3704		0.9478	0.6364		tp=0.29, tn=0.37, fp=0.077, fn=0.26		False
	37	0.1554		1.39		0.8945		0.2973		0.9463	0.6483		tp=0.33, tn=0.31, fp=0.13, fn=0.22		False
	38	0.1794		1.344		0.8713		0.2619		0.9325	0.679		tp=0.38, tn=0.25, fp=0.2, fn=0.16		False
	39	0.311		2.425		0.7333		0.155		0.8644	0.2273		tp=0.07, tn=0.45, fp=0.021, fn=0.45		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		114
learning rate		0.000189176747382
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_61-lr0.00019-h_size114-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.617		0.6266		0.04674		0		0.8175	0.8057		tp=0.67, tn=0, fp=0.33, fn=0		False
	2	0.5832		0.6212		0.1045		0.003323		0.8208	0.8053		tp=0.67, tn=0.0044, fp=0.32, fn=0.0089		True
	3	0.5568		0.6159		0.2076		0.1483		0.8261	0.8067		tp=0.64, tn=0.046, fp=0.27, fn=0.038		True
	4	0.5399		0.6241		0.2942		0.1365		0.8331	0.8019		tp=0.63, tn=0.052, fp=0.26, fn=0.052		False
	5	0.5079		0.6304		0.3704		0.1855		0.8442	0.7615		tp=0.54, tn=0.12, fp=0.19, fn=0.15		True
	6	0.491		0.6553		0.405		0.1282		0.8478	0.7924		tp=0.62, tn=0.056, fp=0.27, fn=0.059		False
	7	0.4682		0.6566		0.4622		0.1649		0.8585	0.7503		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	8	0.4489		0.6831		0.4837		0.1725		0.8616	0.7099		tp=0.46, tn=0.16, fp=0.16, fn=0.22		False
	9	0.4379		0.6798		0.5141		0.1392		0.8676	0.7528		tp=0.54, tn=0.11, fp=0.21, fn=0.14		False
	10	0.4168		0.7067		0.5523		0.1378		0.8768	0.7632		tp=0.56, tn=0.096, fp=0.23, fn=0.12		False
	11	0.3982		0.7168		0.5724		0.1432		0.8812	0.7567		tp=0.54, tn=0.11, fp=0.21, fn=0.14		False
	12	0.3993		0.7689		0.5682		0.1728		0.8788	0.7148		tp=0.47, tn=0.16, fp=0.17, fn=0.21		False
	13	0.3898		0.7739		0.5884		0.1724		0.8833	0.7375		tp=0.5, tn=0.14, fp=0.19, fn=0.17		False
	14	0.3718		0.7576		0.6076		0.188		0.888	0.7651		tp=0.55, tn=0.12, fp=0.2, fn=0.14		True
	15	0.3617		0.7999		0.6359		0.1756		0.896	0.7526		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	16	0.3552		0.8376		0.6367		0.1546		0.8953	0.7444		tp=0.52, tn=0.12, fp=0.2, fn=0.16		False
	17	0.3485		0.8464		0.6459		0.1308		0.8985	0.773		tp=0.58, tn=0.084, fp=0.23, fn=0.11		False
	18	0.3368		0.9076		0.6625		0.1766		0.9027	0.7071		tp=0.46, tn=0.16, fp=0.16, fn=0.22		False
	19	0.3289		0.8671		0.6767		0.1876		0.9062	0.7668		tp=0.55, tn=0.12, fp=0.2, fn=0.14		False
	20	0.3278		0.9119		0.6755		0.2189		0.9055	0.7386		tp=0.49, tn=0.16, fp=0.16, fn=0.19		True
	21	0.3237		0.954		0.6698		0.1688		0.904	0.7686		tp=0.56, tn=0.11, fp=0.21, fn=0.12		False
	22	0.3144		0.9962		0.6772		0.1251		0.9064	0.7739		tp=0.58, tn=0.081, fp=0.23, fn=0.11		False
	23	0.3023		0.969		0.7012		0.1778		0.9128	0.7338		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	24	0.3023		0.991		0.7034		0.1829		0.9131	0.7346		tp=0.5, tn=0.15, fp=0.17, fn=0.19		False
	25	0.2932		1.028		0.7207		0.1802		0.9178	0.768		tp=0.55, tn=0.11, fp=0.21, fn=0.12		False
	26	0.2963		1.054		0.7189		0.1735		0.9174	0.733		tp=0.5, tn=0.14, fp=0.18, fn=0.19		False
	27	0.2996		1.102		0.7062		0.1599		0.9135	0.7756		tp=0.57, tn=0.095, fp=0.22, fn=0.11		False
	28	0.2924		1.079		0.6975		0.1865		0.9115	0.7321		tp=0.49, tn=0.15, fp=0.17, fn=0.19		False
	29	0.2758		1.091		0.7309		0.2		0.9208	0.7639		tp=0.54, tn=0.13, fp=0.19, fn=0.15		False
	30	0.2832		1.127		0.7286		0.1684		0.919	0.7283		tp=0.49, tn=0.14, fp=0.18, fn=0.19		False
	31	0.2774		1.157		0.7298		0.1731		0.92	0.723		tp=0.48, tn=0.15, fp=0.16, fn=0.2		False
	32	0.2672		1.151		0.751		0.1929		0.9263	0.7357		tp=0.49, tn=0.15, fp=0.17, fn=0.18		False
	33	0.2764		1.227		0.7395		0.1782		0.9226	0.6977		tp=0.44, tn=0.17, fp=0.15, fn=0.23		False
	34	0.2633		1.219		0.7553		0.171		0.927	0.7127		tp=0.47, tn=0.16, fp=0.16, fn=0.21		False
	35	0.2533		1.215		0.7671		0.161		0.9306	0.7365		tp=0.51, tn=0.13, fp=0.18, fn=0.18		False
	36	0.2483		1.248		0.771		0.1637		0.9318	0.7179		tp=0.48, tn=0.15, fp=0.17, fn=0.21		False
	37	0.2484		1.257		0.7731		0.184		0.9325	0.7301		tp=0.49, tn=0.15, fp=0.17, fn=0.19		False
	38	0.2415		1.326		0.7848		0.1736		0.9358	0.7106		tp=0.46, tn=0.16, fp=0.16, fn=0.22		False
	39	0.2577		1.294		0.7489		0.1646		0.9253	0.7281		tp=0.49, tn=0.14, fp=0.18, fn=0.19		False
	40	0.2456		1.343		0.7761		0.1787		0.9329	0.7021		tp=0.45, tn=0.17, fp=0.15, fn=0.23		False
	41	0.2505		1.334		0.7674		0.1702		0.9308	0.7381		tp=0.51, tn=0.14, fp=0.19, fn=0.17		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		54
learning rate		0.00262504824839
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_62-lr0.0026-h_size54-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6159		0.6249		0.03206		0		0.8183	0.8067		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5953		0.6143		0.1159		0.09937		0.8182	0.8036		tp=0.65, tn=0.025, fp=0.3, fn=0.022		True
	3	0.5828		0.6266		0.1707		0.1255		0.8173	0.8167		tp=0.68, tn=0.015, fp=0.3, fn=0.0059		True
	4	0.5689		0.6107		0.2376		0.1355		0.8218	0.8044		tp=0.64, tn=0.041, fp=0.28, fn=0.036		True
	5	0.5613		0.6193		0.2367		0.2036		0.8201	0.7593		tp=0.53, tn=0.13, fp=0.19, fn=0.15		True
	6	0.5552		0.607		0.256		0.208		0.8221	0.7925		tp=0.59, tn=0.096, fp=0.22, fn=0.087		True
	7	0.5459		0.6065		0.3053		0.2122		0.8304	0.8113		tp=0.64, tn=0.062, fp=0.26, fn=0.039		True
	8	0.5414		0.6293		0.2983		0.2005		0.8278	0.8165		tp=0.66, tn=0.046, fp=0.27, fn=0.024		False
	9	0.5334		0.6195		0.3215		0.1561		0.8306	0.742		tp=0.52, tn=0.13, fp=0.2, fn=0.16		False
	10	0.529		0.6001		0.3262		0.2304		0.8307	0.8088		tp=0.62, tn=0.08, fp=0.24, fn=0.055		True
	11	0.516		0.6076		0.3588		0.1934		0.8387	0.791		tp=0.6, tn=0.09, fp=0.23, fn=0.084		False
	12	0.5079		0.6229		0.373		0.2282		0.841	0.8118		tp=0.63, tn=0.074, fp=0.24, fn=0.049		False
	13	0.4923		0.6203		0.4084		0.2035		0.8473	0.8038		tp=0.62, tn=0.079, fp=0.24, fn=0.065		False
	14	0.4861		0.6346		0.4126		0.1853		0.8473	0.7756		tp=0.57, tn=0.11, fp=0.21, fn=0.12		False
	15	0.4725		0.6413		0.456		0.2197		0.8572	0.8095		tp=0.63, tn=0.074, fp=0.24, fn=0.052		False
	16	0.4579		0.6449		0.4717		0.2044		0.8604	0.7945		tp=0.6, tn=0.092, fp=0.23, fn=0.083		False
	17	0.4448		0.6356		0.4942		0.2321		0.8642	0.8039		tp=0.61, tn=0.089, fp=0.23, fn=0.065		True
	18	0.4247		0.6404		0.5481		0.2163		0.877	0.7932		tp=0.59, tn=0.1, fp=0.22, fn=0.092		False
	19	0.4084		0.6408		0.5564		0.209		0.8784	0.7913		tp=0.59, tn=0.1, fp=0.21, fn=0.096		False
	20	0.3915		0.6748		0.5764		0.1774		0.883	0.7375		tp=0.5, tn=0.14, fp=0.18, fn=0.18		False
	21	0.3741		0.6706		0.606		0.2132		0.8895	0.783		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	22	0.3541		0.7109		0.6385		0.2114		0.8979	0.7925		tp=0.59, tn=0.099, fp=0.22, fn=0.092		False
	23	0.3354		0.6866		0.6586		0.2045		0.9032	0.7822		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	24	0.3204		0.7118		0.6872		0.2353		0.9101	0.7972		tp=0.59, tn=0.1, fp=0.22, fn=0.086		True
	25	0.2954		0.7298		0.7347		0.2461		0.9232	0.7952		tp=0.59, tn=0.11, fp=0.21, fn=0.088		True
	26	0.2753		0.7282		0.7601		0.2501		0.9302	0.7915		tp=0.58, tn=0.12, fp=0.2, fn=0.1		True
	27	0.2622		0.7446		0.7672		0.2334		0.9319	0.7814		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	28	0.2369		0.7744		0.8036		0.229		0.9419	0.7874		tp=0.58, tn=0.11, fp=0.21, fn=0.1		False
	29	0.2207		0.7928		0.8304		0.2404		0.9497	0.7694		tp=0.54, tn=0.14, fp=0.18, fn=0.15		False
	30	0.2106		0.8307		0.8336		0.2535		0.9504	0.7931		tp=0.58, tn=0.12, fp=0.2, fn=0.1		True
	31	0.191		0.8581		0.8709		0.2106		0.9613	0.79		tp=0.59, tn=0.1, fp=0.22, fn=0.096		False
	32	0.1758		0.9013		0.8827		0.2064		0.9647	0.79		tp=0.59, tn=0.099, fp=0.22, fn=0.093		False
	33	0.1626		0.8711		0.8933		0.2552		0.9678	0.7764		tp=0.54, tn=0.14, fp=0.18, fn=0.13		True
	34	0.1495		0.8786		0.9087		0.2526		0.9724	0.7759		tp=0.54, tn=0.14, fp=0.17, fn=0.14		False
	35	0.1352		0.9296		0.9349		0.2312		0.9802	0.7618		tp=0.53, tn=0.15, fp=0.17, fn=0.16		False
	36	0.1234		0.9365		0.941		0.2704		0.9821	0.7814		tp=0.55, tn=0.15, fp=0.17, fn=0.13		True
	37	0.115		0.9762		0.9484		0.2502		0.9843	0.7733		tp=0.54, tn=0.14, fp=0.17, fn=0.14		False
	38	0.107		0.9557		0.9536		0.2871		0.9859	0.7675		tp=0.52, tn=0.17, fp=0.14, fn=0.17		True
	39	0.09899		1.014		0.9567		0.2344		0.9868	0.765		tp=0.53, tn=0.14, fp=0.17, fn=0.15		False
	40	0.09		1.02		0.9693		0.2537		0.9906	0.7777		tp=0.55, tn=0.14, fp=0.17, fn=0.14		False
	41	0.08345		1.042		0.9728		0.2957		0.9916	0.7682		tp=0.52, tn=0.17, fp=0.15, fn=0.16		True
	42	0.08051		1.07		0.9728		0.2797		0.9916	0.7768		tp=0.54, tn=0.16, fp=0.16, fn=0.15		False
	43	0.07265		1.132		0.9758		0.2521		0.9926	0.7873		tp=0.57, tn=0.13, fp=0.2, fn=0.11		False
	44	0.06869		1.118		0.978		0.2466		0.9932	0.7656		tp=0.53, tn=0.15, fp=0.16, fn=0.16		False
	45	0.06467		1.147		0.9754		0.2593		0.9924	0.7829		tp=0.56, tn=0.14, fp=0.19, fn=0.12		False
	46	0.06147		1.173		0.9788		0.258		0.9935	0.7686		tp=0.53, tn=0.15, fp=0.16, fn=0.15		False
	47	0.06051		1.216		0.9784		0.2261		0.9934	0.7697		tp=0.54, tn=0.13, fp=0.19, fn=0.13		False
	48	0.05686		1.237		0.9806		0.2385		0.994	0.7801		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	49	0.05257		1.239		0.984		0.2725		0.9951	0.7769		tp=0.54, tn=0.15, fp=0.17, fn=0.14		False
	50	0.05287		1.255		0.9802		0.2376		0.9939	0.7762		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	51	0.05022		1.277		0.984		0.2894		0.9951	0.7749		tp=0.53, tn=0.16, fp=0.16, fn=0.14		False
	52	0.04851		1.294		0.9853		0.2539		0.9955	0.7751		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	53	0.045		1.307		0.9875		0.234		0.9962	0.7673		tp=0.53, tn=0.14, fp=0.18, fn=0.14		False
	54	0.04458		1.358		0.9836		0.2406		0.995	0.7717		tp=0.54, tn=0.14, fp=0.18, fn=0.14		False
	55	0.04573		1.432		0.9827		0.2155		0.9947	0.7787		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	56	0.0441		1.394		0.9862		0.2171		0.9958	0.7795		tp=0.56, tn=0.12, fp=0.19, fn=0.12		False
	57	0.04446		1.385		0.9831		0.2695		0.9948	0.7716		tp=0.53, tn=0.16, fp=0.16, fn=0.15		False
	58	0.04051		1.437		0.9857		0.2269		0.9956	0.7737		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	59	0.04055		1.42		0.9857		0.2625		0.9956	0.778		tp=0.54, tn=0.14, fp=0.17, fn=0.14		False
	60	0.03857		1.383		0.9836		0.288		0.995	0.7772		tp=0.53, tn=0.16, fp=0.16, fn=0.15		False
	61	0.0387		1.518		0.9844		0.2334		0.9952	0.7806		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	62	0.03885		1.528		0.9853		0.2267		0.9955	0.7759		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False


data			/scratch/asw462/data/levin
input size		300
hidden size		65
learning rate		0.00015085591907
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_63-lr0.00015-h_size65-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6022		0.6013		-0.02538		0		0.8242	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5706		0.5805		0		0		0.8441	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	3	0.5678		0.572		0.05668		-0.05139		0.8402	0.8374		tp=0.72, tn=0, fp=0.27, fn=0.007		False
	4	0.5531		0.6045		0.1288		0.1989		0.8469	0.822		tp=0.68, tn=0.028, fp=0.29, fn=0.007		True
	5	0.5489		0.5805		0.1265		0.08325		0.8466	0.8347		tp=0.71, tn=0.014, fp=0.27, fn=0.014		False
	6	0.5449		0.5717		0.1433		0.2392		0.8445	0.8354		tp=0.69, tn=0.042, fp=0.26, fn=0.014		True
	7	0.5476		0.5681		0.1823		0.1873		0.8432	0.8403		tp=0.7, tn=0.035, fp=0.24, fn=0.021		False
	8	0.5384		0.5849		0.1759		0.1894		0.8459	0.8174		tp=0.65, tn=0.056, fp=0.25, fn=0.042		False
	9	0.5407		0.5804		0.2151		0.1382		0.846	0.8205		tp=0.67, tn=0.042, fp=0.25, fn=0.042		False
	10	0.5364		0.5812		0.2578		0.202		0.8512	0.8276		tp=0.67, tn=0.056, fp=0.24, fn=0.042		False
	11	0.5318		0.5682		0.2715		0.1485		0.8511	0.8291		tp=0.68, tn=0.042, fp=0.24, fn=0.042		False
	12	0.5265		0.5668		0.2568		0.2422		0.8517	0.8161		tp=0.64, tn=0.077, fp=0.24, fn=0.049		True
	13	0.5259		0.6075		0.3082		0.2883		0.8554	0.8161		tp=0.64, tn=0.077, fp=0.26, fn=0.028		True
	14	0.5188		0.5541		0.2719		0.2802		0.8538	0.8421		tp=0.67, tn=0.077, fp=0.2, fn=0.049		False
	15	0.5184		0.5694		0.2872		0.2451		0.8526	0.8267		tp=0.65, tn=0.077, fp=0.22, fn=0.056		False
	16	0.5138		0.5946		0.3015		0.2417		0.8557	0.8108		tp=0.62, tn=0.083, fp=0.24, fn=0.056		False
	17	0.5115		0.5842		0.2939		0.2543		0.8524	0.8412		tp=0.69, tn=0.056, fp=0.23, fn=0.028		False
	18	0.5085		0.5827		0.3134		0.1952		0.856	0.7982		tp=0.61, tn=0.084, fp=0.23, fn=0.077		False
	19	0.5042		0.557		0.3227		0.2275		0.8588	0.8198		tp=0.64, tn=0.084, fp=0.2, fn=0.077		False
	20	0.4992		0.581		0.3484		0.2283		0.8625	0.8018		tp=0.61, tn=0.091, fp=0.23, fn=0.07		False
	21	0.5021		0.5139		0.321		0.3688		0.8563	0.8739		tp=0.73, tn=0.063, fp=0.2, fn=0.014		True
	22	0.4999		0.5902		0.3178		0.2629		0.8574	0.8214		tp=0.64, tn=0.077, fp=0.24, fn=0.042		False
	23	0.4952		0.5903		0.3371		0.203		0.8611	0.8037		tp=0.62, tn=0.084, fp=0.22, fn=0.077		False
	24	0.4923		0.5617		0.3582		0.2927		0.8616	0.8421		tp=0.67, tn=0.077, fp=0.21, fn=0.042		False
	25	0.4861		0.56		0.3413		0.2719		0.8625	0.8182		tp=0.63, tn=0.091, fp=0.22, fn=0.056		False
	26	0.4835		0.5505		0.3754		0.2612		0.8645	0.8304		tp=0.65, tn=0.084, fp=0.2, fn=0.063		False
	27	0.4792		0.5519		0.3757		0.3304		0.8647	0.8472		tp=0.68, tn=0.077, fp=0.22, fn=0.028		False
	28	0.4777		0.5671		0.406		0.2443		0.8699	0.8128		tp=0.62, tn=0.091, fp=0.22, fn=0.07		False
	29	0.4741		0.533		0.4035		0.2256		0.8694	0.8267		tp=0.65, tn=0.077, fp=0.2, fn=0.07		False
	30	0.4706		0.543		0.4144		0.229		0.8711	0.8161		tp=0.63, tn=0.083, fp=0.22, fn=0.069		False
	31	0.4712		0.5509		0.3952		0.2026		0.8673	0.8178		tp=0.64, tn=0.076, fp=0.21, fn=0.076		False
	32	0.4595		0.521		0.4239		0.2782		0.8742	0.8288		tp=0.64, tn=0.091, fp=0.2, fn=0.063		False
	33	0.4615		0.5628		0.4016		0.2096		0.8693	0.8161		tp=0.64, tn=0.077, fp=0.22, fn=0.07		False
	34	0.4559		0.529		0.4209		0.2611		0.8732	0.8356		tp=0.66, tn=0.084, fp=0.19, fn=0.07		False
	35	0.4589		0.5732		0.4184		0.1792		0.8713	0.7926		tp=0.6, tn=0.084, fp=0.23, fn=0.084		False
	36	0.4562		0.5634		0.4341		0.1888		0.8722	0.8		tp=0.61, tn=0.083, fp=0.22, fn=0.083		False
	37	0.4482		0.5366		0.4532		0.288		0.8767	0.8288		tp=0.64, tn=0.091, fp=0.21, fn=0.056		False
	38	0.4536		0.5403		0.4408		0.2603		0.8745	0.8165		tp=0.62, tn=0.098, fp=0.2, fn=0.077		False
	39	0.4446		0.5362		0.4363		0.3188		0.8744	0.8458		tp=0.67, tn=0.084, fp=0.2, fn=0.042		False
	40	0.4415		0.5462		0.4614		0.2813		0.8781	0.8398		tp=0.67, tn=0.069, fp=0.22, fn=0.035		False
	41	0.4419		0.5374		0.4584		0.2235		0.8767	0.8056		tp=0.61, tn=0.098, fp=0.2, fn=0.098		False
	42	0.437		0.5534		0.4733		0.2244		0.8796	0.8326		tp=0.67, tn=0.056, fp=0.24, fn=0.035		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		33
learning rate		0.000294074324314
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_64-lr0.00029-h_size33-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6219		0.6357		0		0		0.8182	0.8064		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6112		0.6232		0		0		0.8181	0.812		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.6041		0.6227		0.02034		0.05615		0.8183	0.8102		tp=0.68, tn=0.0015, fp=0.32, fn=0		True
	4	0.5974		0.6186		0.04841		0.07974		0.819	0.812		tp=0.68, tn=0.003, fp=0.32, fn=0		True
	5	0.5899		0.6136		0.07539		0.09005		0.819	0.8145		tp=0.68, tn=0.0059, fp=0.31, fn=0.0015		True
	6	0.5827		0.6173		0.124		0.05152		0.8213	0.8085		tp=0.68, tn=0.0044, fp=0.32, fn=0.003		False
	7	0.5772		0.6135		0.1468		0.08739		0.8221	0.8107		tp=0.67, tn=0.01, fp=0.31, fn=0.0059		False
	8	0.5722		0.6102		0.1923		0.1208		0.825	0.808		tp=0.66, tn=0.03, fp=0.29, fn=0.024		True
	9	0.5662		0.6101		0.2146		0.1402		0.8261	0.8044		tp=0.64, tn=0.044, fp=0.27, fn=0.039		True
	10	0.5623		0.612		0.2352		0.1601		0.8268	0.8034		tp=0.64, tn=0.049, fp=0.28, fn=0.037		True
	11	0.5603		0.606		0.2372		0.1375		0.8266	0.8106		tp=0.66, tn=0.033, fp=0.28, fn=0.024		False
	12	0.5557		0.6034		0.2552		0.1703		0.8283	0.7989		tp=0.62, tn=0.071, fp=0.24, fn=0.068		True
	13	0.5544		0.6226		0.2622		0.1453		0.8274	0.8073		tp=0.65, tn=0.033, fp=0.29, fn=0.021		False
	14	0.5519		0.6084		0.2737		0.1377		0.8281	0.8066		tp=0.65, tn=0.041, fp=0.28, fn=0.036		False
	15	0.5489		0.6101		0.2744		0.1732		0.8288	0.803		tp=0.63, tn=0.059, fp=0.26, fn=0.047		True
	16	0.5472		0.6103		0.2696		0.1864		0.8259	0.8008		tp=0.62, tn=0.073, fp=0.25, fn=0.062		True
	17	0.5471		0.6061		0.2873		0.2118		0.8284	0.7937		tp=0.59, tn=0.099, fp=0.21, fn=0.093		True
	18	0.5456		0.6188		0.2911		0.1353		0.8286	0.8041		tp=0.64, tn=0.041, fp=0.28, fn=0.036		False
	19	0.5451		0.6124		0.3048		0.1678		0.8313	0.8089		tp=0.64, tn=0.05, fp=0.27, fn=0.038		False
	20	0.544		0.6178		0.2979		0.1989		0.8291	0.8134		tp=0.65, tn=0.053, fp=0.27, fn=0.033		False
	21	0.5419		0.6144		0.3024		0.1917		0.83	0.8123		tp=0.64, tn=0.058, fp=0.26, fn=0.041		False
	22	0.5409		0.6132		0.3017		0.1783		0.8293	0.795		tp=0.61, tn=0.075, fp=0.25, fn=0.068		False
	23	0.5412		0.6118		0.301		0.175		0.8297	0.8008		tp=0.62, tn=0.068, fp=0.25, fn=0.061		False
	24	0.5404		0.625		0.3058		0.1787		0.8293	0.8068		tp=0.64, tn=0.058, fp=0.26, fn=0.044		False
	25	0.5389		0.6192		0.3102		0.2117		0.8296	0.7796		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	26	0.5402		0.6158		0.3129		0.1748		0.8306	0.7969		tp=0.62, tn=0.07, fp=0.25, fn=0.061		False
	27	0.5407		0.6243		0.3081		0.1771		0.8292	0.8008		tp=0.63, tn=0.062, fp=0.26, fn=0.049		False
	28	0.5369		0.6052		0.3177		0.2138		0.8318	0.8023		tp=0.61, tn=0.086, fp=0.23, fn=0.071		True
	29	0.5382		0.6129		0.311		0.189		0.8297	0.7977		tp=0.61, tn=0.08, fp=0.24, fn=0.073		False
	30	0.5378		0.6121		0.3245		0.201		0.8317	0.7969		tp=0.6, tn=0.087, fp=0.23, fn=0.079		False
	31	0.5366		0.6226		0.3243		0.1983		0.8322	0.8094		tp=0.64, tn=0.061, fp=0.26, fn=0.041		False
	32	0.5369		0.6152		0.3184		0.1842		0.831	0.7992		tp=0.62, tn=0.074, fp=0.24, fn=0.065		False
	33	0.5371		0.6144		0.313		0.1826		0.8291	0.7981		tp=0.61, tn=0.075, fp=0.24, fn=0.068		False
	34	0.536		0.6139		0.328		0.1977		0.832	0.8131		tp=0.64, tn=0.059, fp=0.25, fn=0.041		False
	35	0.5357		0.6212		0.3147		0.1699		0.8292	0.7981		tp=0.62, tn=0.065, fp=0.26, fn=0.056		False
	36	0.5353		0.6227		0.3231		0.1625		0.8319	0.7946		tp=0.61, tn=0.07, fp=0.25, fn=0.067		False
	37	0.5359		0.6126		0.3245		0.168		0.8315	0.7934		tp=0.61, tn=0.074, fp=0.25, fn=0.071		False
	38	0.535		0.6203		0.3205		0.1539		0.8316	0.7888		tp=0.6, tn=0.074, fp=0.25, fn=0.077		False
	39	0.5359		0.6082		0.3167		0.1921		0.8305	0.7856		tp=0.58, tn=0.098, fp=0.22, fn=0.098		False
	40	0.5346		0.6136		0.3194		0.1881		0.8302	0.7988		tp=0.61, tn=0.076, fp=0.24, fn=0.065		False
	41	0.5349		0.6349		0.3261		0.2187		0.8321	0.8156		tp=0.65, tn=0.055, fp=0.27, fn=0.028		True
	42	0.5346		0.6248		0.3236		0.1818		0.8318	0.8079		tp=0.64, tn=0.059, fp=0.26, fn=0.046		False
	43	0.5351		0.618		0.3224		0.1619		0.8308	0.7923		tp=0.61, tn=0.07, fp=0.25, fn=0.065		False
	44	0.5342		0.6155		0.3271		0.1768		0.832	0.7969		tp=0.61, tn=0.074, fp=0.24, fn=0.068		False
	45	0.5343		0.6021		0.3295		0.215		0.8313	0.8		tp=0.61, tn=0.09, fp=0.23, fn=0.077		False
	46	0.5337		0.6176		0.3247		0.1997		0.832	0.8064		tp=0.63, tn=0.065, fp=0.26, fn=0.046		False
	47	0.5336		0.6196		0.3204		0.1721		0.8304	0.7915		tp=0.6, tn=0.077, fp=0.25, fn=0.073		False
	48	0.5332		0.62		0.3285		0.1795		0.8314	0.7922		tp=0.6, tn=0.079, fp=0.25, fn=0.071		False
	49	0.5356		0.6076		0.3211		0.182		0.8293	0.7945		tp=0.6, tn=0.083, fp=0.23, fn=0.081		False
	50	0.5324		0.6156		0.3274		0.1914		0.8323	0.7981		tp=0.61, tn=0.079, fp=0.24, fn=0.068		False
	51	0.5331		0.6211		0.3256		0.1783		0.8311	0.7946		tp=0.61, tn=0.074, fp=0.25, fn=0.065		False
	52	0.5321		0.611		0.3268		0.2179		0.8318	0.7838		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	53	0.5323		0.6094		0.3299		0.1789		0.8312	0.789		tp=0.59, tn=0.089, fp=0.23, fn=0.092		False
	54	0.5312		0.627		0.3297		0.1823		0.8321	0.8034		tp=0.63, tn=0.064, fp=0.26, fn=0.05		False
	55	0.5308		0.6213		0.3311		0.1782		0.8328	0.7989		tp=0.62, tn=0.067, fp=0.26, fn=0.055		False
	56	0.5303		0.6108		0.3381		0.1957		0.8351	0.8		tp=0.61, tn=0.078, fp=0.24, fn=0.066		False
	57	0.5291		0.6246		0.3456		0.1597		0.836	0.7962		tp=0.62, tn=0.065, fp=0.26, fn=0.061		False
	58	0.5281		0.6205		0.3334		0.1767		0.833	0.8015		tp=0.63, tn=0.065, fp=0.25, fn=0.055		False
	59	0.5295		0.6145		0.3373		0.186		0.8338	0.8038		tp=0.63, tn=0.07, fp=0.25, fn=0.059		False
	60	0.5289		0.6187		0.3353		0.1783		0.8335	0.8011		tp=0.62, tn=0.067, fp=0.25, fn=0.056		False
	61	0.528		0.6187		0.3268		0.1775		0.8318	0.7862		tp=0.59, tn=0.087, fp=0.24, fn=0.086		False
	62	0.5288		0.6228		0.3348		0.2264		0.8335	0.8183		tp=0.65, tn=0.061, fp=0.25, fn=0.034		True
	63	0.5272		0.6225		0.335		0.1564		0.8339	0.7876		tp=0.6, tn=0.074, fp=0.25, fn=0.074		False
	64	0.5267		0.6187		0.3386		0.2445		0.8328	0.8166		tp=0.64, tn=0.068, fp=0.25, fn=0.036		True
	65	0.5273		0.6093		0.3217		0.1772		0.8305	0.7918		tp=0.6, tn=0.08, fp=0.24, fn=0.076		False
	66	0.5251		0.613		0.3395		0.195		0.8338	0.8008		tp=0.62, tn=0.077, fp=0.24, fn=0.065		False
	67	0.526		0.614		0.3411		0.1934		0.834	0.7897		tp=0.59, tn=0.093, fp=0.22, fn=0.09		False
	68	0.5245		0.6072		0.339		0.2009		0.8337	0.8084		tp=0.63, tn=0.074, fp=0.24, fn=0.062		False
	69	0.5255		0.614		0.3296		0.1942		0.8312	0.8015		tp=0.62, tn=0.074, fp=0.25, fn=0.061		False
	70	0.5255		0.6181		0.3502		0.1517		0.8363	0.7899		tp=0.6, tn=0.074, fp=0.24, fn=0.08		False
	71	0.5229		0.6126		0.3486		0.1805		0.8354	0.7981		tp=0.61, tn=0.075, fp=0.24, fn=0.07		False
	72	0.5237		0.6177		0.3512		0.1761		0.8356	0.793		tp=0.61, tn=0.078, fp=0.24, fn=0.074		False
	73	0.5219		0.6066		0.3491		0.215		0.8355	0.8103		tp=0.63, tn=0.076, fp=0.24, fn=0.058		False
	74	0.5206		0.6193		0.3484		0.1758		0.8347	0.7891		tp=0.6, tn=0.081, fp=0.24, fn=0.077		False
	75	0.5213		0.6179		0.34		0.1892		0.8341	0.7802		tp=0.57, tn=0.1, fp=0.21, fn=0.11		False
	76	0.5199		0.6088		0.3455		0.1896		0.834	0.7914		tp=0.6, tn=0.087, fp=0.23, fn=0.081		False
	77	0.5198		0.6193		0.348		0.1992		0.8353	0.7751		tp=0.56, tn=0.11, fp=0.21, fn=0.11		False
	78	0.5192		0.6226		0.3459		0.1992		0.8342	0.8027		tp=0.62, tn=0.071, fp=0.25, fn=0.053		False
	79	0.5193		0.6042		0.3509		0.194		0.836	0.7977		tp=0.61, tn=0.084, fp=0.23, fn=0.079		False
	80	0.5174		0.6085		0.3527		0.1962		0.8361	0.7889		tp=0.59, tn=0.095, fp=0.23, fn=0.09		False
	81	0.5172		0.6079		0.3576		0.1981		0.8374	0.7957		tp=0.6, tn=0.089, fp=0.23, fn=0.083		False
	82	0.5163		0.6152		0.3567		0.1787		0.8363	0.7926		tp=0.6, tn=0.081, fp=0.24, fn=0.079		False
	83	0.5157		0.6104		0.3591		0.1975		0.8375	0.7877		tp=0.59, tn=0.095, fp=0.23, fn=0.087		False
	84	0.5149		0.6077		0.3668		0.1933		0.8385	0.7905		tp=0.59, tn=0.093, fp=0.22, fn=0.092		False
	85	0.5152		0.6157		0.3539		0.153		0.836	0.7887		tp=0.6, tn=0.079, fp=0.23, fn=0.089		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		122
learning rate		0.000557517875225
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_65-lr0.00056-h_size122-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6522		0.6164		0.2486		0.3194		0.6538	0.7061		tp=0.41, tn=0.25, fp=0.24, fn=0.1		True
	2	0.6315		0.6303		0.3042		0.3372		0.6851	0.6906		tp=0.37, tn=0.3, fp=0.17, fn=0.16		True
	3	0.6244		0.6085		0.32		0.3295		0.6886	0.7162		tp=0.42, tn=0.25, fp=0.22, fn=0.12		False
	4	0.6123		0.6238		0.3214		0.2905		0.688	0.7074		tp=0.43, tn=0.21, fp=0.26, fn=0.097		False
	5	0.598		0.6141		0.3781		0.3121		0.7152	0.7077		tp=0.41, tn=0.25, fp=0.22, fn=0.12		False
	6	0.5917		0.6206		0.3707		0.2904		0.708	0.6805		tp=0.38, tn=0.27, fp=0.22, fn=0.13		False
	7	0.5771		0.6179		0.3852		0.2916		0.7126	0.6935		tp=0.4, tn=0.25, fp=0.22, fn=0.13		False
	8	0.5755		0.629		0.3966		0.264		0.7193	0.6842		tp=0.4, tn=0.23, fp=0.25, fn=0.12		False
	9	0.562		0.6614		0.4335		0.3138		0.7357	0.6124		tp=0.28, tn=0.37, fp=0.11, fn=0.25		False
	10	0.5628		0.6967		0.4172		0.3178		0.7246	0.5662		tp=0.23, tn=0.41, fp=0.077, fn=0.28		False
	11	0.5546		0.6755		0.4334		0.3367		0.7324	0.5988		tp=0.26, tn=0.4, fp=0.09, fn=0.25		False
	12	0.5555		0.6726		0.4155		0.3002		0.7213	0.6089		tp=0.28, tn=0.36, fp=0.12, fn=0.24		False
	13	0.5456		0.6726		0.4493		0.314		0.7414	0.6347		tp=0.3, tn=0.35, fp=0.12, fn=0.23		False
	14	0.5378		0.6483		0.4513		0.2429		0.7417	0.6573		tp=0.36, tn=0.26, fp=0.22, fn=0.16		False
	15	0.5258		0.6855		0.4689		0.2422		0.7507	0.6069		tp=0.29, tn=0.32, fp=0.15, fn=0.23		False
	16	0.5336		0.6581		0.4681		0.3099		0.7473	0.6344		tp=0.3, tn=0.35, fp=0.13, fn=0.22		False
	17	0.5348		0.6981		0.4622		0.2984		0.7458	0.5749		tp=0.25, tn=0.39, fp=0.095, fn=0.27		False
	18	0.521		0.6657		0.4845		0.2638		0.7548	0.6885		tp=0.41, tn=0.23, fp=0.25, fn=0.12		False
	19	0.5159		0.6614		0.4773		0.2659		0.7539	0.6486		tp=0.34, tn=0.29, fp=0.17, fn=0.19		False
	20	0.5219		0.6826		0.4822		0.2465		0.7559	0.6166		tp=0.31, tn=0.32, fp=0.16, fn=0.22		False
	21	0.5306		0.6862		0.4513		0.3028		0.7365	0.6349		tp=0.31, tn=0.34, fp=0.13, fn=0.22		False
	22	0.5175		0.7259		0.472		0.2517		0.7495	0.5487		tp=0.24, tn=0.37, fp=0.097, fn=0.29		False
	23	0.5058		0.6895		0.498		0.2398		0.764	0.639		tp=0.34, tn=0.28, fp=0.2, fn=0.18		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		40
learning rate		0.00255366427016
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_66-lr0.0026-h_size40-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5877		0.5691		0.1918		0.2613		0.8166	0.8032		tp=0.6, tn=0.11, fp=0.21, fn=0.083		True
	2	0.5335		0.5792		0.3258		0.2188		0.8313	0.8197		tp=0.67, tn=0.04, fp=0.28, fn=0.013		False
	3	0.5067		0.5525		0.3804		0.2353		0.8418	0.8129		tp=0.63, tn=0.074, fp=0.25, fn=0.046		False
	4	0.4852		0.5594		0.4232		0.2792		0.8472	0.8113		tp=0.61, tn=0.1, fp=0.22, fn=0.061		True
	5	0.4639		0.5436		0.4363		0.3152		0.8503	0.8105		tp=0.59, tn=0.13, fp=0.19, fn=0.087		True
	6	0.434		0.6024		0.4996		0.2296		0.8626	0.8168		tp=0.65, tn=0.062, fp=0.26, fn=0.034		False
	7	0.4055		0.6024		0.5355		0.2704		0.8703	0.8083		tp=0.61, tn=0.1, fp=0.22, fn=0.067		False
	8	0.3912		0.5667		0.5593		0.3447		0.875	0.7864		tp=0.53, tn=0.18, fp=0.14, fn=0.15		True
	9	0.3763		0.5985		0.6006		0.3158		0.8853	0.7585		tp=0.49, tn=0.19, fp=0.12, fn=0.19		False
	10	0.3422		0.5423		0.6502		0.4047		0.8992	0.8215		tp=0.58, tn=0.17, fp=0.14, fn=0.11		True
	11	0.3183		0.5965		0.6809		0.3512		0.907	0.7683		tp=0.5, tn=0.2, fp=0.12, fn=0.18		False
	12	0.2903		0.5698		0.7182		0.3139		0.9173	0.8156		tp=0.6, tn=0.12, fp=0.19, fn=0.084		False
	13	0.2757		0.6694		0.7464		0.3118		0.9259	0.8248		tp=0.63, tn=0.1, fp=0.21, fn=0.055		False
	14	0.2492		0.6897		0.7844		0.3405		0.936	0.8228		tp=0.62, tn=0.11, fp=0.21, fn=0.052		False
	15	0.2247		0.6421		0.7981		0.3448		0.9401	0.7913		tp=0.54, tn=0.18, fp=0.14, fn=0.14		False
	16	0.1993		0.7081		0.844		0.3436		0.9532	0.8257		tp=0.62, tn=0.12, fp=0.2, fn=0.065		False
	17	0.1829		0.6723		0.8503		0.3549		0.9551	0.8047		tp=0.56, tn=0.17, fp=0.15, fn=0.12		False
	18	0.1684		0.7047		0.8709		0.3572		0.9612	0.8211		tp=0.6, tn=0.14, fp=0.17, fn=0.087		False
	19	0.1554		0.7006		0.882		0.3822		0.9644	0.82		tp=0.58, tn=0.16, fp=0.16, fn=0.098		False
	20	0.1457		0.7768		0.8937		0.3753		0.968	0.8118		tp=0.57, tn=0.17, fp=0.15, fn=0.12		False
	21	0.122		0.7576		0.9245		0.3747		0.9771	0.8073		tp=0.56, tn=0.17, fp=0.14, fn=0.13		False
	22	0.1113		0.8721		0.9283		0.3843		0.9783	0.7846		tp=0.51, tn=0.21, fp=0.11, fn=0.17		False
	23	0.09968		0.8577		0.9405		0.3622		0.9819	0.8181		tp=0.59, tn=0.15, fp=0.17, fn=0.089		False
	24	0.102		0.809		0.9393		0.3851		0.9815	0.8128		tp=0.57, tn=0.17, fp=0.15, fn=0.12		False
	25	0.0966		0.8869		0.9371		0.3644		0.9808	0.8047		tp=0.56, tn=0.17, fp=0.16, fn=0.12		False
	26	0.0823		0.872		0.9567		0.3692		0.9868	0.803		tp=0.55, tn=0.18, fp=0.15, fn=0.12		False
	27	0.07665		0.8892		0.9589		0.4006		0.9874	0.8129		tp=0.56, tn=0.18, fp=0.13, fn=0.13		False
	28	0.07539		0.9493		0.9585		0.3738		0.9873	0.7996		tp=0.54, tn=0.18, fp=0.13, fn=0.14		False
	29	0.06723		0.9591		0.9666		0.3677		0.9898	0.8077		tp=0.56, tn=0.17, fp=0.14, fn=0.13		False
	30	0.07978		0.9545		0.9467		0.3217		0.9837	0.8176		tp=0.6, tn=0.13, fp=0.19, fn=0.083		False
	31	0.07764		0.9901		0.9537		0.3733		0.9858	0.8017		tp=0.55, tn=0.18, fp=0.13, fn=0.14		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		112
learning rate		0.000317751049279
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_67-lr0.00032-h_size112-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5843		0.5674		0.1783		0.293		0.8174	0.8211		tp=0.63, tn=0.089, fp=0.23, fn=0.043		True
	2	0.5459		0.5882		0.2957		0.2539		0.831	0.8221		tp=0.66, tn=0.053, fp=0.27, fn=0.018		False
	3	0.5254		0.549		0.3467		0.344		0.8373	0.8309		tp=0.64, tn=0.1, fp=0.22, fn=0.043		True
	4	0.5056		0.5533		0.385		0.3023		0.8433	0.8135		tp=0.61, tn=0.11, fp=0.21, fn=0.07		False
	5	0.4842		0.5495		0.4141		0.304		0.8487	0.8037		tp=0.58, tn=0.13, fp=0.19, fn=0.095		False
	6	0.473		0.5546		0.434		0.2872		0.8508	0.7852		tp=0.55, tn=0.15, fp=0.16, fn=0.14		False
	7	0.453		0.581		0.4889		0.2945		0.8619	0.8264		tp=0.65, tn=0.079, fp=0.24, fn=0.033		False
	8	0.4371		0.5583		0.5095		0.3303		0.8676	0.8185		tp=0.6, tn=0.13, fp=0.19, fn=0.081		False
	9	0.4193		0.5895		0.5454		0.2797		0.8748	0.8235		tp=0.64, tn=0.081, fp=0.23, fn=0.041		False
	10	0.4029		0.6012		0.5606		0.2519		0.8777	0.8197		tp=0.64, tn=0.079, fp=0.23, fn=0.049		False
	11	0.3987		0.5692		0.5584		0.3146		0.8769	0.8082		tp=0.59, tn=0.14, fp=0.18, fn=0.099		False
	12	0.3807		0.5912		0.5969		0.2985		0.8865	0.7873		tp=0.55, tn=0.15, fp=0.17, fn=0.13		False
	13	0.382		0.5937		0.5967		0.3092		0.8866	0.8004		tp=0.57, tn=0.14, fp=0.19, fn=0.1		False
	14	0.3641		0.6256		0.617		0.2708		0.8907	0.8063		tp=0.6, tn=0.11, fp=0.22, fn=0.07		False
	15	0.3543		0.6212		0.6447		0.2789		0.8988	0.7778		tp=0.54, tn=0.15, fp=0.17, fn=0.14		False
	16	0.3492		0.5933		0.6401		0.3122		0.8974	0.8049		tp=0.58, tn=0.14, fp=0.18, fn=0.1		False
	17	0.3305		0.6341		0.6707		0.2926		0.9058	0.7775		tp=0.53, tn=0.16, fp=0.16, fn=0.14		False
	18	0.3235		0.6511		0.6794		0.2696		0.9077	0.7819		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	19	0.3229		0.6636		0.6768		0.2582		0.9068	0.8086		tp=0.61, tn=0.1, fp=0.21, fn=0.074		False
	20	0.3181		0.6631		0.6945		0.2901		0.9115	0.778		tp=0.53, tn=0.16, fp=0.16, fn=0.15		False
	21	0.3071		0.6869		0.7008		0.2994		0.9133	0.7829		tp=0.54, tn=0.16, fp=0.16, fn=0.14		False
	22	0.2945		0.66		0.7265		0.3288		0.9206	0.8021		tp=0.57, tn=0.15, fp=0.16, fn=0.12		False
	23	0.2915		0.6832		0.717		0.3388		0.9176	0.7657		tp=0.5, tn=0.2, fp=0.12, fn=0.18		False
	24	0.2872		0.6968		0.7194		0.3015		0.9178	0.785		tp=0.54, tn=0.16, fp=0.16, fn=0.14		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		92
learning rate		0.000289954592603
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_68-lr0.00029-h_size92-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6961		0.686		0.02709		0.04075		0.5713	0.6725		tp=0.49, tn=0.031, fp=0.46, fn=0.023		True
	2	0.6871		0.6817		0.08076		0.1529		0.5747	0.545		tp=0.26, tn=0.32, fp=0.17, fn=0.26		True
	3	0.6776		0.6769		0.1629		0.0302		0.5938	0.6842		tp=0.5, tn=0.038, fp=0.43, fn=0.036		False
	4	0.6729		0.6756		0.1762		0.1937		0.6243	0.5531		tp=0.25, tn=0.34, fp=0.14, fn=0.27		True
	5	0.6658		0.6749		0.2038		0.1318		0.6135	0.5127		tp=0.23, tn=0.32, fp=0.15, fn=0.29		False
	6	0.6626		0.6679		0.1966		0.2033		0.6156	0.6453		tp=0.36, tn=0.24, fp=0.24, fn=0.15		True
	7	0.6515		0.6731		0.2358		0.1409		0.6251	0.6393		tp=0.38, tn=0.2, fp=0.27, fn=0.15		False
	8	0.6469		0.6799		0.2411		0.1434		0.6389	0.5156		tp=0.23, tn=0.33, fp=0.14, fn=0.3		False
	9	0.6489		0.6847		0.2349		0.1554		0.6199	0.5		tp=0.22, tn=0.35, fp=0.13, fn=0.31		False
	10	0.6385		0.6693		0.2708		0.2065		0.6522	0.6115		tp=0.31, tn=0.29, fp=0.18, fn=0.22		True
	11	0.6323		0.6816		0.2925		0.1447		0.6561	0.5877		tp=0.3, tn=0.27, fp=0.21, fn=0.21		False
	12	0.6291		0.6777		0.286		0.1694		0.6543	0.6049		tp=0.32, tn=0.27, fp=0.21, fn=0.2		False
	13	0.6256		0.6895		0.2844		0.1475		0.6501	0.601		tp=0.32, tn=0.26, fp=0.22, fn=0.21		False
	14	0.6248		0.6862		0.2949		0.1434		0.6569	0.5435		tp=0.26, tn=0.31, fp=0.17, fn=0.26		False
	15	0.6221		0.693		0.299		0.1626		0.6611	0.6034		tp=0.32, tn=0.26, fp=0.22, fn=0.19		False
	16	0.6187		0.6936		0.3025		0.1568		0.6597	0.5865		tp=0.3, tn=0.28, fp=0.18, fn=0.24		False
	17	0.6177		0.693		0.3132		0.1815		0.6655	0.655		tp=0.38, tn=0.21, fp=0.26, fn=0.14		False
	18	0.6153		0.7111		0.318		0.09721		0.6723	0.5241		tp=0.25, tn=0.29, fp=0.18, fn=0.28		False
	19	0.613		0.6923		0.328		0.1358		0.6728	0.555		tp=0.27, tn=0.29, fp=0.18, fn=0.25		False
	20	0.6196		0.6875		0.3126		0.1709		0.6636	0.6176		tp=0.33, tn=0.25, fp=0.23, fn=0.19		False
	21	0.616		0.6802		0.309		0.1899		0.6636	0.6488		tp=0.37, tn=0.23, fp=0.25, fn=0.16		False
	22	0.6149		0.703		0.3168		0.1584		0.664	0.6478		tp=0.38, tn=0.2, fp=0.27, fn=0.15		False
	23	0.6066		0.7081		0.3421		0.1465		0.6793	0.5951		tp=0.31, tn=0.26, fp=0.22, fn=0.21		False
	24	0.6092		0.703		0.3103		0.1775		0.6646	0.6135		tp=0.33, tn=0.26, fp=0.22, fn=0.19		False
	25	0.6074		0.7128		0.3433		0.1183		0.6807	0.5553		tp=0.28, tn=0.28, fp=0.19, fn=0.25		False
	26	0.607		0.7095		0.3297		0.1457		0.6724	0.601		tp=0.32, tn=0.25, fp=0.23, fn=0.2		False
	27	0.6058		0.7375		0.3456		0.1037		0.682	0.441		tp=0.18, tn=0.36, fp=0.12, fn=0.34		False
	28	0.602		0.7037		0.3476		0.1439		0.6785	0.6157		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	29	0.6069		0.714		0.3328		0.1214		0.6777	0.5544		tp=0.27, tn=0.28, fp=0.19, fn=0.25		False
	30	0.6101		0.7065		0.3422		0.1642		0.6797	0.6053		tp=0.32, tn=0.26, fp=0.22, fn=0.2		False
	31	0.6049		0.72		0.3481		0.1453		0.6826	0.5678		tp=0.28, tn=0.29, fp=0.18, fn=0.25		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		125
learning rate		0.00434839147088
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_69-lr0.0043-h_size125-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6958		0.6838		0.03867		0.1551		0.5585	0.4802		tp=0.2, tn=0.36, fp=0.11, fn=0.33		True
	2	0.6671		0.6762		0.1889		0.1771		0.6109	0.686		tp=0.45, tn=0.13, fp=0.35, fn=0.069		True
	3	0.6437		0.6819		0.2486		0.1646		0.638	0.5915		tp=0.3, tn=0.28, fp=0.19, fn=0.22		False
	4	0.6291		0.6693		0.3156		0.1744		0.6705	0.5803		tp=0.29, tn=0.3, fp=0.17, fn=0.24		False
	5	0.6148		0.6907		0.3287		0.1543		0.6726	0.6062		tp=0.32, tn=0.26, fp=0.22, fn=0.2		False
	6	0.5965		0.7239		0.3696		0.152		0.6944	0.5101		tp=0.23, tn=0.34, fp=0.14, fn=0.29		False
	7	0.5876		0.7683		0.3809		0.1671		0.7038	0.4192		tp=0.16, tn=0.41, fp=0.082, fn=0.35		False
	8	0.5769		0.7296		0.4025		0.09881		0.707	0.6133		tp=0.35, tn=0.2, fp=0.27, fn=0.18		False
	9	0.5575		0.7114		0.4109		0.1378		0.716	0.6453		tp=0.39, tn=0.19, fp=0.28, fn=0.15		False
	10	0.5391		0.7373		0.4687		0.175		0.7417	0.6411		tp=0.36, tn=0.23, fp=0.24, fn=0.17		False
	11	0.5209		0.7373		0.4841		0.1679		0.7505	0.5955		tp=0.31, tn=0.28, fp=0.2, fn=0.21		False
	12	0.5038		0.7452		0.5069		0.1875		0.7626	0.5745		tp=0.28, tn=0.31, fp=0.16, fn=0.25		True
	13	0.4794		0.8139		0.5433		0.1208		0.7779	0.4699		tp=0.2, tn=0.35, fp=0.13, fn=0.32		False
	14	0.469		0.7481		0.5562		0.2175		0.782	0.6329		tp=0.34, tn=0.27, fp=0.19, fn=0.19		True
	15	0.4316		0.8143		0.6052		0.203		0.8065	0.6404		tp=0.35, tn=0.25, fp=0.23, fn=0.17		False
	16	0.417		0.8422		0.6166		0.1944		0.812	0.6104		tp=0.32, tn=0.28, fp=0.19, fn=0.21		False
	17	0.3846		0.8645		0.6738		0.167		0.8391	0.6247		tp=0.34, tn=0.24, fp=0.22, fn=0.19		False
	18	0.3594		0.8704		0.7045		0.2277		0.8542	0.6479		tp=0.35, tn=0.26, fp=0.21, fn=0.18		True
	19	0.3375		0.8985		0.7323		0.2426		0.868	0.6726		tp=0.39, tn=0.24, fp=0.24, fn=0.14		True
	20	0.3066		0.975		0.7695		0.2127		0.8867	0.599		tp=0.29, tn=0.31, fp=0.17, fn=0.22		False
	21	0.2772		0.9852		0.8062		0.2032		0.9044	0.6229		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	22	0.2617		0.9999		0.8156		0.2373		0.9091	0.6696		tp=0.38, tn=0.24, fp=0.24, fn=0.14		False
	23	0.2233		1.05		0.867		0.2326		0.9346	0.6082		tp=0.3, tn=0.31, fp=0.15, fn=0.23		False
	24	0.2091		1.04		0.8771		0.2039		0.9395	0.6419		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	25	0.1812		1.083		0.9019		0.2032		0.9518	0.5901		tp=0.29, tn=0.31, fp=0.16, fn=0.24		False
	26	0.1621		1.102		0.9184		0.2114		0.9598	0.6333		tp=0.34, tn=0.27, fp=0.21, fn=0.18		False
	27	0.1431		1.094		0.9403		0.22		0.9706	0.62		tp=0.32, tn=0.29, fp=0.19, fn=0.19		False
	28	0.1314		1.149		0.951		0.1827		0.9758	0.6326		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	29	0.1153		1.231		0.9586		0.2474		0.9796	0.6589		tp=0.36, tn=0.26, fp=0.21, fn=0.16		True
	30	0.1007		1.271		0.9687		0.2155		0.9846	0.6146		tp=0.31, tn=0.29, fp=0.19, fn=0.21		False
	31	0.08878		1.241		0.9781		0.2306		0.9892	0.6377		tp=0.34, tn=0.28, fp=0.18, fn=0.2		False
	32	0.08429		1.284		0.9811		0.2067		0.9907	0.6385		tp=0.35, tn=0.26, fp=0.22, fn=0.17		False
	33	0.07456		1.349		0.9805		0.214		0.9904	0.653		tp=0.37, tn=0.24, fp=0.23, fn=0.16		False
	34	0.06782		1.335		0.9817		0.2363		0.991	0.6375		tp=0.34, tn=0.28, fp=0.18, fn=0.2		False
	35	0.06332		1.454		0.987		0.19		0.9936	0.6359		tp=0.35, tn=0.24, fp=0.24, fn=0.16		False
	36	0.06079		1.464		0.9823		0.1789		0.9913	0.6395		tp=0.36, tn=0.23, fp=0.24, fn=0.17		False
	37	0.05727		1.38		0.9846		0.21		0.9924	0.6262		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	38	0.0546		1.446		0.9864		0.2235		0.9933	0.6326		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	39	0.05169		1.442		0.987		0.198		0.9936	0.6195		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	40	0.04725		1.46		0.9894		0.2749		0.9948	0.6569		tp=0.35, tn=0.29, fp=0.18, fn=0.18		True
	41	0.04385		1.52		0.9852		0.2299		0.9927	0.6138		tp=0.31, tn=0.31, fp=0.17, fn=0.21		False
	42	0.04405		1.48		0.9858		0.26		0.993	0.6471		tp=0.34, tn=0.29, fp=0.18, fn=0.19		False
	43	0.04289		1.578		0.9882		0.1927		0.9942	0.6253		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	44	0.03863		1.559		0.9911		0.2284		0.9956	0.6196		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	45	0.03868		1.578		0.9894		0.2404		0.9947	0.6621		tp=0.37, tn=0.25, fp=0.22, fn=0.16		False
	46	0.04165		1.563		0.9888		0.2567		0.9945	0.6329		tp=0.32, tn=0.31, fp=0.18, fn=0.19		False
	47	0.03533		1.639		0.9911		0.2446		0.9956	0.6557		tp=0.36, tn=0.27, fp=0.2, fn=0.18		False
	48	0.03431		1.671		0.9917		0.2346		0.9959	0.6652		tp=0.38, tn=0.25, fp=0.22, fn=0.16		False
	49	0.03453		1.553		0.99		0.2579		0.995	0.662		tp=0.36, tn=0.27, fp=0.21, fn=0.16		False
	50	0.03421		1.719		0.99		0.1956		0.9951	0.6455		tp=0.36, tn=0.24, fp=0.24, fn=0.16		False
	51	0.03567		1.666		0.9888		0.2511		0.9945	0.6368		tp=0.33, tn=0.3, fp=0.18, fn=0.2		False
	52	0.03802		1.66		0.987		0.2254		0.9936	0.6344		tp=0.34, tn=0.28, fp=0.2, fn=0.19		False
	53	0.04357		1.692		0.9864		0.2033		0.9933	0.6484		tp=0.36, tn=0.24, fp=0.22, fn=0.17		False
	54	0.03723		1.694		0.9864		0.22		0.9933	0.6591		tp=0.37, tn=0.24, fp=0.24, fn=0.15		False
	55	0.03766		1.726		0.9852		0.2198		0.9927	0.6165		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	56	0.03332		1.754		0.9876		0.2301		0.9939	0.6377		tp=0.34, tn=0.28, fp=0.19, fn=0.19		False
	57	0.03532		1.793		0.9876		0.1808		0.9939	0.6409		tp=0.36, tn=0.23, fp=0.23, fn=0.17		False
	58	0.0336		1.703		0.987		0.2295		0.9936	0.6305		tp=0.33, tn=0.29, fp=0.19, fn=0.19		False
	59	0.02915		1.761		0.9911		0.2172		0.9956	0.6415		tp=0.35, tn=0.26, fp=0.22, fn=0.17		False
	60	0.02854		1.878		0.9906		0.2275		0.9953	0.6394		tp=0.34, tn=0.27, fp=0.2, fn=0.19		False
	61	0.02754		1.718		0.9929		0.2469		0.9965	0.6297		tp=0.32, tn=0.3, fp=0.17, fn=0.2		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		71
learning rate		0.00222645865942
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_6-lr0.0022-h_size71-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6925		0.6679		0.09121		0.1654		0.5622	0.6582		tp=0.4, tn=0.19, fp=0.28, fn=0.13		True
	2	0.6604		0.6694		0.2123		0.2074		0.6296	0.5691		tp=0.26, tn=0.34, fp=0.15, fn=0.25		True
	3	0.6363		0.6627		0.2848		0.2469		0.6515	0.6205		tp=0.31, tn=0.31, fp=0.16, fn=0.22		True
	4	0.61		0.6715		0.3436		0.2158		0.6764	0.6766		tp=0.41, tn=0.2, fp=0.27, fn=0.12		False
	5	0.5948		0.6896		0.3605		0.2104		0.6875	0.5282		tp=0.23, tn=0.36, fp=0.11, fn=0.29		False
	6	0.5796		0.6897		0.4037		0.1743		0.7115	0.685		tp=0.45, tn=0.14, fp=0.33, fn=0.085		False
	7	0.5595		0.6795		0.432		0.2263		0.7231	0.6062		tp=0.3, tn=0.31, fp=0.17, fn=0.22		False
	8	0.5406		0.712		0.4581		0.2254		0.734	0.5963		tp=0.29, tn=0.32, fp=0.15, fn=0.24		False
	9	0.528		0.7602		0.4788		0.245		0.7449	0.5389		tp=0.23, tn=0.38, fp=0.099, fn=0.29		False
	10	0.5216		0.7269		0.4776		0.2224		0.7463	0.5838		tp=0.28, tn=0.33, fp=0.14, fn=0.25		False
	11	0.5009		0.7143		0.5132		0.2129		0.7609	0.6076		tp=0.31, tn=0.3, fp=0.16, fn=0.23		False
	12	0.492		0.8035		0.526		0.2804		0.7683	0.5797		tp=0.26, tn=0.37, fp=0.11, fn=0.27		True
	13	0.4755		0.7697		0.5303		0.2042		0.7717	0.5587		tp=0.26, tn=0.34, fp=0.14, fn=0.27		False
	14	0.4465		0.8858		0.5828		0.1592		0.7965	0.4654		tp=0.19, tn=0.37, fp=0.11, fn=0.33		False
	15	0.423		0.7642		0.6141		0.2341		0.8111	0.6357		tp=0.33, tn=0.28, fp=0.19, fn=0.19		False
	16	0.3944		0.8715		0.6378		0.1773		0.8233	0.5341		tp=0.24, tn=0.34, fp=0.14, fn=0.28		False
	17	0.3713		0.8449		0.681		0.1899		0.8444	0.6374		tp=0.35, tn=0.24, fp=0.23, fn=0.17		False
	18	0.3528		0.9705		0.7063		0.2153		0.8562	0.4452		tp=0.17, tn=0.42, fp=0.069, fn=0.35		False
	19	0.3346		0.9143		0.7235		0.2225		0.8647	0.6361		tp=0.34, tn=0.27, fp=0.2, fn=0.19		False
	20	0.314		0.9174		0.7429		0.2102		0.874	0.5829		tp=0.28, tn=0.32, fp=0.15, fn=0.25		False
	21	0.2751		0.9459		0.8003		0.2567		0.9015	0.6366		tp=0.33, tn=0.3, fp=0.17, fn=0.2		False
	22	0.2558		1.017		0.8221		0.2065		0.9127	0.6154		tp=0.32, tn=0.28, fp=0.18, fn=0.22		False
	23	0.2257		1.035		0.8488		0.2273		0.926	0.6177		tp=0.31, tn=0.3, fp=0.17, fn=0.21		False
	24	0.2152		1.184		0.8689		0.1628		0.9357	0.4847		tp=0.2, tn=0.37, fp=0.12, fn=0.32		False
	25	0.1822		1.127		0.9072		0.209		0.9545	0.5851		tp=0.28, tn=0.32, fp=0.16, fn=0.24		False
	26	0.1658		1.176		0.912		0.2402		0.9568	0.617		tp=0.31, tn=0.31, fp=0.16, fn=0.22		False
	27	0.1471		1.184		0.9261		0.2027		0.9636	0.6247		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	28	0.1364		1.305		0.9427		0.1782		0.9718	0.5691		tp=0.27, tn=0.31, fp=0.16, fn=0.25		False
	29	0.1255		1.311		0.9457		0.1921		0.9733	0.603		tp=0.31, tn=0.29, fp=0.19, fn=0.21		False
	30	0.1135		1.3		0.9545		0.2207		0.9776	0.6293		tp=0.33, tn=0.28, fp=0.19, fn=0.19		False
	31	0.1012		1.329		0.9634		0.1905		0.9819	0.6253		tp=0.34, tn=0.26, fp=0.21, fn=0.2		False
	32	0.09104		1.386		0.9752		0.2234		0.9878	0.6326		tp=0.33, tn=0.28, fp=0.19, fn=0.19		False
	33	0.07932		1.489		0.9805		0.1637		0.9904	0.611		tp=0.33, tn=0.26, fp=0.23, fn=0.19		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		141
learning rate		8.84143252882e&05
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_70-lr8.8e&05-h_size141-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6924		0.6898		0.0389		0.1145		0.4914	0.5676		tp=0.29, tn=0.26, fp=0.17, fn=0.27		True
	2	0.6818		0.6873		0.2353		0.1742		0.4933	0.3889		tp=0.15, tn=0.39, fp=0.056, fn=0.41		True
	3	0.6739		0.6862		0.2384		0.137		0.4606	0.4138		tp=0.17, tn=0.36, fp=0.077, fn=0.4		False
	4	0.6676		0.6758		0.317		0.1682		0.6657	0.496		tp=0.22, tn=0.34, fp=0.1, fn=0.34		False
	5	0.6617		0.6687		0.227		0.2505		0.4458	0.6301		tp=0.32, tn=0.3, fp=0.15, fn=0.22		True
	6	0.6526		0.6705		0.3783		0.2062		0.6944	0.5496		tp=0.25, tn=0.34, fp=0.12, fn=0.29		False
	7	0.6458		0.6747		0.3185		0.1722		0.5651	0.4576		tp=0.19, tn=0.36, fp=0.084, fn=0.36		False
	8	0.6376		0.6652		0.3806		0.1951		0.6798	0.6369		tp=0.35, tn=0.25, fp=0.2, fn=0.2		False
	9	0.6313		0.6626		0.3576		0.1975		0.6507	0.5588		tp=0.26, tn=0.32, fp=0.12, fn=0.29		False
	10	0.6245		0.6677		0.3904		0.2247		0.6667	0.4915		tp=0.2, tn=0.38, fp=0.077, fn=0.34		False
	11	0.6167		0.6517		0.4047		0.2727		0.6783	0.6294		tp=0.31, tn=0.31, fp=0.13, fn=0.24		True
	12	0.6112		0.6519		0.3981		0.2167		0.6832	0.5538		tp=0.25, tn=0.34, fp=0.12, fn=0.29		False
	13	0.6033		0.6501		0.4141		0.2766		0.6667	0.6345		tp=0.32, tn=0.31, fp=0.13, fn=0.24		True
	14	0.5966		0.657		0.4452		0.24		0.7141	0.5354		tp=0.24, tn=0.35, fp=0.084, fn=0.33		False
	15	0.5921		0.6555		0.4366		0.2171		0.7	0.5203		tp=0.22, tn=0.36, fp=0.098, fn=0.31		False
	16	0.5842		0.6466		0.4692		0.2331		0.6794	0.6259		tp=0.32, tn=0.29, fp=0.17, fn=0.22		False
	17	0.5782		0.6598		0.4722		0.2526		0.7321	0.5512		tp=0.24, tn=0.36, fp=0.091, fn=0.31		False
	18	0.5693		0.643		0.4691		0.2287		0.7167	0.5899		tp=0.29, tn=0.31, fp=0.13, fn=0.27		False
	19	0.5619		0.6481		0.4894		0.2842		0.7298	0.6074		tp=0.29, tn=0.34, fp=0.11, fn=0.26		True
	20	0.5569		0.6581		0.5039		0.2544		0.7412	0.5128		tp=0.21, tn=0.39, fp=0.077, fn=0.32		False
	21	0.5522		0.6507		0.4775		0.2762		0.7253	0.6187		tp=0.3, tn=0.33, fp=0.13, fn=0.24		False
	22	0.5433		0.6346		0.5209		0.3009		0.7372	0.6383		tp=0.31, tn=0.33, fp=0.13, fn=0.23		True
	23	0.5373		0.6317		0.5258		0.2105		0.7267	0.641		tp=0.35, tn=0.26, fp=0.2, fn=0.19		False
	24	0.5313		0.6376		0.5229		0.316		0.7606	0.6154		tp=0.28, tn=0.37, fp=0.11, fn=0.24		True
	25	0.5244		0.6301		0.5291		0.21		0.744	0.6707		tp=0.39, tn=0.22, fp=0.21, fn=0.17		False
	26	0.5163		0.641		0.5656		0.3117		0.7737	0.6165		tp=0.29, tn=0.36, fp=0.1, fn=0.25		False
	27	0.5085		0.5972		0.5515		0.3052		0.7613	0.6434		tp=0.32, tn=0.32, fp=0.12, fn=0.24		False
	28	0.5024		0.6353		0.5779		0.3093		0.7757	0.6331		tp=0.31, tn=0.34, fp=0.11, fn=0.24		False
	29	0.4965		0.6325		0.5921		0.3178		0.7865	0.6755		tp=0.36, tn=0.3, fp=0.14, fn=0.2		True
	30	0.4898		0.6321		0.6021		0.3138		0.7862	0.5873		tp=0.26, tn=0.38, fp=0.084, fn=0.28		False
	31	0.4838		0.6207		0.6099		0.3327		0.7944	0.7081		tp=0.4, tn=0.27, fp=0.17, fn=0.15		True
	32	0.4783		0.6146		0.6193		0.363		0.7969	0.6849		tp=0.35, tn=0.33, fp=0.13, fn=0.2		True
	33	0.4699		0.6254		0.6302		0.3251		0.8073	0.6377		tp=0.31, tn=0.35, fp=0.11, fn=0.24		False
	34	0.4637		0.6161		0.6285		0.3344		0.8006	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.2		False
	35	0.4615		0.6305		0.6067		0.3246		0.7976	0.6621		tp=0.33, tn=0.33, fp=0.14, fn=0.2		False
	36	0.4536		0.6229		0.638		0.3257		0.7974	0.6883		tp=0.37, tn=0.29, fp=0.15, fn=0.18		False
	37	0.4466		0.621		0.6657		0.3208		0.8246	0.6377		tp=0.31, tn=0.34, fp=0.11, fn=0.24		False
	38	0.44		0.6293		0.6507		0.345		0.8189	0.626		tp=0.29, tn=0.37, fp=0.091, fn=0.25		False
	39	0.4394		0.6753		0.6486		0.2334		0.8131	0.5426		tp=0.24, tn=0.34, fp=0.091, fn=0.32		False
	40	0.4289		0.6234		0.686		0.3594		0.828	0.6933		tp=0.36, tn=0.31, fp=0.13, fn=0.19		False
	41	0.4234		0.617		0.6714		0.3169		0.8282	0.6429		tp=0.31, tn=0.34, fp=0.12, fn=0.23		False
	42	0.4162		0.6234		0.7003		0.3386		0.8368	0.6968		tp=0.38, tn=0.29, fp=0.15, fn=0.17		False
	43	0.4107		0.6648		0.6742		0.3175		0.8326	0.6119		tp=0.28, tn=0.35, fp=0.09, fn=0.27		False
	44	0.4128		0.6655		0.6637		0.3236		0.82	0.592		tp=0.26, tn=0.38, fp=0.084, fn=0.27		False
	45	0.4052		0.641		0.6979		0.2974		0.8418	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.22		False
	46	0.3973		0.6312		0.6869		0.3151		0.8269	0.6711		tp=0.35, tn=0.31, fp=0.15, fn=0.19		False
	47	0.3913		0.6082		0.7191		0.3655		0.8509	0.6619		tp=0.32, tn=0.35, fp=0.1, fn=0.22		True
	48	0.385		0.6462		0.7216		0.3027		0.8536	0.6232		tp=0.3, tn=0.34, fp=0.1, fn=0.26		False
	49	0.3785		0.6003		0.725		0.3194		0.854	0.6667		tp=0.34, tn=0.31, fp=0.14, fn=0.2		False
	50	0.3742		0.6272		0.7426		0.3255		0.8634	0.6621		tp=0.34, tn=0.32, fp=0.13, fn=0.22		False
	51	0.3678		0.631		0.7577		0.3819		0.8705	0.6897		tp=0.35, tn=0.34, fp=0.11, fn=0.2		True
	52	0.3629		0.6357		0.7605		0.3619		0.8723	0.6713		tp=0.34, tn=0.34, fp=0.1, fn=0.22		False
	53	0.3578		0.652		0.7577		0.2913		0.8705	0.6531		tp=0.34, tn=0.31, fp=0.15, fn=0.21		False
	54	0.3536		0.6732		0.7476		0.2973		0.8697	0.6232		tp=0.3, tn=0.34, fp=0.11, fn=0.25		False
	55	0.3519		0.6514		0.7421		0.2876		0.8646	0.6623		tp=0.35, tn=0.29, fp=0.15, fn=0.2		False
	56	0.3458		0.6518		0.7429		0.3068		0.8629	0.6575		tp=0.34, tn=0.31, fp=0.14, fn=0.21		False
	57	0.3398		0.6718		0.7858		0.325		0.8896	0.6324		tp=0.3, tn=0.35, fp=0.1, fn=0.24		False
	58	0.3338		0.6108		0.785		0.3412		0.8836	0.6887		tp=0.36, tn=0.31, fp=0.15, fn=0.17		False
	59	0.3365		0.6319		0.7801		0.3731		0.8851	0.6667		tp=0.32, tn=0.36, fp=0.1, fn=0.22		False
	60	0.325		0.683		0.7859		0.3086		0.8906	0.6277		tp=0.3, tn=0.34, fp=0.11, fn=0.24		False
	61	0.3216		0.6684		0.7949		0.3365		0.8926	0.68		tp=0.36, tn=0.31, fp=0.13, fn=0.21		False
	62	0.3181		0.6637		0.8036		0.3454		0.8974	0.6803		tp=0.35, tn=0.32, fp=0.14, fn=0.19		False
	63	0.3125		0.6386		0.8184		0.384		0.9049	0.702		tp=0.37, tn=0.31, fp=0.1, fn=0.21		True
	64	0.3064		0.6554		0.8226		0.3141		0.9048	0.6755		tp=0.36, tn=0.3, fp=0.15, fn=0.19		False
	65	0.3129		0.6719		0.7975		0.3708		0.8953	0.6667		tp=0.33, tn=0.35, fp=0.097, fn=0.23		False
	66	0.3015		0.6737		0.8357		0.3439		0.9149	0.6471		tp=0.31, tn=0.36, fp=0.11, fn=0.22		False
	67	0.2961		0.6861		0.8298		0.333		0.9124	0.6475		tp=0.31, tn=0.34, fp=0.11, fn=0.23		False
	68	0.2968		0.6348		0.8201		0.3455		0.9028	0.6667		tp=0.34, tn=0.33, fp=0.11, fn=0.22		False
	69	0.2878		0.6611		0.8389		0.3662		0.9158	0.6806		tp=0.34, tn=0.34, fp=0.12, fn=0.2		False
	70	0.2838		0.6789		0.8415		0.3506		0.9184	0.6713		tp=0.34, tn=0.34, fp=0.13, fn=0.2		False
	71	0.2792		0.7002		0.8475		0.3058		0.9207	0.6434		tp=0.32, tn=0.33, fp=0.12, fn=0.23		False
	72	0.2754		0.6892		0.8476		0.3251		0.9205	0.6667		tp=0.34, tn=0.31, fp=0.13, fn=0.22		False
	73	0.2716		0.7032		0.8681		0.3225		0.9315	0.6573		tp=0.33, tn=0.33, fp=0.13, fn=0.21		False
	74	0.2673		0.7173		0.8797		0.3213		0.9383	0.6429		tp=0.31, tn=0.34, fp=0.11, fn=0.24		False
	75	0.267		0.6895		0.8543		0.3601		0.9226	0.6892		tp=0.36, tn=0.32, fp=0.13, fn=0.19		False
	76	0.2625		0.7303		0.8712		0.288		0.9327	0.6232		tp=0.3, tn=0.34, fp=0.13, fn=0.24		False
	77	0.2583		0.6882		0.8684		0.3601		0.9309	0.6892		tp=0.36, tn=0.32, fp=0.13, fn=0.19		False
	78	0.2527		0.7137		0.88		0.3373		0.9372	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.21		False
	79	0.2493		0.7058		0.8944		0.3787		0.9453	0.6809		tp=0.34, tn=0.35, fp=0.12, fn=0.2		False
	80	0.2488		0.6849		0.8562		0.3863		0.9261	0.7027		tp=0.36, tn=0.33, fp=0.13, fn=0.17		True
	81	0.2439		0.7129		0.9066		0.3575		0.9509	0.6933		tp=0.36, tn=0.31, fp=0.14, fn=0.18		False
	82	0.2416		0.672		0.8887		0.3787		0.9421	0.6897		tp=0.35, tn=0.34, fp=0.12, fn=0.2		False
	83	0.2371		0.6716		0.8865		0.4187		0.9397	0.7162		tp=0.37, tn=0.34, fp=0.12, fn=0.17		True
	84	0.2372		0.6679		0.8769		0.3584		0.936	0.6974		tp=0.37, tn=0.31, fp=0.13, fn=0.19		False
	85	0.231		0.6842		0.9091		0.3527		0.953	0.6846		tp=0.36, tn=0.31, fp=0.12, fn=0.21		False
	86	0.229		0.7444		0.9032		0.3344		0.9499	0.6522		tp=0.31, tn=0.35, fp=0.13, fn=0.2		False
	87	0.2258		0.7637		0.9061		0.305		0.952	0.6383		tp=0.31, tn=0.33, fp=0.12, fn=0.24		False
	88	0.2203		0.71		0.9239		0.3571		0.9604	0.7013		tp=0.38, tn=0.3, fp=0.13, fn=0.19		False
	89	0.2177		0.7483		0.9238		0.3344		0.9605	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.2		False
	90	0.2173		0.7071		0.9061		0.3912		0.9517	0.6986		tp=0.36, tn=0.34, fp=0.12, fn=0.19		False
	91	0.2116		0.7522		0.9237		0.3697		0.9606	0.6806		tp=0.34, tn=0.34, fp=0.11, fn=0.21		False
	92	0.2083		0.7446		0.915		0.3505		0.956	0.6759		tp=0.34, tn=0.33, fp=0.13, fn=0.2		False
	93	0.2061		0.7843		0.9238		0.3246		0.9605	0.6621		tp=0.33, tn=0.33, fp=0.14, fn=0.2		False
	94	0.202		0.7397		0.9326		0.3378		0.9655	0.6712		tp=0.34, tn=0.32, fp=0.13, fn=0.21		False
	95	0.2027		0.7852		0.9327		0.3091		0.965	0.6377		tp=0.31, tn=0.34, fp=0.13, fn=0.22		False
	96	0.197		0.7589		0.9356		0.3381		0.9666	0.6667		tp=0.34, tn=0.33, fp=0.13, fn=0.21		False
	97	0.1939		0.7891		0.9443		0.3099		0.9713	0.6528		tp=0.33, tn=0.32, fp=0.13, fn=0.22		False
	98	0.1915		0.7673		0.9356		0.3452		0.9666	0.6712		tp=0.34, tn=0.32, fp=0.11, fn=0.22		False
	99	0.1928		0.8058		0.9326		0.3373		0.9651	0.6522		tp=0.31, tn=0.35, fp=0.13, fn=0.21		False
	100	0.1869		0.7823		0.9472		0.333		0.973	0.6475		tp=0.31, tn=0.34, fp=0.11, fn=0.23		False
	101	0.1909		0.7763		0.9325		0.3415		0.9653	0.662		tp=0.33, tn=0.34, fp=0.12, fn=0.22		False
	102	0.1848		0.8131		0.9414		0.3527		0.9696	0.6846		tp=0.36, tn=0.31, fp=0.12, fn=0.21		False
	103	0.1803		0.7692		0.9443		0.3734		0.9712	0.6939		tp=0.36, tn=0.33, fp=0.13, fn=0.18		False
	104	0.1761		0.7996		0.9562		0.3655		0.9772	0.6892		tp=0.36, tn=0.32, fp=0.12, fn=0.2		False


data			/scratch/asw462/data/levin
input size		300
hidden size		175
learning rate		0.000156565177649
encoding size		1515
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_71-lr0.00016-h_size175-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_1-lr0.00022-h_size1515-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5805		0.5575		0		0		0.844	0.8434		tp=0.73, tn=0, fp=0.27, fn=0		False
	2	0.5486		0.5748		0.1363		0.128		0.8441	0.8264		tp=0.7, tn=0.007, fp=0.29, fn=0		True
	3	0.5178		0.5484		0.2069		0.1301		0.8487	0.8313		tp=0.71, tn=0.007, fp=0.29, fn=0		True
	4	0.4882		0.5409		0.309		0.3643		0.8575	0.8584		tp=0.69, tn=0.076, fp=0.21, fn=0.021		True
	5	0.4617		0.5578		0.3738		0.2971		0.8663	0.8384		tp=0.67, tn=0.07, fp=0.23, fn=0.028		False
	6	0.4328		0.5419		0.4967		0.3167		0.8853	0.8523		tp=0.71, tn=0.049, fp=0.24, fn=0.007		False
	7	0.4059		0.5643		0.5093		0.2873		0.8863	0.8165		tp=0.62, tn=0.098, fp=0.22, fn=0.056		False
	8	0.381		0.5525		0.586		0.3516		0.8996	0.8318		tp=0.62, tn=0.13, fp=0.15, fn=0.097		False
	9	0.354		0.5682		0.6354		0.2732		0.9111	0.8333		tp=0.66, tn=0.07, fp=0.23, fn=0.035		False
	10	0.3397		0.566		0.6571		0.2774		0.9163	0.8203		tp=0.62, tn=0.1, fp=0.19, fn=0.084		False
	11	0.3095		0.5503		0.7095		0.4274		0.9265	0.8491		tp=0.63, tn=0.15, fp=0.15, fn=0.077		True
	12	0.2877		0.5208		0.7254		0.3653		0.9308	0.8571		tp=0.67, tn=0.1, fp=0.16, fn=0.063		False
	13	0.2674		0.55		0.7672		0.4343		0.9407	0.8571		tp=0.65, tn=0.13, fp=0.16, fn=0.056		True
	14	0.2493		0.555		0.7891		0.4487		0.9455	0.8545		tp=0.64, tn=0.15, fp=0.15, fn=0.063		True
	15	0.2371		0.5834		0.7965		0.4304		0.9477	0.8532		tp=0.65, tn=0.13, fp=0.18, fn=0.042		False
	16	0.2219		0.566		0.8212		0.3724		0.9535	0.8341		tp=0.62, tn=0.14, fp=0.15, fn=0.098		False
	17	0.2068		0.6361		0.8328		0.4613		0.9556	0.8491		tp=0.63, tn=0.15, fp=0.18, fn=0.042		True
	18	0.188		0.6175		0.8863		0.3782		0.9696	0.8195		tp=0.58, tn=0.16, fp=0.15, fn=0.1		False
	19	0.1741		0.6622		0.9025		0.4147		0.9738	0.8396		tp=0.62, tn=0.14, fp=0.18, fn=0.056		False
	20	0.1643		0.6172		0.8946		0.4341		0.9721	0.8406		tp=0.6, tn=0.17, fp=0.1, fn=0.12		False
	21	0.152		0.6421		0.9275		0.3786		0.9804	0.8479		tp=0.64, tn=0.13, fp=0.15, fn=0.084		False
	22	0.1425		0.6054		0.9344		0.4176		0.9824	0.8436		tp=0.62, tn=0.15, fp=0.13, fn=0.097		False
	23	0.1307		0.6788		0.9507		0.3905		0.9866	0.8465		tp=0.64, tn=0.13, fp=0.15, fn=0.084		False
	24	0.1241		0.6639		0.9434		0.4463		0.9847	0.8447		tp=0.61, tn=0.17, fp=0.13, fn=0.098		False
	25	0.1204		0.645		0.9417		0.5103		0.9842	0.8571		tp=0.61, tn=0.19, fp=0.12, fn=0.084		True
	26	0.1091		0.6753		0.9539		0.4577		0.9876	0.8517		tp=0.62, tn=0.16, fp=0.14, fn=0.077		False
	27	0.1019		0.681		0.9735		0.5293		0.9928	0.8641		tp=0.62, tn=0.19, fp=0.12, fn=0.069		True
	28	0.09598		0.7174		0.9683		0.467		0.9914	0.8488		tp=0.61, tn=0.17, fp=0.12, fn=0.098		False
	29	0.08985		0.6857		0.9789		0.5128		0.9942	0.8571		tp=0.61, tn=0.19, fp=0.13, fn=0.077		False
	30	0.08523		0.7612		0.9718		0.4694		0.9923	0.84		tp=0.59, tn=0.19, fp=0.13, fn=0.098		False
	31	0.08013		0.784		0.9751		0.4859		0.9933	0.8458		tp=0.59, tn=0.19, fp=0.13, fn=0.084		False
	32	0.07475		0.8355		0.9789		0.4553		0.9942	0.8358		tp=0.59, tn=0.18, fp=0.15, fn=0.084		False
	33	0.07229		0.7158		0.9772		0.5006		0.9937	0.8585		tp=0.62, tn=0.18, fp=0.1, fn=0.098		False
	34	0.06861		0.7401		0.9824		0.5149		0.9952	0.872		tp=0.64, tn=0.17, fp=0.11, fn=0.077		False
	35	0.06304		0.6394		0.9842		0.5733		0.9957	0.8792		tp=0.63, tn=0.19, fp=0.1, fn=0.069		True
	36	0.05959		0.7886		0.9877		0.5145		0.9966	0.8641		tp=0.62, tn=0.18, fp=0.1, fn=0.091		False
	37	0.058		0.8094		0.9877		0.4889		0.9966	0.8544		tp=0.61, tn=0.18, fp=0.11, fn=0.097		False
	38	0.05761		0.7947		0.986		0.4641		0.9961	0.8571		tp=0.63, tn=0.16, fp=0.12, fn=0.091		False
	39	0.0513		0.7452		0.9912		0.5822		0.9976	0.8857		tp=0.65, tn=0.19, fp=0.1, fn=0.062		True
	40	0.04937		0.9008		0.9912		0.4959		0.9976	0.8515		tp=0.6, tn=0.19, fp=0.12, fn=0.091		False
	41	0.04826		0.9256		0.9912		0.5318		0.9976	0.8614		tp=0.61, tn=0.2, fp=0.12, fn=0.077		False
	42	0.04391		0.8408		0.9894		0.4887		0.9971	0.8529		tp=0.61, tn=0.18, fp=0.12, fn=0.091		False
	43	0.04482		0.8182		0.9912		0.4845		0.9976	0.8692		tp=0.65, tn=0.15, fp=0.12, fn=0.077		False
	44	0.04093		0.9403		0.9929		0.4711		0.9981	0.8488		tp=0.61, tn=0.17, fp=0.13, fn=0.084		False
	45	0.03894		0.8268		0.993		0.5635		0.9981	0.8713		tp=0.62, tn=0.2, fp=0.1, fn=0.077		False
	46	0.03803		0.9347		0.9912		0.4835		0.9976	0.8458		tp=0.59, tn=0.19, fp=0.13, fn=0.091		False
	47	0.03569		1.006		0.993		0.4545		0.9981	0.8431		tp=0.6, tn=0.17, fp=0.13, fn=0.098		False
	48	0.03322		0.8598		0.9948		0.4856		0.9986	0.8612		tp=0.63, tn=0.17, fp=0.11, fn=0.091		False
	49	0.03398		0.9277		0.993		0.4873		0.9981	0.8612		tp=0.63, tn=0.17, fp=0.12, fn=0.084		False
	50	0.03295		1.013		0.9948		0.4396		0.9986	0.8462		tp=0.62, tn=0.16, fp=0.13, fn=0.091		False
	51	0.03022		0.977		0.993		0.4908		0.9981	0.8529		tp=0.61, tn=0.18, fp=0.13, fn=0.084		False
	52	0.03013		0.984		0.993		0.4729		0.9981	0.8571		tp=0.62, tn=0.17, fp=0.11, fn=0.097		False
	53	0.02901		0.9443		0.9948		0.47		0.9986	0.8502		tp=0.61, tn=0.17, fp=0.12, fn=0.09		False
	54	0.02947		1.131		0.9947		0.4722		0.9986	0.8638		tp=0.64, tn=0.15, fp=0.13, fn=0.077		False
	55	0.02728		1.099		0.9947		0.509		0.9986	0.8585		tp=0.62, tn=0.18, fp=0.13, fn=0.07		False
	56	0.02789		0.9567		0.9947		0.4929		0.9986	0.8599		tp=0.62, tn=0.17, fp=0.1, fn=0.098		False
	57	0.02715		0.9332		0.993		0.4814		0.9981	0.8626		tp=0.64, tn=0.16, fp=0.13, fn=0.077		False
	58	0.02424		1.057		0.9948		0.5243		0.9986	0.8641		tp=0.62, tn=0.19, fp=0.11, fn=0.083		False
	59	0.02448		0.9881		0.9895		0.536		0.9971	0.86		tp=0.6, tn=0.2, fp=0.11, fn=0.084		False
	60	0.02389		1.015		0.9948		0.4517		0.9985	0.8517		tp=0.62, tn=0.16, fp=0.13, fn=0.091		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		55
learning rate		0.00168930295807
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_72-lr0.0017-h_size55-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.575		0.5718		0.2153		0.2827		0.8201	0.7971		tp=0.58, tn=0.13, fp=0.19, fn=0.1		True
	2	0.5295		0.5758		0.3383		0.2604		0.834	0.8178		tp=0.64, tn=0.078, fp=0.24, fn=0.043		False
	3	0.4982		0.5543		0.393		0.3087		0.8436	0.8112		tp=0.6, tn=0.12, fp=0.2, fn=0.079		True
	4	0.4831		0.5363		0.4075		0.2351		0.8451	0.81		tp=0.62, tn=0.086, fp=0.23, fn=0.064		False
	5	0.4457		0.5802		0.4829		0.267		0.8608	0.8248		tp=0.66, tn=0.061, fp=0.26, fn=0.022		False
	6	0.4235		0.5619		0.511		0.2491		0.8658	0.7877		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	7	0.3982		0.5296		0.5539		0.2988		0.8757	0.8104		tp=0.6, tn=0.12, fp=0.2, fn=0.077		False
	8	0.3674		0.5665		0.6026		0.3028		0.8875	0.7933		tp=0.56, tn=0.15, fp=0.17, fn=0.12		False
	9	0.3339		0.5547		0.6628		0.3446		0.9029	0.8182		tp=0.6, tn=0.14, fp=0.18, fn=0.081		True
	10	0.3114		0.6652		0.7017		0.263		0.914	0.8209		tp=0.65, tn=0.064, fp=0.26, fn=0.025		False
	11	0.2811		0.615		0.7366		0.334		0.923	0.8091		tp=0.58, tn=0.15, fp=0.17, fn=0.099		False
	12	0.2639		0.6576		0.747		0.3353		0.9255	0.7962		tp=0.55, tn=0.16, fp=0.16, fn=0.13		False
	13	0.2275		0.6549		0.8039		0.3553		0.9417	0.8196		tp=0.59, tn=0.14, fp=0.17, fn=0.09		True
	14	0.2046		0.6489		0.8436		0.3887		0.9532	0.8281		tp=0.6, tn=0.15, fp=0.18, fn=0.074		True
	15	0.18		0.6924		0.8626		0.3774		0.9587	0.8094		tp=0.56, tn=0.17, fp=0.15, fn=0.12		False
	16	0.1577		0.7601		0.8884		0.3397		0.9664	0.8272		tp=0.62, tn=0.12, fp=0.19, fn=0.068		False
	17	0.1468		0.7501		0.8981		0.3795		0.9692	0.8164		tp=0.58, tn=0.16, fp=0.15, fn=0.11		False
	18	0.1206		0.7826		0.9332		0.3835		0.9797	0.8152		tp=0.57, tn=0.17, fp=0.15, fn=0.11		False
	19	0.1199		0.7658		0.9322		0.3662		0.9795	0.7852		tp=0.52, tn=0.2, fp=0.12, fn=0.16		False
	20	0.0986		0.8491		0.9532		0.3677		0.9857	0.8224		tp=0.6, tn=0.15, fp=0.17, fn=0.084		False
	21	0.08323		0.8417		0.9602		0.4061		0.9878	0.8215		tp=0.58, tn=0.17, fp=0.15, fn=0.1		True
	22	0.07481		0.9087		0.9675		0.3264		0.9901	0.7807		tp=0.53, tn=0.18, fp=0.14, fn=0.15		False
	23	0.0652		0.954		0.9749		0.3804		0.9923	0.823		tp=0.59, tn=0.15, fp=0.17, fn=0.087		False
	24	0.06305		0.997		0.9758		0.3616		0.9926	0.7682		tp=0.49, tn=0.21, fp=0.11, fn=0.19		False
	25	0.06365		0.9817		0.9732		0.3644		0.9918	0.8232		tp=0.6, tn=0.14, fp=0.17, fn=0.083		False
	26	0.05974		0.9136		0.9788		0.3651		0.9935	0.8068		tp=0.56, tn=0.17, fp=0.15, fn=0.12		False
	27	0.05397		0.9766		0.978		0.3558		0.9932	0.7943		tp=0.54, tn=0.18, fp=0.14, fn=0.14		False
	28	0.0465		1.029		0.984		0.3471		0.9951	0.7948		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	29	0.05057		1		0.9818		0.3502		0.9944	0.7987		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	30	0.04629		1.035		0.9823		0.3627		0.9946	0.8047		tp=0.56, tn=0.17, fp=0.15, fn=0.12		False
	31	0.04806		1.009		0.981		0.3652		0.9942	0.8039		tp=0.56, tn=0.17, fp=0.14, fn=0.13		False
	32	0.04647		1.154		0.9814		0.3395		0.9943	0.8091		tp=0.58, tn=0.15, fp=0.17, fn=0.11		False
	33	0.04192		1.065		0.9836		0.3667		0.995	0.8		tp=0.55, tn=0.18, fp=0.14, fn=0.14		False
	34	0.04188		1.111		0.984		0.3519		0.9951	0.8025		tp=0.56, tn=0.17, fp=0.16, fn=0.12		False
	35	0.03784		1.136		0.9853		0.3687		0.9955	0.8158		tp=0.58, tn=0.16, fp=0.16, fn=0.1		False
	36	0.03404		1.152		0.9853		0.4155		0.9955	0.8209		tp=0.57, tn=0.18, fp=0.14, fn=0.11		True
	37	0.03675		1.228		0.9857		0.3482		0.9956	0.8175		tp=0.59, tn=0.14, fp=0.18, fn=0.087		False
	38	0.0433		1.006		0.981		0.3795		0.9942	0.8081		tp=0.56, tn=0.18, fp=0.14, fn=0.12		False
	39	0.05983		1.012		0.9654		0.3853		0.9894	0.8192		tp=0.58, tn=0.16, fp=0.16, fn=0.099		False
	40	0.079		1.043		0.9502		0.3586		0.9848	0.7858		tp=0.52, tn=0.19, fp=0.12, fn=0.16		False
	41	0.04747		1.047		0.9823		0.3405		0.9946	0.7931		tp=0.54, tn=0.17, fp=0.15, fn=0.14		False
	42	0.03762		1.093		0.9857		0.4118		0.9956	0.8155		tp=0.56, tn=0.19, fp=0.13, fn=0.12		False
	43	0.03431		1.131		0.9888		0.3883		0.9965	0.8124		tp=0.56, tn=0.18, fp=0.14, fn=0.12		False
	44	0.03383		1.143		0.9836		0.3973		0.995	0.8198		tp=0.58, tn=0.17, fp=0.15, fn=0.1		False
	45	0.03269		1.119		0.9879		0.4009		0.9963	0.8		tp=0.53, tn=0.2, fp=0.12, fn=0.15		False
	46	0.03869		1.207		0.9819		0.3483		0.9944	0.7419		tp=0.46, tn=0.22, fp=0.098, fn=0.22		False
	47	0.04437		1.116		0.9827		0.3911		0.9947	0.8069		tp=0.55, tn=0.19, fp=0.13, fn=0.13		False
	48	0.06238		1.104		0.9628		0.4055		0.9886	0.8171		tp=0.57, tn=0.18, fp=0.13, fn=0.12		False
	49	0.03544		1.175		0.9892		0.3787		0.9967	0.8168		tp=0.58, tn=0.16, fp=0.16, fn=0.1		False
	50	0.03007		1.145		0.9888		0.4016		0.9965	0.804		tp=0.54, tn=0.2, fp=0.12, fn=0.14		False
	51	0.02879		1.25		0.9909		0.3513		0.9972	0.8207		tp=0.6, tn=0.14, fp=0.18, fn=0.083		False
	52	0.02971		1.195		0.9884		0.3795		0.9964	0.8081		tp=0.56, tn=0.18, fp=0.14, fn=0.12		False
	53	0.02882		1.202		0.9888		0.3891		0.9965	0.8224		tp=0.59, tn=0.16, fp=0.16, fn=0.093		False
	54	0.03164		1.26		0.9879		0.3816		0.9963	0.7974		tp=0.54, tn=0.19, fp=0.13, fn=0.15		False
	55	0.03484		1.198		0.9849		0.3679		0.9954	0.8138		tp=0.58, tn=0.16, fp=0.16, fn=0.1		False
	56	0.05398		1.105		0.9727		0.3754		0.9917	0.7929		tp=0.53, tn=0.19, fp=0.13, fn=0.15		False
	57	0.06277		1.118		0.9675		0.367		0.9901	0.7871		tp=0.52, tn=0.19, fp=0.13, fn=0.16		False


data			/scratch/asw462/data/levin
input size		300
hidden size		128
learning rate		0.000297466796329
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_73-lr0.0003-h_size128-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5792		0.5772		0.02032		0		0.8404	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.56		0.5788		0.06134		0		0.8439	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	3	0.5381		0.5439		0.1221		0		0.8439	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	4	0.5194		0.5604		0.2008		0.2631		0.8487	0.8198		tp=0.63, tn=0.09, fp=0.22, fn=0.062		True
	5	0.4988		0.5517		0.2929		0.05617		0.8564	0.8313		tp=0.71, tn=0.007, fp=0.28, fn=0.007		False
	6	0.4766		0.531		0.3492		0.2122		0.8629	0.834		tp=0.69, tn=0.042, fp=0.25, fn=0.021		False
	7	0.4543		0.5341		0.4202		0.3143		0.8735	0.8241		tp=0.62, tn=0.11, fp=0.2, fn=0.07		True
	8	0.4331		0.5175		0.4631		0.3408		0.8803	0.8393		tp=0.66, tn=0.091, fp=0.22, fn=0.035		True
	9	0.4141		0.5255		0.5283		0.251		0.8906	0.8282		tp=0.66, tn=0.07, fp=0.23, fn=0.042		False
	10	0.4054		0.5121		0.5449		0.3402		0.8921	0.8407		tp=0.66, tn=0.084, fp=0.22, fn=0.028		False
	11	0.3869		0.4836		0.5602		0.3959		0.897	0.8559		tp=0.66, tn=0.11, fp=0.17, fn=0.049		True
	12	0.3678		0.5377		0.5953		0.3655		0.9025	0.8416		tp=0.65, tn=0.1, fp=0.2, fn=0.042		False
	13	0.3533		0.5213		0.6174		0.3397		0.9069	0.843		tp=0.66, tn=0.098, fp=0.2, fn=0.049		False
	14	0.3333		0.5151		0.6556		0.437		0.9157	0.8421		tp=0.62, tn=0.15, fp=0.17, fn=0.063		True
	15	0.3288		0.5064		0.6338		0.44		0.9081	0.8584		tp=0.66, tn=0.13, fp=0.17, fn=0.042		True
	16	0.3086		0.5145		0.6909		0.461		0.9229	0.8624		tp=0.66, tn=0.13, fp=0.17, fn=0.042		True
	17	0.2992		0.5207		0.7167		0.3905		0.9283	0.8341		tp=0.62, tn=0.14, fp=0.17, fn=0.07		False
	18	0.2873		0.5151		0.714		0.3783		0.9271	0.8426		tp=0.64, tn=0.13, fp=0.17, fn=0.07		False
	19	0.2731		0.547		0.742		0.4341		0.934	0.839		tp=0.6, tn=0.17, fp=0.13, fn=0.098		False
	20	0.2646		0.5731		0.7311		0.3698		0.9308	0.8302		tp=0.62, tn=0.13, fp=0.18, fn=0.07		False
	21	0.2556		0.5224		0.7705		0.4226		0.9401	0.8241		tp=0.57, tn=0.18, fp=0.11, fn=0.13		False
	22	0.2512		0.5361		0.7604		0.4596		0.9373	0.8598		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	23	0.2359		0.5375		0.7878		0.4494		0.9444	0.8661		tp=0.67, tn=0.12, fp=0.17, fn=0.035		False
	24	0.2269		0.6164		0.819		0.3356		0.9523	0.8444		tp=0.66, tn=0.091, fp=0.2, fn=0.042		False
	25	0.2345		0.6873		0.7872		0.3717		0.9447	0.8496		tp=0.67, tn=0.091, fp=0.21, fn=0.028		False
	26	0.2332		0.6292		0.7875		0.404		0.9441	0.8571		tp=0.67, tn=0.1, fp=0.19, fn=0.035		False
	27	0.2096		0.6323		0.8287		0.4112		0.9545	0.8479		tp=0.64, tn=0.13, fp=0.18, fn=0.049		False
	28	0.1961		0.5704		0.8413		0.3856		0.9577	0.8426		tp=0.63, tn=0.13, fp=0.16, fn=0.076		False
	29	0.1896		0.6396		0.8369		0.4017		0.9577	0.8622		tp=0.68, tn=0.1, fp=0.17, fn=0.042		False
	30	0.1863		0.6393		0.8643		0.4756		0.9639	0.8502		tp=0.62, tn=0.17, fp=0.15, fn=0.063		True
	31	0.1831		0.6522		0.8581		0.463		0.9626	0.8611		tp=0.65, tn=0.14, fp=0.16, fn=0.049		False
	32	0.177		0.5998		0.852		0.4921		0.9612	0.8692		tp=0.65, tn=0.15, fp=0.13, fn=0.063		True
	33	0.1748		0.715		0.8583		0.3725		0.9618	0.852		tp=0.66, tn=0.1, fp=0.18, fn=0.049		False
	34	0.164		0.7064		0.8873		0.3997		0.9692	0.8309		tp=0.6, tn=0.15, fp=0.16, fn=0.084		False
	35	0.1542		0.612		0.891		0.4566		0.971	0.8727		tp=0.67, tn=0.13, fp=0.13, fn=0.07		False
	36	0.1495		0.7033		0.9059		0.445		0.9747	0.8558		tp=0.64, tn=0.14, fp=0.16, fn=0.056		False
	37	0.1521		0.7046		0.8794		0.431		0.9676	0.8406		tp=0.61, tn=0.16, fp=0.15, fn=0.084		False
	38	0.1417		0.68		0.8974		0.4329		0.9722	0.8558		tp=0.64, tn=0.14, fp=0.15, fn=0.07		False
	39	0.1376		0.6657		0.9098		0.4711		0.9756	0.8488		tp=0.61, tn=0.17, fp=0.13, fn=0.084		False
	40	0.1321		0.7001		0.9203		0.4545		0.9785	0.8598		tp=0.64, tn=0.15, fp=0.14, fn=0.07		False
	41	0.1399		0.873		0.9001		0.3733		0.9733	0.8496		tp=0.67, tn=0.097, fp=0.2, fn=0.035		False
	42	0.1409		0.7943		0.8923		0.3738		0.9707	0.8357		tp=0.62, tn=0.13, fp=0.17, fn=0.077		False
	43	0.1373		0.7157		0.8889		0.4767		0.9698	0.8651		tp=0.65, tn=0.15, fp=0.15, fn=0.056		False
	44	0.115		0.645		0.9511		0.4971		0.9865	0.8744		tp=0.66, tn=0.15, fp=0.11, fn=0.077		True
	45	0.1169		0.7079		0.9269		0.485		0.9804	0.8626		tp=0.64, tn=0.16, fp=0.13, fn=0.07		False
	46	0.1125		0.7472		0.9349		0.4709		0.9822	0.8651		tp=0.65, tn=0.15, fp=0.14, fn=0.063		False
	47	0.1113		0.9783		0.9346		0.4511		0.9823	0.8597		tp=0.66, tn=0.12, fp=0.19, fn=0.028		False
	48	0.122		0.8461		0.9		0.446		0.9733	0.8505		tp=0.63, tn=0.15, fp=0.17, fn=0.056		False
	49	0.1017		0.8237		0.9453		0.4385		0.9851	0.8558		tp=0.64, tn=0.14, fp=0.15, fn=0.063		False
	50	0.09265		0.7519		0.9559		0.4657		0.988	0.8598		tp=0.64, tn=0.15, fp=0.15, fn=0.056		False
	51	0.09053		0.8422		0.9541		0.3973		0.9875	0.8341		tp=0.62, tn=0.14, fp=0.18, fn=0.063		False
	52	0.09227		0.648		0.9576		0.4856		0.9885	0.8612		tp=0.63, tn=0.17, fp=0.11, fn=0.091		False
	53	0.09285		0.883		0.9491		0.4524		0.986	0.8624		tp=0.66, tn=0.13, fp=0.16, fn=0.049		False
	54	0.08999		0.8977		0.9485		0.4329		0.9861	0.8558		tp=0.64, tn=0.14, fp=0.15, fn=0.07		False
	55	0.08196		0.9997		0.9598		0.3797		0.9889	0.8357		tp=0.62, tn=0.13, fp=0.17, fn=0.07		False
	56	0.08054		0.8215		0.9667		0.4005		0.9908	0.8545		tp=0.65, tn=0.12, fp=0.15, fn=0.069		False
	57	0.07767		0.9092		0.9719		0.4541		0.9923	0.8476		tp=0.62, tn=0.15, fp=0.17, fn=0.056		False
	58	0.07421		0.8248		0.9702		0.5054		0.9918	0.8667		tp=0.64, tn=0.17, fp=0.13, fn=0.07		True
	59	0.07472		0.9351		0.9684		0.4596		0.9913	0.8598		tp=0.64, tn=0.15, fp=0.15, fn=0.063		False
	60	0.07101		0.9826		0.9773		0.3879		0.9937	0.8559		tp=0.66, tn=0.12, fp=0.15, fn=0.069		False
	61	0.07188		0.9564		0.9649		0.4066		0.9904	0.8465		tp=0.64, tn=0.13, fp=0.17, fn=0.063		False
	62	0.06568		0.9851		0.9806		0.4276		0.9947	0.8571		tp=0.65, tn=0.13, fp=0.15, fn=0.063		False
	63	0.06215		0.8607		0.9806		0.4667		0.9947	0.8789		tp=0.69, tn=0.13, fp=0.13, fn=0.056		False
	64	0.06227		1.016		0.9773		0.441		0.9937	0.8636		tp=0.66, tn=0.13, fp=0.16, fn=0.049		False
	65	0.06664		1.043		0.9753		0.438		0.9933	0.8491		tp=0.63, tn=0.15, fp=0.16, fn=0.063		False
	66	0.05957		1.1		0.9771		0.4426		0.9938	0.8505		tp=0.64, tn=0.14, fp=0.17, fn=0.049		False
	67	0.05371		0.9464		0.9876		0.4879		0.9966	0.8704		tp=0.66, tn=0.15, fp=0.14, fn=0.056		False
	68	0.05417		1.095		0.9877		0.4109		0.9966	0.8381		tp=0.62, tn=0.15, fp=0.17, fn=0.07		False
	69	0.05808		1.137		0.9807		0.373		0.9947	0.8571		tp=0.67, tn=0.1, fp=0.17, fn=0.056		False
	70	0.05376		0.8412		0.9807		0.4862		0.9947	0.8638		tp=0.64, tn=0.16, fp=0.13, fn=0.069		False
	71	0.05929		1.147		0.97		0.4385		0.9918	0.8558		tp=0.64, tn=0.14, fp=0.15, fn=0.063		False
	72	0.0562		1.268		0.9719		0.4246		0.9923	0.8451		tp=0.63, tn=0.14, fp=0.17, fn=0.056		False
	73	0.04953		1.083		0.9859		0.4545		0.9961	0.8598		tp=0.64, tn=0.15, fp=0.14, fn=0.07		False
	74	0.04678		1.096		0.9894		0.4752		0.9971	0.8585		tp=0.64, tn=0.15, fp=0.15, fn=0.056		False
	75	0.04497		1.09		0.9894		0.4543		0.9971	0.8517		tp=0.62, tn=0.16, fp=0.13, fn=0.084		False
	76	0.04295		1.033		0.9895		0.4556		0.9971	0.8611		tp=0.65, tn=0.14, fp=0.15, fn=0.056		False
	77	0.04179		1.099		0.993		0.4218		0.9981	0.8421		tp=0.62, tn=0.15, fp=0.15, fn=0.084		False
	78	0.04309		1.091		0.9895		0.4276		0.9971	0.8571		tp=0.65, tn=0.13, fp=0.15, fn=0.063		False
	79	0.03945		1.289		0.993		0.4718		0.9981	0.8531		tp=0.63, tn=0.15, fp=0.17, fn=0.049		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		53
learning rate		0.00433052791406
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_74-lr0.0043-h_size53-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6887		0.6833		0.08602		0.1143		0.5575	0.5257		tp=0.25, tn=0.3, fp=0.17, fn=0.28		True
	2	0.6647		0.668		0.2007		0.2148		0.617	0.6592		tp=0.38, tn=0.23, fp=0.24, fn=0.15		True
	3	0.6417		0.6912		0.2582		0.1591		0.6391	0.664		tp=0.42, tn=0.16, fp=0.33, fn=0.097		False
	4	0.6274		0.6742		0.3251		0.1938		0.6821	0.5827		tp=0.28, tn=0.31, fp=0.16, fn=0.25		False
	5	0.6108		0.7235		0.3321		0.1505		0.6749	0.4788		tp=0.2, tn=0.36, fp=0.12, fn=0.32		False
	6	0.6003		0.6955		0.367		0.1916		0.6922	0.5699		tp=0.27, tn=0.32, fp=0.15, fn=0.26		False
	7	0.5844		0.71		0.3973		0.1205		0.7096	0.5839		tp=0.31, tn=0.25, fp=0.22, fn=0.22		False
	8	0.5784		0.6919		0.396		0.1042		0.7065	0.6417		tp=0.39, tn=0.16, fp=0.31, fn=0.13		False
	9	0.5637		0.7219		0.4251		0.1233		0.7224	0.5671		tp=0.29, tn=0.27, fp=0.21, fn=0.23		False
	10	0.5514		0.7108		0.4451		0.1454		0.7301	0.6224		tp=0.35, tn=0.23, fp=0.24, fn=0.18		False
	11	0.5401		0.7232		0.4556		0.1153		0.7398	0.5506		tp=0.27, tn=0.28, fp=0.2, fn=0.25		False
	12	0.5196		0.7022		0.4969		0.2286		0.758	0.6621		tp=0.37, tn=0.24, fp=0.23, fn=0.16		True
	13	0.5009		0.7414		0.5083		0.1862		0.7593	0.5939		tp=0.3, tn=0.29, fp=0.18, fn=0.23		False
	14	0.4889		0.756		0.5367		0.2177		0.7747	0.6071		tp=0.3, tn=0.3, fp=0.16, fn=0.23		False
	15	0.4594		0.7679		0.5709		0.232		0.7904	0.6461		tp=0.35, tn=0.27, fp=0.21, fn=0.18		True
	16	0.4382		0.8096		0.6011		0.1971		0.8045	0.5985		tp=0.3, tn=0.3, fp=0.18, fn=0.22		False
	17	0.4049		0.8442		0.6428		0.1955		0.8275	0.5691		tp=0.27, tn=0.32, fp=0.15, fn=0.26		False
	18	0.3904		0.8518		0.6627		0.1969		0.8323	0.6355		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	19	0.3572		0.9214		0.7175		0.1778		0.8606	0.6098		tp=0.32, tn=0.27, fp=0.22, fn=0.19		False
	20	0.326		0.9176		0.7476		0.2267		0.876	0.6445		tp=0.35, tn=0.27, fp=0.21, fn=0.18		False
	21	0.3012		0.9456		0.7785		0.2342		0.892	0.6637		tp=0.38, tn=0.24, fp=0.24, fn=0.14		True
	22	0.273		0.9787		0.8097		0.1707		0.9066	0.6158		tp=0.33, tn=0.26, fp=0.22, fn=0.19		False
	23	0.2372		1.032		0.8617		0.1785		0.932	0.6005		tp=0.31, tn=0.28, fp=0.19, fn=0.22		False
	24	0.2199		1.06		0.8653		0.1848		0.9336	0.6308		tp=0.35, tn=0.25, fp=0.21, fn=0.19		False
	25	0.1954		1.154		0.8936		0.2341		0.9476	0.6667		tp=0.38, tn=0.23, fp=0.25, fn=0.13		False
	26	0.1801		1.122		0.909		0.1887		0.9553	0.622		tp=0.33, tn=0.26, fp=0.21, fn=0.19		False
	27	0.1582		1.158		0.9338		0.2088		0.9674	0.628		tp=0.33, tn=0.27, fp=0.22, fn=0.18		False
	28	0.1374		1.253		0.9456		0.2114		0.9733	0.6071		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	29	0.1234		1.247		0.9586		0.2168		0.9796	0.6051		tp=0.3, tn=0.31, fp=0.17, fn=0.22		False
	30	0.1111		1.247		0.9645		0.2517		0.9825	0.626		tp=0.31, tn=0.31, fp=0.16, fn=0.21		True
	31	0.1012		1.333		0.9705		0.182		0.9855	0.5918		tp=0.3, tn=0.29, fp=0.18, fn=0.23		False
	32	0.08735		1.268		0.9764		0.2096		0.9883	0.628		tp=0.33, tn=0.27, fp=0.2, fn=0.19		False
	33	0.08048		1.374		0.9817		0.1993		0.991	0.6119		tp=0.32, tn=0.28, fp=0.2, fn=0.2		False
	34	0.0699		1.362		0.9829		0.2185		0.9916	0.6293		tp=0.33, tn=0.28, fp=0.19, fn=0.2		False
	35	0.06404		1.404		0.9894		0.2198		0.9947	0.6238		tp=0.32, tn=0.29, fp=0.19, fn=0.2		False
	36	0.06084		1.428		0.9852		0.2207		0.9927	0.6447		tp=0.35, tn=0.26, fp=0.21, fn=0.18		False
	37	0.05934		1.466		0.987		0.2065		0.9936	0.6419		tp=0.35, tn=0.25, fp=0.23, fn=0.17		False
	38	0.05712		1.534		0.987		0.2134		0.9936	0.6091		tp=0.31, tn=0.3, fp=0.18, fn=0.21		False
	39	0.05406		1.504		0.9882		0.2121		0.9942	0.6111		tp=0.31, tn=0.29, fp=0.18, fn=0.22		False
	40	0.0491		1.483		0.9894		0.2363		0.9948	0.6357		tp=0.33, tn=0.29, fp=0.19, fn=0.19		False
	41	0.04745		1.641		0.9858		0.1926		0.993	0.618		tp=0.33, tn=0.27, fp=0.21, fn=0.2		False
	42	0.04444		1.57		0.9882		0.2037		0.9942	0.6283		tp=0.34, tn=0.27, fp=0.2, fn=0.19		False
	43	0.04136		1.523		0.9894		0.2361		0.9948	0.6526		tp=0.36, tn=0.26, fp=0.21, fn=0.17		False
	44	0.04106		1.665		0.9876		0.1685		0.9939	0.6087		tp=0.32, tn=0.26, fp=0.21, fn=0.21		False
	45	0.03899		1.689		0.9876		0.19		0.9939	0.6146		tp=0.32, tn=0.27, fp=0.21, fn=0.2		False
	46	0.03928		1.665		0.99		0.1978		0.9951	0.6025		tp=0.3, tn=0.29, fp=0.19, fn=0.21		False
	47	0.03728		1.759		0.9911		0.1795		0.9956	0.6313		tp=0.35, tn=0.24, fp=0.24, fn=0.17		False
	48	0.03408		1.763		0.9929		0.2048		0.9965	0.6318		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	49	0.03473		1.745		0.987		0.2264		0.9936	0.6234		tp=0.32, tn=0.29, fp=0.18, fn=0.21		False
	50	0.03545		1.844		0.99		0.1898		0.995	0.6291		tp=0.34, tn=0.25, fp=0.23, fn=0.17		False
	51	0.03521		1.725		0.99		0.2244		0.995	0.6413		tp=0.35, tn=0.27, fp=0.21, fn=0.18		False


data			/scratch/asw462/data/levin
input size		300
hidden size		53
learning rate		0.000528437782369
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_75-lr0.00053-h_size53-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5941		0.606		-0.001522		0		0.8316	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.5757		0.5865		0		0		0.843	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5692		0.5937		0		0		0.8416	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	4	0.5669		0.5869		0.0697		0.05176		0.8417	0.8216		tp=0.69, tn=0.007, fp=0.29, fn=0.007		True
	5	0.5565		0.5826		0.118		-0.0532		0.8444	0.8279		tp=0.71, tn=0, fp=0.29, fn=0.007		False
	6	0.5557		0.5661		0.143		0.1262		0.8446	0.8395		tp=0.71, tn=0.014, fp=0.27, fn=0.007		True
	7	0.5474		0.5986		0.1781		0.1627		0.8466	0.8155		tp=0.66, tn=0.035, fp=0.28, fn=0.021		True
	8	0.546		0.5704		0.1672		0.123		0.846	0.8347		tp=0.71, tn=0.014, fp=0.27, fn=0.007		False
	9	0.5385		0.5795		0.2176		0.2006		0.8507	0.827		tp=0.68, tn=0.035, fp=0.27, fn=0.014		True
	10	0.5341		0.5692		0.2032		0.1765		0.8479	0.8382		tp=0.7, tn=0.028, fp=0.26, fn=0.014		False
	11	0.5285		0.5782		0.2415		0.1428		0.8505	0.8319		tp=0.69, tn=0.028, fp=0.26, fn=0.021		False
	12	0.5237		0.5743		0.2473		0.2172		0.8529	0.8326		tp=0.68, tn=0.049, fp=0.24, fn=0.028		True
	13	0.5206		0.5822		0.2738		0.1392		0.8544	0.8155		tp=0.66, tn=0.035, fp=0.27, fn=0.028		False
	14	0.5164		0.6037		0.2588		0.1206		0.8516	0.8186		tp=0.68, tn=0.021, fp=0.29, fn=0.014		False
	15	0.5117		0.585		0.272		0.1867		0.8546	0.8261		tp=0.66, tn=0.056, fp=0.23, fn=0.049		False
	16	0.5079		0.5875		0.2756		0.1699		0.8539	0.8225		tp=0.66, tn=0.049, fp=0.24, fn=0.042		False
	17	0.5057		0.5858		0.2729		0.1909		0.8519	0.8091		tp=0.62, tn=0.084, fp=0.2, fn=0.098		False
	18	0.5045		0.6		0.2765		0.1261		0.8523	0.8087		tp=0.65, tn=0.042, fp=0.27, fn=0.042		False
	19	0.4979		0.6183		0.2996		0.07679		0.8535	0.8069		tp=0.66, tn=0.028, fp=0.28, fn=0.035		False
	20	0.4935		0.5672		0.2986		0.2722		0.8543	0.837		tp=0.66, tn=0.077, fp=0.21, fn=0.049		True
	21	0.4911		0.5773		0.3301		0.2095		0.8584	0.8246		tp=0.66, tn=0.063, fp=0.23, fn=0.049		False
	22	0.4896		0.5983		0.3271		0.2108		0.8573	0.821		tp=0.66, tn=0.056, fp=0.25, fn=0.035		False
	23	0.4843		0.6263		0.3276		0.1964		0.8573	0.819		tp=0.66, tn=0.042, fp=0.27, fn=0.021		False
	24	0.4748		0.6326		0.3461		0.05484		0.8606	0.8017		tp=0.65, tn=0.028, fp=0.28, fn=0.042		False
	25	0.4732		0.6258		0.3429		0.1479		0.8617	0.8053		tp=0.64, tn=0.056, fp=0.25, fn=0.056		False
	26	0.4777		0.619		0.3104		0.2103		0.8531	0.8142		tp=0.64, tn=0.063, fp=0.25, fn=0.042		False
	27	0.4682		0.6257		0.3712		0.217		0.8606	0.8261		tp=0.66, tn=0.056, fp=0.24, fn=0.035		False
	28	0.4663		0.5581		0.3442		0.2453		0.858	0.8412		tp=0.68, tn=0.062, fp=0.22, fn=0.042		False
	29	0.465		0.5915		0.3428		0.2569		0.8571	0.8267		tp=0.65, tn=0.077, fp=0.22, fn=0.049		False
	30	0.4628		0.5833		0.3761		0.1984		0.8629	0.8261		tp=0.66, tn=0.062, fp=0.22, fn=0.056		False
	31	0.4589		0.6167		0.3858		0.2095		0.8633	0.8246		tp=0.66, tn=0.063, fp=0.23, fn=0.049		False
	32	0.4574		0.6093		0.3886		0.2478		0.8642	0.8362		tp=0.68, tn=0.056, fp=0.24, fn=0.028		False
	33	0.4511		0.6204		0.4273		0.2629		0.8711	0.8214		tp=0.64, tn=0.077, fp=0.24, fn=0.042		False
	34	0.4493		0.6038		0.3913		0.1346		0.8647	0.8305		tp=0.69, tn=0.035, fp=0.24, fn=0.035		False
	35	0.4457		0.5924		0.3792		0.1888		0.8627	0.7867		tp=0.58, tn=0.1, fp=0.17, fn=0.14		False
	36	0.4518		0.575		0.3921		0.3072		0.866	0.8341		tp=0.65, tn=0.091, fp=0.21, fn=0.049		True
	37	0.4405		0.6202		0.4201		0.203		0.8684	0.8037		tp=0.62, tn=0.084, fp=0.22, fn=0.077		False
	38	0.4392		0.6246		0.4119		0.1547		0.8679	0.8089		tp=0.64, tn=0.063, fp=0.23, fn=0.07		False
	39	0.4356		0.5873		0.4229		0.1617		0.8677	0.8276		tp=0.67, tn=0.049, fp=0.23, fn=0.049		False
	40	0.4389		0.6274		0.4479		0.1968		0.8739	0.8072		tp=0.63, tn=0.07, fp=0.24, fn=0.056		False
	41	0.4396		0.6087		0.4377		0.1902		0.869	0.8178		tp=0.64, tn=0.07, fp=0.22, fn=0.07		False
	42	0.4319		0.6319		0.4405		0.1777		0.872	0.8		tp=0.62, tn=0.077, fp=0.23, fn=0.077		False
	43	0.4341		0.5884		0.4389		0.2096		0.8704	0.8161		tp=0.64, tn=0.077, fp=0.22, fn=0.07		False
	44	0.4245		0.6385		0.4641		0.1373		0.8776	0.7928		tp=0.61, tn=0.069, fp=0.24, fn=0.083		False
	45	0.4335		0.6498		0.4542		0.244		0.8732	0.823		tp=0.65, tn=0.07, fp=0.24, fn=0.042		False
	46	0.4257		0.6216		0.4583		0.2302		0.872	0.8297		tp=0.66, tn=0.063, fp=0.23, fn=0.042		False
	47	0.4278		0.6183		0.4563		0.2732		0.8747	0.8333		tp=0.66, tn=0.07, fp=0.23, fn=0.035		False
	48	0.4183		0.6995		0.4682		0.1369		0.8761	0.7965		tp=0.62, tn=0.056, fp=0.26, fn=0.056		False
	49	0.4159		0.6666		0.4787		0.11		0.8773	0.7721		tp=0.58, tn=0.077, fp=0.24, fn=0.1		False
	50	0.4208		0.6276		0.4928		0.1466		0.8805	0.789		tp=0.6, tn=0.077, fp=0.23, fn=0.091		False
	51	0.4138		0.6621		0.4724		0.164		0.8738	0.8174		tp=0.66, tn=0.049, fp=0.25, fn=0.042		False
	52	0.4175		0.6606		0.4838		0.1094		0.8765	0.8		tp=0.63, tn=0.056, fp=0.24, fn=0.077		False
	53	0.4177		0.6431		0.46		0.1865		0.8739	0.7887		tp=0.59, tn=0.098, fp=0.2, fn=0.11		False
	54	0.4034		0.6443		0.5069		0.1186		0.8835	0.7596		tp=0.55, tn=0.098, fp=0.17, fn=0.17		False
	55	0.4042		0.6308		0.5014		0.1339		0.8819	0.789		tp=0.6, tn=0.077, fp=0.22, fn=0.1		False
	56	0.4104		0.6645		0.4943		0.1348		0.8784	0.7757		tp=0.58, tn=0.084, fp=0.23, fn=0.1		False
	57	0.4144		0.6459		0.4738		0.1013		0.8735	0.7928		tp=0.62, tn=0.063, fp=0.22, fn=0.098		False


data			/scratch/asw462/data/levin
input size		300
hidden size		16
learning rate		0.00120804630725
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_76-lr0.0012-h_size16-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6054		0.6022		-0.01634		0		0.8317	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.5703		0.6088		0.1146		0.1989		0.8409	0.822		tp=0.68, tn=0.028, fp=0.29, fn=0.007		True
	3	0.5571		0.5905		0.1585		0.1722		0.8415	0.8255		tp=0.68, tn=0.035, fp=0.27, fn=0.021		False
	4	0.5527		0.5768		0.2258		0.2234		0.8467	0.8246		tp=0.66, tn=0.063, fp=0.24, fn=0.042		True
	5	0.5319		0.5551		0.2644		0.17		0.8534	0.8452		tp=0.71, tn=0.035, fp=0.23, fn=0.028		False
	6	0.5268		0.5774		0.3013		0.2849		0.854	0.8267		tp=0.65, tn=0.077, fp=0.24, fn=0.035		True
	7	0.5174		0.5732		0.3177		0.2192		0.8585	0.8161		tp=0.64, tn=0.077, fp=0.22, fn=0.063		False
	8	0.505		0.5393		0.3584		0.2785		0.8615	0.8341		tp=0.65, tn=0.091, fp=0.19, fn=0.07		False
	9	0.49		0.5544		0.3666		0.2371		0.8644	0.8214		tp=0.64, tn=0.083, fp=0.21, fn=0.069		False
	10	0.4781		0.5629		0.4035		0.2292		0.8681	0.8056		tp=0.61, tn=0.098, fp=0.2, fn=0.091		False
	11	0.4714		0.5439		0.4376		0.2277		0.8728	0.8073		tp=0.62, tn=0.091, fp=0.22, fn=0.077		False
	12	0.4655		0.5401		0.4478		0.3227		0.8751	0.8326		tp=0.64, tn=0.098, fp=0.21, fn=0.049		True
	13	0.457		0.5253		0.4466		0.2951		0.8742	0.8304		tp=0.65, tn=0.084, fp=0.22, fn=0.042		False
	14	0.44		0.5279		0.4648		0.2842		0.8792	0.8113		tp=0.6, tn=0.12, fp=0.18, fn=0.098		False
	15	0.4386		0.5284		0.4711		0.3206		0.8763	0.819		tp=0.6, tn=0.13, fp=0.15, fn=0.12		False
	16	0.4341		0.6029		0.4899		0.2764		0.881	0.78		tp=0.55, tn=0.15, fp=0.19, fn=0.12		False
	17	0.4367		0.5364		0.4999		0.2722		0.8837	0.837		tp=0.66, tn=0.077, fp=0.21, fn=0.049		False
	18	0.4086		0.5208		0.5449		0.3419		0.8923	0.8318		tp=0.62, tn=0.13, fp=0.16, fn=0.091		True
	19	0.4014		0.562		0.5257		0.2217		0.8875	0.8091		tp=0.62, tn=0.09, fp=0.21, fn=0.083		False
	20	0.3898		0.5167		0.5542		0.413		0.8943	0.8505		tp=0.64, tn=0.14, fp=0.14, fn=0.084		True
	21	0.382		0.535		0.5851		0.3738		0.9005	0.8357		tp=0.62, tn=0.13, fp=0.17, fn=0.077		False
	22	0.3833		0.567		0.568		0.2691		0.8947	0.8219		tp=0.63, tn=0.098, fp=0.2, fn=0.077		False
	23	0.3783		0.5875		0.5282		0.3685		0.8897	0.81		tp=0.57, tn=0.17, fp=0.14, fn=0.13		False
	24	0.3668		0.5903		0.5813		0.3041		0.8975	0.798		tp=0.57, tn=0.15, fp=0.15, fn=0.14		False
	25	0.3634		0.5548		0.6059		0.305		0.9023	0.8288		tp=0.64, tn=0.097, fp=0.21, fn=0.056		False
	26	0.3608		0.6376		0.6015		0.2431		0.9026	0.8056		tp=0.61, tn=0.098, fp=0.22, fn=0.077		False
	27	0.3414		0.5825		0.6256		0.3688		0.908	0.8269		tp=0.6, tn=0.15, fp=0.15, fn=0.1		False
	28	0.3582		0.5879		0.6152		0.2374		0.9059	0.8182		tp=0.63, tn=0.091, fp=0.2, fn=0.084		False
	29	0.3399		0.5723		0.6084		0.284		0.9032	0.8203		tp=0.62, tn=0.1, fp=0.2, fn=0.077		False
	30	0.3394		0.5942		0.6251		0.2963		0.9088	0.8458		tp=0.67, tn=0.084, fp=0.19, fn=0.056		False
	31	0.3294		0.5865		0.6346		0.4006		0.9098	0.8365		tp=0.61, tn=0.15, fp=0.12, fn=0.12		False
	32	0.326		0.6293		0.6216		0.4273		0.9055	0.8317		tp=0.59, tn=0.17, fp=0.11, fn=0.13		True
	33	0.3212		0.6511		0.6484		0.4183		0.9129	0.7979		tp=0.52, tn=0.21, fp=0.098, fn=0.17		False
	34	0.3387		0.6033		0.6085		0.4555		0.9019	0.8247		tp=0.56, tn=0.2, fp=0.11, fn=0.13		True
	35	0.3302		0.5965		0.646		0.3239		0.9093	0.8444		tp=0.66, tn=0.091, fp=0.2, fn=0.049		False
	36	0.3191		0.5885		0.6645		0.3761		0.9161	0.8493		tp=0.65, tn=0.12, fp=0.16, fn=0.07		False
	37	0.3036		0.6191		0.6778		0.3847		0.9197	0.8341		tp=0.62, tn=0.14, fp=0.17, fn=0.077		False
	38	0.299		0.5357		0.6964		0.485		0.9222	0.8626		tp=0.64, tn=0.16, fp=0.13, fn=0.07		True
	39	0.3091		0.6481		0.6533		0.4119		0.9113	0.8041		tp=0.54, tn=0.19, fp=0.09, fn=0.17		False
	40	0.3156		0.6609		0.6498		0.3973		0.9121	0.8293		tp=0.59, tn=0.16, fp=0.12, fn=0.13		False
	41	0.2939		0.5869		0.688		0.5031		0.9204	0.8585		tp=0.62, tn=0.18, fp=0.12, fn=0.084		True
	42	0.2862		0.5951		0.6994		0.4425		0.9224	0.8462		tp=0.62, tn=0.16, fp=0.14, fn=0.084		False
	43	0.2956		0.7541		0.6844		0.3698		0.9193	0.7624		tp=0.48, tn=0.22, fp=0.098, fn=0.2		False
	44	0.2917		0.6592		0.6791		0.4341		0.9183	0.839		tp=0.6, tn=0.17, fp=0.13, fn=0.098		False
	45	0.2956		0.7183		0.6847		0.4144		0.9191	0.7667		tp=0.48, tn=0.23, fp=0.069, fn=0.22		False
	46	0.2841		0.6284		0.6953		0.3599		0.9236	0.844		tp=0.64, tn=0.12, fp=0.16, fn=0.077		False
	47	0.2722		0.6264		0.7053		0.3538		0.9241	0.8468		tp=0.66, tn=0.1, fp=0.18, fn=0.056		False
	48	0.2788		0.7257		0.7051		0.244		0.9243	0.8251		tp=0.64, tn=0.084, fp=0.2, fn=0.07		False
	49	0.2931		0.705		0.6934		0.3395		0.9218	0.8173		tp=0.59, tn=0.14, fp=0.17, fn=0.098		False
	50	0.2655		0.6576		0.7361		0.3417		0.9315	0.8311		tp=0.63, tn=0.11, fp=0.2, fn=0.056		False
	51	0.2571		0.6424		0.7563		0.4577		0.9357	0.8517		tp=0.62, tn=0.16, fp=0.14, fn=0.077		False
	52	0.2551		0.7165		0.764		0.3365		0.9383	0.8279		tp=0.62, tn=0.12, fp=0.19, fn=0.07		False
	53	0.2617		0.6993		0.7211		0.4463		0.9277	0.8447		tp=0.61, tn=0.17, fp=0.13, fn=0.098		False
	54	0.2488		0.6832		0.754		0.3789		0.9362	0.8325		tp=0.61, tn=0.15, fp=0.13, fn=0.11		False
	55	0.2544		0.703		0.7548		0.3143		0.9358	0.8241		tp=0.62, tn=0.11, fp=0.2, fn=0.07		False
	56	0.2617		0.6939		0.7259		0.4381		0.9301	0.8205		tp=0.56, tn=0.2, fp=0.1, fn=0.14		False
	57	0.2417		0.6495		0.7564		0.5006		0.9371	0.8585		tp=0.62, tn=0.18, fp=0.1, fn=0.098		False
	58	0.2418		0.688		0.7616		0.3903		0.9379	0.8309		tp=0.6, tn=0.15, fp=0.14, fn=0.1		False
	59	0.2384		0.689		0.7802		0.4888		0.9432	0.8442		tp=0.59, tn=0.2, fp=0.12, fn=0.098		False
	60	0.2352		0.697		0.7765		0.3438		0.9415	0.819		tp=0.6, tn=0.13, fp=0.19, fn=0.077		False
	61	0.2292		0.6797		0.7604		0.2956		0.9373	0.8393		tp=0.66, tn=0.091, fp=0.19, fn=0.063		False
	62	0.2352		0.7463		0.7705		0.3888		0.941	0.7895		tp=0.52, tn=0.2, fp=0.091, fn=0.19		False


data			/scratch/asw462/data/levin
input size		300
hidden size		18
learning rate		0.000599561806521
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_77-lr0.0006-h_size18-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5943		0.6426		0		0		0.8398	0.8083		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5869		0.6125		0		0		0.8398	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	3	0.5874		0.6045		0		0		0.8413	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	4	0.5843		0.6072		0		0		0.8412	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	5	0.5856		0.6061		0		0		0.8402	0.8245		tp=0.7, tn=0, fp=0.3, fn=0		False
	6	0.5813		0.6059		0		0		0.843	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	7	0.5835		0.5936		0		0		0.8408	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	8	0.5857		0.5909		0		0		0.8393	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	9	0.5803		0.5959		0		0		0.8427	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	10	0.5845		0.5874		0		-0.0523		0.8393	0.8327		tp=0.71, tn=0, fp=0.28, fn=0.007		False
	11	0.5829		0.5973		0		-0.0532		0.8405	0.8279		tp=0.71, tn=0, fp=0.29, fn=0.007		False
	12	0.5821		0.5873		0		-0.05186		0.8416	0.834		tp=0.72, tn=0, fp=0.28, fn=0.0069		False
	13	0.5794		0.6129		0		0		0.8435	0.8197		tp=0.69, tn=0, fp=0.31, fn=0		False
	14	0.5822		0.6354		0.04297		-0.05687		0.841	0.8083		tp=0.68, tn=0, fp=0.31, fn=0.007		False
	15	0.5857		0.5917		0.04275		0		0.8396	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	16	0.581		0.631		0.04305		-0.05687		0.8415	0.8083		tp=0.68, tn=0, fp=0.31, fn=0.007		False
	17	0.5815		0.614		0.0432		-0.05503		0.8424	0.8182		tp=0.69, tn=0, fp=0.3, fn=0.007		False
	18	0.5814		0.6211		0.04312		-0.05595		0.842	0.8133		tp=0.69, tn=0, fp=0.31, fn=0.007		False
	19	0.581		0.6066		0.0432		-0.05412		0.8424	0.823		tp=0.7, tn=0, fp=0.29, fn=0.007		False
	20	0.5816		0.6067		0.04297		-0.05412		0.841	0.823		tp=0.7, tn=0, fp=0.29, fn=0.007		False
	21	0.5794		0.5844		0.0432		-0.05048		0.8424	0.8421		tp=0.73, tn=0, fp=0.27, fn=0.007		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		170
learning rate		0.00400834944607
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_78-lr0.004-h_size170-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6305		0.6272		-0.007557		0		0.8173	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6131		0.6347		0.06174		0		0.8174	0.8109		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.6126		0.6569		0.07883		0		0.8091	0.8137		tp=0.69, tn=0, fp=0.31, fn=0		False
	4	0.603		0.6269		0.1475		0.05836		0.8114	0.8082		tp=0.67, tn=0.0074, fp=0.31, fn=0.0059		True
	5	0.5736		0.6261		0.1878		0.05911		0.8157	0.8004		tp=0.65, tn=0.025, fp=0.29, fn=0.034		True
	6	0.5739		0.6455		0.2117		0.06217		0.8158	0.7866		tp=0.62, tn=0.038, fp=0.28, fn=0.055		True
	7	0.5605		0.6405		0.2512		0.04935		0.8207	0.7788		tp=0.61, tn=0.043, fp=0.28, fn=0.068		False
	8	0.5475		0.6543		0.272		0.06258		0.8222	0.7698		tp=0.59, tn=0.058, fp=0.26, fn=0.09		True
	9	0.5239		0.6959		0.3359		0.1108		0.8338	0.8079		tp=0.67, tn=0.016, fp=0.31, fn=0.0089		True
	10	0.5111		0.6805		0.35		0.07581		0.8324	0.8029		tp=0.66, tn=0.016, fp=0.31, fn=0.015		False
	11	0.4955		0.6645		0.3745		0.1694		0.8376	0.7449		tp=0.52, tn=0.13, fp=0.18, fn=0.17		True
	12	0.4623		0.7332		0.4526		0.1099		0.8527	0.8101		tp=0.66, tn=0.025, fp=0.29, fn=0.021		False
	13	0.4559		0.81		0.4559		0.1547		0.8535	0.8131		tp=0.66, tn=0.031, fp=0.29, fn=0.018		False
	14	0.4282		0.7177		0.506		0.1448		0.865	0.7536		tp=0.54, tn=0.11, fp=0.22, fn=0.13		False
	15	0.3926		0.7148		0.5721		0.1416		0.8806	0.7824		tp=0.59, tn=0.077, fp=0.24, fn=0.087		False
	16	0.3636		0.7378		0.6135		0.1777		0.8908	0.7232		tp=0.48, tn=0.15, fp=0.17, fn=0.2		True
	17	0.3453		0.7898		0.6357		0.1303		0.8961	0.6821		tp=0.43, tn=0.16, fp=0.16, fn=0.24		False
	18	0.3193		0.7802		0.6748		0.1917		0.9064	0.755		tp=0.53, tn=0.13, fp=0.19, fn=0.16		True
	19	0.2927		0.7798		0.7184		0.2073		0.9183	0.7843		tp=0.57, tn=0.11, fp=0.2, fn=0.11		True
	20	0.2783		0.8335		0.7224		0.1866		0.9187	0.7977		tp=0.61, tn=0.076, fp=0.25, fn=0.065		False
	21	0.2377		0.8096		0.7841		0.2103		0.9359	0.7846		tp=0.57, tn=0.11, fp=0.21, fn=0.11		True
	22	0.2219		0.8931		0.804		0.2092		0.9417	0.7925		tp=0.59, tn=0.095, fp=0.23, fn=0.083		False
	23	0.2055		0.8644		0.8199		0.2248		0.9463	0.7535		tp=0.51, tn=0.15, fp=0.18, fn=0.16		True
	24	0.1882		0.8948		0.8428		0.2152		0.9528	0.7473		tp=0.51, tn=0.15, fp=0.17, fn=0.17		False
	25	0.1849		0.9396		0.8524		0.2119		0.9557	0.7434		tp=0.5, tn=0.15, fp=0.17, fn=0.18		False
	26	0.1632		0.9447		0.8846		0.2259		0.9652	0.7591		tp=0.52, tn=0.15, fp=0.17, fn=0.16		True
	27	0.1404		0.9878		0.8992		0.2656		0.9694	0.8036		tp=0.6, tn=0.11, fp=0.21, fn=0.083		True
	28	0.1289		1.062		0.9145		0.2539		0.974	0.7984		tp=0.59, tn=0.11, fp=0.21, fn=0.09		False
	29	0.126		1.01		0.917		0.2407		0.9748	0.7988		tp=0.59, tn=0.11, fp=0.21, fn=0.09		False
	30	0.1206		1.077		0.9247		0.2342		0.977	0.7805		tp=0.56, tn=0.13, fp=0.19, fn=0.13		False
	31	0.1053		1.177		0.9411		0.2244		0.982	0.798		tp=0.6, tn=0.096, fp=0.22, fn=0.08		False
	32	0.1045		1.098		0.9311		0.1946		0.979	0.7497		tp=0.52, tn=0.14, fp=0.19, fn=0.16		False
	33	0.09881		1.167		0.9415		0.2244		0.9821	0.7828		tp=0.57, tn=0.12, fp=0.19, fn=0.12		False
	34	0.08833		1.164		0.9519		0.2543		0.9853	0.7847		tp=0.56, tn=0.13, fp=0.19, fn=0.12		False
	35	0.08784		1.201		0.942		0.244		0.9822	0.7911		tp=0.58, tn=0.12, fp=0.2, fn=0.1		False
	36	0.08013		1.209		0.9567		0.2258		0.9868	0.7511		tp=0.51, tn=0.15, fp=0.17, fn=0.17		False
	37	0.07352		1.212		0.9619		0.2299		0.9883	0.7665		tp=0.53, tn=0.14, fp=0.18, fn=0.14		False
	38	0.07312		1.225		0.9602		0.2011		0.9878	0.768		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	39	0.07302		1.366		0.9623		0.1913		0.9885	0.7382		tp=0.5, tn=0.15, fp=0.17, fn=0.18		False
	40	0.06851		1.247		0.9619		0.2325		0.9883	0.7771		tp=0.55, tn=0.13, fp=0.18, fn=0.13		False
	41	0.07993		1.443		0.9476		0.2398		0.984	0.7903		tp=0.58, tn=0.11, fp=0.22, fn=0.092		False
	42	0.07447		1.382		0.9521		0.2799		0.9853	0.8099		tp=0.61, tn=0.11, fp=0.21, fn=0.078		True
	43	0.06488		1.306		0.968		0.2317		0.9902	0.766		tp=0.53, tn=0.14, fp=0.18, fn=0.14		False
	44	0.06792		1.395		0.9603		0.184		0.9878	0.7545		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	45	0.05621		1.349		0.9754		0.2285		0.9924	0.7591		tp=0.52, tn=0.15, fp=0.17, fn=0.16		False
	46	0.05196		1.428		0.9745		0.2178		0.9922	0.7731		tp=0.55, tn=0.13, fp=0.2, fn=0.13		False
	47	0.05322		1.441		0.9749		0.2625		0.9923	0.793		tp=0.57, tn=0.13, fp=0.19, fn=0.11		False
	48	0.04951		1.567		0.9749		0.2866		0.9923	0.8164		tp=0.62, tn=0.1, fp=0.21, fn=0.064		True
	49	0.05274		1.531		0.9702		0.2024		0.9909	0.767		tp=0.54, tn=0.13, fp=0.19, fn=0.14		False
	50	0.0634		1.414		0.9654		0.2735		0.9894	0.7849		tp=0.55, tn=0.14, fp=0.18, fn=0.12		False
	51	0.05488		1.549		0.9698		0.249		0.9907	0.7935		tp=0.58, tn=0.12, fp=0.2, fn=0.099		False
	52	0.05328		1.589		0.9749		0.2153		0.9923	0.7846		tp=0.57, tn=0.11, fp=0.2, fn=0.12		False
	53	0.05509		1.642		0.9676		0.2221		0.99	0.7764		tp=0.56, tn=0.12, fp=0.2, fn=0.12		False
	54	0.06634		1.546		0.9602		0.1956		0.9878	0.754		tp=0.52, tn=0.13, fp=0.18, fn=0.16		False
	55	0.05285		1.54		0.9732		0.2187		0.9918	0.7594		tp=0.53, tn=0.14, fp=0.18, fn=0.15		False
	56	0.04436		1.664		0.9788		0.1949		0.9935	0.7068		tp=0.45, tn=0.17, fp=0.15, fn=0.23		False
	57	0.08412		1.58		0.942		0.213		0.9823	0.7423		tp=0.5, tn=0.15, fp=0.17, fn=0.18		False
	58	0.04823		1.598		0.9753		0.1909		0.9924	0.7564		tp=0.53, tn=0.13, fp=0.18, fn=0.16		False
	59	0.03748		1.721		0.9836		0.2111		0.995	0.7825		tp=0.57, tn=0.11, fp=0.2, fn=0.11		False
	60	0.04005		1.607		0.9819		0.1846		0.9944	0.7044		tp=0.45, tn=0.17, fp=0.15, fn=0.23		False
	61	0.05012		1.702		0.971		0.2028		0.9911	0.767		tp=0.54, tn=0.13, fp=0.19, fn=0.14		False
	62	0.05082		1.639		0.9697		0.2285		0.9907	0.775		tp=0.55, tn=0.13, fp=0.19, fn=0.13		False
	63	0.06732		1.688		0.9537		0.1985		0.9858	0.759		tp=0.53, tn=0.13, fp=0.19, fn=0.14		False
	64	0.0426		1.75		0.9767		0.1695		0.9928	0.7524		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	65	0.04052		1.799		0.9814		0.1983		0.9943	0.7672		tp=0.55, tn=0.12, fp=0.2, fn=0.14		False
	66	0.0329		1.707		0.9862		0.2004		0.9958	0.7566		tp=0.53, tn=0.13, fp=0.18, fn=0.16		False
	67	0.03329		1.681		0.9853		0.2073		0.9955	0.7642		tp=0.54, tn=0.13, fp=0.19, fn=0.14		False
	68	0.03917		1.786		0.9805		0.1599		0.994	0.7661		tp=0.56, tn=0.11, fp=0.21, fn=0.13		False
	69	0.03669		1.755		0.9862		0.2252		0.9958	0.7879		tp=0.58, tn=0.11, fp=0.21, fn=0.11		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		144
learning rate		0.00258437501471
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_79-lr0.0026-h_size144-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6809		0.638		0.1768		0.3238		0.5935	0.7235		tp=0.45, tn=0.21, fp=0.26, fn=0.082		True
	2	0.6133		0.628		0.3149		0.3264		0.6756	0.7251		tp=0.48, tn=0.16, fp=0.32, fn=0.038		True
	3	0.5839		0.5899		0.3653		0.355		0.6919	0.6866		tp=0.35, tn=0.32, fp=0.16, fn=0.16		True
	4	0.5452		0.5894		0.4251		0.3862		0.723	0.7087		tp=0.37, tn=0.32, fp=0.15, fn=0.16		True
	5	0.5015		0.5833		0.5095		0.4142		0.7614	0.6997		tp=0.34, tn=0.36, fp=0.12, fn=0.17		True
	6	0.4946		0.6224		0.5148		0.3876		0.7624	0.6497		tp=0.29, tn=0.39, fp=0.087, fn=0.23		False
	7	0.4798		0.6022		0.5331		0.4128		0.7702	0.6995		tp=0.35, tn=0.36, fp=0.12, fn=0.18		False
	8	0.4174		0.6262		0.609		0.3849		0.8053	0.7391		tp=0.43, tn=0.26, fp=0.21, fn=0.097		False
	9	0.3655		0.6064		0.698		0.4053		0.8521	0.7335		tp=0.41, tn=0.29, fp=0.2, fn=0.1		False
	10	0.3323		0.6549		0.724		0.3714		0.8639	0.7336		tp=0.43, tn=0.26, fp=0.21, fn=0.1		False
	11	0.2922		0.6789		0.7678		0.4083		0.8855	0.7407		tp=0.43, tn=0.26, fp=0.23, fn=0.074		False
	12	0.2621		0.6898		0.8127		0.4327		0.9074	0.6952		tp=0.33, tn=0.37, fp=0.09, fn=0.2		True
	13	0.2269		0.773		0.8529		0.397		0.9273	0.705		tp=0.36, tn=0.34, fp=0.14, fn=0.16		False
	14	0.1982		0.7833		0.8724		0.4135		0.9372	0.7246		tp=0.38, tn=0.32, fp=0.15, fn=0.14		False
	15	0.1624		0.8346		0.9161		0.4349		0.9586	0.7161		tp=0.36, tn=0.36, fp=0.12, fn=0.17		True
	16	0.1373		0.8359		0.9291		0.4089		0.9651	0.7071		tp=0.36, tn=0.35, fp=0.13, fn=0.17		False
	17	0.1443		0.8331		0.9214		0.4176		0.9613	0.7366		tp=0.4, tn=0.31, fp=0.16, fn=0.13		False
	18	0.1237		0.861		0.9415		0.4028		0.9712	0.7068		tp=0.36, tn=0.34, fp=0.13, fn=0.17		False
	19	0.09288		0.9668		0.9687		0.389		0.9845	0.6891		tp=0.34, tn=0.35, fp=0.13, fn=0.18		False
	20	0.08286		0.99		0.9717		0.4053		0.9861	0.7171		tp=0.38, tn=0.33, fp=0.15, fn=0.15		False
	21	0.07868		1.004		0.9776		0.4231		0.989	0.7062		tp=0.35, tn=0.36, fp=0.11, fn=0.18		False
	22	0.06365		1.015		0.9775		0.4036		0.9889	0.6992		tp=0.35, tn=0.35, fp=0.13, fn=0.17		False
	23	0.0539		0.9765		0.9829		0.4529		0.9915	0.75		tp=0.41, tn=0.32, fp=0.15, fn=0.13		True
	24	0.04834		1.056		0.9847		0.4704		0.9924	0.723		tp=0.35, tn=0.38, fp=0.095, fn=0.17		True
	25	0.0474		1.097		0.9905		0.4081		0.9953	0.7268		tp=0.39, tn=0.31, fp=0.16, fn=0.13		False
	26	0.04962		1.187		0.9858		0.3875		0.993	0.6891		tp=0.34, tn=0.35, fp=0.13, fn=0.18		False
	27	0.04115		1.142		0.9917		0.4054		0.9959	0.7171		tp=0.38, tn=0.33, fp=0.15, fn=0.14		False
	28	0.04038		1.206		0.9876		0.3867		0.9939	0.72		tp=0.39, tn=0.3, fp=0.16, fn=0.15		False
	29	0.03586		1.231		0.9905		0.4143		0.9953	0.7028		tp=0.35, tn=0.36, fp=0.12, fn=0.17		False
	30	0.04824		1.199		0.9835		0.402		0.9919	0.6961		tp=0.34, tn=0.36, fp=0.13, fn=0.17		False
	31	0.04152		1.209		0.9876		0.4338		0.9939	0.7053		tp=0.34, tn=0.37, fp=0.11, fn=0.18		False
	32	0.03705		1.24		0.9888		0.3974		0.9945	0.7208		tp=0.39, tn=0.31, fp=0.16, fn=0.14		False
	33	0.03545		1.312		0.9917		0.4274		0.9959	0.7172		tp=0.36, tn=0.35, fp=0.14, fn=0.15		False
	34	0.03187		1.27		0.99		0.3898		0.995	0.6907		tp=0.34, tn=0.35, fp=0.13, fn=0.18		False
	35	0.03786		1.364		0.9876		0.4034		0.9939	0.7352		tp=0.41, tn=0.29, fp=0.18, fn=0.11		False
	36	0.03726		1.306		0.9923		0.4235		0.9962	0.6984		tp=0.34, tn=0.37, fp=0.11, fn=0.18		False
	37	0.06656		1.122		0.9645		0.409		0.9825	0.7462		tp=0.44, tn=0.26, fp=0.22, fn=0.082		False
	38	0.06908		1.251		0.9752		0.3963		0.9878	0.7122		tp=0.37, tn=0.32, fp=0.17, fn=0.13		False
	39	0.04068		1.215		0.9917		0.4008		0.9959	0.7125		tp=0.37, tn=0.33, fp=0.14, fn=0.16		False
	40	0.03517		1.293		0.99		0.3681		0.9951	0.6787		tp=0.34, tn=0.34, fp=0.12, fn=0.2		False
	41	0.03463		1.225		0.99		0.4138		0.9951	0.7028		tp=0.35, tn=0.36, fp=0.13, fn=0.17		False
	42	0.03383		1.285		0.9923		0.4095		0.9962	0.6995		tp=0.35, tn=0.36, fp=0.13, fn=0.17		False
	43	0.02855		1.359		0.9917		0.3902		0.9959	0.709		tp=0.37, tn=0.32, fp=0.16, fn=0.15		False
	44	0.02752		1.28		0.9917		0.4312		0.9959	0.7299		tp=0.38, tn=0.33, fp=0.15, fn=0.13		False
	45	0.02878		1.308		0.9905		0.3935		0.9953	0.7136		tp=0.38, tn=0.32, fp=0.16, fn=0.14		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		24
learning rate		0.000662804938036
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_7-lr0.00066-h_size24-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6164		0.6205		-0.001076		0		0.8153	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.5949		0.6155		0.07395		0.05638		0.8169	0.812		tp=0.68, tn=0.0015, fp=0.32, fn=0		True
	3	0.577		0.6276		0.1635		0.1767		0.8222	0.7622		tp=0.54, tn=0.12, fp=0.2, fn=0.14		True
	4	0.5661		0.6057		0.2228		0.1358		0.8237	0.8087		tp=0.66, tn=0.033, fp=0.29, fn=0.024		False
	5	0.5535		0.614		0.2703		0.2286		0.8286	0.8027		tp=0.61, tn=0.092, fp=0.23, fn=0.073		True
	6	0.5478		0.6319		0.3006		0.1724		0.8305	0.7395		tp=0.51, tn=0.14, fp=0.18, fn=0.18		False
	7	0.5351		0.6117		0.3209		0.198		0.8334	0.8057		tp=0.63, tn=0.071, fp=0.25, fn=0.056		False
	8	0.5284		0.6493		0.34		0.1433		0.8346	0.7071		tp=0.47, tn=0.15, fp=0.17, fn=0.21		False
	9	0.5253		0.6112		0.3476		0.2051		0.8352	0.7925		tp=0.59, tn=0.096, fp=0.22, fn=0.09		False
	10	0.518		0.6242		0.3725		0.2071		0.8397	0.78		tp=0.57, tn=0.11, fp=0.21, fn=0.11		False
	11	0.5128		0.6477		0.3701		0.1652		0.8387	0.7497		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	12	0.5124		0.6295		0.379		0.1873		0.8404	0.779		tp=0.57, tn=0.1, fp=0.21, fn=0.11		False
	13	0.5047		0.6351		0.4079		0.1968		0.8451	0.7738		tp=0.56, tn=0.11, fp=0.21, fn=0.12		False
	14	0.5052		0.6356		0.3948		0.1622		0.8426	0.7484		tp=0.52, tn=0.12, fp=0.2, fn=0.15		False
	15	0.4986		0.6256		0.4121		0.1952		0.8465	0.7877		tp=0.59, tn=0.096, fp=0.22, fn=0.093		False
	16	0.4943		0.6306		0.4068		0.1885		0.8441	0.7849		tp=0.58, tn=0.096, fp=0.22, fn=0.096		False
	17	0.4973		0.645		0.4144		0.1766		0.8461	0.7452		tp=0.51, tn=0.13, fp=0.19, fn=0.16		False
	18	0.4906		0.631		0.4156		0.1735		0.8451	0.7702		tp=0.56, tn=0.11, fp=0.21, fn=0.13		False
	19	0.4911		0.659		0.4202		0.1597		0.8474	0.779		tp=0.58, tn=0.087, fp=0.24, fn=0.093		False
	20	0.4832		0.6595		0.4295		0.1869		0.8484	0.8127		tp=0.65, tn=0.056, fp=0.26, fn=0.041		False
	21	0.4849		0.6479		0.4284		0.1873		0.8488	0.7537		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	22	0.487		0.6497		0.4294		0.1877		0.8485	0.7592		tp=0.53, tn=0.13, fp=0.19, fn=0.15		False
	23	0.475		0.6454		0.4466		0.1909		0.8523	0.7681		tp=0.55, tn=0.12, fp=0.2, fn=0.13		False
	24	0.4734		0.6351		0.4497		0.1826		0.8532	0.7858		tp=0.59, tn=0.089, fp=0.24, fn=0.084		False
	25	0.4678		0.6481		0.4563		0.2022		0.8538	0.7776		tp=0.56, tn=0.11, fp=0.21, fn=0.12		False
	26	0.4676		0.6463		0.4619		0.2004		0.8556	0.7984		tp=0.61, tn=0.081, fp=0.24, fn=0.068		False


data			/scratch/asw462/data/levin
input size		300
hidden size		147
learning rate		0.0046196293478
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_80-lr0.0046-h_size147-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5817		0.5755		0.1163		0		0.8457	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	2	0.5534		0.5825		0.1752		0.1844		0.8443	0.8291		tp=0.68, tn=0.042, fp=0.25, fn=0.028		True
	3	0.5343		0.563		0.2069		0.1593		0.8405	0.8354		tp=0.69, tn=0.035, fp=0.24, fn=0.028		False
	4	0.5198		0.5665		0.2353		0.2732		0.8438	0.8333		tp=0.66, tn=0.07, fp=0.23, fn=0.035		True
	5	0.4996		0.6503		0.3272		0.1799		0.8533	0.8255		tp=0.67, tn=0.042, fp=0.26, fn=0.028		False
	6	0.4879		0.627		0.3545		0.2115		0.8565	0.7963		tp=0.6, tn=0.091, fp=0.23, fn=0.077		False
	7	0.4744		0.6756		0.3822		0.06839		0.8575	0.6875		tp=0.46, tn=0.12, fp=0.17, fn=0.24		False
	8	0.4654		0.7231		0.3822		0.167		0.8579	0.827		tp=0.69, tn=0.028, fp=0.27, fn=0.014		False
	9	0.4667		0.6029		0.3847		0.217		0.8584	0.8261		tp=0.66, tn=0.056, fp=0.24, fn=0.035		False
	10	0.4579		0.6439		0.4099		0.2043		0.8679	0.8297		tp=0.66, tn=0.063, fp=0.22, fn=0.056		False
	11	0.4653		0.6263		0.3945		0.1715		0.8591	0.7964		tp=0.62, tn=0.07, fp=0.25, fn=0.063		False
	12	0.4513		0.6428		0.4471		0.1615		0.8703	0.8403		tp=0.69, tn=0.042, fp=0.22, fn=0.042		False
	13	0.4715		0.5983		0.3543		0.1602		0.8491	0.7773		tp=0.57, tn=0.098, fp=0.2, fn=0.13		False
	14	0.4325		0.6426		0.4789		0.08254		0.8758	0.7664		tp=0.57, tn=0.077, fp=0.22, fn=0.13		False
	15	0.4536		0.6322		0.4241		0.1598		0.8621	0.7525		tp=0.53, tn=0.12, fp=0.2, fn=0.15		False
	16	0.4145		0.7972		0.467		0.1758		0.8735	0.8368		tp=0.7, tn=0.028, fp=0.26, fn=0.014		False
	17	0.4002		0.6576		0.5286		0.1507		0.8857	0.7926		tp=0.6, tn=0.084, fp=0.2, fn=0.12		False
	18	0.3906		0.7302		0.5453		0.1771		0.889	0.8291		tp=0.67, tn=0.049, fp=0.24, fn=0.042		False
	19	0.4099		0.6161		0.5047		0.225		0.8779	0.7723		tp=0.55, tn=0.13, fp=0.17, fn=0.15		False
	20	0.408		0.6373		0.4956		0.1181		0.8805	0.7678		tp=0.57, tn=0.091, fp=0.2, fn=0.15		False
	21	0.3997		0.643		0.5081		0.2367		0.8791	0.7864		tp=0.57, tn=0.13, fp=0.16, fn=0.15		False
	22	0.3782		0.7327		0.5464		0.1633		0.8883	0.7982		tp=0.62, tn=0.063, fp=0.26, fn=0.056		False
	23	0.3809		0.7814		0.5437		0.1527		0.8861	0.6742		tp=0.42, tn=0.17, fp=0.15, fn=0.26		False
	24	0.4212		0.6866		0.5036		0.1882		0.8796	0.8158		tp=0.65, tn=0.056, fp=0.25, fn=0.042		False
	25	0.3619		0.6596		0.5677		0.2276		0.8932	0.8145		tp=0.63, tn=0.084, fp=0.22, fn=0.07		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		15
learning rate		0.00218051514292
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_81-lr0.0022-h_size15-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6871		0.6746		0.1012		0.1811		0.5718	0.6441		tp=0.37, tn=0.23, fp=0.24, fn=0.16		True
	2	0.6794		0.6708		0.1324		0.1964		0.6081	0.6593		tp=0.38, tn=0.22, fp=0.25, fn=0.15		True
	3	0.6833		0.6747		0.1149		0.1566		0.5998	0.6509		tp=0.39, tn=0.2, fp=0.27, fn=0.15		False
	4	0.6822		0.6757		0.1185		0.207		0.6123	0.6593		tp=0.38, tn=0.23, fp=0.25, fn=0.14		True
	5	0.6825		0.6734		0.142		0.1652		0.6222	0.6523		tp=0.39, tn=0.2, fp=0.27, fn=0.14		False
	6	0.6806		0.6768		0.1438		0.177		0.631	0.633		tp=0.35, tn=0.24, fp=0.25, fn=0.16		False
	7	0.6814		0.676		0.1396		0.1908		0.6276	0.6374		tp=0.35, tn=0.24, fp=0.24, fn=0.17		False
	8	0.6812		0.6741		0.1321		0.1989		0.6186	0.6532		tp=0.37, tn=0.23, fp=0.25, fn=0.15		False
	9	0.681		0.6785		0.127		0.1675		0.619	0.6349		tp=0.36, tn=0.23, fp=0.25, fn=0.17		False
	10	0.6813		0.6786		0.1295		0.1425		0.6207	0.6481		tp=0.39, tn=0.19, fp=0.27, fn=0.15		False
	11	0.6805		0.6733		0.129		0.2041		0.6202	0.6336		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	12	0.6808		0.6812		0.1327		0.1761		0.6237	0.6154		tp=0.33, tn=0.26, fp=0.21, fn=0.2		False
	13	0.6811		0.676		0.1514		0.1421		0.6293	0.6758		tp=0.44, tn=0.13, fp=0.34, fn=0.085		False
	14	0.6801		0.6787		0.1414		0.1382		0.6303	0.6705		tp=0.44, tn=0.12, fp=0.36, fn=0.071		False
	15	0.6809		0.6768		0.1209		0.2107		0.6319	0.6383		tp=0.35, tn=0.26, fp=0.21, fn=0.18		True
	16	0.6806		0.6751		0.1388		0.1859		0.6225	0.652		tp=0.38, tn=0.22, fp=0.26, fn=0.14		False
	17	0.6801		0.6743		0.138		0.1689		0.6184	0.6581		tp=0.39, tn=0.19, fp=0.27, fn=0.14		False
	18	0.68		0.6787		0.1367		0.1127		0.6211	0.6641		tp=0.43, tn=0.13, fp=0.35, fn=0.09		False
	19	0.6806		0.677		0.1271		0.2033		0.6314	0.621		tp=0.33, tn=0.28, fp=0.2, fn=0.19		False
	20	0.681		0.6767		0.1213		0.1532		0.6151	0.6467		tp=0.39, tn=0.19, fp=0.29, fn=0.13		False
	21	0.68		0.6717		0.1336		0.1721		0.6195	0.6694		tp=0.42, tn=0.17, fp=0.3, fn=0.11		False
	22	0.6803		0.6777		0.1273		0.1358		0.6327	0.6498		tp=0.39, tn=0.18, fp=0.29, fn=0.14		False
	23	0.6798		0.6789		0.13		0.12		0.6159	0.6458		tp=0.4, tn=0.17, fp=0.31, fn=0.13		False
	24	0.6798		0.6748		0.1346		0.1389		0.6215	0.6569		tp=0.4, tn=0.18, fp=0.28, fn=0.14		False
	25	0.679		0.6749		0.137		0.1187		0.6207	0.6667		tp=0.43, tn=0.14, fp=0.33, fn=0.11		False
	26	0.6802		0.6757		0.1378		0.1935		0.637	0.6372		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	27	0.6788		0.6773		0.14		0.1549		0.6058	0.6732		tp=0.44, tn=0.13, fp=0.36, fn=0.072		False
	28	0.6787		0.6725		0.1279		0.1524		0.6214	0.6626		tp=0.42, tn=0.16, fp=0.32, fn=0.11		False
	29	0.6782		0.6796		0.1403		0.1486		0.6285	0.6405		tp=0.38, tn=0.2, fp=0.28, fn=0.14		False
	30	0.6793		0.676		0.1396		0.163		0.6256	0.6463		tp=0.38, tn=0.21, fp=0.27, fn=0.15		False
	31	0.6783		0.6767		0.1553		0.1871		0.6336	0.6488		tp=0.37, tn=0.23, fp=0.25, fn=0.16		False
	32	0.6791		0.676		0.1339		0.1319		0.6091	0.6795		tp=0.45, tn=0.12, fp=0.34, fn=0.085		False
	33	0.6804		0.6754		0.1344		0.1653		0.6299	0.6567		tp=0.39, tn=0.19, fp=0.28, fn=0.13		False
	34	0.6794		0.6754		0.1211		0.1806		0.6092	0.6536		tp=0.38, tn=0.21, fp=0.27, fn=0.14		False
	35	0.6785		0.6715		0.1309		0.203		0.6205	0.6652		tp=0.39, tn=0.21, fp=0.26, fn=0.14		False
	36	0.6785		0.6779		0.1308		0.1752		0.6335	0.6476		tp=0.38, tn=0.21, fp=0.27, fn=0.14		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		126
learning rate		0.000829867113903
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_82-lr0.00083-h_size126-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6109		0.6044		0.05845		0.1746		0.8153	0.8124		tp=0.66, tn=0.036, fp=0.29, fn=0.018		True
	2	0.607		0.6071		0.0916		0.0861		0.817	0.8099		tp=0.68, tn=0.0074, fp=0.31, fn=0.003		False
	3	0.6066		0.6114		0.08668		0.09955		0.8178	0.8085		tp=0.67, tn=0.0089, fp=0.32, fn=0.003		False
	4	0.6059		0.6022		0.07781		0.08843		0.8163	0.8128		tp=0.68, tn=0.01, fp=0.31, fn=0.0059		False
	5	0.6085		0.6095		0.08414		0.113		0.8173	0.8097		tp=0.67, tn=0.018, fp=0.3, fn=0.01		False
	6	0.6066		0.6105		0.09177		0.09005		0.8174	0.8145		tp=0.68, tn=0.0059, fp=0.31, fn=0.0015		False
	7	0.6061		0.6084		0.1045		0.05104		0.8184	0.8151		tp=0.69, tn=0.003, fp=0.31, fn=0.0015		False
	8	0.6042		0.6159		0.08392		0.09955		0.8196	0.8085		tp=0.67, tn=0.0089, fp=0.32, fn=0.003		False
	9	0.6056		0.6102		0.08748		0.08567		0.8178	0.8089		tp=0.67, tn=0.0074, fp=0.32, fn=0.003		False
	10	0.6053		0.602		0.08966		0.1171		0.8181	0.8199		tp=0.68, tn=0.015, fp=0.29, fn=0.0074		False
	11	0.6057		0.6067		0.09464		0.1238		0.8185	0.8132		tp=0.67, tn=0.018, fp=0.3, fn=0.0089		False
	12	0.6051		0.6073		0.09352		0.1015		0.8195	0.8131		tp=0.68, tn=0.0089, fp=0.31, fn=0.003		False
	13	0.6035		0.6116		0.0948		0.1005		0.8187	0.8121		tp=0.68, tn=0.012, fp=0.31, fn=0.0059		False
	14	0.6057		0.6105		0.0907		0.07038		0.8183	0.8103		tp=0.68, tn=0.0059, fp=0.31, fn=0.003		False
	15	0.6048		0.6086		0.09402		0.07123		0.8184	0.8127		tp=0.68, tn=0.0059, fp=0.31, fn=0.003		False
	16	0.6041		0.6083		0.08717		0.114		0.819	0.8153		tp=0.68, tn=0.012, fp=0.3, fn=0.0044		False
	17	0.6053		0.6128		0.09626		0.1005		0.8188	0.8107		tp=0.68, tn=0.0089, fp=0.31, fn=0.003		False
	18	0.604		0.6094		0.09076		0.09897		0.8175	0.8096		tp=0.67, tn=0.01, fp=0.31, fn=0.0044		False
	19	0.6042		0.6056		0.1046		0.1156		0.8194	0.8156		tp=0.68, tn=0.01, fp=0.31, fn=0.003		False
	20	0.6049		0.6048		0.08917		0.1024		0.8178	0.8149		tp=0.68, tn=0.0089, fp=0.31, fn=0.003		False
	21	0.6041		0.6103		0.09506		0.06961		0.8186	0.8082		tp=0.67, tn=0.0059, fp=0.32, fn=0.003		False
	22	0.6038		0.6043		0.09949		0.1522		0.82	0.8151		tp=0.67, tn=0.022, fp=0.3, fn=0.0089		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		43
learning rate		0.000434372846796
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_83-lr0.00043-h_size43-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5887		0.5714		0.1597		0.2228		0.8169	0.8182		tp=0.65, tn=0.056, fp=0.26, fn=0.03		True
	2	0.5447		0.5557		0.2968		0.2589		0.8313	0.8209		tp=0.64, tn=0.079, fp=0.23, fn=0.046		True
	3	0.5292		0.5794		0.3415		0.2538		0.8362	0.8175		tp=0.65, tn=0.061, fp=0.27, fn=0.024		False
	4	0.5058		0.5595		0.388		0.3258		0.8445	0.8269		tp=0.64, tn=0.096, fp=0.23, fn=0.04		True
	5	0.4892		0.5594		0.3993		0.2933		0.8454	0.8296		tp=0.66, tn=0.074, fp=0.24, fn=0.03		False
	6	0.47		0.565		0.4413		0.299		0.8534	0.7802		tp=0.54, tn=0.16, fp=0.15, fn=0.15		False
	7	0.4489		0.5733		0.4911		0.2926		0.8635	0.8193		tp=0.63, tn=0.095, fp=0.23, fn=0.05		False
	8	0.4293		0.5591		0.514		0.2693		0.8682	0.7896		tp=0.56, tn=0.13, fp=0.18, fn=0.12		False
	9	0.4162		0.5804		0.5439		0.2742		0.8746	0.7814		tp=0.55, tn=0.15, fp=0.18, fn=0.13		False
	10	0.4044		0.594		0.5599		0.3563		0.8782	0.7532		tp=0.47, tn=0.22, fp=0.099, fn=0.21		True
	11	0.3916		0.5637		0.5858		0.2635		0.8843	0.8113		tp=0.62, tn=0.097, fp=0.22, fn=0.066		False
	12	0.3777		0.5948		0.6108		0.2558		0.8901	0.8195		tp=0.64, tn=0.084, fp=0.22, fn=0.056		False
	13	0.3711		0.58		0.6227		0.297		0.8927	0.7869		tp=0.55, tn=0.15, fp=0.17, fn=0.12		False
	14	0.3597		0.602		0.6316		0.3148		0.8958	0.7954		tp=0.56, tn=0.15, fp=0.17, fn=0.12		False
	15	0.3475		0.5835		0.6486		0.3163		0.8998	0.8054		tp=0.58, tn=0.14, fp=0.18, fn=0.1		False
	16	0.3413		0.6376		0.6579		0.3087		0.9022	0.82		tp=0.62, tn=0.11, fp=0.21, fn=0.059		False
	17	0.3228		0.6118		0.6923		0.3082		0.9116	0.7967		tp=0.57, tn=0.15, fp=0.18, fn=0.11		False
	18	0.3183		0.6051		0.6908		0.3354		0.9109	0.7878		tp=0.54, tn=0.17, fp=0.14, fn=0.15		False
	19	0.3143		0.6603		0.6943		0.2918		0.9117	0.7775		tp=0.53, tn=0.16, fp=0.16, fn=0.15		False
	20	0.3044		0.6375		0.7149		0.2912		0.9169	0.802		tp=0.58, tn=0.13, fp=0.18, fn=0.11		False
	21	0.2928		0.6444		0.7339		0.3278		0.9225	0.7879		tp=0.54, tn=0.17, fp=0.15, fn=0.14		False
	22	0.2887		0.6708		0.7192		0.2873		0.9184	0.779		tp=0.54, tn=0.16, fp=0.17, fn=0.14		False
	23	0.2817		0.6433		0.7309		0.2957		0.9212	0.7886		tp=0.55, tn=0.15, fp=0.17, fn=0.13		False
	24	0.2709		0.6672		0.7648		0.3162		0.9308	0.7954		tp=0.56, tn=0.15, fp=0.17, fn=0.12		False
	25	0.268		0.6641		0.7713		0.3287		0.9329	0.7856		tp=0.53, tn=0.17, fp=0.15, fn=0.14		False
	26	0.2541		0.7202		0.7871		0.2894		0.9373	0.766		tp=0.51, tn=0.17, fp=0.15, fn=0.17		False
	27	0.2436		0.7005		0.8001		0.3128		0.9409	0.788		tp=0.55, tn=0.16, fp=0.16, fn=0.14		False
	28	0.2407		0.718		0.7926		0.3021		0.9386	0.8089		tp=0.59, tn=0.12, fp=0.2, fn=0.084		False
	29	0.2421		0.719		0.7801		0.3567		0.9351	0.7779		tp=0.51, tn=0.2, fp=0.12, fn=0.17		True
	30	0.2232		0.7157		0.8221		0.3203		0.9471	0.8004		tp=0.57, tn=0.15, fp=0.17, fn=0.11		False
	31	0.22		0.7239		0.8283		0.3586		0.949	0.7921		tp=0.54, tn=0.18, fp=0.13, fn=0.15		True
	32	0.2154		0.7181		0.8207		0.3632		0.9467	0.8105		tp=0.57, tn=0.16, fp=0.15, fn=0.11		True
	33	0.207		0.7458		0.8442		0.3487		0.9536	0.7881		tp=0.53, tn=0.18, fp=0.14, fn=0.15		False
	34	0.199		0.7546		0.8412		0.349		0.9526	0.7922		tp=0.54, tn=0.18, fp=0.14, fn=0.14		False
	35	0.1869		0.7501		0.8717		0.3535		0.9615	0.8034		tp=0.56, tn=0.17, fp=0.16, fn=0.12		False
	36	0.1874		0.7939		0.8622		0.3167		0.9586	0.7808		tp=0.53, tn=0.17, fp=0.15, fn=0.15		False
	37	0.1739		0.7655		0.885		0.3664		0.9654	0.8158		tp=0.58, tn=0.16, fp=0.16, fn=0.1		True
	38	0.1751		0.7896		0.8785		0.3538		0.9634	0.816		tp=0.59, tn=0.15, fp=0.17, fn=0.092		False
	39	0.163		0.8331		0.8933		0.3304		0.9679	0.7684		tp=0.5, tn=0.19, fp=0.13, fn=0.17		False
	40	0.1571		0.8191		0.9021		0.3362		0.9705	0.8017		tp=0.56, tn=0.16, fp=0.16, fn=0.12		False
	41	0.1555		0.8136		0.8999		0.3353		0.9698	0.7962		tp=0.55, tn=0.16, fp=0.16, fn=0.13		False
	42	0.1413		0.8441		0.9183		0.3323		0.9753	0.7992		tp=0.56, tn=0.16, fp=0.16, fn=0.12		False
	43	0.1427		0.8501		0.9148		0.3228		0.9742	0.7798		tp=0.53, tn=0.18, fp=0.14, fn=0.16		False
	44	0.136		0.8449		0.9232		0.355		0.9767	0.7987		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	45	0.1286		0.8689		0.9367		0.3545		0.9808	0.8113		tp=0.58, tn=0.16, fp=0.16, fn=0.11		False
	46	0.1294		0.8712		0.9252		0.3563		0.9774	0.7885		tp=0.53, tn=0.19, fp=0.14, fn=0.15		False
	47	0.1243		0.8925		0.9301		0.3548		0.9788	0.8092		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	48	0.1176		0.9152		0.9358		0.3443		0.9805	0.8042		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	49	0.1111		0.9086		0.9488		0.3529		0.9844	0.8051		tp=0.56, tn=0.16, fp=0.15, fn=0.12		False
	50	0.1052		0.9082		0.9545		0.3523		0.9861	0.7913		tp=0.54, tn=0.18, fp=0.14, fn=0.15		False
	51	0.102		0.9452		0.9514		0.3527		0.9852	0.7746		tp=0.51, tn=0.2, fp=0.12, fn=0.17		False
	52	0.1096		0.9422		0.9419		0.3479		0.9823	0.7895		tp=0.53, tn=0.18, fp=0.14, fn=0.14		False
	53	0.1004		0.921		0.9523		0.3565		0.9855	0.8084		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	54	0.09318		0.9525		0.9571		0.3692		0.9869	0.8051		tp=0.56, tn=0.17, fp=0.15, fn=0.12		True
	55	0.0858		0.9762		0.9684		0.3471		0.9903	0.7804		tp=0.52, tn=0.19, fp=0.13, fn=0.16		False
	56	0.08903		1.019		0.9623		0.3571		0.9885	0.8188		tp=0.59, tn=0.15, fp=0.17, fn=0.09		False
	57	0.07979		1.037		0.9727		0.3271		0.9917	0.7737		tp=0.51, tn=0.19, fp=0.13, fn=0.17		False
	58	0.07673		1.025		0.9745		0.3205		0.9922	0.7663		tp=0.5, tn=0.19, fp=0.13, fn=0.18		False
	59	0.07384		1.019		0.9762		0.3531		0.9927	0.7957		tp=0.54, tn=0.18, fp=0.14, fn=0.14		False
	60	0.07169		1.026		0.9801		0.3683		0.9939	0.8114		tp=0.57, tn=0.16, fp=0.15, fn=0.11		False
	61	0.0728		1.026		0.9749		0.3367		0.9923	0.7833		tp=0.53, tn=0.18, fp=0.14, fn=0.15		False
	62	0.06876		1.083		0.9775		0.3609		0.9931	0.8101		tp=0.57, tn=0.16, fp=0.16, fn=0.1		False
	63	0.07114		1.034		0.9727		0.3696		0.9917	0.8089		tp=0.56, tn=0.17, fp=0.15, fn=0.12		True
	64	0.06189		1.13		0.9818		0.3217		0.9944	0.7835		tp=0.53, tn=0.17, fp=0.15, fn=0.15		False
	65	0.06232		1.044		0.9797		0.336		0.9938	0.7922		tp=0.54, tn=0.17, fp=0.14, fn=0.14		False
	66	0.05906		1.176		0.9836		0.3688		0.995	0.817		tp=0.58, tn=0.15, fp=0.17, fn=0.092		False
	67	0.05928		1.08		0.984		0.3564		0.9951	0.7921		tp=0.54, tn=0.18, fp=0.14, fn=0.14		False
	68	0.05583		1.1		0.9823		0.3667		0.9946	0.7912		tp=0.53, tn=0.19, fp=0.13, fn=0.15		False
	69	0.05664		1.118		0.9823		0.3554		0.9946	0.8092		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	70	0.05308		1.115		0.9853		0.3578		0.9955	0.8004		tp=0.55, tn=0.17, fp=0.14, fn=0.13		False
	71	0.04979		1.135		0.984		0.3628		0.9951	0.8105		tp=0.57, tn=0.16, fp=0.15, fn=0.12		False
	72	0.04735		1.181		0.987		0.3774		0.996	0.8139		tp=0.57, tn=0.17, fp=0.16, fn=0.11		True
	73	0.04866		1.158		0.9857		0.3573		0.9956	0.7987		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	74	0.04869		1.199		0.9862		0.3555		0.9958	0.8141		tp=0.58, tn=0.15, fp=0.16, fn=0.11		False
	75	0.04594		1.163		0.9879		0.3436		0.9963	0.8017		tp=0.56, tn=0.16, fp=0.15, fn=0.12		False
	76	0.04358		1.182		0.9866		0.3408		0.9959	0.7944		tp=0.55, tn=0.17, fp=0.15, fn=0.14		False
	77	0.04614		1.221		0.9866		0.3722		0.9959	0.8085		tp=0.56, tn=0.17, fp=0.14, fn=0.12		False
	78	0.04238		1.214		0.9883		0.3364		0.9964	0.7815		tp=0.52, tn=0.18, fp=0.13, fn=0.16		False
	79	0.04404		1.291		0.9853		0.3686		0.9955	0.8182		tp=0.59, tn=0.15, fp=0.16, fn=0.096		False
	80	0.0408		1.279		0.9875		0.3622		0.9962	0.8076		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	81	0.04184		1.292		0.9853		0.3888		0.9955	0.824		tp=0.59, tn=0.16, fp=0.16, fn=0.095		True
	82	0.03988		1.259		0.9879		0.3341		0.9963	0.7949		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	83	0.03954		1.271		0.9866		0.3712		0.9959	0.8043		tp=0.55, tn=0.18, fp=0.14, fn=0.13		False
	84	0.04324		1.283		0.9858		0.3443		0.9956	0.79		tp=0.54, tn=0.18, fp=0.14, fn=0.14		False
	85	0.03938		1.377		0.9866		0.3702		0.9959	0.8274		tp=0.61, tn=0.14, fp=0.17, fn=0.081		False
	86	0.04579		1.25		0.9853		0.3384		0.9955	0.7896		tp=0.54, tn=0.17, fp=0.14, fn=0.14		False
	87	0.03856		1.252		0.9866		0.3434		0.9959	0.7957		tp=0.55, tn=0.17, fp=0.14, fn=0.14		False
	88	0.03689		1.325		0.9866		0.348		0.9959	0.8051		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	89	0.03555		1.321		0.9866		0.3497		0.9959	0.8004		tp=0.56, tn=0.17, fp=0.16, fn=0.12		False
	90	0.03591		1.28		0.9844		0.3544		0.9952	0.8013		tp=0.55, tn=0.17, fp=0.14, fn=0.13		False
	91	0.04041		1.312		0.9857		0.344		0.9956	0.8		tp=0.56, tn=0.16, fp=0.16, fn=0.12		False
	92	0.03489		1.356		0.9888		0.3381		0.9966	0.7883		tp=0.54, tn=0.18, fp=0.15, fn=0.14		False
	93	0.0371		1.374		0.9849		0.3428		0.9954	0.7877		tp=0.53, tn=0.18, fp=0.14, fn=0.15		False
	94	0.03708		1.44		0.987		0.3455		0.996	0.814		tp=0.59, tn=0.15, fp=0.17, fn=0.095		False
	95	0.03596		1.351		0.9866		0.3634		0.9959	0.8072		tp=0.56, tn=0.17, fp=0.15, fn=0.12		False
	96	0.03395		1.349		0.9896		0.3407		0.9968	0.8091		tp=0.58, tn=0.15, fp=0.16, fn=0.11		False
	97	0.0336		1.407		0.9875		0.3675		0.9962	0.8178		tp=0.59, tn=0.15, fp=0.16, fn=0.098		False
	98	0.03515		1.362		0.9879		0.3439		0.9963	0.81		tp=0.58, tn=0.15, fp=0.17, fn=0.11		False
	99	0.03561		1.411		0.9857		0.3274		0.9956	0.7962		tp=0.56, tn=0.16, fp=0.16, fn=0.13		False
	100	0.03355		1.434		0.9879		0.3501		0.9963	0.7961		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	101	0.03216		1.433		0.9901		0.3665		0.9969	0.8198		tp=0.59, tn=0.15, fp=0.16, fn=0.096		False
	102	0.03342		1.382		0.9875		0.3367		0.9961	0.8		tp=0.56, tn=0.16, fp=0.15, fn=0.13		False


data			/scratch/asw462/data/levin
input size		300
hidden size		62
learning rate		0.000155142492995
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_84-lr0.00016-h_size62-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6188		0.5838		-0.01626		0		0.8407	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	2	0.5812		0.5939		0		0		0.8427	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5769		0.5722		0		0		0.8435	0.8421		tp=0.73, tn=0, fp=0.27, fn=0		False
	4	0.5727		0.5961		0		0		0.8435	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	5	0.5702		0.5849		0		0		0.8426	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	6	0.5675		0.5921		0		0		0.8414	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	7	0.5644		0.5745		0		0		0.8412	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	8	0.5605		0.5646		0		0		0.8416	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	9	0.5539		0.5911		0		0		0.843	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	10	0.5501		0.5752		0		0		0.8426	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	11	0.5457		0.576		0		0		0.8412	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	12	0.5391		0.5827		0		0		0.843	0.8148		tp=0.69, tn=0, fp=0.31, fn=0		False
	13	0.5354		0.5761		0.09639		0		0.8429	0.8133		tp=0.69, tn=0, fp=0.31, fn=0		False
	14	0.5274		0.5788		0.0969		0.1219		0.8443	0.8117		tp=0.68, tn=0.007, fp=0.31, fn=0		True
	15	0.5246		0.5615		0.1433		0.128		0.8449	0.8264		tp=0.7, tn=0.007, fp=0.29, fn=0		True
	16	0.5182		0.5458		0.223		0.1324		0.8505	0.8361		tp=0.71, tn=0.007, fp=0.28, fn=0		True
	17	0.5129		0.5352		0.185		0.1324		0.8466	0.8361		tp=0.71, tn=0.007, fp=0.28, fn=0		False
	18	0.5065		0.5422		0.2315		0.1301		0.851	0.8313		tp=0.71, tn=0.007, fp=0.29, fn=0		False
	19	0.4972		0.5352		0.2933		0.1301		0.8586	0.8313		tp=0.71, tn=0.007, fp=0.29, fn=0		False
	20	0.4965		0.5398		0.2831		0.0501		0.8551	0.8182		tp=0.69, tn=0.0069, fp=0.3, fn=0.0069		False
	21	0.4874		0.5346		0.3136		0.1714		0.8601	0.8319		tp=0.69, tn=0.028, fp=0.27, fn=0.014		True
	22	0.4822		0.5311		0.3418		0.2807		0.8642	0.8439		tp=0.7, tn=0.042, fp=0.25, fn=0.007		True
	23	0.4771		0.5301		0.3585		0.3191		0.864	0.8439		tp=0.7, tn=0.042, fp=0.26, fn=0		True
	24	0.4724		0.528		0.3829		0.2385		0.8656	0.834		tp=0.69, tn=0.042, fp=0.26, fn=0.014		False
	25	0.4657		0.4919		0.3921		0.3292		0.8673	0.8619		tp=0.72, tn=0.049, fp=0.22, fn=0.007		True
	26	0.4614		0.5127		0.4171		0.2754		0.8702	0.8426		tp=0.69, tn=0.049, fp=0.24, fn=0.014		False
	27	0.4536		0.5438		0.4016		0.2751		0.8707	0.821		tp=0.66, tn=0.056, fp=0.27, fn=0.014		False
	28	0.4446		0.4865		0.4232		0.3004		0.8734	0.8619		tp=0.72, tn=0.049, fp=0.22, fn=0.014		False
	29	0.4427		0.5221		0.4311		0.338		0.8756	0.8384		tp=0.67, tn=0.07, fp=0.24, fn=0.014		True
	30	0.438		0.4982		0.4283		0.3912		0.8735	0.8621		tp=0.7, tn=0.077, fp=0.21, fn=0.014		True
	31	0.4354		0.5273		0.4408		0.2748		0.8745	0.8412		tp=0.69, tn=0.056, fp=0.24, fn=0.021		False
	32	0.4274		0.522		0.4555		0.2754		0.8779	0.8426		tp=0.69, tn=0.049, fp=0.24, fn=0.014		False
	33	0.4275		0.4996		0.4582		0.2298		0.8776	0.8362		tp=0.68, tn=0.056, fp=0.23, fn=0.035		False
	34	0.4224		0.5009		0.4608		0.4265		0.8784	0.861		tp=0.67, tn=0.11, fp=0.18, fn=0.035		True
	35	0.416		0.4972		0.4799		0.3654		0.881	0.8546		tp=0.68, tn=0.091, fp=0.2, fn=0.035		False
	36	0.4147		0.4827		0.4904		0.3708		0.8817	0.8646		tp=0.69, tn=0.091, fp=0.17, fn=0.042		False
	37	0.4074		0.5028		0.5058		0.4172		0.8854	0.8571		tp=0.67, tn=0.1, fp=0.2, fn=0.028		False
	38	0.4039		0.5169		0.5213		0.4275		0.8884	0.8622		tp=0.67, tn=0.11, fp=0.18, fn=0.035		True
	39	0.3972		0.5276		0.5073		0.3912		0.8844	0.8387		tp=0.64, tn=0.12, fp=0.2, fn=0.042		False
	40	0.3945		0.4858		0.5299		0.3869		0.8909	0.8634		tp=0.69, tn=0.098, fp=0.17, fn=0.042		False
	41	0.3923		0.4837		0.5248		0.4577		0.8888	0.8711		tp=0.69, tn=0.11, fp=0.17, fn=0.028		True
	42	0.3906		0.5039		0.5281		0.4265		0.8884	0.861		tp=0.67, tn=0.11, fp=0.18, fn=0.035		False
	43	0.3851		0.4857		0.5347		0.4391		0.8908	0.861		tp=0.67, tn=0.11, fp=0.19, fn=0.028		False
	44	0.3856		0.502		0.5536		0.4411		0.892	0.8532		tp=0.65, tn=0.13, fp=0.19, fn=0.035		False
	45	0.3841		0.5305		0.5496		0.3788		0.8925	0.8402		tp=0.64, tn=0.11, fp=0.2, fn=0.042		False
	46	0.379		0.5142		0.5624		0.4304		0.897	0.8532		tp=0.65, tn=0.13, fp=0.18, fn=0.042		False
	47	0.3769		0.5171		0.5824		0.3864		0.8977	0.8468		tp=0.66, tn=0.1, fp=0.2, fn=0.035		False
	48	0.374		0.4964		0.5511		0.4719		0.8933	0.8636		tp=0.66, tn=0.13, fp=0.17, fn=0.035		True
	49	0.3719		0.4754		0.5865		0.4585		0.8989	0.875		tp=0.69, tn=0.12, fp=0.15, fn=0.042		False
	50	0.3668		0.5182		0.5816		0.4485		0.8996	0.8649		tp=0.67, tn=0.12, fp=0.17, fn=0.035		False
	51	0.3669		0.5017		0.5917		0.4808		0.8995	0.8676		tp=0.66, tn=0.13, fp=0.17, fn=0.035		True
	52	0.3641		0.4901		0.5905		0.4113		0.8989	0.8673		tp=0.69, tn=0.1, fp=0.17, fn=0.042		False
	53	0.3602		0.4849		0.6105		0.4499		0.9046	0.8636		tp=0.66, tn=0.13, fp=0.17, fn=0.042		False
	54	0.3574		0.5067		0.5978		0.4421		0.9026	0.8571		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False
	55	0.3541		0.5354		0.6086		0.3967		0.9033	0.8507		tp=0.66, tn=0.11, fp=0.19, fn=0.042		False
	56	0.3518		0.507		0.6193		0.4712		0.9063	0.8676		tp=0.66, tn=0.13, fp=0.16, fn=0.042		False
	57	0.3487		0.5272		0.6197		0.4001		0.9046	0.844		tp=0.64, tn=0.12, fp=0.2, fn=0.042		False
	58	0.3485		0.5034		0.6141		0.44		0.9045	0.8584		tp=0.66, tn=0.13, fp=0.17, fn=0.042		False
	59	0.3448		0.5185		0.6203		0.4421		0.9076	0.8571		tp=0.65, tn=0.13, fp=0.17, fn=0.049		False
	60	0.3437		0.5078		0.6162		0.4699		0.9053	0.8688		tp=0.67, tn=0.13, fp=0.17, fn=0.035		False
	61	0.3428		0.5211		0.6314		0.3898		0.9078	0.844		tp=0.64, tn=0.12, fp=0.19, fn=0.049		False
	62	0.3368		0.5288		0.6319		0.3967		0.9088	0.8507		tp=0.66, tn=0.11, fp=0.19, fn=0.042		False
	63	0.3369		0.5191		0.6424		0.4304		0.9113	0.8532		tp=0.65, tn=0.13, fp=0.18, fn=0.042		False
	64	0.334		0.5203		0.6319		0.41		0.9094	0.8559		tp=0.66, tn=0.12, fp=0.17, fn=0.049		False
	65	0.335		0.5251		0.637		0.3831		0.9087	0.852		tp=0.66, tn=0.1, fp=0.19, fn=0.042		False
	66	0.3338		0.5062		0.6285		0.3487		0.9063	0.8559		tp=0.69, tn=0.084, fp=0.2, fn=0.035		False
	67	0.3309		0.497		0.6355		0.4288		0.9096	0.8649		tp=0.67, tn=0.12, fp=0.16, fn=0.049		False
	68	0.3254		0.5353		0.6309		0.3538		0.9084	0.8468		tp=0.66, tn=0.1, fp=0.18, fn=0.056		False
	69	0.3307		0.5566		0.6303		0.3245		0.9078	0.8203		tp=0.62, tn=0.11, fp=0.22, fn=0.056		False
	70	0.3241		0.4917		0.6449		0.4339		0.9123	0.87		tp=0.67, tn=0.12, fp=0.13, fn=0.069		False
	71	0.326		0.525		0.6353		0.424		0.9085	0.8519		tp=0.64, tn=0.13, fp=0.17, fn=0.056		False
	72	0.3217		0.5286		0.6541		0.4092		0.913	0.8493		tp=0.65, tn=0.12, fp=0.19, fn=0.042		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		134
learning rate		0.000431720190288
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_85-lr0.00043-h_size134-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.689		0.6748		0.07602		0.2004		0.5913	0.5521		tp=0.25, tn=0.34, fp=0.14, fn=0.27		True
	2	0.6692		0.6828		0.1834		0.1281		0.5947	0.6982		tp=0.51, tn=0.049, fp=0.42, fn=0.021		False
	3	0.646		0.6656		0.2682		0.171		0.6471	0.6625		tp=0.41, tn=0.18, fp=0.3, fn=0.11		False
	4	0.6216		0.6741		0.322		0.1761		0.6714	0.6798		tp=0.44, tn=0.14, fp=0.34, fn=0.079		False
	5	0.6142		0.7011		0.341		0.117		0.6765	0.6816		tp=0.47, tn=0.092, fp=0.38, fn=0.059		False
	6	0.593		0.6654		0.377		0.2222		0.6956	0.6622		tp=0.38, tn=0.24, fp=0.23, fn=0.16		True
	7	0.5848		0.7081		0.3889		0.178		0.7046	0.6812		tp=0.44, tn=0.15, fp=0.33, fn=0.082		False
	8	0.5736		0.6942		0.4161		0.2097		0.713	0.5879		tp=0.29, tn=0.31, fp=0.15, fn=0.25		False
	9	0.5705		0.689		0.406		0.2299		0.7086	0.6287		tp=0.33, tn=0.29, fp=0.19, fn=0.2		True
	10	0.5687		0.6815		0.4273		0.2029		0.7184	0.637		tp=0.35, tn=0.25, fp=0.23, fn=0.17		False
	11	0.5533		0.7004		0.4362		0.1839		0.7227	0.6359		tp=0.35, tn=0.24, fp=0.23, fn=0.17		False
	12	0.5453		0.741		0.4527		0.2154		0.7314	0.5282		tp=0.23, tn=0.36, fp=0.11, fn=0.3		False
	13	0.5369		0.7337		0.461		0.1574		0.7363	0.6273		tp=0.35, tn=0.23, fp=0.26, fn=0.16		False
	14	0.5424		0.7096		0.451		0.1998		0.7303	0.6176		tp=0.32, tn=0.28, fp=0.18, fn=0.22		False
	15	0.5339		0.7422		0.4722		0.2066		0.7424	0.5651		tp=0.26, tn=0.34, fp=0.14, fn=0.26		False
	16	0.5295		0.7385		0.4782		0.18		0.7452	0.5774		tp=0.28, tn=0.31, fp=0.18, fn=0.24		False
	17	0.5258		0.7386		0.4635		0.1927		0.737	0.6199		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	18	0.5236		0.772		0.4847		0.2269		0.7461	0.5706		tp=0.26, tn=0.34, fp=0.13, fn=0.27		False
	19	0.5244		0.7696		0.4937		0.1967		0.7511	0.562		tp=0.26, tn=0.33, fp=0.15, fn=0.26		False
	20	0.5275		0.7394		0.4734		0.1769		0.7412	0.6154		tp=0.33, tn=0.26, fp=0.22, fn=0.19		False
	21	0.5138		0.755		0.5024		0.1863		0.7554	0.6378		tp=0.36, tn=0.23, fp=0.26, fn=0.15		False
	22	0.5249		0.7243		0.4888		0.1973		0.7485	0.6532		tp=0.37, tn=0.23, fp=0.24, fn=0.16		False
	23	0.5086		0.8477		0.5219		0.1942		0.7653	0.4828		tp=0.2, tn=0.38, fp=0.095, fn=0.33		False
	24	0.5213		0.7495		0.5037		0.2054		0.7571	0.6		tp=0.3, tn=0.3, fp=0.17, fn=0.23		False
	25	0.5106		0.7767		0.5112		0.1908		0.7612	0.5827		tp=0.28, tn=0.31, fp=0.17, fn=0.24		False
	26	0.5027		0.7883		0.5124		0.2369		0.7614	0.5808		tp=0.27, tn=0.34, fp=0.13, fn=0.27		True
	27	0.5128		0.7608		0.5059		0.165		0.7571	0.6091		tp=0.32, tn=0.26, fp=0.21, fn=0.2		False
	28	0.5068		0.7519		0.5113		0.2089		0.7604	0.6076		tp=0.31, tn=0.3, fp=0.18, fn=0.22		False
	29	0.4983		0.7647		0.5207		0.1709		0.7644	0.595		tp=0.3, tn=0.28, fp=0.2, fn=0.21		False
	30	0.4988		0.7702		0.5284		0.1578		0.769	0.5961		tp=0.31, tn=0.27, fp=0.2, fn=0.22		False
	31	0.5008		0.7993		0.5213		0.1591		0.7654	0.6353		tp=0.36, tn=0.22, fp=0.25, fn=0.17		False
	32	0.5013		0.7767		0.5244		0.1485		0.7636	0.6085		tp=0.33, tn=0.25, fp=0.23, fn=0.2		False
	33	0.4987		0.7832		0.5161		0.1689		0.7643	0.597		tp=0.31, tn=0.28, fp=0.2, fn=0.22		False
	34	0.5128		0.7798		0.5071		0.1835		0.7577	0.554		tp=0.26, tn=0.33, fp=0.16, fn=0.26		False
	35	0.4957		0.7759		0.5279		0.1694		0.7685	0.6212		tp=0.34, tn=0.25, fp=0.23, fn=0.19		False
	36	0.4897		0.7932		0.5473		0.1735		0.7795	0.5781		tp=0.28, tn=0.3, fp=0.18, fn=0.24		False
	37	0.4867		0.7858		0.5272		0.2124		0.7685	0.5932		tp=0.29, tn=0.31, fp=0.16, fn=0.24		False
	38	0.4903		0.7963		0.5308		0.16		0.7696	0.6351		tp=0.36, tn=0.22, fp=0.25, fn=0.17		False
	39	0.486		0.8024		0.5396		0.1512		0.7739	0.6081		tp=0.33, tn=0.25, fp=0.24, fn=0.19		False
	40	0.4964		0.7825		0.5291		0.1916		0.7695	0.6184		tp=0.33, tn=0.27, fp=0.21, fn=0.19		False
	41	0.4832		0.838		0.5473		0.1389		0.7775	0.6541		tp=0.4, tn=0.18, fp=0.28, fn=0.14		False
	42	0.4826		0.8071		0.5455		0.1463		0.7766	0.5971		tp=0.32, tn=0.26, fp=0.22, fn=0.21		False
	43	0.4767		0.8208		0.5538		0.1777		0.7797	0.584		tp=0.29, tn=0.3, fp=0.18, fn=0.23		False
	44	0.4711		0.813		0.5686		0.1551		0.7891	0.578		tp=0.29, tn=0.29, fp=0.19, fn=0.23		False
	45	0.4767		0.8338		0.5467		0.1822		0.7779	0.5752		tp=0.28, tn=0.31, fp=0.16, fn=0.25		False
	46	0.4659		0.8181		0.5556		0.1774		0.7814	0.6044		tp=0.31, tn=0.28, fp=0.21, fn=0.2		False
	47	0.4638		0.8106		0.5674		0.1669		0.7875	0.6068		tp=0.32, tn=0.26, fp=0.2, fn=0.22		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		40
learning rate		5.70839980969e&05
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_86-lr5.7e&05-h_size40-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6247		0.6286		-0.02308		0		0.8163	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6165		0.627		0		0		0.8182	0.812		tp=0.68, tn=0, fp=0.32, fn=0		False
	3	0.6148		0.6201		0		0		0.818	0.8158		tp=0.69, tn=0, fp=0.31, fn=0		False
	4	0.6129		0.629		0		0		0.8184	0.8081		tp=0.68, tn=0, fp=0.32, fn=0		False
	5	0.6117		0.6266		0		0		0.8183	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	6	0.6103		0.629		0		0		0.8183	0.8064		tp=0.68, tn=0, fp=0.32, fn=0		False
	7	0.6089		0.6241		0		0		0.8182	0.8109		tp=0.68, tn=0, fp=0.32, fn=0		False
	8	0.6072		0.6289		0		0		0.8184	0.8085		tp=0.68, tn=0, fp=0.32, fn=0		False
	9	0.606		0.6241		0		0		0.8184	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	10	0.6041		0.6299		0		0		0.8187	0.8053		tp=0.67, tn=0, fp=0.33, fn=0		False
	11	0.603		0.6221		0		0		0.8182	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	12	0.602		0.6278		0		0		0.8184	0.8078		tp=0.68, tn=0, fp=0.32, fn=0		False
	13	0.6003		0.6212		0		0		0.8185	0.812		tp=0.68, tn=0, fp=0.32, fn=0		False
	14	0.599		0.6279		0		0		0.8183	0.8078		tp=0.68, tn=0, fp=0.32, fn=0		False
	15	0.5977		0.6246		0		0		0.8182	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	16	0.5962		0.6223		0		0		0.8184	0.8127		tp=0.68, tn=0, fp=0.32, fn=0		False
	17	0.5951		0.6222		0		0		0.8183	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	18	0.5933		0.626		0		0		0.8184	0.8095		tp=0.68, tn=0, fp=0.32, fn=0		False
	19	0.5918		0.6278		0.02587		0		0.8184	0.8085		tp=0.68, tn=0, fp=0.32, fn=0		False
	20	0.5902		0.6236		0.04278		0		0.8188	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False
	21	0.589		0.6223		0.06445		0		0.8194	0.8116		tp=0.68, tn=0, fp=0.32, fn=0		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		109
learning rate		0.000280399117133
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_87-lr0.00028-h_size109-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6913		0.6856		0.03295		0.1508		0.5536	0.6511		tp=0.39, tn=0.19, fp=0.29, fn=0.13		True
	2	0.6803		0.6853		0.1618		0.1168		0.6293	0.441		tp=0.18, tn=0.36, fp=0.11, fn=0.35		False
	3	0.6711		0.6817		0.1809		0.1458		0.5881	0.5237		tp=0.24, tn=0.32, fp=0.15, fn=0.29		False
	4	0.6599		0.6857		0.2482		0.1321		0.6559	0.3931		tp=0.15, tn=0.4, fp=0.085, fn=0.37		False
	5	0.6525		0.6688		0.248		0.1559		0.6248	0.6597		tp=0.4, tn=0.18, fp=0.29, fn=0.13		True
	6	0.6418		0.6793		0.2808		0.2038		0.6619	0.5768		tp=0.27, tn=0.32, fp=0.15, fn=0.25		True
	7	0.6315		0.6747		0.2991		0.1648		0.6548	0.5638		tp=0.27, tn=0.31, fp=0.17, fn=0.25		False
	8	0.6219		0.6804		0.325		0.1382		0.6735	0.6196		tp=0.35, tn=0.22, fp=0.26, fn=0.17		False
	9	0.6175		0.6833		0.3238		0.2023		0.6715	0.5813		tp=0.28, tn=0.32, fp=0.16, fn=0.24		False
	10	0.6085		0.6805		0.3677		0.1322		0.6958	0.6264		tp=0.36, tn=0.21, fp=0.25, fn=0.17		False
	11	0.6059		0.6816		0.351		0.1697		0.6836	0.6049		tp=0.32, tn=0.27, fp=0.21, fn=0.2		False
	12	0.5991		0.6848		0.3706		0.1382		0.6944	0.5922		tp=0.31, tn=0.26, fp=0.21, fn=0.22		False
	13	0.6001		0.6948		0.377		0.1593		0.695	0.64		tp=0.37, tn=0.22, fp=0.25, fn=0.16		False
	14	0.5958		0.6955		0.3743		0.142		0.6984	0.5897		tp=0.31, tn=0.26, fp=0.22, fn=0.21		False
	15	0.59		0.6972		0.3855		0.1495		0.6998	0.6306		tp=0.36, tn=0.22, fp=0.25, fn=0.17		False
	16	0.5881		0.7022		0.3951		0.1527		0.7094	0.5926		tp=0.31, tn=0.27, fp=0.22, fn=0.21		False
	17	0.5848		0.7045		0.393		0.1737		0.7053	0.6413		tp=0.37, tn=0.22, fp=0.25, fn=0.16		False
	18	0.5818		0.7218		0.3967		0.1265		0.7084	0.5426		tp=0.26, tn=0.3, fp=0.18, fn=0.26		False
	19	0.584		0.7071		0.3991		0.1599		0.7077	0.5961		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	20	0.5798		0.7175		0.4007		0.1241		0.7069	0.6083		tp=0.34, tn=0.23, fp=0.25, fn=0.19		False
	21	0.58		0.7257		0.3919		0.1249		0.7059	0.5972		tp=0.32, tn=0.24, fp=0.22, fn=0.22		False
	22	0.5776		0.7251		0.4126		0.1252		0.7157	0.5627		tp=0.28, tn=0.28, fp=0.2, fn=0.24		False
	23	0.5773		0.7206		0.4066		0.1271		0.7085	0.6182		tp=0.35, tn=0.22, fp=0.24, fn=0.19		False
	24	0.5791		0.7279		0.3856		0.1446		0.7065	0.561		tp=0.28, tn=0.29, fp=0.18, fn=0.26		False
	25	0.579		0.744		0.3984		0.1683		0.7046	0.5455		tp=0.25, tn=0.32, fp=0.15, fn=0.27		False
	26	0.5761		0.7161		0.3936		0.1466		0.7038	0.6172		tp=0.34, tn=0.24, fp=0.23, fn=0.19		False
	27	0.577		0.7272		0.4169		0.1283		0.7202	0.6005		tp=0.33, tn=0.24, fp=0.23, fn=0.2		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		12
learning rate		5.18732281719e&05
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_88-lr5.2e&05-h_size12-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6973		0.6921		-0.02719		0.07112		0.1249	0.4211		tp=0.17, tn=0.35, fp=0.13, fn=0.35		True
	2	0.6931		0.6894		0.02352		0.1222		0.4925	0.5757		tp=0.3, tn=0.26, fp=0.22, fn=0.22		True
	3	0.6917		0.6869		0.0561		0.1545		0.5375	0.6186		tp=0.34, tn=0.24, fp=0.24, fn=0.18		True
	4	0.6904		0.6875		0.07696		0.1579		0.5927	0.6236		tp=0.35, tn=0.24, fp=0.24, fn=0.18		True
	5	0.6894		0.6874		0.09503		0.1757		0.5847	0.6226		tp=0.34, tn=0.25, fp=0.23, fn=0.18		True
	6	0.6883		0.6844		0.1026		0.1982		0.5883	0.6469		tp=0.36, tn=0.24, fp=0.23, fn=0.16		True
	7	0.6871		0.6854		0.1225		0.1979		0.5829	0.6268		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	8	0.6862		0.6847		0.1405		0.1713		0.6055	0.612		tp=0.33, tn=0.26, fp=0.22, fn=0.2		False
	9	0.6851		0.6844		0.1391		0.1606		0.6103	0.6039		tp=0.32, tn=0.26, fp=0.21, fn=0.21		False
	10	0.6842		0.6851		0.154		0.1505		0.6055	0.6024		tp=0.32, tn=0.26, fp=0.22, fn=0.21		False
	11	0.6832		0.6833		0.1594		0.1724		0.6057	0.6064		tp=0.32, tn=0.27, fp=0.21, fn=0.21		False
	12	0.6823		0.6821		0.1652		0.1852		0.604	0.6238		tp=0.34, tn=0.26, fp=0.21, fn=0.19		False
	13	0.6812		0.6807		0.1809		0.2192		0.6033	0.6398		tp=0.35, tn=0.27, fp=0.21, fn=0.18		True
	14	0.6803		0.6825		0.1784		0.1632		0.6286	0.5955		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	15	0.6793		0.6809		0.1947		0.1792		0.6283	0.6005		tp=0.31, tn=0.28, fp=0.19, fn=0.22		False
	16	0.6782		0.6805		0.1972		0.1846		0.6146	0.6015		tp=0.31, tn=0.28, fp=0.19, fn=0.21		False
	17	0.6773		0.6806		0.2016		0.1431		0.6213	0.5956		tp=0.31, tn=0.26, fp=0.21, fn=0.21		False
	18	0.6764		0.6803		0.1995		0.1742		0.6287	0.5945		tp=0.3, tn=0.28, fp=0.2, fn=0.21		False
	19	0.6753		0.6806		0.2182		0.1635		0.6285	0.5955		tp=0.31, tn=0.27, fp=0.2, fn=0.22		False
	20	0.6743		0.6782		0.2211		0.1903		0.6245	0.6165		tp=0.32, tn=0.27, fp=0.19, fn=0.21		False
	21	0.6734		0.6767		0.2244		0.1914		0.6247	0.6323		tp=0.35, tn=0.25, fp=0.22, fn=0.18		False
	22	0.6725		0.6767		0.2243		0.2017		0.6394	0.6283		tp=0.34, tn=0.27, fp=0.21, fn=0.19		False
	23	0.6715		0.6759		0.2243		0.2049		0.6378	0.6135		tp=0.32, tn=0.29, fp=0.19, fn=0.21		False
	24	0.6705		0.6754		0.2339		0.2104		0.6406	0.6188		tp=0.32, tn=0.28, fp=0.18, fn=0.21		False
	25	0.6696		0.6771		0.2379		0.1794		0.6429	0.6		tp=0.31, tn=0.28, fp=0.19, fn=0.22		False
	26	0.6688		0.6746		0.2434		0.2117		0.6328	0.6169		tp=0.32, tn=0.29, fp=0.2, fn=0.19		False
	27	0.6678		0.6775		0.2494		0.1858		0.6423	0.6256		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	28	0.6666		0.6738		0.2473		0.2283		0.6451	0.6359		tp=0.34, tn=0.28, fp=0.19, fn=0.19		True
	29	0.6656		0.6797		0.2529		0.1682		0.6569	0.5831		tp=0.29, tn=0.29, fp=0.18, fn=0.24		False
	30	0.6649		0.6762		0.242		0.1685		0.6236	0.6087		tp=0.32, tn=0.26, fp=0.21, fn=0.21		False
	31	0.6638		0.6777		0.2567		0.1887		0.6368	0.6108		tp=0.32, tn=0.28, fp=0.21, fn=0.19		False
	32	0.6629		0.6746		0.2629		0.1848		0.6541	0.6131		tp=0.32, tn=0.27, fp=0.2, fn=0.21		False
	33	0.662		0.674		0.2705		0.1694		0.6603	0.5955		tp=0.31, tn=0.28, fp=0.19, fn=0.23		False
	34	0.6608		0.6736		0.266		0.1966		0.6396	0.6085		tp=0.31, tn=0.29, fp=0.19, fn=0.21		False
	35	0.6599		0.6746		0.2711		0.167		0.6568	0.5894		tp=0.3, tn=0.28, fp=0.19, fn=0.22		False
	36	0.6591		0.6733		0.2683		0.1798		0.6407	0.602		tp=0.31, tn=0.28, fp=0.19, fn=0.22		False
	37	0.658		0.677		0.2799		0.1661		0.665	0.6087		tp=0.32, tn=0.26, fp=0.21, fn=0.21		False
	38	0.6571		0.6707		0.2821		0.2237		0.6635	0.6122		tp=0.31, tn=0.3, fp=0.17, fn=0.22		False
	39	0.6559		0.6734		0.2794		0.1675		0.6488	0.6029		tp=0.32, tn=0.27, fp=0.21, fn=0.21		False
	40	0.655		0.6762		0.2867		0.1606		0.6574	0.6039		tp=0.32, tn=0.26, fp=0.21, fn=0.21		False
	41	0.6541		0.6762		0.2912		0.131		0.6665	0.5888		tp=0.31, tn=0.26, fp=0.21, fn=0.22		False
	42	0.6532		0.6684		0.2961		0.1737		0.6638	0.6044		tp=0.32, tn=0.27, fp=0.19, fn=0.22		False
	43	0.6521		0.67		0.2934		0.1673		0.661	0.6049		tp=0.32, tn=0.27, fp=0.2, fn=0.22		False
	44	0.651		0.6764		0.2919		0.1474		0.6573	0.5931		tp=0.31, tn=0.26, fp=0.22, fn=0.2		False
	45	0.6503		0.6714		0.2949		0.1682		0.6631	0.623		tp=0.34, tn=0.25, fp=0.22, fn=0.19		False
	46	0.6496		0.6705		0.2926		0.1582		0.6674	0.6039		tp=0.32, tn=0.26, fp=0.21, fn=0.21		False
	47	0.6487		0.6754		0.2954		0.1613		0.66	0.6128		tp=0.33, tn=0.25, fp=0.21, fn=0.21		False
	48	0.6476		0.6715		0.305		0.1835		0.6661	0.6187		tp=0.33, tn=0.26, fp=0.21, fn=0.19		False
	49	0.6466		0.6713		0.308		0.175		0.6697	0.6209		tp=0.34, tn=0.25, fp=0.22, fn=0.19		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		160
learning rate		0.000118750691122
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_89-lr0.00012-h_size160-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6206		0.6222		-0.001691		0		0.8167	0.8106		tp=0.68, tn=0, fp=0.32, fn=0		False
	2	0.6066		0.6152		0.006119		0.02951		0.8185	0.8078		tp=0.68, tn=0.003, fp=0.32, fn=0.003		True
	3	0.6015		0.6145		0.05705		0.0717		0.8184	0.8054		tp=0.67, tn=0.0089, fp=0.32, fn=0.0059		True
	4	0.5992		0.6096		0.08746		0.09116		0.8188	0.8076		tp=0.66, tn=0.022, fp=0.29, fn=0.021		True
	5	0.5969		0.6095		0.1024		0.08608		0.8184	0.804		tp=0.66, tn=0.024, fp=0.3, fn=0.024		False
	6	0.5937		0.6056		0.1032		0.108		0.8192	0.8115		tp=0.67, tn=0.019, fp=0.3, fn=0.013		True
	7	0.5907		0.6081		0.1097		0.1267		0.8184	0.8022		tp=0.64, tn=0.037, fp=0.29, fn=0.031		True
	8	0.5897		0.6051		0.1297		0.1528		0.8206	0.8095		tp=0.66, tn=0.033, fp=0.29, fn=0.019		True
	9	0.5889		0.6041		0.1364		0.1234		0.8197	0.8132		tp=0.67, tn=0.016, fp=0.3, fn=0.0074		False
	10	0.5872		0.6014		0.1384		0.1353		0.8193	0.8138		tp=0.66, tn=0.033, fp=0.28, fn=0.025		False
	11	0.5847		0.6062		0.1371		0.1425		0.8193	0.8101		tp=0.66, tn=0.027, fp=0.3, fn=0.015		False
	12	0.5843		0.5996		0.1432		0.1344		0.8198	0.8116		tp=0.66, tn=0.03, fp=0.29, fn=0.021		False
	13	0.5817		0.602		0.1392		0.1754		0.8182	0.8093		tp=0.65, tn=0.05, fp=0.27, fn=0.035		True
	14	0.5817		0.6049		0.1512		0.1745		0.8192	0.8041		tp=0.63, tn=0.059, fp=0.26, fn=0.047		False
	15	0.5797		0.5975		0.1564		0.1832		0.8196	0.8158		tp=0.66, tn=0.043, fp=0.27, fn=0.025		True
	16	0.5787		0.5999		0.1647		0.1746		0.8197	0.8049		tp=0.64, tn=0.056, fp=0.27, fn=0.043		False
	17	0.5773		0.5961		0.1649		0.1669		0.8187	0.8093		tp=0.64, tn=0.052, fp=0.26, fn=0.041		False
	18	0.5771		0.5995		0.1608		0.1395		0.8169	0.8127		tp=0.67, tn=0.028, fp=0.29, fn=0.018		False
	19	0.5755		0.5985		0.1687		0.1718		0.8192	0.8136		tp=0.66, tn=0.043, fp=0.27, fn=0.028		False
	20	0.5748		0.5975		0.1672		0.1971		0.8186	0.8147		tp=0.66, tn=0.043, fp=0.28, fn=0.021		True
	21	0.5738		0.5987		0.1799		0.1912		0.8188	0.8105		tp=0.64, tn=0.056, fp=0.26, fn=0.039		False
	22	0.5717		0.6037		0.1772		0.1927		0.8193	0.7973		tp=0.61, tn=0.077, fp=0.25, fn=0.064		False
	23	0.5723		0.5966		0.184		0.1812		0.8184	0.815		tp=0.66, tn=0.041, fp=0.28, fn=0.024		False
	24	0.5701		0.6007		0.193		0.1853		0.82	0.7992		tp=0.62, tn=0.07, fp=0.25, fn=0.056		False
	25	0.5691		0.5948		0.1849		0.1755		0.8193	0.8075		tp=0.64, tn=0.059, fp=0.25, fn=0.049		False
	26	0.5693		0.6062		0.1832		0.1243		0.8175	0.8058		tp=0.65, tn=0.03, fp=0.29, fn=0.022		False
	27	0.5685		0.5969		0.1858		0.1755		0.8183	0.8143		tp=0.66, tn=0.041, fp=0.28, fn=0.025		False
	28	0.5676		0.5984		0.186		0.1576		0.8191	0.7992		tp=0.63, tn=0.058, fp=0.26, fn=0.05		False
	29	0.5674		0.602		0.2021		0.1526		0.82	0.7992		tp=0.63, tn=0.056, fp=0.27, fn=0.05		False
	30	0.5666		0.5902		0.2088		0.1964		0.8215	0.8134		tp=0.64, tn=0.061, fp=0.25, fn=0.044		False
	31	0.5663		0.6026		0.2032		0.1612		0.8205	0.8099		tp=0.66, tn=0.036, fp=0.29, fn=0.021		False
	32	0.5656		0.594		0.2055		0.1841		0.8207	0.8119		tp=0.65, tn=0.055, fp=0.26, fn=0.04		False
	33	0.5643		0.5999		0.2089		0.1644		0.8205	0.7996		tp=0.62, tn=0.062, fp=0.26, fn=0.055		False
	34	0.5636		0.6173		0.2143		0.1143		0.8203	0.8055		tp=0.66, tn=0.027, fp=0.3, fn=0.021		False
	35	0.5644		0.5994		0.215		0.1567		0.8213	0.7992		tp=0.63, tn=0.061, fp=0.26, fn=0.056		False
	36	0.5637		0.6006		0.2177		0.1697		0.8211	0.7946		tp=0.61, tn=0.075, fp=0.24, fn=0.074		False
	37	0.562		0.6005		0.207		0.1791		0.8192	0.8038		tp=0.63, tn=0.061, fp=0.26, fn=0.047		False
	38	0.5622		0.5965		0.2189		0.1661		0.821	0.7989		tp=0.62, tn=0.071, fp=0.24, fn=0.071		False
	39	0.5604		0.6036		0.2192		0.1289		0.8204	0.8091		tp=0.66, tn=0.031, fp=0.29, fn=0.024		False
	40	0.5614		0.5967		0.2177		0.1576		0.8215	0.8103		tp=0.65, tn=0.044, fp=0.27, fn=0.034		False
	41	0.5608		0.6074		0.2174		0.1795		0.8203	0.8056		tp=0.64, tn=0.05, fp=0.28, fn=0.033		False


data			/scratch/asw462/data/levin
input size		300
hidden size		22
learning rate		0.000439549581118
encoding size		279
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_8-lr0.00044-h_size22-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_10-lr0.00044-h_size279-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6094		0.5995		0.06091		0		0.8275	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	2	0.583		0.5857		0		0		0.8402	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5755		0.5803		0		0		0.8412	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	4	0.5713		0.5562		0		0		0.8405	0.8434		tp=0.73, tn=0, fp=0.27, fn=0		False
	5	0.5623		0.5734		0		0		0.843	0.823		tp=0.7, tn=0, fp=0.3, fn=0		False
	6	0.5544		0.5825		0		0		0.8432	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	7	0.5493		0.56		0.06101		0		0.8423	0.8279		tp=0.71, tn=0, fp=0.29, fn=0		False
	8	0.5406		0.5708		0.1056		0		0.8432	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	9	0.53		0.5614		0.1624		0.1238		0.8469	0.8167		tp=0.69, tn=0.007, fp=0.31, fn=0		True
	10	0.5211		0.5608		0.1987		0.1238		0.8484	0.8167		tp=0.69, tn=0.007, fp=0.31, fn=0		False
	11	0.5133		0.5443		0.2453		0.1238		0.8503	0.8167		tp=0.69, tn=0.007, fp=0.31, fn=0		False
	12	0.5004		0.5288		0.2783		0.1259		0.856	0.8216		tp=0.69, tn=0.007, fp=0.3, fn=0		True
	13	0.4919		0.5296		0.3523		0.07373		0.864	0.8201		tp=0.69, tn=0.014, fp=0.29, fn=0.014		False
	14	0.4831		0.5333		0.3599		0.3048		0.8626	0.8462		tp=0.69, tn=0.056, fp=0.24, fn=0.014		True
	15	0.4706		0.509		0.3868		0.2814		0.8684	0.8475		tp=0.7, tn=0.049, fp=0.24, fn=0.014		False
	16	0.4594		0.5056		0.4048		0.3463		0.8717	0.8596		tp=0.71, tn=0.063, fp=0.22, fn=0.014		True
	17	0.4537		0.5261		0.4008		0.338		0.8694	0.8384		tp=0.67, tn=0.07, fp=0.24, fn=0.014		False
	18	0.4454		0.5175		0.4323		0.3324		0.8758	0.8462		tp=0.69, tn=0.056, fp=0.24, fn=0.007		False
	19	0.4326		0.5164		0.4294		0.3882		0.8748	0.8496		tp=0.67, tn=0.091, fp=0.22, fn=0.021		True
	20	0.4268		0.515		0.4751		0.3559		0.8813	0.8522		tp=0.69, tn=0.077, fp=0.22, fn=0.021		False
	21	0.4218		0.5046		0.4725		0.3381		0.879	0.8522		tp=0.69, tn=0.077, fp=0.21, fn=0.028		False
	22	0.4123		0.5108		0.4816		0.4496		0.8802	0.8673		tp=0.69, tn=0.1, fp=0.19, fn=0.021		True
	23	0.4098		0.4829		0.4945		0.3654		0.8816	0.8546		tp=0.68, tn=0.091, fp=0.2, fn=0.035		False
	24	0.4019		0.5236		0.5149		0.378		0.8873	0.8416		tp=0.65, tn=0.1, fp=0.21, fn=0.035		False
	25	0.3943		0.5003		0.5258		0.5012		0.8877	0.8716		tp=0.66, tn=0.14, fp=0.16, fn=0.035		True
	26	0.3927		0.4895		0.5319		0.4393		0.8902	0.87		tp=0.68, tn=0.12, fp=0.15, fn=0.049		False
	27	0.3834		0.486		0.5429		0.491		0.8913	0.8727		tp=0.67, tn=0.13, fp=0.16, fn=0.035		False
	28	0.3778		0.5035		0.5648		0.4389		0.8956	0.8597		tp=0.66, tn=0.12, fp=0.18, fn=0.035		False
	29	0.3749		0.4761		0.5756		0.4154		0.8967	0.861		tp=0.67, tn=0.11, fp=0.17, fn=0.042		False
	30	0.377		0.5048		0.5707		0.3967		0.8951	0.8507		tp=0.66, tn=0.11, fp=0.19, fn=0.042		False
	31	0.3677		0.4995		0.5962		0.4411		0.9003	0.8597		tp=0.66, tn=0.12, fp=0.17, fn=0.042		False
	32	0.3575		0.5051		0.5939		0.3654		0.9016	0.8546		tp=0.68, tn=0.091, fp=0.2, fn=0.035		False
	33	0.3586		0.5068		0.6042		0.4282		0.9035	0.8597		tp=0.66, tn=0.12, fp=0.17, fn=0.042		False
	34	0.3498		0.5078		0.6055		0.4304		0.9052	0.8532		tp=0.65, tn=0.13, fp=0.18, fn=0.042		False
	35	0.3526		0.5367		0.6072		0.3742		0.9033	0.8468		tp=0.66, tn=0.1, fp=0.2, fn=0.042		False
	36	0.3495		0.5171		0.6118		0.3271		0.9043	0.8509		tp=0.68, tn=0.084, fp=0.2, fn=0.042		False
	37	0.3452		0.5109		0.6129		0.4059		0.9053	0.8559		tp=0.66, tn=0.11, fp=0.18, fn=0.042		False
	38	0.3377		0.5153		0.6389		0.4494		0.9115	0.8611		tp=0.65, tn=0.14, fp=0.15, fn=0.063		False
	39	0.3416		0.5109		0.6301		0.3527		0.9067	0.8546		tp=0.68, tn=0.091, fp=0.19, fn=0.042		False
	40	0.3309		0.5054		0.6431		0.4389		0.9112	0.8597		tp=0.66, tn=0.12, fp=0.18, fn=0.035		False
	41	0.3288		0.5344		0.6412		0.3692		0.9107	0.8416		tp=0.65, tn=0.11, fp=0.19, fn=0.049		False
	42	0.3259		0.5122		0.6382		0.4669		0.9105	0.8727		tp=0.67, tn=0.13, fp=0.14, fn=0.056		False
	43	0.3259		0.4884		0.6508		0.4943		0.9118	0.8756		tp=0.66, tn=0.15, fp=0.13, fn=0.063		False
	44	0.3222		0.5265		0.6466		0.4041		0.9109	0.8411		tp=0.63, tn=0.13, fp=0.18, fn=0.056		False
	45	0.32		0.5079		0.6523		0.4034		0.9119	0.8597		tp=0.66, tn=0.12, fp=0.15, fn=0.063		False
	46	0.3216		0.5257		0.6534		0.4015		0.912	0.8559		tp=0.66, tn=0.12, fp=0.17, fn=0.056		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		127
learning rate		0.00266861152905
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_90-lr0.0027-h_size127-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6875		0.6771		0.1018		0.1825		0.5933	0.6521		tp=0.38, tn=0.21, fp=0.27, fn=0.14		True
	2	0.6843		0.6749		0.1173		0.1597		0.6118	0.6735		tp=0.42, tn=0.17, fp=0.28, fn=0.13		False
	3	0.6844		0.683		0.1107		0.1596		0.6056	0.5		tp=0.21, tn=0.36, fp=0.13, fn=0.29		False
	4	0.6843		0.6838		0.1158		0.1543		0.6049	0.5172		tp=0.23, tn=0.34, fp=0.14, fn=0.29		False
	5	0.6832		0.6746		0.121		0.1455		0.6042	0.6526		tp=0.4, tn=0.18, fp=0.29, fn=0.13		False
	6	0.6855		0.69		0.09855		0.03829		0.6063	0.2576		tp=0.087, tn=0.41, fp=0.066, fn=0.43		False
	7	0.6851		0.6785		0.1043		0.1378		0.6023	0.6348		tp=0.37, tn=0.19, fp=0.29, fn=0.14		False
	8	0.6824		0.6879		0.1169		0.09375		0.6148	0.3729		tp=0.14, tn=0.38, fp=0.09, fn=0.38		False
	9	0.68		0.6727		0.1338		0.1555		0.6197	0.6824		tp=0.45, tn=0.14, fp=0.33, fn=0.09		False
	10	0.6846		0.674		0.1026		0.1463		0.593	0.6809		tp=0.45, tn=0.13, fp=0.34, fn=0.082		False
	11	0.6822		0.673		0.1207		0.1487		0.6107	0.6955		tp=0.47, tn=0.11, fp=0.34, fn=0.072		False
	12	0.6814		0.6757		0.1165		0.1594		0.6178	0.6568		tp=0.4, tn=0.19, fp=0.28, fn=0.14		False
	13	0.6853		0.6787		0.1202		0.1958		0.6126	0.6253		tp=0.33, tn=0.27, fp=0.21, fn=0.19		True
	14	0.6833		0.6826		0.1186		0.1553		0.6055	0.6372		tp=0.37, tn=0.21, fp=0.27, fn=0.15		False
	15	0.6825		0.6791		0.1252		0.1864		0.6087	0.644		tp=0.36, tn=0.24, fp=0.23, fn=0.18		False
	16	0.6812		0.6738		0.1084		0.2177		0.6181	0.6667		tp=0.38, tn=0.23, fp=0.23, fn=0.16		True
	17	0.6837		0.6799		0.09579		0.1538		0.5926	0.6388		tp=0.37, tn=0.21, fp=0.27, fn=0.15		False
	18	0.6819		0.6771		0.1121		0.2107		0.602	0.6383		tp=0.35, tn=0.26, fp=0.21, fn=0.18		False
	19	0.6801		0.68		0.1189		0.2204		0.6206	0.6513		tp=0.36, tn=0.25, fp=0.21, fn=0.17		True
	20	0.6837		0.6839		0.1269		0.07089		0.6143	0.3771		tp=0.14, tn=0.38, fp=0.11, fn=0.37		False
	21	0.6794		0.6781		0.1306		0.1403		0.6159	0.6869		tp=0.46, tn=0.11, fp=0.35, fn=0.072		False
	22	0.6813		0.6768		0.1171		0.149		0.6146	0.6808		tp=0.45, tn=0.12, fp=0.35, fn=0.074		False
	23	0.6816		0.6776		0.11		0.183		0.6089	0.6457		tp=0.37, tn=0.23, fp=0.25, fn=0.16		False
	24	0.6794		0.6744		0.1244		0.1745		0.6228	0.6638		tp=0.4, tn=0.19, fp=0.28, fn=0.13		False
	25	0.6788		0.6838		0.1509		0.1366		0.6338	0.57		tp=0.29, tn=0.28, fp=0.19, fn=0.24		False
	26	0.6805		0.672		0.1179		0.2213		0.6182	0.6667		tp=0.38, tn=0.23, fp=0.23, fn=0.16		True
	27	0.6832		0.6812		0.1087		0.1588		0.5926	0.6256		tp=0.35, tn=0.23, fp=0.26, fn=0.16		False
	28	0.68		0.6799		0.1356		0.09188		0.6156	0.6548		tp=0.42, tn=0.13, fp=0.34, fn=0.11		False
	29	0.6816		0.6744		0.1237		0.1174		0.6136	0.656		tp=0.42, tn=0.14, fp=0.34, fn=0.1		False
	30	0.6791		0.6816		0.1399		0.1526		0.6107	0.6372		tp=0.37, tn=0.21, fp=0.26, fn=0.16		False
	31	0.6801		0.6798		0.138		0.1485		0.6241	0.6389		tp=0.37, tn=0.2, fp=0.27, fn=0.15		False
	32	0.6806		0.6797		0.1106		0.1887		0.6067	0.6256		tp=0.34, tn=0.26, fp=0.22, fn=0.18		False
	33	0.681		0.6775		0.1144		0.1469		0.5954	0.6514		tp=0.4, tn=0.17, fp=0.32, fn=0.11		False
	34	0.6805		0.6885		0.126		0.05427		0.6136	0.3448		tp=0.13, tn=0.38, fp=0.097, fn=0.39		False
	35	0.6799		0.6843		0.1232		0.1805		0.6017	0.6078		tp=0.32, tn=0.27, fp=0.21, fn=0.19		False
	36	0.6825		0.6758		0.1212		0.1219		0.598	0.668		tp=0.43, tn=0.14, fp=0.33, fn=0.1		False
	37	0.6811		0.673		0.1221		0.1668		0.593	0.6611		tp=0.4, tn=0.19, fp=0.28, fn=0.13		False
	38	0.68		0.6868		0.1195		0.1641		0.6075	0.6805		tp=0.46, tn=0.11, fp=0.38, fn=0.051		False
	39	0.6797		0.6835		0.1318		0.1076		0.6178	0.487		tp=0.22, tn=0.33, fp=0.15, fn=0.31		False
	40	0.6799		0.6842		0.1349		0.1526		0.6035	0.5926		tp=0.31, tn=0.27, fp=0.21, fn=0.21		False
	41	0.6824		0.6778		0.1255		0.1879		0.6055	0.6533		tp=0.38, tn=0.22, fp=0.24, fn=0.16		False
	42	0.6802		0.6715		0.1286		0.1908		0.6053	0.6667		tp=0.4, tn=0.2, fp=0.27, fn=0.13		False
	43	0.6759		0.6748		0.1423		0.1601		0.612	0.6447		tp=0.38, tn=0.21, fp=0.26, fn=0.15		False
	44	0.6792		0.6787		0.1153		0.1564		0.6121	0.637		tp=0.37, tn=0.22, fp=0.26, fn=0.16		False
	45	0.6791		0.6739		0.1174		0.1236		0.6005	0.6531		tp=0.41, tn=0.15, fp=0.33, fn=0.11		False
	46	0.6755		0.6873		0.1363		0.1002		0.6108	0.5177		tp=0.24, tn=0.3, fp=0.18, fn=0.28		False
	47	0.6804		0.679		0.1118		0.1347		0.5923	0.6807		tp=0.46, tn=0.12, fp=0.35, fn=0.074		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		29
learning rate		0.000886268204849
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_91-lr0.00089-h_size29-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.7		0.6813		0.05283		0		0.4889	0.7232		tp=0.57, tn=0, fp=0.43, fn=0		False
	2	0.6967		0.6987		-0.01356		0.1067		0.3759	0.2857		tp=0.098, tn=0.41, fp=0.049, fn=0.44		True
	3	0.6924		0.6953		0.04222		0.1698		0.5747	0.431		tp=0.17, tn=0.36, fp=0.07, fn=0.39		True
	4	0.6892		0.6948		0.07554		0.1449		0.247	0.3894		tp=0.15, tn=0.36, fp=0.063, fn=0.42		False
	5	0.6891		0.6856		0.04761		0.1821		0.574	0.4483		tp=0.18, tn=0.38, fp=0.076, fn=0.37		True
	6	0.6914		0.684		0.04397		0.002557		0.2535	0.5359		tp=0.29, tn=0.22, fp=0.26, fn=0.24		False
	7	0.6911		0.6882		0.06746		0.1731		0.4944	0.3725		tp=0.13, tn=0.42, fp=0.056, fn=0.39		False
	8	0.6877		0.6843		0.01632		0.2142		0.5159	0.4779		tp=0.19, tn=0.4, fp=0.084, fn=0.33		True
	9	0.6868		0.6912		0.09416		0.1736		0.3043	0.4386		tp=0.17, tn=0.38, fp=0.077, fn=0.37		False
	10	0.6866		0.692		0.07648		0.1302		0.5687	0.4237		tp=0.17, tn=0.35, fp=0.084, fn=0.39		False
	11	0.6852		0.6887		0.09193		0.2		0.3568	0.4324		tp=0.17, tn=0.39, fp=0.063, fn=0.38		False
	12	0.6842		0.6868		0.07526		-0.03974		0.3312	0.5909		tp=0.36, tn=0.13, fp=0.33, fn=0.17		False
	13	0.6844		0.6885		0.09522		0.2308		0.5515	0.4959		tp=0.21, tn=0.36, fp=0.07, fn=0.36		True
	14	0.6831		0.6912		0.1162		0.1401		0.3753	0.4839		tp=0.21, tn=0.34, fp=0.12, fn=0.33		False
	15	0.6844		0.6906		0.09701		0.02043		0.3815	0.5333		tp=0.28, tn=0.23, fp=0.22, fn=0.27		False
	16	0.6817		0.706		0.08607		0.1859		0.5757	0.3619		tp=0.13, tn=0.4, fp=0.042, fn=0.43		False
	17	0.686		0.6868		0.05911		0.07842		0.4293	0.5479		tp=0.28, tn=0.26, fp=0.21, fn=0.25		False
	18	0.6852		0.6942		0.1152		0.1749		0.3829	0.4538		tp=0.19, tn=0.36, fp=0.077, fn=0.38		False
	19	0.6816		0.6933		0.1187		0.1974		0.5631	0.4696		tp=0.19, tn=0.38, fp=0.084, fn=0.34		False
	20	0.6797		0.6867		0.1025		-0.04185		0.4602	0.5576		tp=0.32, tn=0.17, fp=0.29, fn=0.22		False
	21	0.6779		0.6884		0.139		0.1291		0.5863	0.4961		tp=0.22, tn=0.32, fp=0.13, fn=0.33		False
	22	0.6783		0.69		0.1292		0.2615		0.4157	0.4587		tp=0.17, tn=0.41, fp=0.049, fn=0.36		True
	23	0.6766		0.6927		0.1174		0.09982		0.505	0.5517		tp=0.28, tn=0.27, fp=0.18, fn=0.27		False
	24	0.6764		0.7019		0.1091		0.2497		0.5198	0.4364		tp=0.17, tn=0.4, fp=0.042, fn=0.39		False
	25	0.6766		0.6854		0.1538		-0.002644		0.5085	0.5833		tp=0.34, tn=0.17, fp=0.29, fn=0.2		False
	26	0.6754		0.6919		0.1323		-0.09422		0.5124	0.5217		tp=0.29, tn=0.17, fp=0.27, fn=0.27		False
	27	0.6737		0.6889		0.1355		-0.02644		0.5034	0.6732		tp=0.48, tn=0.049, fp=0.4, fn=0.07		False
	28	0.6821		0.7039		0.0975		0.149		0.5181	0.459		tp=0.2, tn=0.34, fp=0.091, fn=0.37		False
	29	0.6779		0.6931		0.09469		0.1471		0.5476	0.5401		tp=0.26, tn=0.3, fp=0.14, fn=0.3		False
	30	0.6729		0.6969		0.1494		0.1806		0.5849	0.4615		tp=0.19, tn=0.37, fp=0.084, fn=0.36		False
	31	0.672		0.6932		0.1366		-0.03721		0.4787	0.5765		tp=0.34, tn=0.15, fp=0.29, fn=0.21		False
	32	0.6753		0.6899		0.1182		0.008078		0.5298	0.6145		tp=0.38, tn=0.13, fp=0.34, fn=0.15		False
	33	0.6731		0.6981		0.1058		-0.03833		0.4571	0.6		tp=0.38, tn=0.12, fp=0.33, fn=0.17		False
	34	0.6859		0.6867		0.08482		-0.00332		0.4959	0.6952		tp=0.51, tn=0.042, fp=0.39, fn=0.056		False
	35	0.6884		0.6901		0.06694		-0.03738		0.5225	0.6196		tp=0.4, tn=0.11, fp=0.33, fn=0.16		False
	36	0.6703		0.7		0.1477		0.1163		0.5752	0.5075		tp=0.24, tn=0.3, fp=0.13, fn=0.33		False
	37	0.6689		0.7049		0.1646		0.1309		0.579	0.4628		tp=0.2, tn=0.35, fp=0.11, fn=0.34		False
	38	0.6687		0.7003		0.1567		0.1098		0.5144	0.5578		tp=0.29, tn=0.26, fp=0.16, fn=0.29		False
	39	0.6672		0.7108		0.1635		0.07416		0.5688	0.375		tp=0.15, tn=0.37, fp=0.097, fn=0.39		False
	40	0.6676		0.7029		0.1534		0.0804		0.5769	0.5109		tp=0.24, tn=0.29, fp=0.17, fn=0.3		False
	41	0.6663		0.7002		0.1814		-0.0102		0.4928	0.5882		tp=0.35, tn=0.16, fp=0.28, fn=0.21		False
	42	0.6651		0.7105		0.1375		0.01645		0.5912	0.4818		tp=0.23, tn=0.27, fp=0.2, fn=0.3		False
	43	0.6694		0.7154		0.1477		0.01769		0.5455	0.416		tp=0.18, tn=0.31, fp=0.14, fn=0.37		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		139
learning rate		0.0025229616842
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_92-lr0.0025-h_size139-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6904		0.6769		0.0915		0.1071		0.5562	0.5797		tp=0.31, tn=0.25, fp=0.23, fn=0.21		True
	2	0.6713		0.6747		0.1789		0.1351		0.6091	0.6019		tp=0.33, tn=0.24, fp=0.24, fn=0.19		True
	3	0.6659		0.6785		0.196		0.1043		0.6167	0.5368		tp=0.26, tn=0.29, fp=0.18, fn=0.27		False
	4	0.6607		0.678		0.195		0.1443		0.6189	0.5395		tp=0.25, tn=0.31, fp=0.16, fn=0.27		True
	5	0.6536		0.691		0.2404		0.1438		0.6319	0.6405		tp=0.38, tn=0.2, fp=0.27, fn=0.15		False
	6	0.6486		0.6814		0.25		0.1469		0.6444	0.5729		tp=0.29, tn=0.28, fp=0.19, fn=0.24		True
	7	0.6422		0.685		0.2535		0.1116		0.6429	0.6037		tp=0.34, tn=0.22, fp=0.25, fn=0.19		False
	8	0.6412		0.7111		0.2652		0.1233		0.647	0.6627		tp=0.43, tn=0.13, fp=0.36, fn=0.082		False
	9	0.64		0.6854		0.2645		0.142		0.6541	0.6121		tp=0.34, tn=0.24, fp=0.23, fn=0.19		False
	10	0.6355		0.6975		0.2718		0.1567		0.6474	0.5744		tp=0.29, tn=0.29, fp=0.18, fn=0.24		True
	11	0.634		0.6886		0.2765		0.1153		0.6521	0.6105		tp=0.34, tn=0.22, fp=0.26, fn=0.18		False
	12	0.6258		0.6959		0.2844		0.1451		0.6565	0.5662		tp=0.28, tn=0.29, fp=0.19, fn=0.23		False
	13	0.626		0.707		0.2717		0.1117		0.65	0.5469		tp=0.27, tn=0.28, fp=0.19, fn=0.25		False
	14	0.6241		0.6973		0.3062		0.08325		0.6579	0.5931		tp=0.33, tn=0.22, fp=0.25, fn=0.2		False
	15	0.6299		0.6818		0.2841		0.1155		0.6533	0.6444		tp=0.39, tn=0.17, fp=0.3, fn=0.13		False
	16	0.6229		0.7084		0.3031		0.1724		0.6636	0.4847		tp=0.2, tn=0.37, fp=0.11, fn=0.32		True
	17	0.6178		0.6985		0.2942		0.08908		0.6583	0.6349		tp=0.39, tn=0.16, fp=0.31, fn=0.14		False
	18	0.6188		0.7183		0.296		0.1651		0.6612	0.4732		tp=0.19, tn=0.38, fp=0.11, fn=0.32		False
	19	0.6107		0.7094		0.3327		0.09288		0.6723	0.5789		tp=0.31, tn=0.24, fp=0.23, fn=0.22		False
	20	0.6125		0.7113		0.3103		0.1146		0.6638	0.6627		tp=0.43, tn=0.13, fp=0.34, fn=0.097		False
	21	0.6178		0.7126		0.2949		0.09479		0.6557	0.6154		tp=0.36, tn=0.19, fp=0.29, fn=0.16		False
	22	0.61		0.6979		0.3152		0.1503		0.6716	0.5829		tp=0.3, tn=0.28, fp=0.19, fn=0.23		False
	23	0.6052		0.6937		0.3351		0.1456		0.6776	0.5793		tp=0.29, tn=0.28, fp=0.21, fn=0.22		False
	24	0.6052		0.6974		0.3208		0.1286		0.6701	0.6286		tp=0.37, tn=0.2, fp=0.28, fn=0.15		False
	25	0.601		0.7201		0.3357		0.1234		0.6748	0.6366		tp=0.38, tn=0.19, fp=0.28, fn=0.15		False
	26	0.5921		0.7379		0.35		0.1663		0.6855	0.4566		tp=0.18, tn=0.38, fp=0.097, fn=0.34		False
	27	0.5922		0.7155		0.3475		0.138		0.6818	0.6585		tp=0.41, tn=0.16, fp=0.32, fn=0.11		False
	28	0.5851		0.758		0.3605		0.08023		0.6871	0.4889		tp=0.23, tn=0.3, fp=0.16, fn=0.31		False
	29	0.5923		0.7024		0.3504		0.2352		0.6828	0.5738		tp=0.26, tn=0.34, fp=0.13, fn=0.27		True
	30	0.5789		0.7081		0.3847		0.1748		0.7011	0.5559		tp=0.26, tn=0.32, fp=0.16, fn=0.26		False
	31	0.5752		0.7208		0.396		0.152		0.7046	0.5966		tp=0.31, tn=0.26, fp=0.22, fn=0.21		False
	32	0.5735		0.7445		0.3942		0.0802		0.7037	0.6027		tp=0.35, tn=0.2, fp=0.28, fn=0.18		False
	33	0.5692		0.7276		0.4013		0.1192		0.7088	0.6174		tp=0.35, tn=0.21, fp=0.28, fn=0.16		False
	34	0.5657		0.7191		0.3942		0.1532		0.7045	0.6239		tp=0.35, tn=0.23, fp=0.25, fn=0.17		False
	35	0.5647		0.7266		0.396		0.1427		0.7093	0.614		tp=0.34, tn=0.24, fp=0.24, fn=0.19		False
	36	0.5624		0.7351		0.4126		0.1966		0.7105	0.5885		tp=0.29, tn=0.31, fp=0.16, fn=0.24		False
	37	0.5565		0.7424		0.4155		0.1258		0.7147	0.6105		tp=0.34, tn=0.22, fp=0.27, fn=0.16		False
	38	0.5473		0.7354		0.4328		0.1295		0.723	0.6061		tp=0.33, tn=0.24, fp=0.24, fn=0.19		False
	39	0.5535		0.7359		0.4267		0.1477		0.7197	0.5931		tp=0.31, tn=0.26, fp=0.2, fn=0.23		False
	40	0.5399		0.7505		0.4492		0.1461		0.7302	0.6172		tp=0.34, tn=0.24, fp=0.23, fn=0.19		False
	41	0.5318		0.7913		0.4634		0.1282		0.7371	0.4866		tp=0.21, tn=0.35, fp=0.14, fn=0.31		False
	42	0.5282		0.7121		0.4587		0.2033		0.7334	0.6623		tp=0.38, tn=0.22, fp=0.24, fn=0.15		False
	43	0.5329		0.7293		0.4492		0.1959		0.733	0.5849		tp=0.29, tn=0.31, fp=0.16, fn=0.25		False
	44	0.5251		0.7778		0.4676		0.1291		0.7369	0.4898		tp=0.21, tn=0.34, fp=0.13, fn=0.31		False
	45	0.5166		0.7612		0.4919		0.2085		0.7512	0.5974		tp=0.29, tn=0.31, fp=0.17, fn=0.23		False
	46	0.515		0.7678		0.4913		0.144		0.7479	0.5445		tp=0.26, tn=0.31, fp=0.16, fn=0.27		False
	47	0.5061		0.7628		0.487		0.1457		0.7494	0.6175		tp=0.34, tn=0.23, fp=0.23, fn=0.19		False
	48	0.5039		0.7913		0.4976		0.1554		0.7539	0.6653		tp=0.42, tn=0.17, fp=0.31, fn=0.11		False
	49	0.4917		0.8181		0.526		0.1488		0.7667	0.6436		tp=0.38, tn=0.19, fp=0.28, fn=0.14		False
	50	0.4959		0.7986		0.5208		0.1522		0.7662	0.6435		tp=0.38, tn=0.2, fp=0.27, fn=0.15		False


data			/scratch/asw462/data/levin
input size		300
hidden size		26
learning rate		0.000995238284685
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_93-lr0.001-h_size26-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5908		0.5998		0.02415		0		0.8398	0.8327		tp=0.71, tn=0, fp=0.29, fn=0		False
	2	0.5619		0.5884		0.1144		0.1714		0.8377	0.8319		tp=0.69, tn=0.028, fp=0.27, fn=0.014		True
	3	0.5474		0.6079		0.1768		0.1586		0.8469	0.817		tp=0.67, tn=0.028, fp=0.29, fn=0.014		False
	4	0.5354		0.5706		0.238		0.1995		0.8498	0.834		tp=0.68, tn=0.049, fp=0.24, fn=0.035		True
	5	0.5241		0.5627		0.2965		0.3449		0.8562	0.8584		tp=0.7, tn=0.07, fp=0.21, fn=0.021		True
	6	0.5137		0.5738		0.3342		0.264		0.859	0.8326		tp=0.68, tn=0.049, fp=0.26, fn=0.014		False
	7	0.5034		0.6093		0.3356		0.1429		0.8592	0.7596		tp=0.55, tn=0.098, fp=0.24, fn=0.11		False
	8	0.5005		0.5577		0.3437		0.2603		0.8606	0.8165		tp=0.62, tn=0.098, fp=0.2, fn=0.077		False
	9	0.4947		0.5723		0.3834		0.1902		0.8659	0.7963		tp=0.6, tn=0.091, fp=0.21, fn=0.098		False
	10	0.4863		0.5636		0.3626		0.251		0.8635	0.8282		tp=0.66, tn=0.07, fp=0.23, fn=0.042		False
	11	0.4622		0.5376		0.4459		0.3115		0.8762	0.8288		tp=0.64, tn=0.091, fp=0.22, fn=0.042		False
	12	0.4606		0.5698		0.4182		0.1871		0.8685	0.7982		tp=0.61, tn=0.084, fp=0.22, fn=0.084		False
	13	0.4557		0.565		0.4342		0.2109		0.8721	0.8178		tp=0.64, tn=0.07, fp=0.23, fn=0.056		False
	14	0.4519		0.5819		0.4273		0.2761		0.8715	0.7981		tp=0.58, tn=0.13, fp=0.17, fn=0.12		False
	15	0.4468		0.5472		0.4587		0.2449		0.8742	0.8198		tp=0.64, tn=0.084, fp=0.22, fn=0.063		False
	16	0.4219		0.5321		0.4934		0.2175		0.884	0.8214		tp=0.64, tn=0.077, fp=0.21, fn=0.07		False
	17	0.4197		0.5319		0.5101		0.2696		0.8869	0.8288		tp=0.64, tn=0.091, fp=0.2, fn=0.07		False
	18	0.4083		0.5455		0.528		0.2613		0.8871	0.8057		tp=0.59, tn=0.12, fp=0.16, fn=0.13		False
	19	0.4217		0.5322		0.4909		0.3446		0.8801	0.8416		tp=0.65, tn=0.1, fp=0.19, fn=0.056		False
	20	0.3953		0.5503		0.5378		0.3461		0.8906	0.8333		tp=0.63, tn=0.12, fp=0.18, fn=0.07		True
	21	0.3857		0.5595		0.5505		0.3575		0.8939	0.8213		tp=0.59, tn=0.15, fp=0.15, fn=0.1		True
	22	0.3733		0.5687		0.55		0.3448		0.8929	0.823		tp=0.6, tn=0.14, fp=0.15, fn=0.11		False
	23	0.3742		0.5043		0.5853		0.3376		0.8992	0.8416		tp=0.65, tn=0.11, fp=0.17, fn=0.076		False
	24	0.3677		0.5514		0.581		0.3121		0.8985	0.8364		tp=0.64, tn=0.1, fp=0.17, fn=0.077		False
	25	0.3607		0.5849		0.6108		0.3639		0.905	0.802		tp=0.55, tn=0.17, fp=0.13, fn=0.14		True
	26	0.3609		0.546		0.5839		0.406		0.8991	0.8451		tp=0.63, tn=0.14, fp=0.15, fn=0.077		True
	27	0.3492		0.5619		0.6202		0.3235		0.9075	0.8295		tp=0.63, tn=0.11, fp=0.19, fn=0.07		False
	28	0.3325		0.5687		0.6263		0.357		0.9088	0.8372		tp=0.63, tn=0.13, fp=0.16, fn=0.084		False
	29	0.335		0.6126		0.6462		0.4058		0.9129	0.8103		tp=0.55, tn=0.19, fp=0.11, fn=0.15		False
	30	0.3341		0.6033		0.6222		0.3314		0.9061	0.8263		tp=0.62, tn=0.13, fp=0.17, fn=0.091		False
	31	0.3267		0.6093		0.6321		0.3268		0.9093	0.8311		tp=0.64, tn=0.1, fp=0.2, fn=0.056		False
	32	0.3297		0.5852		0.6272		0.4359		0.9077	0.8462		tp=0.62, tn=0.16, fp=0.11, fn=0.11		True
	33	0.3211		0.6124		0.6643		0.342		0.9157	0.8263		tp=0.62, tn=0.13, fp=0.18, fn=0.077		False
	34	0.3102		0.6105		0.6609		0.3582		0.9142	0.8302		tp=0.62, tn=0.13, fp=0.17, fn=0.084		False
	35	0.3002		0.6411		0.674		0.2591		0.9186	0.8093		tp=0.61, tn=0.1, fp=0.2, fn=0.084		False
	36	0.3091		0.5514		0.6609		0.4694		0.914	0.8571		tp=0.63, tn=0.16, fp=0.13, fn=0.077		True
	37	0.3023		0.6303		0.6723		0.455		0.9151	0.8342		tp=0.58, tn=0.19, fp=0.11, fn=0.12		False
	38	0.2944		0.6056		0.6939		0.4136		0.9234	0.8421		tp=0.62, tn=0.15, fp=0.11, fn=0.12		False
	39	0.2837		0.6365		0.7153		0.461		0.9265	0.8416		tp=0.59, tn=0.18, fp=0.12, fn=0.1		False
	40	0.2918		0.6406		0.691		0.294		0.9211	0.8273		tp=0.64, tn=0.098, fp=0.2, fn=0.063		False
	41	0.3047		0.6416		0.6602		0.3134		0.9138	0.8208		tp=0.61, tn=0.13, fp=0.16, fn=0.1		False
	42	0.2986		0.6646		0.6626		0.2833		0.9145	0.8093		tp=0.61, tn=0.1, fp=0.22, fn=0.063		False
	43	0.2752		0.6486		0.704		0.4747		0.9244	0.8384		tp=0.58, tn=0.2, fp=0.11, fn=0.11		True
	44	0.2833		0.6715		0.6835		0.3189		0.9185	0.8364		tp=0.64, tn=0.1, fp=0.18, fn=0.07		False
	45	0.2902		0.6773		0.6918		0.3487		0.9203	0.8263		tp=0.62, tn=0.13, fp=0.19, fn=0.07		False
	46	0.2745		0.6647		0.7037		0.3756		0.9239	0.8341		tp=0.62, tn=0.14, fp=0.15, fn=0.091		False
	47	0.2705		0.6783		0.717		0.253		0.9276	0.8319		tp=0.66, tn=0.077, fp=0.21, fn=0.056		False
	48	0.2878		0.6718		0.6683		0.314		0.9166	0.8224		tp=0.62, tn=0.12, fp=0.18, fn=0.084		False
	49	0.2589		0.6965		0.7293		0.4815		0.9293	0.8367		tp=0.57, tn=0.2, fp=0.1, fn=0.12		True
	50	0.2622		0.6566		0.7246		0.3773		0.9277	0.8507		tp=0.66, tn=0.11, fp=0.17, fn=0.056		False
	51	0.2634		0.7393		0.7243		0.4325		0.9287	0.839		tp=0.6, tn=0.17, fp=0.13, fn=0.1		False
	52	0.2568		0.7035		0.7482		0.4142		0.9346	0.8259		tp=0.58, tn=0.17, fp=0.12, fn=0.13		False
	53	0.2494		0.7273		0.7453		0.369		0.9345	0.8213		tp=0.59, tn=0.15, fp=0.15, fn=0.1		False
	54	0.2444		0.6692		0.7257		0.521		0.9291	0.8543		tp=0.59, tn=0.2, fp=0.098, fn=0.1		True
	55	0.2469		0.6803		0.7556		0.4663		0.9357	0.8502		tp=0.62, tn=0.17, fp=0.14, fn=0.077		False
	56	0.2413		0.7024		0.7569		0.406		0.9362	0.8276		tp=0.59, tn=0.17, fp=0.12, fn=0.13		False
	57	0.2382		0.7361		0.7623		0.4292		0.9384	0.8223		tp=0.57, tn=0.19, fp=0.13, fn=0.12		False
	58	0.2379		0.7201		0.7633		0.4399		0.939	0.8531		tp=0.63, tn=0.15, fp=0.11, fn=0.1		False
	59	0.2437		0.7099		0.7498		0.4149		0.9353	0.8259		tp=0.58, tn=0.17, fp=0.13, fn=0.11		False
	60	0.235		0.7282		0.7562		0.4304		0.9363	0.8532		tp=0.65, tn=0.13, fp=0.18, fn=0.042		False
	61	0.232		0.7741		0.7685		0.3297		0.9396	0.8279		tp=0.62, tn=0.12, fp=0.18, fn=0.077		False
	62	0.245		0.7879		0.7552		0.4407		0.9368	0.8531		tp=0.63, tn=0.15, fp=0.12, fn=0.098		False
	63	0.234		0.7045		0.7547		0.4424		0.9357	0.8531		tp=0.63, tn=0.15, fp=0.13, fn=0.091		False
	64	0.2285		0.7522		0.789		0.4386		0.9431	0.8105		tp=0.54, tn=0.21, fp=0.1, fn=0.15		False
	65	0.2388		0.8007		0.7625		0.3702		0.9367	0.8372		tp=0.62, tn=0.13, fp=0.16, fn=0.083		False
	66	0.2208		0.7265		0.7908		0.4875		0.9454	0.8529		tp=0.61, tn=0.18, fp=0.11, fn=0.098		False
	67	0.2159		0.7309		0.7982		0.4529		0.9473	0.8431		tp=0.6, tn=0.17, fp=0.11, fn=0.11		False
	68	0.2135		0.8205		0.786		0.4018		0.9428	0.7826		tp=0.5, tn=0.22, fp=0.098, fn=0.18		False
	69	0.2192		0.8164		0.7902		0.3635		0.9446	0.8302		tp=0.62, tn=0.13, fp=0.17, fn=0.077		False
	70	0.2268		0.7929		0.7679		0.4606		0.9389	0.8416		tp=0.59, tn=0.18, fp=0.11, fn=0.11		False
	71	0.2467		0.6201		0.7475		0.4609		0.9339	0.8611		tp=0.65, tn=0.15, fp=0.15, fn=0.062		False
	72	0.2046		0.7827		0.7996		0.4679		0.9476	0.84		tp=0.59, tn=0.19, fp=0.11, fn=0.11		False
	73	0.2124		0.8581		0.7951		0.4367		0.9453	0.8205		tp=0.56, tn=0.2, fp=0.11, fn=0.13		False
	74	0.2205		0.7866		0.7764		0.4812		0.9414	0.8367		tp=0.57, tn=0.2, fp=0.11, fn=0.11		False
	75	0.2021		0.7925		0.7998		0.4424		0.9476	0.8531		tp=0.63, tn=0.15, fp=0.13, fn=0.091		False


data			/scratch/asw462/data/aj_all/
input size		300
hidden size		18
learning rate		0.00155853177603
encoding size		1034
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_94-lr0.0016-h_size18-dataaj_all-encCPU_sweep_1106235815_rnn_classifier_pooling_16-lr8e&05-h_size1034-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5794		0.5716		0.2054		0.2488		0.8214	0.8115		tp=0.63, tn=0.081, fp=0.24, fn=0.049		True
	2	0.5342		0.5475		0.3509		0.2729		0.8391	0.8191		tp=0.63, tn=0.087, fp=0.23, fn=0.05		True
	3	0.5058		0.5472		0.3749		0.2987		0.8406	0.8136		tp=0.6, tn=0.12, fp=0.19, fn=0.083		True
	4	0.4787		0.5449		0.4345		0.2788		0.8525	0.8241		tp=0.65, tn=0.074, fp=0.24, fn=0.033		False
	5	0.4445		0.5485		0.4838		0.3084		0.8628	0.8132		tp=0.6, tn=0.12, fp=0.2, fn=0.078		True
	6	0.427		0.5558		0.5247		0.289		0.8706	0.795		tp=0.57, tn=0.14, fp=0.18, fn=0.11		False
	7	0.4075		0.5511		0.5505		0.3105		0.8754	0.8148		tp=0.6, tn=0.12, fp=0.19, fn=0.083		True
	8	0.3791		0.5417		0.6031		0.305		0.888	0.815		tp=0.61, tn=0.11, fp=0.21, fn=0.067		False
	9	0.3515		0.5819		0.6392		0.3428		0.8975	0.8174		tp=0.6, tn=0.13, fp=0.19, fn=0.075		True
	10	0.3273		0.5722		0.6839		0.3624		0.9099	0.8076		tp=0.57, tn=0.17, fp=0.16, fn=0.11		True
	11	0.3182		0.6258		0.6841		0.3135		0.909	0.8259		tp=0.63, tn=0.1, fp=0.21, fn=0.055		False
	12	0.2875		0.624		0.7303		0.308		0.9219	0.8156		tp=0.61, tn=0.12, fp=0.19, fn=0.08		False
	13	0.2757		0.6108		0.7491		0.3581		0.9267	0.8234		tp=0.6, tn=0.14, fp=0.18, fn=0.077		False
	14	0.2525		0.5884		0.7745		0.3446		0.9341	0.814		tp=0.59, tn=0.15, fp=0.17, fn=0.096		False
	15	0.2272		0.6511		0.818		0.3673		0.9461	0.7978		tp=0.54, tn=0.18, fp=0.13, fn=0.14		True
	16	0.2284		0.63		0.8075		0.3588		0.9431	0.8197		tp=0.59, tn=0.15, fp=0.17, fn=0.095		False
	17	0.1948		0.7052		0.8581		0.3486		0.9575	0.8116		tp=0.58, tn=0.15, fp=0.17, fn=0.096		False
	18	0.1781		0.7214		0.8703		0.3657		0.9613	0.7815		tp=0.51, tn=0.2, fp=0.12, fn=0.17		False
	19	0.1712		0.715		0.8801		0.3462		0.964	0.7953		tp=0.55, tn=0.17, fp=0.15, fn=0.13		False
	20	0.1494		0.7896		0.91		0.3398		0.9728	0.773		tp=0.51, tn=0.19, fp=0.12, fn=0.17		False
	21	0.1409		0.7543		0.917		0.3462		0.9749	0.7691		tp=0.5, tn=0.2, fp=0.12, fn=0.18		False
	22	0.1309		0.7558		0.9231		0.392		0.9767	0.8074		tp=0.55, tn=0.18, fp=0.14, fn=0.12		True
	23	0.1173		0.8351		0.9348		0.3735		0.9803	0.8118		tp=0.57, tn=0.17, fp=0.15, fn=0.11		False
	24	0.112		0.8399		0.9393		0.3588		0.9815	0.808		tp=0.57, tn=0.16, fp=0.16, fn=0.11		False
	25	0.1018		0.8375		0.954		0.3877		0.986	0.8232		tp=0.59, tn=0.16, fp=0.16, fn=0.089		False
	26	0.09		0.8317		0.9645		0.37		0.9892	0.8085		tp=0.56, tn=0.17, fp=0.14, fn=0.12		False
	27	0.08338		0.8647		0.9671		0.3753		0.9899	0.826		tp=0.6, tn=0.15, fp=0.17, fn=0.083		False
	28	0.07972		0.8667		0.9693		0.3977		0.9906	0.819		tp=0.57, tn=0.17, fp=0.14, fn=0.12		True
	29	0.0745		0.9144		0.9728		0.3891		0.9916	0.8244		tp=0.59, tn=0.16, fp=0.16, fn=0.09		False
	30	0.06775		0.8865		0.9758		0.38		0.9926	0.818		tp=0.58, tn=0.16, fp=0.15, fn=0.11		False
	31	0.07109		0.9432		0.9723		0.3726		0.9915	0.806		tp=0.56, tn=0.17, fp=0.14, fn=0.12		False
	32	0.05704		0.9734		0.9831		0.3647		0.9948	0.8189		tp=0.59, tn=0.15, fp=0.17, fn=0.092		False
	33	0.06359		0.9946		0.9706		0.3615		0.991	0.7844		tp=0.52, tn=0.19, fp=0.13, fn=0.16		False
	34	0.05542		0.9383		0.9793		0.3841		0.9936	0.8128		tp=0.57, tn=0.17, fp=0.14, fn=0.12		False
	35	0.05165		1.008		0.9814		0.3722		0.9943	0.8081		tp=0.56, tn=0.17, fp=0.15, fn=0.12		False
	36	0.05127		1.019		0.9827		0.3929		0.9947	0.8244		tp=0.59, tn=0.16, fp=0.16, fn=0.092		False
	37	0.05152		1.056		0.9797		0.3642		0.9938	0.8004		tp=0.55, tn=0.18, fp=0.15, fn=0.12		False
	38	0.04734		1.029		0.9818		0.3823		0.9944	0.806		tp=0.55, tn=0.18, fp=0.14, fn=0.12		False
	39	0.04505		1.129		0.9848		0.3703		0.9954	0.8154		tp=0.58, tn=0.16, fp=0.16, fn=0.099		False
	40	0.04651		1.109		0.9805		0.36		0.994	0.8121		tp=0.58, tn=0.16, fp=0.16, fn=0.1		False
	41	0.05304		1.036		0.9762		0.3537		0.9927	0.7831		tp=0.52, tn=0.19, fp=0.13, fn=0.16		False
	42	0.04592		1.06		0.9831		0.3706		0.9948	0.8143		tp=0.57, tn=0.16, fp=0.15, fn=0.11		False
	43	0.03983		1.145		0.9849		0.365		0.9954	0.8186		tp=0.59, tn=0.15, fp=0.17, fn=0.095		False
	44	0.0447		1.122		0.9792		0.3678		0.9936	0.7956		tp=0.54, tn=0.18, fp=0.14, fn=0.13		False
	45	0.03938		1.097		0.9857		0.36		0.9956	0.8034		tp=0.56, tn=0.17, fp=0.15, fn=0.12		False
	46	0.042		1.142		0.9823		0.3379		0.9946	0.7979		tp=0.55, tn=0.16, fp=0.15, fn=0.13		False
	47	0.03642		1.145		0.9888		0.3666		0.9965	0.7939		tp=0.54, tn=0.19, fp=0.14, fn=0.14		False
	48	0.03497		1.16		0.9844		0.3585		0.9952	0.8038		tp=0.56, tn=0.17, fp=0.15, fn=0.12		False
	49	0.03434		1.214		0.9862		0.3745		0.9958	0.8183		tp=0.58, tn=0.16, fp=0.16, fn=0.096		False


data			/scratch/asw462/data/levin
input size		300
hidden size		100
learning rate		0.00328464577304
encoding size		313
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
experiment name		sweep_1116234245_aj_classifier_95-lr0.0033-h_size100-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_19-lr0.00029-h_size313-databnc_lm-num_layers1
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.594		0.5959		0.006022		0		0.8402	0.8197		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.558		0.5799		0.1503		0.3685		0.8445	0.8533		tp=0.67, tn=0.098, fp=0.19, fn=0.042		True
	3	0.566		0.5721		0.2255		0		0.8425	0.8374		tp=0.72, tn=0, fp=0.28, fn=0		False
	4	0.5305		0.6817		0.2578		0.1708		0.8493	0.6433		tp=0.38, tn=0.19, fp=0.1, fn=0.32		False
	5	0.4932		0.5725		0.3374		0.2302		0.8555	0.8297		tp=0.66, tn=0.063, fp=0.23, fn=0.042		False
	6	0.4645		0.62		0.3938		0.3339		0.8617	0.8224		tp=0.61, tn=0.12, fp=0.19, fn=0.076		False
	7	0.4433		0.5728		0.4763		0.2631		0.8755	0.8523		tp=0.71, tn=0.049, fp=0.22, fn=0.021		False
	8	0.429		0.636		0.5093		0.309		0.8809	0.8058		tp=0.58, tn=0.14, fp=0.16, fn=0.12		False
	9	0.3967		0.6666		0.5526		0.2923		0.8915	0.8095		tp=0.59, tn=0.13, fp=0.17, fn=0.1		False
	10	0.3836		0.6838		0.561		0.2587		0.8901	0.7822		tp=0.55, tn=0.14, fp=0.16, fn=0.15		False
	11	0.3732		0.7182		0.5673		0.2567		0.8919	0.7739		tp=0.54, tn=0.15, fp=0.15, fn=0.16		False
	12	0.3601		0.6766		0.595		0.2138		0.8976	0.7487		tp=0.51, tn=0.15, fp=0.15, fn=0.2		False
	13	0.3534		0.7476		0.5826		0.3063		0.8952	0.75		tp=0.48, tn=0.2, fp=0.13, fn=0.2		False
	14	0.325		0.771		0.6506		0.2088		0.9103	0.7396		tp=0.5, tn=0.15, fp=0.16, fn=0.19		False
	15	0.3547		0.8739		0.5969		0.05394		0.897	0.8264		tp=0.7, tn=0.007, fp=0.29, fn=0.007		False
	16	0.3285		0.8126		0.6367		0.4182		0.9078	0.8584		tp=0.67, tn=0.1, fp=0.19, fn=0.028		True
	17	0.3391		0.7202		0.5884		0.4389		0.8952	0.8597		tp=0.66, tn=0.12, fp=0.18, fn=0.035		True
	18	0.2788		0.7177		0.6891		0.382		0.9214	0.8571		tp=0.67, tn=0.1, fp=0.17, fn=0.049		False
	19	0.2664		0.8019		0.7229		0.1956		0.9279	0.6961		tp=0.44, tn=0.17, fp=0.13, fn=0.26		False
	20	0.2672		0.8692		0.7171		0.2008		0.9269	0.7513		tp=0.52, tn=0.14, fp=0.17, fn=0.17		False
	21	0.2301		0.8774		0.7862		0.294		0.9429	0.8273		tp=0.64, tn=0.098, fp=0.2, fn=0.063		False
	22	0.2082		0.8402		0.8096		0.2988		0.9499	0.8169		tp=0.61, tn=0.12, fp=0.18, fn=0.091		False
	23	0.1943		0.9752		0.8192		0.2542		0.9522	0.7653		tp=0.52, tn=0.15, fp=0.16, fn=0.16		False
	24	0.185		0.9762		0.8141		0.2107		0.9507	0.7104		tp=0.45, tn=0.17, fp=0.13, fn=0.24		False
	25	0.1769		1.005		0.8484		0.2506		0.9596	0.7761		tp=0.55, tn=0.14, fp=0.18, fn=0.13		False
	26	0.1533		1.001		0.8711		0.3211		0.9658	0.8208		tp=0.6, tn=0.13, fp=0.14, fn=0.12		False
	27	0.1376		1.016		0.891		0.3212		0.971	0.8208		tp=0.61, tn=0.13, fp=0.17, fn=0.091		False
	28	0.1275		0.9669		0.9078		0.405		0.9751	0.8584		tp=0.67, tn=0.1, fp=0.19, fn=0.035		False
	29	0.1248		1.104		0.9006		0.266		0.9733	0.7716		tp=0.53, tn=0.15, fp=0.15, fn=0.16		False
	30	0.1308		1.148		0.8939		0.4109		0.9713	0.8381		tp=0.62, tn=0.15, fp=0.17, fn=0.07		False
	31	0.09723		1.131		0.9399		0.3169		0.9837	0.8208		tp=0.61, tn=0.13, fp=0.17, fn=0.098		False
	32	0.08318		1.059		0.9561		0.3223		0.988	0.8208		tp=0.6, tn=0.13, fp=0.15, fn=0.12		False
	33	0.08478		0.9849		0.9455		0.41		0.9851	0.835		tp=0.6, tn=0.16, fp=0.12, fn=0.12		False
	34	0.07538		1.036		0.9665		0.4202		0.9909	0.8333		tp=0.59, tn=0.17, fp=0.13, fn=0.1		False
	35	0.06581		1.093		0.9683		0.3727		0.9913	0.8411		tp=0.63, tn=0.13, fp=0.14, fn=0.098		False
	36	0.0604		1.233		0.9702		0.2711		0.9918	0.7961		tp=0.57, tn=0.13, fp=0.15, fn=0.15		False
	37	0.06687		1.294		0.9681		0.3783		0.9914	0.8426		tp=0.64, tn=0.13, fp=0.17, fn=0.07		False
	38	0.05271		1.275		0.9718		0.4099		0.9923	0.8505		tp=0.64, tn=0.14, fp=0.13, fn=0.091		False


data			/scratch/asw462/data/levin
input size		300
hidden size		22
learning rate		0.00120426426566
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_96-lr0.0012-h_size22-datalevin-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.5879		0.6024		0		0		0.8408	0.8182		tp=0.69, tn=0, fp=0.31, fn=0		False
	2	0.569		0.5863		0		0		0.843	0.8293		tp=0.71, tn=0, fp=0.29, fn=0		False
	3	0.5681		0.5804		0.1251		0.05845		0.8436	0.8361		tp=0.71, tn=0.007, fp=0.27, fn=0.007		True
	4	0.5565		0.5807		0.1624		0.2121		0.8475	0.8382		tp=0.7, tn=0.028, fp=0.26, fn=0.0069		True
	5	0.5533		0.5947		0.1658		0.1296		0.845	0.817		tp=0.67, tn=0.028, fp=0.28, fn=0.021		False
	6	0.5489		0.589		0.2108		0.1287		0.8482	0.8299		tp=0.69, tn=0.021, fp=0.27, fn=0.014		False
	7	0.5381		0.5745		0.2198		0.1765		0.8498	0.8382		tp=0.7, tn=0.028, fp=0.26, fn=0.014		False
	8	0.536		0.5811		0.2209		0.1391		0.8508	0.8285		tp=0.69, tn=0.028, fp=0.26, fn=0.021		False
	9	0.5298		0.5793		0.2572		0.2168		0.8487	0.8194		tp=0.65, tn=0.063, fp=0.24, fn=0.042		True
	10	0.5241		0.5691		0.2639		0.1777		0.8494	0.843		tp=0.71, tn=0.021, fp=0.26, fn=0.007		False
	11	0.5126		0.5934		0.2653		0.06326		0.8539	0.8136		tp=0.67, tn=0.021, fp=0.28, fn=0.028		False
	12	0.51		0.5888		0.3002		0.251		0.8546	0.8282		tp=0.66, tn=0.07, fp=0.23, fn=0.042		True
	13	0.506		0.6275		0.3114		0.1199		0.8563	0.8299		tp=0.7, tn=0.014, fp=0.28, fn=0.007		False
	14	0.5009		0.6075		0.2941		0.1487		0.8511	0.8139		tp=0.66, tn=0.042, fp=0.27, fn=0.035		False
	15	0.5022		0.5913		0.3096		0.2699		0.856	0.8235		tp=0.64, tn=0.091, fp=0.21, fn=0.063		True
	16	0.4928		0.5662		0.3253		0.149		0.8521	0.8255		tp=0.68, tn=0.035, fp=0.26, fn=0.028		False
	17	0.4837		0.6042		0.352		0.1649		0.8585	0.8089		tp=0.64, tn=0.063, fp=0.24, fn=0.063		False
	18	0.4791		0.6054		0.3455		0.2165		0.8597	0.8297		tp=0.66, tn=0.063, fp=0.22, fn=0.049		False
	19	0.4718		0.6195		0.3519		0.1054		0.8605	0.8035		tp=0.64, tn=0.042, fp=0.27, fn=0.049		False
	20	0.4684		0.6111		0.3623		0.2095		0.8601	0.8246		tp=0.66, tn=0.063, fp=0.23, fn=0.049		False
	21	0.465		0.6423		0.3512		0.1427		0.8578	0.824		tp=0.67, tn=0.042, fp=0.24, fn=0.042		False
	22	0.464		0.6008		0.3777		0.2772		0.8635	0.8165		tp=0.62, tn=0.098, fp=0.22, fn=0.063		True
	23	0.4635		0.6154		0.3882		0.2102		0.8623	0.7925		tp=0.59, tn=0.1, fp=0.2, fn=0.11		False
	24	0.4553		0.6333		0.3723		0.2294		0.8602	0.8091		tp=0.62, tn=0.084, fp=0.23, fn=0.063		False
	25	0.4568		0.5769		0.4138		0.2043		0.8655	0.8297		tp=0.66, tn=0.063, fp=0.22, fn=0.056		False
	26	0.4441		0.6373		0.4058		0.1971		0.8656	0.8		tp=0.62, tn=0.077, fp=0.24, fn=0.063		False
	27	0.4471		0.613		0.4251		0.211		0.8689	0.8091		tp=0.62, tn=0.084, fp=0.22, fn=0.077		False
	28	0.4362		0.5896		0.4416		0.2013		0.8733	0.8348		tp=0.67, tn=0.063, fp=0.2, fn=0.063		False
	29	0.4391		0.6241		0.4396		0.137		0.8712	0.7573		tp=0.55, tn=0.1, fp=0.2, fn=0.15		False
	30	0.4359		0.657		0.4406		0.1925		0.87	0.8276		tp=0.67, tn=0.049, fp=0.24, fn=0.035		False
	31	0.431		0.6016		0.44		0.2701		0.8713	0.8267		tp=0.65, tn=0.077, fp=0.23, fn=0.042		False
	32	0.4248		0.6416		0.4352		0.1825		0.8715	0.783		tp=0.58, tn=0.098, fp=0.22, fn=0.1		False
	33	0.423		0.6161		0.4718		0.1313		0.8751	0.8225		tp=0.66, tn=0.049, fp=0.22, fn=0.063		False
	34	0.4232		0.6416		0.4736		0.2038		0.8752	0.8125		tp=0.64, tn=0.07, fp=0.24, fn=0.056		False
	35	0.4221		0.6101		0.4759		0.2234		0.8767	0.8246		tp=0.66, tn=0.063, fp=0.24, fn=0.042		False
	36	0.4185		0.6491		0.4901		0.2009		0.8799	0.8261		tp=0.66, tn=0.056, fp=0.24, fn=0.042		False
	37	0.4145		0.6514		0.4766		0.2201		0.8762	0.8073		tp=0.62, tn=0.091, fp=0.21, fn=0.084		False
	38	0.4331		0.6659		0.4414		0.183		0.8679	0.8036		tp=0.63, tn=0.063, fp=0.26, fn=0.049		False
	39	0.4129		0.6187		0.5081		0.1681		0.8828	0.8326		tp=0.68, tn=0.049, fp=0.22, fn=0.049		False
	40	0.4069		0.6406		0.4941		0.1695		0.881	0.8		tp=0.62, tn=0.077, fp=0.22, fn=0.084		False
	41	0.4108		0.6331		0.4997		0.091		0.8789	0.8122		tp=0.65, tn=0.049, fp=0.22, fn=0.084		False
	42	0.4025		0.6645		0.5276		0.1431		0.8853	0.7633		tp=0.55, tn=0.1, fp=0.17, fn=0.17		False
	43	0.4048		0.6681		0.5083		0.1183		0.8816	0.7363		tp=0.52, tn=0.11, fp=0.22, fn=0.15		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		122
learning rate		9.13571557961e&05
encoding size		748
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
experiment name		sweep_1116234245_aj_classifier_97-lr9.1e&05-h_size122-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_14-lr0.00088-h_size748-datadiscriminator-num_layers3
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6935		0.6944		0		0.1519		0	0.268		tp=0.091, tn=0.41, fp=0.028, fn=0.47		True
	2	0.6912		0.6906		0.07856		0.176		0.3376	0.4324		tp=0.17, tn=0.39, fp=0.077, fn=0.36		True
	3	0.691		0.6919		0.05679		0.1455		0.3277	0.3495		tp=0.13, tn=0.41, fp=0.056, fn=0.41		False
	4	0.6904		0.688		0.07226		0.1664		0.3883	0.4667		tp=0.2, tn=0.36, fp=0.091, fn=0.36		False
	5	0.6901		0.6926		0.06056		0.1784		0.3256	0.3495		tp=0.13, tn=0.41, fp=0.042, fn=0.43		True
	6	0.6899		0.6872		0.04912		0.1217		0.3586	0.459		tp=0.2, tn=0.34, fp=0.11, fn=0.35		False
	7	0.6891		0.6933		0.05889		0.1647		0.4015	0.4211		tp=0.17, tn=0.37, fp=0.07, fn=0.39		False
	8	0.6889		0.6925		0.08259		0.1903		0.296	0.4348		tp=0.17, tn=0.37, fp=0.063, fn=0.39		True
	9	0.6881		0.6913		0.07152		0.1383		0.3305	0.4274		tp=0.17, tn=0.36, fp=0.084, fn=0.38		False
	10	0.688		0.6903		0.05572		0.1464		0.3774	0.431		tp=0.17, tn=0.36, fp=0.084, fn=0.38		False
	11	0.6891		0.6927		0.08254		0.1869		0.3355	0.4182		tp=0.16, tn=0.39, fp=0.063, fn=0.38		False
	12	0.6872		0.687		0.09293		0.1217		0.3881	0.459		tp=0.2, tn=0.34, fp=0.11, fn=0.35		False
	13	0.6883		0.686		0.06585		0.1494		0.537	0.4706		tp=0.2, tn=0.36, fp=0.11, fn=0.33		False
	14	0.6871		0.6896		0.07856		0.2014		0.3376	0.4112		tp=0.15, tn=0.41, fp=0.056, fn=0.38		True
	15	0.6872		0.6894		0.08254		0.1853		0.3355	0.4386		tp=0.17, tn=0.38, fp=0.07, fn=0.38		False
	16	0.6873		0.6819		0.1038		0.1557		0.4299	0.4839		tp=0.21, tn=0.34, fp=0.1, fn=0.34		False
	17	0.6893		0.695		0.08333		0.1673		0.3269	0.3774		tp=0.14, tn=0.4, fp=0.056, fn=0.41		False
	18	0.6865		0.6838		0.06589		0.1557		0.3748	0.4839		tp=0.21, tn=0.34, fp=0.1, fn=0.34		False
	19	0.6865		0.6887		0.1152		0.1492		0.4596	0.4248		tp=0.17, tn=0.38, fp=0.084, fn=0.37		False
	20	0.6858		0.6882		0.08306		0.2076		0.3298	0.422		tp=0.16, tn=0.4, fp=0.056, fn=0.38		True
	21	0.6868		0.6922		0.08442		0.1736		0.358	0.4386		tp=0.17, tn=0.38, fp=0.077, fn=0.37		False
	22	0.685		0.6831		0.08507		0.2059		0.35	0.4561		tp=0.18, tn=0.38, fp=0.07, fn=0.36		False
	23	0.6875		0.6879		0.1189		0.1639		0.5794	0.4538		tp=0.19, tn=0.36, fp=0.084, fn=0.37		False
	24	0.6886		0.6949		0.04692		0.1519		0.2838	0.3529		tp=0.13, tn=0.41, fp=0.056, fn=0.41		False
	25	0.6855		0.6826		0.07537		0.2332		0.3962	0.4957		tp=0.2, tn=0.38, fp=0.077, fn=0.34		True
	26	0.6844		0.6869		0.08249		0.2008		0.3882	0.4464		tp=0.17, tn=0.39, fp=0.07, fn=0.36		False
	27	0.6844		0.6898		0.1181		0.1815		0.3621	0.4425		tp=0.17, tn=0.38, fp=0.077, fn=0.36		False
	28	0.6843		0.6877		0.06929		0.1722		0.3755	0.4576		tp=0.19, tn=0.36, fp=0.084, fn=0.36		False
	29	0.6835		0.6891		0.07944		0.1815		0.3802	0.4425		tp=0.17, tn=0.38, fp=0.077, fn=0.36		False
	30	0.6837		0.6957		0.09218		0.1723		0.3542	0.4107		tp=0.16, tn=0.38, fp=0.063, fn=0.4		False
	31	0.6834		0.6903		0.08667		0.1526		0.3768	0.4211		tp=0.17, tn=0.37, fp=0.077, fn=0.38		False
	32	0.6838		0.6914		0.09369		0.1944		0.3783	0.4074		tp=0.15, tn=0.4, fp=0.056, fn=0.39		False
	33	0.6838		0.6896		0.09056		0.1799		0.3725	0.4286		tp=0.17, tn=0.38, fp=0.07, fn=0.38		False
	34	0.6829		0.6888		0.08403		0.1749		0.3633	0.4538		tp=0.19, tn=0.36, fp=0.077, fn=0.38		False
	35	0.6827		0.695		0.09329		0.1799		0.3832	0.4286		tp=0.17, tn=0.38, fp=0.07, fn=0.38		False
	36	0.6829		0.6929		0.08954		0.1667		0.3425	0.4144		tp=0.16, tn=0.38, fp=0.07, fn=0.38		False
	37	0.6826		0.6896		0.09692		0.1481		0.4367	0.4628		tp=0.2, tn=0.35, fp=0.098, fn=0.36		False
	38	0.6821		0.6906		0.1025		0.1926		0.4	0.4286		tp=0.17, tn=0.38, fp=0.063, fn=0.38		False
	39	0.682		0.6877		0.1071		0.2163		0.3888	0.4874		tp=0.2, tn=0.37, fp=0.077, fn=0.35		False
	40	0.6818		0.6905		0.0968		0.189		0.384	0.4655		tp=0.19, tn=0.38, fp=0.084, fn=0.35		False
	41	0.6813		0.6916		0.1079		0.1806		0.3813	0.4615		tp=0.19, tn=0.37, fp=0.084, fn=0.36		False
	42	0.6819		0.6879		0.09423		0.2354		0.4232	0.4915		tp=0.2, tn=0.38, fp=0.07, fn=0.35		True
	43	0.6813		0.6947		0.1006		0.1412		0.3475	0.4211		tp=0.17, tn=0.37, fp=0.084, fn=0.38		False
	44	0.6804		0.6852		0.1145		0.1889		0.3879	0.5079		tp=0.22, tn=0.34, fp=0.098, fn=0.34		False
	45	0.6811		0.6853		0.1517		0.07664		0.5833	0.5541		tp=0.29, tn=0.25, fp=0.22, fn=0.24		False
	46	0.683		0.7018		0.0853		0.1894		0.3473	0.3889		tp=0.15, tn=0.39, fp=0.049, fn=0.41		False
	47	0.6798		0.6889		0.1118		-0.01979		0.4664	0.529		tp=0.28, tn=0.21, fp=0.26, fn=0.25		False
	48	0.68		0.695		0.1175		0.1722		0.4845	0.4576		tp=0.19, tn=0.36, fp=0.084, fn=0.36		False
	49	0.6799		0.6874		0.1004		0.1934		0.4312	0.4746		tp=0.2, tn=0.37, fp=0.084, fn=0.35		False
	50	0.6794		0.6877		0.1347		0.1826		0.4286	0.4878		tp=0.21, tn=0.35, fp=0.091, fn=0.35		False
	51	0.6796		0.6898		0.1331		0.169		0.4142	0.48		tp=0.21, tn=0.34, fp=0.09, fn=0.36		False
	52	0.6796		0.6922		0.09828		0.05096		0.4107	0.4733		tp=0.22, tn=0.3, fp=0.17, fn=0.31		False
	53	0.6795		0.6917		0.09561		0.1552		0.5305	0.48		tp=0.21, tn=0.34, fp=0.098, fn=0.36		False
	54	0.6787		0.6974		0.1276		0.2549		0.4008	0.4957		tp=0.2, tn=0.38, fp=0.063, fn=0.35		True
	55	0.6791		0.6851		0.09967		0.1434		0.3921	0.5532		tp=0.27, tn=0.29, fp=0.15, fn=0.29		False
	56	0.6782		0.6906		0.1425		0.04905		0.5535	0.5036		tp=0.24, tn=0.27, fp=0.18, fn=0.3		False
	57	0.679		0.6974		0.1214		0.2333		0.3919	0.4505		tp=0.17, tn=0.4, fp=0.056, fn=0.37		False
	58	0.678		0.6861		0.1243		0.1098		0.4283	0.4844		tp=0.22, tn=0.32, fp=0.13, fn=0.33		False
	59	0.6782		0.6861		0.115		0.06908		0.417	0.5379		tp=0.27, tn=0.26, fp=0.2, fn=0.27		False
	60	0.6786		0.6883		0.1396		0.1381		0.5989	0.5571		tp=0.27, tn=0.29, fp=0.18, fn=0.25		False
	61	0.6767		0.6922		0.1433		0.2257		0.444	0.5		tp=0.22, tn=0.35, fp=0.07, fn=0.36		False
	62	0.677		0.696		0.1257		0.1557		0.3878	0.4839		tp=0.21, tn=0.34, fp=0.1, fn=0.34		False
	63	0.6777		0.686		0.1387		-0.04409		0.5386	0.5432		tp=0.31, tn=0.18, fp=0.26, fn=0.26		False
	64	0.6766		0.7002		0.1333		0.1647		0.4797	0.4211		tp=0.17, tn=0.37, fp=0.07, fn=0.39		False
	65	0.6784		0.6885		0.1009		0.05294		0.5263	0.5405		tp=0.28, tn=0.24, fp=0.2, fn=0.27		False
	66	0.6797		0.6932		0.09077		0.1125		0.3699	0.4553		tp=0.2, tn=0.34, fp=0.11, fn=0.36		False
	67	0.6764		0.6831		0.1395		0.129		0.5513	0.5714		tp=0.29, tn=0.27, fp=0.19, fn=0.25		False
	68	0.6759		0.6983		0.1762		0.119		0.5079	0.4923		tp=0.22, tn=0.31, fp=0.13, fn=0.34		False
	69	0.6762		0.6887		0.1353		0.09799		0.5132	0.4844		tp=0.22, tn=0.32, fp=0.15, fn=0.31		False
	70	0.6758		0.6908		0.1177		0.1098		0.4245	0.5324		tp=0.26, tn=0.29, fp=0.16, fn=0.29		False
	71	0.675		0.6886		0.1467		0.07736		0.5676	0.5479		tp=0.28, tn=0.26, fp=0.22, fn=0.24		False
	72	0.6746		0.694		0.1326		0.09621		0.4957	0.5147		tp=0.24, tn=0.29, fp=0.16, fn=0.3		False
	73	0.6751		0.6954		0.1206		0.1155		0.5201	0.5113		tp=0.24, tn=0.31, fp=0.15, fn=0.31		False
	74	0.6746		0.6973		0.1423		0.1404		0.4895	0.5113		tp=0.24, tn=0.31, fp=0.12, fn=0.34		False
	75	0.6747		0.6935		0.1544		0.03833		0.561	0.5306		tp=0.27, tn=0.24, fp=0.21, fn=0.27		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		182
learning rate		0.000222825029123
encoding size		689
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
experiment name		sweep_1116234245_aj_classifier_98-lr0.00022-h_size182-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_17-lr0.00015-h_size689-datadiscriminator-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6509		0.6222		0.2639		0.2911		0.6733	0.7051		tp=0.42, tn=0.22, fp=0.25, fn=0.11		True
	2	0.6343		0.6348		0.3004		0.3521		0.682	0.6614		tp=0.32, tn=0.35, fp=0.12, fn=0.21		True
	3	0.6253		0.6151		0.3198		0.3798		0.693	0.7042		tp=0.37, tn=0.32, fp=0.16, fn=0.15		True
	4	0.6188		0.6258		0.3254		0.3156		0.6919	0.6494		tp=0.32, tn=0.34, fp=0.14, fn=0.21		False
	5	0.6136		0.6181		0.3438		0.3011		0.6995	0.6991		tp=0.4, tn=0.25, fp=0.23, fn=0.12		False
	6	0.6035		0.6294		0.3559		0.3139		0.7067	0.644		tp=0.31, tn=0.34, fp=0.13, fn=0.22		False
	7	0.5985		0.6213		0.3684		0.3009		0.7093	0.6897		tp=0.38, tn=0.27, fp=0.19, fn=0.15		False
	8	0.5877		0.6156		0.3951		0.324		0.7228	0.6749		tp=0.35, tn=0.31, fp=0.16, fn=0.17		False
	9	0.5817		0.6234		0.3968		0.2697		0.7181	0.6928		tp=0.41, tn=0.23, fp=0.24, fn=0.13		False
	10	0.5767		0.6314		0.3995		0.306		0.7201	0.6531		tp=0.33, tn=0.32, fp=0.15, fn=0.2		False
	11	0.5722		0.6525		0.4138		0.3434		0.7276	0.6411		tp=0.3, tn=0.36, fp=0.11, fn=0.23		False
	12	0.5637		0.6325		0.4309		0.2663		0.7338	0.6434		tp=0.33, tn=0.3, fp=0.18, fn=0.19		False
	13	0.5596		0.6416		0.4321		0.316		0.7341	0.6512		tp=0.32, tn=0.33, fp=0.13, fn=0.21		False
	14	0.5565		0.6502		0.4281		0.2727		0.7298	0.6305		tp=0.31, tn=0.32, fp=0.15, fn=0.22		False
	15	0.5537		0.6266		0.4252		0.2519		0.7308	0.6636		tp=0.37, tn=0.26, fp=0.2, fn=0.17		False
	16	0.5473		0.6349		0.4458		0.2621		0.7385	0.6772		tp=0.38, tn=0.25, fp=0.23, fn=0.14		False
	17	0.5486		0.6449		0.4241		0.2827		0.73	0.6299		tp=0.31, tn=0.33, fp=0.15, fn=0.21		False
	18	0.5397		0.6455		0.4632		0.265		0.7478	0.6587		tp=0.35, tn=0.28, fp=0.19, fn=0.18		False
	19	0.5403		0.6483		0.442		0.2802		0.7388	0.6848		tp=0.39, tn=0.26, fp=0.21, fn=0.15		False
	20	0.5352		0.652		0.4481		0.2588		0.7388	0.6522		tp=0.35, tn=0.28, fp=0.19, fn=0.18		False
	21	0.5264		0.6695		0.4797		0.2627		0.7563	0.6292		tp=0.31, tn=0.31, fp=0.16, fn=0.21		False
	22	0.528		0.6546		0.4613		0.2629		0.746	0.6382		tp=0.33, tn=0.31, fp=0.17, fn=0.2		False
	23	0.5251		0.6753		0.4565		0.271		0.7435	0.6146		tp=0.29, tn=0.34, fp=0.15, fn=0.22		False
	24	0.5239		0.7215		0.4643		0.2766		0.7449	0.5869		tp=0.26, tn=0.36, fp=0.11, fn=0.26		False


data			/scratch/asw462/data/levin_balanced
input size		300
hidden size		24
learning rate		0.00195816833883
encoding size		1019
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
experiment name		sweep_1116234245_aj_classifier_99-lr0.002-h_size24-datalevin_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_15-lr0.0002-h_size1019-databnc_lm-num_layers2
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6888		0.6619		0.09985		0.2076		0.508	0.6784		tp=0.41, tn=0.21, fp=0.23, fn=0.15		True
	2	0.6267		0.6544		0.3393		0.2687		0.6544	0.6395		tp=0.33, tn=0.3, fp=0.14, fn=0.23		True
	3	0.5821		0.6233		0.4342		0.3136		0.6941	0.6918		tp=0.38, tn=0.28, fp=0.15, fn=0.19		True
	4	0.5327		0.6365		0.5372		0.2687		0.7516	0.6395		tp=0.33, tn=0.3, fp=0.14, fn=0.23		False
	5	0.4891		0.6408		0.5421		0.2932		0.7629	0.5736		tp=0.26, tn=0.36, fp=0.077, fn=0.31		False
	6	0.4415		0.6688		0.6184		0.3162		0.8024	0.5691		tp=0.24, tn=0.38, fp=0.07, fn=0.3		True
	7	0.4085		0.6371		0.6451		0.3255		0.8136	0.6621		tp=0.34, tn=0.32, fp=0.13, fn=0.22		True
	8	0.3651		0.6581		0.686		0.3948		0.8391	0.6763		tp=0.33, tn=0.36, fp=0.091, fn=0.22		True
	9	0.3594		0.6657		0.6774		0.4226		0.8308	0.7042		tp=0.35, tn=0.36, fp=0.1, fn=0.19		True
	10	0.3086		0.7123		0.7506		0.3452		0.8726	0.6712		tp=0.34, tn=0.32, fp=0.11, fn=0.22		False
	11	0.2625		0.739		0.8478		0.301		0.9202	0.6434		tp=0.32, tn=0.32, fp=0.13, fn=0.23		False
	12	0.2289		0.7357		0.8624		0.3863		0.928	0.6853		tp=0.34, tn=0.35, fp=0.11, fn=0.2		False
	13	0.2091		0.7791		0.8886		0.4137		0.9422	0.7308		tp=0.4, tn=0.31, fp=0.13, fn=0.16		False
	14	0.2075		0.8544		0.8562		0.3464		0.9261	0.7229		tp=0.42, tn=0.26, fp=0.2, fn=0.13		False
	15	0.185		0.8761		0.8767		0.363		0.9367	0.6714		tp=0.33, tn=0.35, fp=0.13, fn=0.2		False
	16	0.1537		0.9308		0.9266		0.3412		0.9624	0.6712		tp=0.34, tn=0.32, fp=0.12, fn=0.22		False
	17	0.1313		0.9663		0.9561		0.3887		0.9772	0.6986		tp=0.36, tn=0.34, fp=0.13, fn=0.18		False
	18	0.1265		1.058		0.9472		0.3399		0.9729	0.6471		tp=0.31, tn=0.36, fp=0.12, fn=0.22		False
	19	0.1176		1.003		0.9593		0.3963		0.9786	0.719		tp=0.38, tn=0.31, fp=0.14, fn=0.16		False
	20	0.0992		1.023		0.9736		0.3816		0.9864	0.6939		tp=0.36, tn=0.33, fp=0.11, fn=0.2		False
	21	0.09025		1.11		0.9795		0.3775		0.9895	0.698		tp=0.36, tn=0.33, fp=0.13, fn=0.18		False
	22	0.08941		1.145		0.9736		0.3798		0.9864	0.7179		tp=0.39, tn=0.3, fp=0.16, fn=0.15		False
	23	0.09239		1.181		0.9678		0.4231		0.9833	0.7355		tp=0.4, tn=0.31, fp=0.13, fn=0.15		True
	24	0.07512		1.282		0.9707		0.3712		0.9849	0.698		tp=0.36, tn=0.32, fp=0.14, fn=0.17		False
	25	0.06301		1.156		0.9912		0.376		0.9955	0.6897		tp=0.35, tn=0.34, fp=0.13, fn=0.19		False
	26	0.07011		1.382		0.9736		0.3447		0.9865	0.6757		tp=0.35, tn=0.31, fp=0.11, fn=0.22		False
	27	0.06021		1.353		0.9824		0.3679		0.9909	0.7097		tp=0.38, tn=0.3, fp=0.14, fn=0.17		False
	28	0.04553		1.436		0.9941		0.363		0.997	0.6849		tp=0.35, tn=0.33, fp=0.13, fn=0.2		False
	29	0.04657		1.401		0.9912		0.3594		0.9955	0.6933		tp=0.36, tn=0.31, fp=0.13, fn=0.19		False
	30	0.0427		1.429		0.9971		0.3973		0.9985	0.7152		tp=0.38, tn=0.32, fp=0.14, fn=0.16		False
	31	0.03807		1.372		0.9971		0.382		0.9985	0.7143		tp=0.38, tn=0.31, fp=0.14, fn=0.17		False
	32	0.03407		1.491		1		0.3795		1	0.7179		tp=0.39, tn=0.3, fp=0.15, fn=0.15		False
	33	0.0315		1.455		0.9971		0.3862		0.9985	0.7143		tp=0.38, tn=0.31, fp=0.15, fn=0.16		False
	34	0.03202		1.554		1		0.4346		1	0.7468		tp=0.41, tn=0.31, fp=0.13, fn=0.15		True
	35	0.02741		1.436		1		0.3999		1	0.7226		tp=0.39, tn=0.31, fp=0.12, fn=0.18		False
	36	0.02513		1.601		1		0.4044		1	0.7375		tp=0.41, tn=0.29, fp=0.15, fn=0.14		False
	37	0.02514		1.687		1		0.3741		1	0.702		tp=0.37, tn=0.31, fp=0.13, fn=0.19		False
	38	0.02507		1.632		1		0.3783		1	0.6939		tp=0.36, tn=0.33, fp=0.12, fn=0.2		False
	39	0.022		1.683		1		0.3676		1	0.7059		tp=0.38, tn=0.31, fp=0.15, fn=0.16		False
	40	0.0207		1.653		1		0.4156		1	0.72		tp=0.38, tn=0.33, fp=0.12, fn=0.17		False
	41	0.01959		1.812		1		0.3662		1	0.7097		tp=0.38, tn=0.3, fp=0.15, fn=0.16		False
	42	0.01918		1.804		1		0.3842		1	0.7067		tp=0.37, tn=0.32, fp=0.14, fn=0.17		False
	43	0.01848		1.828		1		0.3777		1	0.698		tp=0.36, tn=0.32, fp=0.12, fn=0.2		False
	44	0.01964		1.568		1		0.4355		1	0.7248		tp=0.38, tn=0.34, fp=0.11, fn=0.17		True
	45	0.02044		1.795		1		0.382		1	0.7143		tp=0.38, tn=0.31, fp=0.14, fn=0.17		False
	46	0.02006		1.817		1		0.4217		1	0.7389		tp=0.41, tn=0.31, fp=0.13, fn=0.15		False
	47	0.01612		1.867		1		0.3594		1	0.6933		tp=0.36, tn=0.31, fp=0.13, fn=0.19		False
	48	0.01797		1.667		1		0.4116		1	0.7273		tp=0.39, tn=0.31, fp=0.13, fn=0.17		False
	49	0.01809		1.823		0.9971		0.4217		0.9985	0.7389		tp=0.41, tn=0.31, fp=0.15, fn=0.13		False
	50	0.01289		2.003		1		0.3701		1	0.698		tp=0.36, tn=0.32, fp=0.15, fn=0.17		False
	51	0.01204		1.854		1		0.4231		1	0.7355		tp=0.4, tn=0.31, fp=0.13, fn=0.15		False
	52	0.01219		2		1		0.369		1	0.6892		tp=0.36, tn=0.32, fp=0.11, fn=0.21		False
	53	0.01186		1.867		1		0.4091		1	0.7273		tp=0.39, tn=0.31, fp=0.15, fn=0.15		False
	54	0.01165		1.939		1		0.3707		1	0.6939		tp=0.36, tn=0.33, fp=0.15, fn=0.17		False
	55	0.01098		2.103		1		0.3537		1	0.6667		tp=0.33, tn=0.34, fp=0.12, fn=0.21		False
	56	0.01383		2.114		1		0.4248		1	0.7285		tp=0.38, tn=0.33, fp=0.14, fn=0.15		False
	57	0.01198		2.096		1		0.3077		1	0.6222		tp=0.29, tn=0.35, fp=0.11, fn=0.24		False
	58	0.01096		2.14		1		0.3693		1	0.702		tp=0.37, tn=0.31, fp=0.15, fn=0.17		False
	59	0.009841		2.059		1		0.3608		1	0.6974		tp=0.37, tn=0.31, fp=0.13, fn=0.2		False
	60	0.01097		1.915		1		0.4362		1	0.7436		tp=0.41, tn=0.31, fp=0.13, fn=0.15		True
	61	0.01366		2.108		1		0.4128		1	0.7237		tp=0.38, tn=0.32, fp=0.13, fn=0.17		False
	62	0.01072		2.123		1		0.3768		1	0.702		tp=0.37, tn=0.31, fp=0.12, fn=0.2		False
	63	0.01151		2.259		1		0.3662		1	0.7097		tp=0.38, tn=0.3, fp=0.15, fn=0.16		False
	64	0.01284		2.048		1		0.4031		1	0.7114		tp=0.37, tn=0.33, fp=0.12, fn=0.18		False
	65	0.009757		2.263		1		0.3172		1	0.6528		tp=0.33, tn=0.32, fp=0.12, fn=0.23		False
	66	0.009117		2.18		1		0.408		1	0.7308		tp=0.4, tn=0.31, fp=0.14, fn=0.15		False
	67	0.00871		2.149		1		0.4325		1	0.75		tp=0.42, tn=0.3, fp=0.14, fn=0.14		False
	68	0.01008		2.213		1		0.3741		1	0.702		tp=0.37, tn=0.31, fp=0.13, fn=0.19		False
	69	0.01038		2.46		1		0.3133		1	0.6528		tp=0.33, tn=0.32, fp=0.13, fn=0.22		False
	70	0.01064		2.148		1		0.4359		1	0.7436		tp=0.41, tn=0.31, fp=0.14, fn=0.14		False
	71	0.01522		2.387		1		0.3214		1	0.7		tp=0.39, tn=0.27, fp=0.19, fn=0.15		False
	72	0.01202		2.458		1		0.3576		1	0.6713		tp=0.34, tn=0.34, fp=0.11, fn=0.22		False
	73	0.01131		2.312		1		0.3415		1	0.662		tp=0.33, tn=0.34, fp=0.12, fn=0.22		False
	74	0.008627		2.347		1		0.3795		1	0.7179		tp=0.39, tn=0.3, fp=0.15, fn=0.15		False
	75	0.007909		1.884		1		0.48		1	0.7582		tp=0.41, tn=0.34, fp=0.13, fn=0.13		True
	76	0.009156		2.471		1		0.4217		1	0.7389		tp=0.41, tn=0.31, fp=0.13, fn=0.15		False
	77	0.0105		2.284		1		0.3712		1	0.698		tp=0.36, tn=0.32, fp=0.14, fn=0.17		False
	78	0.009149		2.462		1		0.4477		1	0.7547		tp=0.42, tn=0.31, fp=0.13, fn=0.14		False
	79	0.0088		2.552		1		0.3344		1	0.6757		tp=0.35, tn=0.31, fp=0.13, fn=0.2		False
	80	0.007648		2.421		1		0.333		1	0.6475		tp=0.31, tn=0.34, fp=0.11, fn=0.23		False
	81	0.01035		2.539		1		0.4346		1	0.7468		tp=0.41, tn=0.31, fp=0.13, fn=0.15		False
	82	0.009559		2.599		1		0.2727		1	0.6294		tp=0.31, tn=0.31, fp=0.13, fn=0.24		False
	83	0.008076		2.534		1		0.4386		1	0.7368		tp=0.39, tn=0.33, fp=0.13, fn=0.15		False
	84	0.01033		2.552		1		0.4141		1	0.7273		tp=0.39, tn=0.32, fp=0.14, fn=0.15		False
	85	0.006849		2.461		1		0.4063		1	0.7342		tp=0.41, tn=0.3, fp=0.14, fn=0.15		False
	86	0.007966		2.68		1			0.3039		1	0.6277		tp=0.3, tn=0.34, fp=0.12, fn=0.24		False
	87	0.008939		2.571		1		0.4328		1	0.75		tp=0.42, tn=0.3, fp=0.15, fn=0.13		False
	88	0.006105		2.594		1		0.4231		1	0.7355		tp=0.4, tn=0.31, fp=0.13, fn=0.15		False
	89	0.01141		2.673		1		0.3005		1	0.6331		tp=0.31, tn=0.34, fp=0.13, fn=0.23		False
	90	0.01044		2.723		1		0.382		1	0.7143		tp=0.38, tn=0.31, fp=0.14, fn=0.17		False
	91	0.006122		2.717		1		0.3552		1	0.7013		tp=0.38, tn=0.3, fp=0.14, fn=0.18		False
	92	0.006802		2.638		1		0.4114		1	0.7342		tp=0.4, tn=0.31, fp=0.14, fn=0.15		False
	93	0.008664		2.783		1		0.3679		1	0.7097		tp=0.38, tn=0.3, fp=0.17, fn=0.14		False
	94	0.005757		2.691		1		0.322		1	0.6667		tp=0.34, tn=0.31, fp=0.13, fn=0.21		False
	95	0.00646		2.803		1		0.408		1	0.7308		tp=0.4, tn=0.31, fp=0.15, fn=0.14		False
	96	0.005937		2.544		1		0.4088		1	0.7308		tp=0.4, tn=0.31, fp=0.16, fn=0.13		False


data			/scratch/asw462/data/aj_balanced
input size		300
hidden size		66
learning rate		0.00235980165447
encoding size		231
encoder name		/scratch/asw462/models/CPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
experiment name		sweep_1116234245_aj_classifier_9-lr0.0024-h_size66-dataaj_balanced-encCPU_sweep_1106235815_rnn_classifier_pooling_4-lr0.00015-h_size231-databnc_lm-num_layers4
# batches | train avg loss | valid avg loss | t matthews | v matthews | t f1 | v f1 |      confusion      |model saved
----------|----------------|----------------|------------|------------|------|------|---------------------|-----------
	1	0.6868		0.6755		0.1051		0.1196		0.5808	0.6188		tp=0.35, tn=0.21, fp=0.26, fn=0.17		True
	2	0.6709		0.6719		0.1664		0.1358		0.6039	0.6439		tp=0.39, tn=0.19, fp=0.29, fn=0.14		True
	3	0.6663		0.6748		0.1853		0.1406		0.6087	0.5956		tp=0.32, tn=0.26, fp=0.22, fn=0.21		True
	4	0.6578		0.6762		0.2339		0.1166		0.6324	0.632		tp=0.37, tn=0.19, fp=0.28, fn=0.15		False
	5	0.6521		0.6905		0.2203		0.1277		0.6333	0.5581		tp=0.28, tn=0.28, fp=0.19, fn=0.25		False
	6	0.6523		0.6772		0.228		0.1413		0.6329	0.5625		tp=0.28, tn=0.29, fp=0.19, fn=0.24		True
	7	0.654		0.6848		0.2399		0.1601		0.6311	0.5714		tp=0.28, tn=0.29, fp=0.17, fn=0.25		True
	8	0.6452		0.6815		0.2466		0.1543		0.644	0.5823		tp=0.29, tn=0.28, fp=0.2, fn=0.22		False
	9	0.6387		0.7056		0.2666		0.1492		0.6515	0.6612		tp=0.41, tn=0.16, fp=0.31, fn=0.11		False
	10	0.6386		0.6856		0.2725		0.1403		0.6547	0.6196		tp=0.35, tn=0.23, fp=0.24, fn=0.18		False
	11	0.6335		0.7035		0.2738		0.1392		0.6498	0.5882		tp=0.31, tn=0.26, fp=0.21, fn=0.22		False
	12	0.6332		0.692		0.2733		0.1181		0.658	0.5825		tp=0.31, tn=0.25, fp=0.21, fn=0.23		False
	13	0.6283		0.7177		0.2992		0.1093		0.6617	0.6418		tp=0.4, tn=0.16, fp=0.32, fn=0.12		False
	14	0.625		0.7005		0.3038		0.1689		0.667	0.5352		tp=0.24, tn=0.34, fp=0.15, fn=0.28		True
	15	0.6299		0.7292		0.2735		0.1504		0.6467	0.4528		tp=0.18, tn=0.37, fp=0.1, fn=0.35		False
	16	0.6242		0.7101		0.2889		0.09065		0.6589	0.6223		tp=0.37, tn=0.18, fp=0.31, fn=0.15		False
	17	0.6229		0.7244		0.2943		0.0919		0.6571	0.6561		tp=0.43, tn=0.13, fp=0.34, fn=0.1		False
	18	0.6193		0.7196		0.3045		0.1138		0.6689	0.5851		tp=0.31, tn=0.25, fp=0.22, fn=0.22		False
	19	0.6209		0.7031		0.308		0.1086		0.6646	0.613		tp=0.35, tn=0.21, fp=0.28, fn=0.16		False
	20	0.6187		0.6912		0.3133		0.11		0.6691	0.6211		tp=0.36, tn=0.2, fp=0.27, fn=0.17		False
	21	0.6155		0.7107		0.3067		0.1644		0.6672	0.6143		tp=0.33, tn=0.25, fp=0.21, fn=0.2		False
	22	0.6073		0.7141		0.3286		0.1129		0.6732	0.6368		tp=0.38, tn=0.18, fp=0.28, fn=0.16		False
	23	0.6095		0.7129		0.3221		0.1389		0.6697	0.5564		tp=0.27, tn=0.3, fp=0.19, fn=0.25		False
	24	0.6104		0.6866		0.3151		0.2057		0.6699	0.6115		tp=0.31, tn=0.29, fp=0.18, fn=0.21		True
	25	0.6035		0.7192		0.3345		0.1632		0.6736	0.5514		tp=0.26, tn=0.31, fp=0.16, fn=0.27		False
	26	0.6045		0.7357		0.3398		0.1363		0.678	0.6653		tp=0.43, tn=0.14, fp=0.35, fn=0.087		False
	27	0.5995		0.7102		0.3423		0.1516		0.6832	0.5514		tp=0.26, tn=0.31, fp=0.18, fn=0.25		False
	28	0.595		0.7214		0.3447		0.1157		0.682	0.5924		tp=0.32, tn=0.24, fp=0.24, fn=0.2		False
	29	0.5944		0.7006		0.3416		0.1492		0.6823	0.6172		tp=0.34, tn=0.24, fp=0.24, fn=0.18		False
	30	0.5995		0.7504		0.3492		0.1137		0.6843	0.6693		tp=0.44, tn=0.12, fp=0.35, fn=0.09		False
	31	0.5907		0.7122		0.3487		0.09874		0.6822	0.5379		tp=0.26, tn=0.28, fp=0.19, fn=0.26		False
	32	0.5897		0.6941		0.3531		0.1271		0.6915	0.6115		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	33	0.5787		0.7197		0.3789		0.08728		0.696	0.6		tp=0.34, tn=0.21, fp=0.26, fn=0.19		False
	34	0.5839		0.7165		0.383		0.1832		0.7019	0.5485		tp=0.25, tn=0.33, fp=0.14, fn=0.28		False
	35	0.587		0.7021		0.3583		0.1422		0.6878	0.5995		tp=0.32, tn=0.25, fp=0.22, fn=0.21		False
	36	0.5761		0.7552		0.3851		0.1731		0.7062	0.5074		tp=0.22, tn=0.35, fp=0.12, fn=0.31		False
	37	0.5683		0.7522		0.3913		0.1893		0.7011	0.6888		tp=0.45, tn=0.14, fp=0.33, fn=0.077		False
	38	0.5736		0.7359		0.3914		0.09736		0.7067	0.5175		tp=0.24, tn=0.3, fp=0.17, fn=0.28		False
	39	0.5694		0.706		0.3983		0.1854		0.706	0.6112		tp=0.32, tn=0.27, fp=0.21, fn=0.19		False
	40	0.5575		0.7212		0.4155		0.1405		0.7152	0.6143		tp=0.34, tn=0.23, fp=0.25, fn=0.18		False
	41	0.5596		0.7329		0.4001		0.08166		0.7093	0.5822		tp=0.32, tn=0.23, fp=0.25, fn=0.21		False
	42	0.5519		0.7524		0.4299		0.161		0.7248	0.6433		tp=0.38, tn=0.21, fp=0.28, fn=0.14		False
	43	0.5531		0.7288		0.4244		0.1483		0.7175	0.5594		tp=0.27, tn=0.3, fp=0.19, fn=0.24		False
	44	0.5484		0.7475		0.435		0.1553		0.7243	0.6292		tp=0.36, tn=0.22, fp=0.27, fn=0.15		False
	45	0.5391		0.7373		0.4498		0.1495		0.733	0.6356		tp=0.37, tn=0.21, fp=0.25, fn=0.17		False